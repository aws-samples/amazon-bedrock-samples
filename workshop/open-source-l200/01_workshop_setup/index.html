<!doctype html><html lang=en class=no-js> <head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="Amazon Bedrock cookbook website"><meta name=author content=Bedrock-GTM><link href=https://github.amazon-bedrock-samples.com/workshop/open-source-l200/01_workshop_setup/ rel=canonical><link rel=icon href=../../../assets/favicon.png><meta name=generator content="mkdocs-1.6.1, mkdocs-material-9.5.49"><title>Retrieval Augmented Generation with Amazon Bedrock - Workshop Setup - Amazon Bedrock Recipes</title><link rel=stylesheet href=../../../assets/stylesheets/main.6f8fc17f.min.css><link rel=stylesheet href=../../../assets/stylesheets/palette.06af60db.min.css><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback"><style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style><script>__md_scope=new URL("../../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script></head> <body dir=ltr data-md-color-scheme=default data-md-color-primary=white data-md-color-accent=purple> <input class=md-toggle data-md-toggle=drawer type=checkbox id=__drawer autocomplete=off> <input class=md-toggle data-md-toggle=search type=checkbox id=__search autocomplete=off> <label class=md-overlay for=__drawer></label> <div data-md-component=skip> <a href=#retrieval-augmented-generation-with-amazon-bedrock-workshop-setup class=md-skip> Skip to content </a> </div> <div data-md-component=announce> </div> <header class="md-header md-header--shadow" data-md-component=header> <nav class="md-header__inner md-grid" aria-label=Header> <a href=../../.. title="Amazon Bedrock Recipes" class="md-header__button md-logo" aria-label="Amazon Bedrock Recipes" data-md-component=logo> <img src=../../../logo.png alt=logo> </a> <label class="md-header__button md-icon" for=__drawer> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg> </label> <div class=md-header__title data-md-component=header-title> <div class=md-header__ellipsis> <div class=md-header__topic> <span class=md-ellipsis> Amazon Bedrock Recipes </span> </div> <div class=md-header__topic data-md-component=header-topic> <span class=md-ellipsis> Retrieval Augmented Generation with Amazon Bedrock - Workshop Setup </span> </div> </div> </div> <form class=md-header__option data-md-component=palette> <input class=md-option data-md-color-media data-md-color-scheme=default data-md-color-primary=white data-md-color-accent=purple aria-hidden=true type=radio name=__palette id=__palette_0> </form> <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script> <label class="md-header__button md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg> </label> <div class=md-search data-md-component=search role=dialog> <label class=md-search__overlay for=__search></label> <div class=md-search__inner role=search> <form class=md-search__form name=search> <input type=text class=md-search__input name=query aria-label=Search placeholder=Search autocapitalize=off autocorrect=off autocomplete=off spellcheck=false data-md-component=search-query required> <label class="md-search__icon md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg> </label> <nav class=md-search__options aria-label=Search> <button type=reset class="md-search__icon md-icon" title=Clear aria-label=Clear tabindex=-1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg> </button> </nav> <div class=md-search__suggest data-md-component=search-suggest></div> </form> <div class=md-search__output> <div class=md-search__scrollwrap tabindex=0 data-md-scrollfix> <div class=md-search-result data-md-component=search-result> <div class=md-search-result__meta> Initializing search </div> <ol class=md-search-result__list role=presentation></ol> </div> </div> </div> </div> </div> <div class=md-header__source> <a href=https://github.com/aws-samples/amazon-bedrock-samples/tree/main title="Go to repository" class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 6.7.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81"/></svg> </div> <div class=md-source__repository> Github: Amazon-Bedrock-Samples </div> </a> </div> </nav> </header> <div class=md-container data-md-component=container> <main class=md-main data-md-component=main> <div class="md-main__inner md-grid"> <div class="md-sidebar md-sidebar--primary" data-md-component=sidebar data-md-type=navigation> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--primary md-nav--integrated" aria-label=Navigation data-md-level=0> <label class=md-nav__title for=__drawer> <a href=../../.. title="Amazon Bedrock Recipes" class="md-nav__button md-logo" aria-label="Amazon Bedrock Recipes" data-md-component=logo> <img src=../../../logo.png alt=logo> </a> Amazon Bedrock Recipes </label> <div class=md-nav__source> <a href=https://github.com/aws-samples/amazon-bedrock-samples/tree/main title="Go to repository" class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 6.7.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81"/></svg> </div> <div class=md-source__repository> Github: Amazon-Bedrock-Samples </div> </a> </div> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../.. class=md-nav__link> <span class=md-ellipsis> Home </span> </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2> <label class=md-nav__link for=__nav_2 id=__nav_2_label tabindex=0> <span class=md-ellipsis> Features </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_2_label aria-expanded=false> <label class=md-nav__title for=__nav_2> <span class="md-nav__icon md-icon"></span> Features </label> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2_1> <label class=md-nav__link for=__nav_2_1 id=__nav_2_1_label tabindex=0> <span class=md-ellipsis> Intro to Amazon Bedrock </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_2_1_label aria-expanded=false> <label class=md-nav__title for=__nav_2_1> <span class="md-nav__icon md-icon"></span> Intro to Amazon Bedrock </label> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2_1_1> <label class=md-nav__link for=__nav_2_1_1 id=__nav_2_1_1_label tabindex=0> <span class=md-ellipsis> API Usage </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=3 aria-labelledby=__nav_2_1_1_label aria-expanded=false> <label class=md-nav__title for=__nav_2_1_1> <span class="md-nav__icon md-icon"></span> API Usage </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../introduction-to-bedrock/bedrock_apis/01_invoke_api/ class=md-nav__link> <span class=md-ellipsis> Invoke Model API Example </span> </a> </li> <li class=md-nav__item> <a href=../../../introduction-to-bedrock/bedrock_apis/04_agents_api/ class=md-nav__link> <span class=md-ellipsis> Agents API Example </span> </a> </li> <li class=md-nav__item> <a href=../../../introduction-to-bedrock/bedrock_apis/03_knowledgebases_api/ class=md-nav__link> <span class=md-ellipsis> Knowledge Bases API Example </span> </a> </li> <li class=md-nav__item> <a href=../../../introduction-to-bedrock/bedrock_apis/02_guardrails_api/ class=md-nav__link> <span class=md-ellipsis> Guardrail API Example </span> </a> </li> <li class=md-nav__item> <a href=../../../introduction-to-bedrock/converse_api/01_converse_api/ class=md-nav__link> <span class=md-ellipsis> Converse API Example </span> </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2_2> <label class=md-nav__link for=__nav_2_2 id=__nav_2_2_label tabindex=0> <span class=md-ellipsis> Agents </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_2_2_label aria-expanded=false> <label class=md-nav__title for=__nav_2_2> <span class="md-nav__icon md-icon"></span> Agents </label> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2_2_1> <label class=md-nav__link for=__nav_2_2_1 id=__nav_2_2_1_label tabindex=0> <span class=md-ellipsis> Amazon Bedrock Agents </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=3 aria-labelledby=__nav_2_2_1_label aria-expanded=false> <label class=md-nav__title for=__nav_2_2_1> <span class="md-nav__icon md-icon"></span> Amazon Bedrock Agents </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../agents-and-function-calling/introduction-to-agents/how_to_create_custom_agents/ class=md-nav__link> <span class=md-ellipsis> How to create an Agent </span> </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2_2_1_2> <label class=md-nav__link for=__nav_2_2_1_2 id=__nav_2_2_1_2_label tabindex=0> <span class=md-ellipsis> Bedrock Agent Features </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=4 aria-labelledby=__nav_2_2_1_2_label aria-expanded=false> <label class=md-nav__title for=__nav_2_2_1_2> <span class="md-nav__icon md-icon"></span> Bedrock Agent Features </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../agents-and-function-calling/bedrock-agents/features-examples/01-create-agent-with-function-definition/01-create-agent-with-function-definition/ class=md-nav__link> <span class=md-ellipsis> Create Agent with Function Definition </span> </a> </li> <li class=md-nav__item> <a href=../../../agents-and-function-calling/bedrock-agents/features-examples/02-create-agent-with-api-schema/02-create-agent-with-api-schema/ class=md-nav__link> <span class=md-ellipsis> Create Agent with API Schema </span> </a> </li> <li class=md-nav__item> <a href=../../../agents-and-function-calling/bedrock-agents/features-examples/03-create-agent-with-return-of-control/03-create-agent-with-return-of-control/ class=md-nav__link> <span class=md-ellipsis> Create Agent with Return of Control </span> </a> </li> <li class=md-nav__item> <a href=../../../agents-and-function-calling/bedrock-agents/features-examples/04-create-agent-with-single-knowledge-base/04-create-agent-with-single-knowledge-base/ class=md-nav__link> <span class=md-ellipsis> Create Agent with Single Knowledge Base </span> </a> </li> <li class=md-nav__item> <a href=../../../agents-and-function-calling/bedrock-agents/features-examples/05-create-agent-with-knowledge-base-and-action-group/05-create-agent-with-knowledge-base-and-action-group/ class=md-nav__link> <span class=md-ellipsis> Create Agent with Knowledge Base and Action Group </span> </a> </li> <li class=md-nav__item> <a href=../../../agents-and-function-calling/bedrock-agents/features-examples/06-prompt-and-session-attributes/06-prompt-and-session-attributes/ class=md-nav__link> <span class=md-ellipsis> Prompt and Session Attributes </span> </a> </li> <li class=md-nav__item> <a href=../../../agents-and-function-calling/bedrock-agents/features-examples/07-advanced-prompts-and-custom-parsers/07-custom-prompt-and-lambda-parsers/ class=md-nav__link> <span class=md-ellipsis> Custom Prompt and Lambda Parsers </span> </a> </li> <li class=md-nav__item> <a href=../../../agents-and-function-calling/bedrock-agents/features-examples/08-create-agent-with-guardrails/08-create-agent-with-guardrails/ class=md-nav__link> <span class=md-ellipsis> Create Agent with Guardrails </span> </a> </li> <li class=md-nav__item> <a href=../../../agents-and-function-calling/bedrock-agents/features-examples/09-create-agent-with-memory/09-create-agent-with-memory/ class=md-nav__link> <span class=md-ellipsis> Create Agent with Memory </span> </a> </li> <li class=md-nav__item> <a href=../../../agents-and-function-calling/bedrock-agents/features-examples/10-create-agent-with-code-interpreter/10-create-agent-with-code-interpreter/ class=md-nav__link> <span class=md-ellipsis> Create Agent with Code Interpreter </span> </a> </li> <li class=md-nav__item> <a href=../../../agents-and-function-calling/bedrock-agents/features-examples/14-create-agent-with-custom-orchestration/custom_orchestration_example/ class=md-nav__link> <span class=md-ellipsis> Create Agent with Custom Orchestration </span> </a> </li> <li class=md-nav__item> <a href=../../../agents-and-function-calling/bedrock-agents/features-examples/15-invoke-inline-agents/inline-agent-api-usage/ class=md-nav__link> <span class=md-ellipsis> Create Dynamic Tooling Inline Agents </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2_2_1_3> <label class=md-nav__link for=__nav_2_2_1_3 id=__nav_2_2_1_3_label tabindex=0> <span class=md-ellipsis> Bedrock Flows </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=4 aria-labelledby=__nav_2_2_1_3_label aria-expanded=false> <label class=md-nav__title for=__nav_2_2_1_3> <span class="md-nav__icon md-icon"></span> Bedrock Flows </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../agents-and-function-calling/bedrock-agents/bedrock-flows/Getting_started_with_Prompt_Management_Flows/ class=md-nav__link> <span class=md-ellipsis> Getting Started with Prompt Management Flows </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2_2_1_4> <label class=md-nav__link for=__nav_2_2_1_4 id=__nav_2_2_1_4_label tabindex=0> <span class=md-ellipsis> Use Case Examples </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=4 aria-labelledby=__nav_2_2_1_4_label aria-expanded=false> <label class=md-nav__title for=__nav_2_2_1_4> <span class="md-nav__icon md-icon"></span> Use Case Examples </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../agents-and-function-calling/bedrock-agents/use-case-examples/text-2-sql-agent/create_and_invoke_sql_agent/ class=md-nav__link> <span class=md-ellipsis> Text to SQL Agent </span> </a> </li> <li class=md-nav__item> <a href=../../../agents-and-function-calling/bedrock-agents/use-case-examples/agentsforbedrock-retailagent/workshop/test_retailagent_agentsforbedrock/ class=md-nav__link> <span class=md-ellipsis> Retail Agent Workshop </span> </a> </li> <li class=md-nav__item> <a href=../../../agents-and-function-calling/bedrock-agents/use-case-examples/product-review-agent/main/ class=md-nav__link> <span class=md-ellipsis> Product Review Agent </span> </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2_2_2> <label class=md-nav__link for=__nav_2_2_2 id=__nav_2_2_2_label tabindex=0> <span class=md-ellipsis> Function Calling </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=3 aria-labelledby=__nav_2_2_2_label aria-expanded=false> <label class=md-nav__title for=__nav_2_2_2> <span class="md-nav__icon md-icon"></span> Function Calling </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../agents-and-function-calling/function-calling/function_calling_with_converse/function_calling_with_converse/ class=md-nav__link> <span class=md-ellipsis> Function Calling with Converse </span> </a> </li> <li class=md-nav__item> <a href=../../../agents-and-function-calling/function-calling/function_calling_with_invoke/function_calling_model_with_invoke/ class=md-nav__link> <span class=md-ellipsis> Function Calling with Invoke </span> </a> </li> <li class=md-nav__item> <a href=../../../agents-and-function-calling/function-calling/return_of_control/return_of_control/ class=md-nav__link> <span class=md-ellipsis> Return of Control </span> </a> </li> <li class=md-nav__item> <a href=../../../agents-and-function-calling/function-calling/tool_binding/tool_bindings/ class=md-nav__link> <span class=md-ellipsis> Tool Binding </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2_2_3> <label class=md-nav__link for=__nav_2_2_3 id=__nav_2_2_3_label tabindex=0> <span class=md-ellipsis> Open Source </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=3 aria-labelledby=__nav_2_2_3_label aria-expanded=false> <label class=md-nav__title for=__nav_2_2_3> <span class="md-nav__icon md-icon"></span> Open Source </label> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2_2_3_1> <label class=md-nav__link for=__nav_2_2_3_1 id=__nav_2_2_3_1_label tabindex=0> <span class=md-ellipsis> CrewAI </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=4 aria-labelledby=__nav_2_2_3_1_label aria-expanded=false> <label class=md-nav__title for=__nav_2_2_3_1> <span class="md-nav__icon md-icon"></span> CrewAI </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../agents-and-function-calling/open-source-agents/crew.ai/Find%20dream%20destination%20with%20CrewAI/ class=md-nav__link> <span class=md-ellipsis> Find Dream Destination with CrewAI </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2_2_3_2> <label class=md-nav__link for=__nav_2_2_3_2 id=__nav_2_2_3_2_label tabindex=0> <span class=md-ellipsis> LangGraph </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=4 aria-labelledby=__nav_2_2_3_2_label aria-expanded=false> <label class=md-nav__title for=__nav_2_2_3_2> <span class="md-nav__icon md-icon"></span> LangGraph </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../agents-and-function-calling/open-source-agents/langgraph/langgraph-single-agent/ class=md-nav__link> <span class=md-ellipsis> LangGraph Agent with Function Calling </span> </a> </li> <li class=md-nav__item> <a href=../../../agents-and-function-calling/open-source-agents/langgraph/langgraph-agents-multimodal/ class=md-nav__link> <span class=md-ellipsis> LangGraph Multi-Modal Agent with Function Calling </span> </a> </li> <li class=md-nav__item> <a href=../../../agents-and-function-calling/open-source-agents/langgraph/langgraph-multi-agent-sql-tools/ class=md-nav__link> <span class=md-ellipsis> LangGraph Multi Agent Orchestration </span> </a> </li> <li class=md-nav__item> <a href=../../../agents-and-function-calling/open-source-agents/langgraph/02_medibot_V3_agents/ class=md-nav__link> <span class=md-ellipsis> LangGraph Multi Agent For Medical Chatbot </span> </a> </li> <li class=md-nav__item> <a href=../../../agents-and-function-calling/open-source-agents/langgraph/langgraph-fact-checker-feedback-loop/ class=md-nav__link> <span class=md-ellipsis> LangGraph Fact Checker with Multi Agent </span> </a> </li> <li class=md-nav__item> <a href=../../../agents-and-function-calling/open-source-agents/langgraph/langgraph-multi-agent-sql-tools/ class=md-nav__link> <span class=md-ellipsis> LangGraph Multi Agent Orchestration </span> </a> </li> <li class=md-nav__item> <a href=../../../agents-and-function-calling/open-source-agents/langgraph/03_langgraph_agents_of_agent/ class=md-nav__link> <span class=md-ellipsis> LangGraph Multi Agent with tools </span> </a> </li> <li class=md-nav__item> <a href=../../../agents-and-function-calling/open-source-agents/langgraph/Travel_planner_with_langgraph/ class=md-nav__link> <span class=md-ellipsis> Managing Memory for Multi Agents </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2_2_3_3> <label class=md-nav__link for=__nav_2_2_3_3 id=__nav_2_2_3_3_label tabindex=0> <span class=md-ellipsis> Multi Agent </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=4 aria-labelledby=__nav_2_2_3_3_label aria-expanded=false> <label class=md-nav__title for=__nav_2_2_3_3> <span class="md-nav__icon md-icon"></span> Multi Agent </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../agents-and-function-calling/introduction-to-agents/how_to_create_multi_agents_from_custom_agents/ class=md-nav__link> <span class=md-ellipsis> Multi Agent Orchestration </span> </a> </li> </ul> </nav> </li> </ul> </nav> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2_3> <label class=md-nav__link for=__nav_2_3 id=__nav_2_3_label tabindex=0> <span class=md-ellipsis> RAG </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_2_3_label aria-expanded=false> <label class=md-nav__title for=__nav_2_3> <span class="md-nav__icon md-icon"></span> RAG </label> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2_3_1> <label class=md-nav__link for=__nav_2_3_1 id=__nav_2_3_1_label tabindex=0> <span class=md-ellipsis> Amazon Bedrock Knowledge Bases </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=3 aria-labelledby=__nav_2_3_1_label aria-expanded=false> <label class=md-nav__title for=__nav_2_3_1> <span class="md-nav__icon md-icon"></span> Amazon Bedrock Knowledge Bases </label> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2_3_1_1> <label class=md-nav__link for=__nav_2_3_1_1 id=__nav_2_3_1_1_label tabindex=0> <span class=md-ellipsis> Zero Setup </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=4 aria-labelledby=__nav_2_3_1_1_label aria-expanded=false> <label class=md-nav__title for=__nav_2_3_1_1> <span class="md-nav__icon md-icon"></span> Zero Setup </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../rag/knowledge-bases/features-examples/00-zero-setup-chat-with-your-document/chat_with_document_kb/ class=md-nav__link> <span class=md-ellipsis> Chat with Your Document </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2_3_1_2> <label class=md-nav__link for=__nav_2_3_1_2 id=__nav_2_3_1_2_label tabindex=0> <span class=md-ellipsis> RAG Concepts </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=4 aria-labelledby=__nav_2_3_1_2_label aria-expanded=false> <label class=md-nav__title for=__nav_2_3_1_2> <span class="md-nav__icon md-icon"></span> RAG Concepts </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../rag/knowledge-bases/features-examples/01-rag-concepts/01_create_ingest_documents_test_kb_multi_ds/ class=md-nav__link> <span class=md-ellipsis> Create and Ingest Documents with Multi-Data Sources </span> </a> </li> <li class=md-nav__item> <a href=../../../rag/knowledge-bases/features-examples/01-rag-concepts/02_managed_rag_custom_prompting_and_no_of_results/ class=md-nav__link> <span class=md-ellipsis> Managed RAG with Custom Prompting </span> </a> </li> <li class=md-nav__item> <a href=../../../rag/knowledge-bases/features-examples/01-rag-concepts/03_customized-rag-retreive-api-hybrid-search-claude-3-sonnet-langchain/ class=md-nav__link> <span class=md-ellipsis> Customized RAG with Claude 3 and Langchain </span> </a> </li> <li class=md-nav__item> <a href=../../../rag/knowledge-bases/features-examples/01-rag-concepts/04_customized-rag-retreive-api-langchain-claude-evaluation-ragas/ class=md-nav__link> <span class=md-ellipsis> RAG Evaluation with Langchain and RAGAS </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2_3_1_3> <label class=md-nav__link for=__nav_2_3_1_3 id=__nav_2_3_1_3_label tabindex=0> <span class=md-ellipsis> Optimizing Retrieval Results </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=4 aria-labelledby=__nav_2_3_1_3_label aria-expanded=false> <label class=md-nav__title for=__nav_2_3_1_3> <span class="md-nav__icon md-icon"></span> Optimizing Retrieval Results </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../rag/knowledge-bases/features-examples/02-optimizing-accuracy-retrieved-results/advanced_chunking_options/ class=md-nav__link> <span class=md-ellipsis> Advanced Chunking Options </span> </a> </li> <li class=md-nav__item> <a href=../../../rag/knowledge-bases/features-examples/02-optimizing-accuracy-retrieved-results/csv_metadata_customization/ class=md-nav__link> <span class=md-ellipsis> CSV Metadata Customization </span> </a> </li> <li class=md-nav__item> <a href=../../../rag/knowledge-bases/features-examples/02-optimizing-accuracy-retrieved-results/query_reformulation/ class=md-nav__link> <span class=md-ellipsis> Query Reformulation </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2_3_1_4> <label class=md-nav__link for=__nav_2_3_1_4 id=__nav_2_3_1_4_label tabindex=0> <span class=md-ellipsis> Advanced Concepts </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=4 aria-labelledby=__nav_2_3_1_4_label aria-expanded=false> <label class=md-nav__title for=__nav_2_3_1_4> <span class="md-nav__icon md-icon"></span> Advanced Concepts </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../rag/knowledge-bases/features-examples/03-advanced-concepts/dynamic-metadata-filtering/dynamic-metadata-filtering-KB/ class=md-nav__link> <span class=md-ellipsis> Dynamic Metadata Filtering </span> </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2_3_1_4_2> <label class=md-nav__link for=__nav_2_3_1_4_2 id=__nav_2_3_1_4_2_label tabindex=0> <span class=md-ellipsis> Reranking </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=5 aria-labelledby=__nav_2_3_1_4_2_label aria-expanded=false> <label class=md-nav__title for=__nav_2_3_1_4_2> <span class="md-nav__icon md-icon"></span> Reranking </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../rag/knowledge-bases/features-examples/03-advanced-concepts/reranking/01_deploy-reranking-model-sm/ class=md-nav__link> <span class=md-ellipsis> Deploy Reranking Model </span> </a> </li> <li class=md-nav__item> <a href=../../../rag/knowledge-bases/features-examples/03-advanced-concepts/reranking/02_kb-reranker/ class=md-nav__link> <span class=md-ellipsis> Knowledge Base Reranker </span> </a> </li> <li class=md-nav__item> <a href=../../../rag/knowledge-bases/features-examples/03-advanced-concepts/reranking/qa-generator/ class=md-nav__link> <span class=md-ellipsis> QA Generator </span> </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2_3_1_5> <label class=md-nav__link for=__nav_2_3_1_5 id=__nav_2_3_1_5_label tabindex=0> <span class=md-ellipsis> Responsible AI </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=4 aria-labelledby=__nav_2_3_1_5_label aria-expanded=false> <label class=md-nav__title for=__nav_2_3_1_5> <span class="md-nav__icon md-icon"></span> Responsible AI </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../rag/knowledge-bases/features-examples/05-responsible-ai/contextual-grounding/ class=md-nav__link> <span class=md-ellipsis> Contextual Grounding </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2_3_1_6> <label class=md-nav__link for=__nav_2_3_1_6 id=__nav_2_3_1_6_label tabindex=0> <span class=md-ellipsis> Use Case Examples </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=4 aria-labelledby=__nav_2_3_1_6_label aria-expanded=false> <label class=md-nav__title for=__nav_2_3_1_6> <span class="md-nav__icon md-icon"></span> Use Case Examples </label> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2_3_1_6_1> <label class=md-nav__link for=__nav_2_3_1_6_1 id=__nav_2_3_1_6_1_label tabindex=0> <span class=md-ellipsis> Metadata Filter Access Control </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=5 aria-labelledby=__nav_2_3_1_6_1_label aria-expanded=false> <label class=md-nav__title for=__nav_2_3_1_6_1> <span class="md-nav__icon md-icon"></span> Metadata Filter Access Control </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../rag/knowledge-bases/use-case-examples/metadata-filter-access-control/kb-end-to-end-acl/ class=md-nav__link> <span class=md-ellipsis> End-to-End ACL with Knowledge Base </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2_3_1_6_2> <label class=md-nav__link for=__nav_2_3_1_6_2 id=__nav_2_3_1_6_2_label tabindex=0> <span class=md-ellipsis> RAG with Structured and Unstructured Data </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=5 aria-labelledby=__nav_2_3_1_6_2_label aria-expanded=false> <label class=md-nav__title for=__nav_2_3_1_6_2> <span class="md-nav__icon md-icon"></span> RAG with Structured and Unstructured Data </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../rag/knowledge-bases/use-case-examples/rag-using-structured-unstructured-data/0-create-dummy-structured-data/ class=md-nav__link> <span class=md-ellipsis> Create Dummy Structured Data </span> </a> </li> <li class=md-nav__item> <a href=../../../rag/knowledge-bases/use-case-examples/rag-using-structured-unstructured-data/1_create_sql_dataset_optional/ class=md-nav__link> <span class=md-ellipsis> Create SQL Dataset (Optional) </span> </a> </li> <li class=md-nav__item> <a href=../../../rag/knowledge-bases/use-case-examples/rag-using-structured-unstructured-data/2_rag_with_structured_unstructured_data/ class=md-nav__link> <span class=md-ellipsis> RAG with Structured and Unstructured Data </span> </a> </li> </ul> </nav> </li> </ul> </nav> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2_3_2> <label class=md-nav__link for=__nav_2_3_2 id=__nav_2_3_2_label tabindex=0> <span class=md-ellipsis> Open Source </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=3 aria-labelledby=__nav_2_3_2_label aria-expanded=false> <label class=md-nav__title for=__nav_2_3_2> <span class="md-nav__icon md-icon"></span> Open Source </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../rag/open-source/chatbots/qa_chatbot_langchain_bedrock/ class=md-nav__link> <span class=md-ellipsis> Chatbot using Langchain </span> </a> </li> <li class=md-nav__item> <a href=../../../rag/open-source/chunking/rag_chunking_strategies_langchain_bedrock/ class=md-nav__link> <span class=md-ellipsis> Chunking strategies for RAG applications </span> </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2_3_2_3> <label class=md-nav__link for=__nav_2_3_2_3 id=__nav_2_3_2_3_label tabindex=0> <span class=md-ellipsis> Vector Stores </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=4 aria-labelledby=__nav_2_3_2_3_label aria-expanded=false> <label class=md-nav__title for=__nav_2_3_2_3> <span class="md-nav__icon md-icon"></span> Vector Stores </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../rag/open-source/vector_stores/rag_langchain_bedrock_opensearch/ class=md-nav__link> <span class=md-ellipsis> Langchain Chatbot with Opensearch </span> </a> </li> </ul> </nav> </li> </ul> </nav> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2_4> <label class=md-nav__link for=__nav_2_4 id=__nav_2_4_label tabindex=0> <span class=md-ellipsis> Model Customization </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_2_4_label aria-expanded=false> <label class=md-nav__title for=__nav_2_4> <span class="md-nav__icon md-icon"></span> Model Customization </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../custom-models/model-distillation/Historical_invocation_distillation/ class=md-nav__link> <span class=md-ellipsis> Model Distillation with Invocation Logs </span> </a> </li> <li class=md-nav__item> <a href=../../../custom-models/model-distillation/Distillation-via-S3-input/ class=md-nav__link> <span class=md-ellipsis> Model Distillation with S3 Data </span> </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_3> <label class=md-nav__link for=__nav_3 id=__nav_3_label tabindex=0> <span class=md-ellipsis> Gen AI Usecases </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_3_label aria-expanded=false> <label class=md-nav__title for=__nav_3> <span class="md-nav__icon md-icon"></span> Gen AI Usecases </label> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_3_1> <label class=md-nav__link for=__nav_3_1 id=__nav_3_1_label tabindex=0> <span class=md-ellipsis> Text Generation </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_3_1_label aria-expanded=false> <label class=md-nav__title for=__nav_3_1> <span class="md-nav__icon md-icon"></span> Text Generation </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../genai-use-cases/text-generation/how_to_work_with_text_generation_w_bedrock/ class=md-nav__link> <span class=md-ellipsis> Streaming Response with Converse </span> </a> </li> <li class=md-nav__item> <a href=../../../genai-use-cases/text-generation/how_to_work_with_code_generation_w_bedrock/ class=md-nav__link> <span class=md-ellipsis> Generate Python Code with Converse </span> </a> </li> <li class=md-nav__item> <a href=../../../genai-use-cases/text-generation/how_to_work_with_text_translation_w_bedrock/ class=md-nav__link> <span class=md-ellipsis> Text Translation with Converse </span> </a> </li> <li class=md-nav__item> <a href=../../../genai-use-cases/text-generation/how_to_work_with_text-summarization-titan%2Bclaude/ class=md-nav__link> <span class=md-ellipsis> Text summarization with Converse </span> </a> </li> <li class=md-nav__item> <a href=../../../genai-use-cases/text-generation/how_to_work_with_batch_example_for_multi_threaded_invocation/ class=md-nav__link> <span class=md-ellipsis> Generate Bulk Emails with Batch Inference </span> </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_4> <label class=md-nav__link for=__nav_4 id=__nav_4_label tabindex=0> <span class=md-ellipsis> Workshops </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_4_label aria-expanded=false> <label class=md-nav__title for=__nav_4> <span class="md-nav__icon md-icon"></span> Workshops </label> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_4_1> <label class=md-nav__link for=__nav_4_1 id=__nav_4_1_label tabindex=0> <span class=md-ellipsis> Open-source L400 </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_4_1_label aria-expanded=false> <label class=md-nav__title for=__nav_4_1> <span class="md-nav__icon md-icon"></span> Open-source L400 </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../open-source-l400/01_usecase_introduction/ class=md-nav__link> <span class=md-ellipsis> Introduction to the Use Case </span> </a> </li> <li class=md-nav__item> <a href=../../open-source-l400/02_Lab_Find%20a%20Dream%20Destination_RAG%20query/ class=md-nav__link> <span class=md-ellipsis> Advanced RAG for Agents </span> </a> </li> <li class=md-nav__item> <a href=../../open-source-l400/02_travel_planner_with_langgraph/ class=md-nav__link> <span class=md-ellipsis> Conversational Memory in Agents </span> </a> </li> <li class=md-nav__item> <a href=../../open-source-l400/03_travel_agent_with_tools/ class=md-nav__link> <span class=md-ellipsis> Multi-Modal and Types of Agents </span> </a> </li> <li class=md-nav__item> <a href=../../open-source-l400/04_travel_booking_multi_agent/ class=md-nav__link> <span class=md-ellipsis> Multi-Agent Collaboration with Human-in-loop </span> </a> </li> <li class=md-nav__item> <a href=../../open-source-l400/05_dream_destination_with_crewai/ class=md-nav__link> <span class=md-ellipsis> Find Dream Destination with CrewAI </span> </a> </li> <li class=md-nav__item> <a href=../../open-source-l400/06_agent_evaluation_with_ragas/ class=md-nav__link> <span class=md-ellipsis> RAGAs Agents Evaluation </span> </a> </li> <li class=md-nav__item> <a href=../../open-source-l400/07_dynamic_tooling_agents/ class=md-nav__link> <span class=md-ellipsis> Dynamic Tool invocation </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_4_2> <label class=md-nav__link for=__nav_4_2 id=__nav_4_2_label tabindex=0> <span class=md-ellipsis> Open-source L200 </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_4_2_label aria-expanded=false> <label class=md-nav__title for=__nav_4_2> <span class="md-nav__icon md-icon"></span> Open-source L200 </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../02_contextual_text_generation/ class=md-nav__link> <span class=md-ellipsis> Introduction to the Use Case </span> </a> </li> <li class=md-nav__item> <a href=../03_retrieval_based_text_application/ class=md-nav__link> <span class=md-ellipsis> Retrieval Based Text Generation </span> </a> </li> <li class=md-nav__item> <a href=../04_retrieval_based_chat_application/ class=md-nav__link> <span class=md-ellipsis> Retrieval Based Chat Application </span> </a> </li> <li class=md-nav__item> <a href=../05_agent_based_text_generation/ class=md-nav__link> <span class=md-ellipsis> Agent Based Text Generation </span> </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../../../general/tags/ class=md-nav__link> <span class=md-ellipsis> Tags </span> </a> </li> <li class=md-nav__item> <a href=../../../general/license/ class=md-nav__link> <span class=md-ellipsis> License </span> </a> </li> </ul> </nav> </div> </div> </div> <div class=md-content data-md-component=content> <article class="md-content__inner md-typeset"> <h1 id=retrieval-augmented-generation-with-amazon-bedrock-workshop-setup>Retrieval Augmented Generation with Amazon Bedrock - Workshop Setup</h1> <blockquote> <p><em>PLEASE NOTE: This notebook should work well with the </em><em><code>Data Science 3.0</code></em><em> kernel in SageMaker Studio</em></p> </blockquote> <hr> <p>In this notebook, we will set up the <a href=https://boto3.amazonaws.com/v1/documentation/api/latest/index.html><code>boto3</code> Python SDK</a> to work with <a href=https://aws.amazon.com/bedrock/ >Amazon Bedrock</a> Foundation Models as well as install extra dependencies needed for this workshop. Specifically, we will be using the following libraries throughout the workshop...</p> <ul> <li><a href=https://python.langchain.com/docs/get_started/introduction>LangChain</a> for large language model (LLM) utilities</li> <li><a href=https://github.com/facebookresearch/faiss>FAISS</a> for vector similarity searching</li> <li><a href=https://streamlit.io/ >Streamlit</a> for user interface (UI) building</li> </ul> <hr> <h2 id=install-external-dependencies>Install External Dependencies</h2> <p>The code below will install the rest of the Python packages required for the workshop.</p> <div class=highlight><pre><span></span><code><span class=o>%</span><span class=n>pip</span> <span class=n>install</span> <span class=o>--</span><span class=n>upgrade</span> <span class=n>pip</span>
<span class=o>%</span><span class=n>pip</span> <span class=n>install</span> <span class=o>--</span><span class=n>quiet</span> <span class=o>-</span><span class=n>r</span> <span class=o>../</span><span class=n>requirements</span><span class=o>.</span><span class=n>txt</span>
</code></pre></div> <pre><code>Defaulting to user installation because normal site-packages is not writeable
Requirement already satisfied: pip in /Users/sergncp/Library/Python/3.9/lib/python/site-packages (24.2)
Note: you may need to restart the kernel to use updated packages.
Note: you may need to restart the kernel to use updated packages.
</code></pre> <div class=highlight><pre><span></span><code><span class=ch>#!pip install boto3 --upgrade</span>
<span class=c1>#!pip install awscli --upgrade</span>
</code></pre></div> <hr> <h2 id=create-the-boto3-client-connection-to-amazon-bedrock>Create the <code>boto3</code> client connection to Amazon Bedrock</h2> <p>Interaction with the Bedrock API is done via the AWS SDK for Python: <a href=https://boto3.amazonaws.com/v1/documentation/api/latest/index.html>boto3</a>.</p> <p>As you are running this notebook from <a href=https://aws.amazon.com/sagemaker/studio/ >Amazon Sagemaker Studio</a> and your Sagemaker Studio <a href=https://docs.aws.amazon.com/sagemaker/latest/dg/sagemaker-roles.html>execution role</a> has permissions to access Bedrock you can just run the cells below as-is in order to create a connection to Amazon Bedrock. This is also the case if you are running these notebooks from a computer whose default AWS credentials have access to Bedrock.</p> <div class=highlight><pre><span></span><code><span class=kn>import</span> <span class=nn>boto3</span>
<span class=kn>import</span> <span class=nn>os</span>
<span class=kn>from</span> <span class=nn>IPython.display</span> <span class=kn>import</span> <span class=n>Markdown</span><span class=p>,</span> <span class=n>display</span>

<span class=n>region</span> <span class=o>=</span> <span class=n>os</span><span class=o>.</span><span class=n>environ</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=s2>&quot;AWS_REGION&quot;</span><span class=p>)</span>
<span class=n>bedrock_service</span> <span class=o>=</span> <span class=n>boto3</span><span class=o>.</span><span class=n>client</span><span class=p>(</span>
    <span class=n>service_name</span><span class=o>=</span><span class=s1>&#39;bedrock&#39;</span><span class=p>,</span>
    <span class=n>region_name</span><span class=o>=</span><span class=n>region</span><span class=p>,</span>
<span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=n>boto3</span><span class=o>.</span><span class=n>__version__</span><span class=p>)</span>
</code></pre></div> <pre><code>1.35.16
</code></pre> <h4 id=validate-the-connection>Validate the connection</h4> <p>We can check the client works by trying out the <code>list_foundation_models()</code> method, which will tell us all the models available for us to use </p> <div class=highlight><pre><span></span><code><span class=n>bedrock_service</span><span class=o>.</span><span class=n>list_foundation_models</span><span class=p>()</span>
</code></pre></div> <pre><code>{'ResponseMetadata': {'RequestId': '1eeb8bb1-1a68-45ae-9d6e-b8ebab32ee1d',
  'HTTPStatusCode': 200,
  'HTTPHeaders': {'date': 'Mon, 30 Sep 2024 21:21:58 GMT',
   'content-type': 'application/json',
   'content-length': '31450',
   'connection': 'keep-alive',
   'x-amzn-requestid': '1eeb8bb1-1a68-45ae-9d6e-b8ebab32ee1d'},
  'RetryAttempts': 0},
 'modelSummaries': [{'modelArn': 'arn:aws:bedrock:us-west-2::foundation-model/amazon.titan-tg1-large',
   'modelId': 'amazon.titan-tg1-large',
   'modelName': 'Titan Text Large',
   'providerName': 'Amazon',
   'inputModalities': ['TEXT'],
   'outputModalities': ['TEXT'],
   'responseStreamingSupported': True,
   'customizationsSupported': [],
   'inferenceTypesSupported': ['ON_DEMAND'],
   'modelLifecycle': {'status': 'ACTIVE'}},
  {'modelArn': 'arn:aws:bedrock:us-west-2::foundation-model/amazon.titan-embed-g1-text-02',
   'modelId': 'amazon.titan-embed-g1-text-02',
   'modelName': 'Titan Text Embeddings v2',
   'providerName': 'Amazon',
   'inputModalities': ['TEXT'],
   'outputModalities': ['EMBEDDING'],
   'customizationsSupported': [],
   'inferenceTypesSupported': ['ON_DEMAND'],
   'modelLifecycle': {'status': 'ACTIVE'}},
  {'modelArn': 'arn:aws:bedrock:us-west-2::foundation-model/amazon.titan-text-lite-v1:0:4k',
   'modelId': 'amazon.titan-text-lite-v1:0:4k',
   'modelName': 'Titan Text G1 - Lite',
   'providerName': 'Amazon',
   'inputModalities': ['TEXT'],
   'outputModalities': ['TEXT'],
   'responseStreamingSupported': True,
   'customizationsSupported': ['FINE_TUNING', 'CONTINUED_PRE_TRAINING'],
   'inferenceTypesSupported': ['PROVISIONED'],
   'modelLifecycle': {'status': 'ACTIVE'}},
  {'modelArn': 'arn:aws:bedrock:us-west-2::foundation-model/amazon.titan-text-lite-v1',
   'modelId': 'amazon.titan-text-lite-v1',
   'modelName': 'Titan Text G1 - Lite',
   'providerName': 'Amazon',
   'inputModalities': ['TEXT'],
   'outputModalities': ['TEXT'],
   'responseStreamingSupported': True,
   'customizationsSupported': [],
   'inferenceTypesSupported': ['ON_DEMAND'],
   'modelLifecycle': {'status': 'ACTIVE'}},
  {'modelArn': 'arn:aws:bedrock:us-west-2::foundation-model/amazon.titan-text-express-v1:0:8k',
   'modelId': 'amazon.titan-text-express-v1:0:8k',
   'modelName': 'Titan Text G1 - Express',
   'providerName': 'Amazon',
   'inputModalities': ['TEXT'],
   'outputModalities': ['TEXT'],
   'responseStreamingSupported': True,
   'customizationsSupported': ['FINE_TUNING', 'CONTINUED_PRE_TRAINING'],
   'inferenceTypesSupported': ['PROVISIONED'],
   'modelLifecycle': {'status': 'ACTIVE'}},
  {'modelArn': 'arn:aws:bedrock:us-west-2::foundation-model/amazon.titan-text-express-v1',
   'modelId': 'amazon.titan-text-express-v1',
   'modelName': 'Titan Text G1 - Express',
   'providerName': 'Amazon',
   'inputModalities': ['TEXT'],
   'outputModalities': ['TEXT'],
   'responseStreamingSupported': True,
   'customizationsSupported': [],
   'inferenceTypesSupported': ['ON_DEMAND'],
   'modelLifecycle': {'status': 'ACTIVE'}},
  {'modelArn': 'arn:aws:bedrock:us-west-2::foundation-model/amazon.titan-embed-text-v1:2:8k',
   'modelId': 'amazon.titan-embed-text-v1:2:8k',
   'modelName': 'Titan Embeddings G1 - Text',
   'providerName': 'Amazon',
   'inputModalities': ['TEXT'],
   'outputModalities': ['EMBEDDING'],
   'responseStreamingSupported': False,
   'customizationsSupported': [],
   'inferenceTypesSupported': ['PROVISIONED'],
   'modelLifecycle': {'status': 'ACTIVE'}},
  {'modelArn': 'arn:aws:bedrock:us-west-2::foundation-model/amazon.titan-embed-text-v1',
   'modelId': 'amazon.titan-embed-text-v1',
   'modelName': 'Titan Embeddings G1 - Text',
   'providerName': 'Amazon',
   'inputModalities': ['TEXT'],
   'outputModalities': ['EMBEDDING'],
   'responseStreamingSupported': False,
   'customizationsSupported': [],
   'inferenceTypesSupported': ['ON_DEMAND'],
   'modelLifecycle': {'status': 'ACTIVE'}},
  {'modelArn': 'arn:aws:bedrock:us-west-2::foundation-model/amazon.titan-embed-text-v2:0:8k',
   'modelId': 'amazon.titan-embed-text-v2:0:8k',
   'modelName': 'Titan Text Embeddings V2',
   'providerName': 'Amazon',
   'inputModalities': ['TEXT'],
   'outputModalities': ['EMBEDDING'],
   'responseStreamingSupported': False,
   'customizationsSupported': [],
   'inferenceTypesSupported': [],
   'modelLifecycle': {'status': 'ACTIVE'}},
  {'modelArn': 'arn:aws:bedrock:us-west-2::foundation-model/amazon.titan-embed-text-v2:0',
   'modelId': 'amazon.titan-embed-text-v2:0',
   'modelName': 'Titan Text Embeddings V2',
   'providerName': 'Amazon',
   'inputModalities': ['TEXT'],
   'outputModalities': ['EMBEDDING'],
   'responseStreamingSupported': False,
   'customizationsSupported': [],
   'inferenceTypesSupported': ['ON_DEMAND'],
   'modelLifecycle': {'status': 'ACTIVE'}},
  {'modelArn': 'arn:aws:bedrock:us-west-2::foundation-model/amazon.titan-embed-image-v1:0',
   'modelId': 'amazon.titan-embed-image-v1:0',
   'modelName': 'Titan Multimodal Embeddings G1',
   'providerName': 'Amazon',
   'inputModalities': ['TEXT', 'IMAGE'],
   'outputModalities': ['EMBEDDING'],
   'customizationsSupported': ['FINE_TUNING'],
   'inferenceTypesSupported': ['PROVISIONED'],
   'modelLifecycle': {'status': 'ACTIVE'}},
  {'modelArn': 'arn:aws:bedrock:us-west-2::foundation-model/amazon.titan-embed-image-v1',
   'modelId': 'amazon.titan-embed-image-v1',
   'modelName': 'Titan Multimodal Embeddings G1',
   'providerName': 'Amazon',
   'inputModalities': ['TEXT', 'IMAGE'],
   'outputModalities': ['EMBEDDING'],
   'customizationsSupported': [],
   'inferenceTypesSupported': ['ON_DEMAND'],
   'modelLifecycle': {'status': 'ACTIVE'}},
  {'modelArn': 'arn:aws:bedrock:us-west-2::foundation-model/amazon.titan-image-generator-v1:0',
   'modelId': 'amazon.titan-image-generator-v1:0',
   'modelName': 'Titan Image Generator G1',
   'providerName': 'Amazon',
   'inputModalities': ['TEXT', 'IMAGE'],
   'outputModalities': ['IMAGE'],
   'customizationsSupported': ['FINE_TUNING'],
   'inferenceTypesSupported': ['PROVISIONED'],
   'modelLifecycle': {'status': 'ACTIVE'}},
  {'modelArn': 'arn:aws:bedrock:us-west-2::foundation-model/amazon.titan-image-generator-v1',
   'modelId': 'amazon.titan-image-generator-v1',
   'modelName': 'Titan Image Generator G1',
   'providerName': 'Amazon',
   'inputModalities': ['TEXT', 'IMAGE'],
   'outputModalities': ['IMAGE'],
   'customizationsSupported': [],
   'inferenceTypesSupported': ['ON_DEMAND'],
   'modelLifecycle': {'status': 'ACTIVE'}},
  {'modelArn': 'arn:aws:bedrock:us-west-2::foundation-model/amazon.titan-image-generator-v2:0',
   'modelId': 'amazon.titan-image-generator-v2:0',
   'modelName': 'Titan Image Generator G1 v2',
   'providerName': 'Amazon',
   'inputModalities': ['TEXT', 'IMAGE'],
   'outputModalities': ['IMAGE'],
   'customizationsSupported': ['FINE_TUNING'],
   'inferenceTypesSupported': ['PROVISIONED', 'ON_DEMAND'],
   'modelLifecycle': {'status': 'ACTIVE'}},
  {'modelArn': 'arn:aws:bedrock:us-west-2::foundation-model/stability.stable-diffusion-xl-v1:0',
   'modelId': 'stability.stable-diffusion-xl-v1:0',
   'modelName': 'SDXL 1.0',
   'providerName': 'Stability AI',
   'inputModalities': ['TEXT', 'IMAGE'],
   'outputModalities': ['IMAGE'],
   'customizationsSupported': [],
   'inferenceTypesSupported': ['PROVISIONED'],
   'modelLifecycle': {'status': 'ACTIVE'}},
  {'modelArn': 'arn:aws:bedrock:us-west-2::foundation-model/stability.stable-diffusion-xl-v1',
   'modelId': 'stability.stable-diffusion-xl-v1',
   'modelName': 'SDXL 1.0',
   'providerName': 'Stability AI',
   'inputModalities': ['TEXT', 'IMAGE'],
   'outputModalities': ['IMAGE'],
   'customizationsSupported': [],
   'inferenceTypesSupported': ['ON_DEMAND'],
   'modelLifecycle': {'status': 'ACTIVE'}},
  {'modelArn': 'arn:aws:bedrock:us-west-2::foundation-model/stability.sd3-large-v1:0',
   'modelId': 'stability.sd3-large-v1:0',
   'modelName': 'SD3 Large 1.0',
   'providerName': 'Stability AI',
   'inputModalities': ['TEXT', 'IMAGE'],
   'outputModalities': ['IMAGE'],
   'customizationsSupported': [],
   'inferenceTypesSupported': ['ON_DEMAND'],
   'modelLifecycle': {'status': 'ACTIVE'}},
  {'modelArn': 'arn:aws:bedrock:us-west-2::foundation-model/stability.stable-image-core-v1:0',
   'modelId': 'stability.stable-image-core-v1:0',
   'modelName': 'Stable Image Core 1.0',
   'providerName': 'Stability AI',
   'inputModalities': ['TEXT'],
   'outputModalities': ['IMAGE'],
   'customizationsSupported': [],
   'inferenceTypesSupported': ['ON_DEMAND'],
   'modelLifecycle': {'status': 'ACTIVE'}},
  {'modelArn': 'arn:aws:bedrock:us-west-2::foundation-model/stability.stable-image-ultra-v1:0',
   'modelId': 'stability.stable-image-ultra-v1:0',
   'modelName': 'Stable Image Ultra 1.0',
   'providerName': 'Stability AI',
   'inputModalities': ['TEXT'],
   'outputModalities': ['IMAGE'],
   'customizationsSupported': [],
   'inferenceTypesSupported': ['ON_DEMAND'],
   'modelLifecycle': {'status': 'ACTIVE'}},
  {'modelArn': 'arn:aws:bedrock:us-west-2::foundation-model/ai21.j2-grande-instruct',
   'modelId': 'ai21.j2-grande-instruct',
   'modelName': 'J2 Grande Instruct',
   'providerName': 'AI21 Labs',
   'inputModalities': ['TEXT'],
   'outputModalities': ['TEXT'],
   'responseStreamingSupported': False,
   'customizationsSupported': [],
   'inferenceTypesSupported': ['ON_DEMAND'],
   'modelLifecycle': {'status': 'ACTIVE'}},
  {'modelArn': 'arn:aws:bedrock:us-west-2::foundation-model/ai21.j2-jumbo-instruct',
   'modelId': 'ai21.j2-jumbo-instruct',
   'modelName': 'J2 Jumbo Instruct',
   'providerName': 'AI21 Labs',
   'inputModalities': ['TEXT'],
   'outputModalities': ['TEXT'],
   'responseStreamingSupported': False,
   'customizationsSupported': [],
   'inferenceTypesSupported': ['ON_DEMAND'],
   'modelLifecycle': {'status': 'ACTIVE'}},
  {'modelArn': 'arn:aws:bedrock:us-west-2::foundation-model/anthropic.claude-instant-v1:2:100k',
   'modelId': 'anthropic.claude-instant-v1:2:100k',
   'modelName': 'Claude Instant',
   'providerName': 'Anthropic',
   'inputModalities': ['TEXT'],
   'outputModalities': ['TEXT'],
   'responseStreamingSupported': True,
   'customizationsSupported': [],
   'inferenceTypesSupported': ['PROVISIONED'],
   'modelLifecycle': {'status': 'ACTIVE'}},
  {'modelArn': 'arn:aws:bedrock:us-west-2::foundation-model/anthropic.claude-instant-v1',
   'modelId': 'anthropic.claude-instant-v1',
   'modelName': 'Claude Instant',
   'providerName': 'Anthropic',
   'inputModalities': ['TEXT'],
   'outputModalities': ['TEXT'],
   'responseStreamingSupported': True,
   'customizationsSupported': [],
   'inferenceTypesSupported': ['ON_DEMAND'],
   'modelLifecycle': {'status': 'ACTIVE'}},
  {'modelArn': 'arn:aws:bedrock:us-west-2::foundation-model/anthropic.claude-v2:0:18k',
   'modelId': 'anthropic.claude-v2:0:18k',
   'modelName': 'Claude',
   'providerName': 'Anthropic',
   'inputModalities': ['TEXT'],
   'outputModalities': ['TEXT'],
   'responseStreamingSupported': True,
   'customizationsSupported': [],
   'inferenceTypesSupported': ['PROVISIONED'],
   'modelLifecycle': {'status': 'ACTIVE'}},
  {'modelArn': 'arn:aws:bedrock:us-west-2::foundation-model/anthropic.claude-v2:0:100k',
   'modelId': 'anthropic.claude-v2:0:100k',
   'modelName': 'Claude',
   'providerName': 'Anthropic',
   'inputModalities': ['TEXT'],
   'outputModalities': ['TEXT'],
   'responseStreamingSupported': True,
   'customizationsSupported': [],
   'inferenceTypesSupported': ['PROVISIONED'],
   'modelLifecycle': {'status': 'ACTIVE'}},
  {'modelArn': 'arn:aws:bedrock:us-west-2::foundation-model/anthropic.claude-v2:1:18k',
   'modelId': 'anthropic.claude-v2:1:18k',
   'modelName': 'Claude',
   'providerName': 'Anthropic',
   'inputModalities': ['TEXT'],
   'outputModalities': ['TEXT'],
   'responseStreamingSupported': True,
   'customizationsSupported': [],
   'inferenceTypesSupported': ['PROVISIONED'],
   'modelLifecycle': {'status': 'ACTIVE'}},
  {'modelArn': 'arn:aws:bedrock:us-west-2::foundation-model/anthropic.claude-v2:1:200k',
   'modelId': 'anthropic.claude-v2:1:200k',
   'modelName': 'Claude',
   'providerName': 'Anthropic',
   'inputModalities': ['TEXT'],
   'outputModalities': ['TEXT'],
   'responseStreamingSupported': True,
   'customizationsSupported': [],
   'inferenceTypesSupported': ['PROVISIONED'],
   'modelLifecycle': {'status': 'ACTIVE'}},
  {'modelArn': 'arn:aws:bedrock:us-west-2::foundation-model/anthropic.claude-v2:1',
   'modelId': 'anthropic.claude-v2:1',
   'modelName': 'Claude',
   'providerName': 'Anthropic',
   'inputModalities': ['TEXT'],
   'outputModalities': ['TEXT'],
   'responseStreamingSupported': True,
   'customizationsSupported': [],
   'inferenceTypesSupported': ['ON_DEMAND'],
   'modelLifecycle': {'status': 'ACTIVE'}},
  {'modelArn': 'arn:aws:bedrock:us-west-2::foundation-model/anthropic.claude-v2',
   'modelId': 'anthropic.claude-v2',
   'modelName': 'Claude',
   'providerName': 'Anthropic',
   'inputModalities': ['TEXT'],
   'outputModalities': ['TEXT'],
   'responseStreamingSupported': True,
   'customizationsSupported': [],
   'inferenceTypesSupported': ['ON_DEMAND'],
   'modelLifecycle': {'status': 'ACTIVE'}},
  {'modelArn': 'arn:aws:bedrock:us-west-2::foundation-model/anthropic.claude-3-sonnet-20240229-v1:0:28k',
   'modelId': 'anthropic.claude-3-sonnet-20240229-v1:0:28k',
   'modelName': 'Claude 3 Sonnet',
   'providerName': 'Anthropic',
   'inputModalities': ['TEXT', 'IMAGE'],
   'outputModalities': ['TEXT'],
   'responseStreamingSupported': True,
   'customizationsSupported': [],
   'inferenceTypesSupported': ['PROVISIONED'],
   'modelLifecycle': {'status': 'ACTIVE'}},
  {'modelArn': 'arn:aws:bedrock:us-west-2::foundation-model/anthropic.claude-3-sonnet-20240229-v1:0:200k',
   'modelId': 'anthropic.claude-3-sonnet-20240229-v1:0:200k',
   'modelName': 'Claude 3 Sonnet',
   'providerName': 'Anthropic',
   'inputModalities': ['TEXT', 'IMAGE'],
   'outputModalities': ['TEXT'],
   'responseStreamingSupported': True,
   'customizationsSupported': [],
   'inferenceTypesSupported': ['PROVISIONED'],
   'modelLifecycle': {'status': 'ACTIVE'}},
  {'modelArn': 'arn:aws:bedrock:us-west-2::foundation-model/anthropic.claude-3-sonnet-20240229-v1:0',
   'modelId': 'anthropic.claude-3-sonnet-20240229-v1:0',
   'modelName': 'Claude 3 Sonnet',
   'providerName': 'Anthropic',
   'inputModalities': ['TEXT', 'IMAGE'],
   'outputModalities': ['TEXT'],
   'responseStreamingSupported': True,
   'customizationsSupported': [],
   'inferenceTypesSupported': ['ON_DEMAND'],
   'modelLifecycle': {'status': 'ACTIVE'}},
  {'modelArn': 'arn:aws:bedrock:us-west-2::foundation-model/anthropic.claude-3-haiku-20240307-v1:0:48k',
   'modelId': 'anthropic.claude-3-haiku-20240307-v1:0:48k',
   'modelName': 'Claude 3 Haiku',
   'providerName': 'Anthropic',
   'inputModalities': ['TEXT', 'IMAGE'],
   'outputModalities': ['TEXT'],
   'responseStreamingSupported': True,
   'customizationsSupported': [],
   'inferenceTypesSupported': ['PROVISIONED'],
   'modelLifecycle': {'status': 'ACTIVE'}},
  {'modelArn': 'arn:aws:bedrock:us-west-2::foundation-model/anthropic.claude-3-haiku-20240307-v1:0:200k',
   'modelId': 'anthropic.claude-3-haiku-20240307-v1:0:200k',
   'modelName': 'Claude 3 Haiku',
   'providerName': 'Anthropic',
   'inputModalities': ['TEXT', 'IMAGE'],
   'outputModalities': ['TEXT'],
   'responseStreamingSupported': True,
   'customizationsSupported': [],
   'inferenceTypesSupported': ['PROVISIONED'],
   'modelLifecycle': {'status': 'ACTIVE'}},
  {'modelArn': 'arn:aws:bedrock:us-west-2::foundation-model/anthropic.claude-3-haiku-20240307-v1:0',
   'modelId': 'anthropic.claude-3-haiku-20240307-v1:0',
   'modelName': 'Claude 3 Haiku',
   'providerName': 'Anthropic',
   'inputModalities': ['TEXT', 'IMAGE'],
   'outputModalities': ['TEXT'],
   'responseStreamingSupported': True,
   'customizationsSupported': [],
   'inferenceTypesSupported': ['ON_DEMAND'],
   'modelLifecycle': {'status': 'ACTIVE'}},
  {'modelArn': 'arn:aws:bedrock:us-west-2::foundation-model/anthropic.claude-3-opus-20240229-v1:0:12k',
   'modelId': 'anthropic.claude-3-opus-20240229-v1:0:12k',
   'modelName': 'Claude 3 Opus',
   'providerName': 'Anthropic',
   'inputModalities': ['TEXT', 'IMAGE'],
   'outputModalities': ['TEXT'],
   'responseStreamingSupported': True,
   'customizationsSupported': [],
   'inferenceTypesSupported': ['PROVISIONED'],
   'modelLifecycle': {'status': 'ACTIVE'}},
  {'modelArn': 'arn:aws:bedrock:us-west-2::foundation-model/anthropic.claude-3-opus-20240229-v1:0:28k',
   'modelId': 'anthropic.claude-3-opus-20240229-v1:0:28k',
   'modelName': 'Claude 3 Opus',
   'providerName': 'Anthropic',
   'inputModalities': ['TEXT', 'IMAGE'],
   'outputModalities': ['TEXT'],
   'responseStreamingSupported': True,
   'customizationsSupported': [],
   'inferenceTypesSupported': ['PROVISIONED'],
   'modelLifecycle': {'status': 'ACTIVE'}},
  {'modelArn': 'arn:aws:bedrock:us-west-2::foundation-model/anthropic.claude-3-opus-20240229-v1:0:200k',
   'modelId': 'anthropic.claude-3-opus-20240229-v1:0:200k',
   'modelName': 'Claude 3 Opus',
   'providerName': 'Anthropic',
   'inputModalities': ['TEXT', 'IMAGE'],
   'outputModalities': ['TEXT'],
   'responseStreamingSupported': True,
   'customizationsSupported': [],
   'inferenceTypesSupported': ['PROVISIONED'],
   'modelLifecycle': {'status': 'ACTIVE'}},
  {'modelArn': 'arn:aws:bedrock:us-west-2::foundation-model/anthropic.claude-3-opus-20240229-v1:0',
   'modelId': 'anthropic.claude-3-opus-20240229-v1:0',
   'modelName': 'Claude 3 Opus',
   'providerName': 'Anthropic',
   'inputModalities': ['TEXT', 'IMAGE'],
   'outputModalities': ['TEXT'],
   'responseStreamingSupported': True,
   'customizationsSupported': [],
   'inferenceTypesSupported': ['ON_DEMAND'],
   'modelLifecycle': {'status': 'ACTIVE'}},
  {'modelArn': 'arn:aws:bedrock:us-west-2::foundation-model/anthropic.claude-3-5-sonnet-20240620-v1:0:18k',
   'modelId': 'anthropic.claude-3-5-sonnet-20240620-v1:0:18k',
   'modelName': 'Claude 3.5 Sonnet',
   'providerName': 'Anthropic',
   'inputModalities': ['TEXT', 'IMAGE'],
   'outputModalities': ['TEXT'],
   'responseStreamingSupported': True,
   'customizationsSupported': [],
   'inferenceTypesSupported': ['PROVISIONED'],
   'modelLifecycle': {'status': 'ACTIVE'}},
  {'modelArn': 'arn:aws:bedrock:us-west-2::foundation-model/anthropic.claude-3-5-sonnet-20240620-v1:0:51k',
   'modelId': 'anthropic.claude-3-5-sonnet-20240620-v1:0:51k',
   'modelName': 'Claude 3.5 Sonnet',
   'providerName': 'Anthropic',
   'inputModalities': ['TEXT', 'IMAGE'],
   'outputModalities': ['TEXT'],
   'responseStreamingSupported': True,
   'customizationsSupported': [],
   'inferenceTypesSupported': ['PROVISIONED'],
   'modelLifecycle': {'status': 'ACTIVE'}},
  {'modelArn': 'arn:aws:bedrock:us-west-2::foundation-model/anthropic.claude-3-5-sonnet-20240620-v1:0:200k',
   'modelId': 'anthropic.claude-3-5-sonnet-20240620-v1:0:200k',
   'modelName': 'Claude 3.5 Sonnet',
   'providerName': 'Anthropic',
   'inputModalities': ['TEXT', 'IMAGE'],
   'outputModalities': ['TEXT'],
   'responseStreamingSupported': True,
   'customizationsSupported': [],
   'inferenceTypesSupported': ['PROVISIONED'],
   'modelLifecycle': {'status': 'ACTIVE'}},
  {'modelArn': 'arn:aws:bedrock:us-west-2::foundation-model/anthropic.claude-3-5-sonnet-20240620-v1:0',
   'modelId': 'anthropic.claude-3-5-sonnet-20240620-v1:0',
   'modelName': 'Claude 3.5 Sonnet',
   'providerName': 'Anthropic',
   'inputModalities': ['TEXT', 'IMAGE'],
   'outputModalities': ['TEXT'],
   'responseStreamingSupported': True,
   'customizationsSupported': [],
   'inferenceTypesSupported': ['ON_DEMAND'],
   'modelLifecycle': {'status': 'ACTIVE'}},
  {'modelArn': 'arn:aws:bedrock:us-west-2::foundation-model/cohere.command-text-v14:7:4k',
   'modelId': 'cohere.command-text-v14:7:4k',
   'modelName': 'Command',
   'providerName': 'Cohere',
   'inputModalities': ['TEXT'],
   'outputModalities': ['TEXT'],
   'responseStreamingSupported': True,
   'customizationsSupported': ['FINE_TUNING'],
   'inferenceTypesSupported': ['PROVISIONED'],
   'modelLifecycle': {'status': 'ACTIVE'}},
  {'modelArn': 'arn:aws:bedrock:us-west-2::foundation-model/cohere.command-text-v14',
   'modelId': 'cohere.command-text-v14',
   'modelName': 'Command',
   'providerName': 'Cohere',
   'inputModalities': ['TEXT'],
   'outputModalities': ['TEXT'],
   'responseStreamingSupported': True,
   'customizationsSupported': [],
   'inferenceTypesSupported': ['ON_DEMAND'],
   'modelLifecycle': {'status': 'ACTIVE'}},
  {'modelArn': 'arn:aws:bedrock:us-west-2::foundation-model/cohere.command-r-v1:0',
   'modelId': 'cohere.command-r-v1:0',
   'modelName': 'Command R',
   'providerName': 'Cohere',
   'inputModalities': ['TEXT'],
   'outputModalities': ['TEXT'],
   'responseStreamingSupported': True,
   'customizationsSupported': [],
   'inferenceTypesSupported': ['ON_DEMAND'],
   'modelLifecycle': {'status': 'ACTIVE'}},
  {'modelArn': 'arn:aws:bedrock:us-west-2::foundation-model/cohere.command-r-plus-v1:0',
   'modelId': 'cohere.command-r-plus-v1:0',
   'modelName': 'Command R+',
   'providerName': 'Cohere',
   'inputModalities': ['TEXT'],
   'outputModalities': ['TEXT'],
   'responseStreamingSupported': True,
   'customizationsSupported': [],
   'inferenceTypesSupported': ['ON_DEMAND'],
   'modelLifecycle': {'status': 'ACTIVE'}},
  {'modelArn': 'arn:aws:bedrock:us-west-2::foundation-model/cohere.command-light-text-v14:7:4k',
   'modelId': 'cohere.command-light-text-v14:7:4k',
   'modelName': 'Command Light',
   'providerName': 'Cohere',
   'inputModalities': ['TEXT'],
   'outputModalities': ['TEXT'],
   'responseStreamingSupported': True,
   'customizationsSupported': ['FINE_TUNING'],
   'inferenceTypesSupported': ['PROVISIONED'],
   'modelLifecycle': {'status': 'ACTIVE'}},
  {'modelArn': 'arn:aws:bedrock:us-west-2::foundation-model/cohere.command-light-text-v14',
   'modelId': 'cohere.command-light-text-v14',
   'modelName': 'Command Light',
   'providerName': 'Cohere',
   'inputModalities': ['TEXT'],
   'outputModalities': ['TEXT'],
   'responseStreamingSupported': True,
   'customizationsSupported': [],
   'inferenceTypesSupported': ['ON_DEMAND'],
   'modelLifecycle': {'status': 'ACTIVE'}},
  {'modelArn': 'arn:aws:bedrock:us-west-2::foundation-model/cohere.embed-english-v3:0:512',
   'modelId': 'cohere.embed-english-v3:0:512',
   'modelName': 'Embed English',
   'providerName': 'Cohere',
   'inputModalities': ['TEXT'],
   'outputModalities': ['EMBEDDING'],
   'responseStreamingSupported': False,
   'customizationsSupported': [],
   'inferenceTypesSupported': ['PROVISIONED'],
   'modelLifecycle': {'status': 'ACTIVE'}},
  {'modelArn': 'arn:aws:bedrock:us-west-2::foundation-model/cohere.embed-english-v3',
   'modelId': 'cohere.embed-english-v3',
   'modelName': 'Embed English',
   'providerName': 'Cohere',
   'inputModalities': ['TEXT'],
   'outputModalities': ['EMBEDDING'],
   'responseStreamingSupported': False,
   'customizationsSupported': [],
   'inferenceTypesSupported': ['ON_DEMAND'],
   'modelLifecycle': {'status': 'ACTIVE'}},
  {'modelArn': 'arn:aws:bedrock:us-west-2::foundation-model/cohere.embed-multilingual-v3:0:512',
   'modelId': 'cohere.embed-multilingual-v3:0:512',
   'modelName': 'Embed Multilingual',
   'providerName': 'Cohere',
   'inputModalities': ['TEXT'],
   'outputModalities': ['EMBEDDING'],
   'responseStreamingSupported': False,
   'customizationsSupported': [],
   'inferenceTypesSupported': ['PROVISIONED'],
   'modelLifecycle': {'status': 'ACTIVE'}},
  {'modelArn': 'arn:aws:bedrock:us-west-2::foundation-model/cohere.embed-multilingual-v3',
   'modelId': 'cohere.embed-multilingual-v3',
   'modelName': 'Embed Multilingual',
   'providerName': 'Cohere',
   'inputModalities': ['TEXT'],
   'outputModalities': ['EMBEDDING'],
   'responseStreamingSupported': False,
   'customizationsSupported': [],
   'inferenceTypesSupported': ['ON_DEMAND'],
   'modelLifecycle': {'status': 'ACTIVE'}},
  {'modelArn': 'arn:aws:bedrock:us-west-2::foundation-model/meta.llama2-13b-chat-v1:0:4k',
   'modelId': 'meta.llama2-13b-chat-v1:0:4k',
   'modelName': 'Llama 2 Chat 13B',
   'providerName': 'Meta',
   'inputModalities': ['TEXT'],
   'outputModalities': ['TEXT'],
   'responseStreamingSupported': True,
   'customizationsSupported': [],
   'inferenceTypesSupported': ['PROVISIONED'],
   'modelLifecycle': {'status': 'LEGACY'}},
  {'modelArn': 'arn:aws:bedrock:us-west-2::foundation-model/meta.llama2-13b-chat-v1',
   'modelId': 'meta.llama2-13b-chat-v1',
   'modelName': 'Llama 2 Chat 13B',
   'providerName': 'Meta',
   'inputModalities': ['TEXT'],
   'outputModalities': ['TEXT'],
   'responseStreamingSupported': True,
   'customizationsSupported': [],
   'inferenceTypesSupported': ['ON_DEMAND'],
   'modelLifecycle': {'status': 'LEGACY'}},
  {'modelArn': 'arn:aws:bedrock:us-west-2::foundation-model/meta.llama2-70b-chat-v1:0:4k',
   'modelId': 'meta.llama2-70b-chat-v1:0:4k',
   'modelName': 'Llama 2 Chat 70B',
   'providerName': 'Meta',
   'inputModalities': ['TEXT'],
   'outputModalities': ['TEXT'],
   'responseStreamingSupported': True,
   'customizationsSupported': [],
   'inferenceTypesSupported': [],
   'modelLifecycle': {'status': 'LEGACY'}},
  {'modelArn': 'arn:aws:bedrock:us-west-2::foundation-model/meta.llama2-70b-chat-v1',
   'modelId': 'meta.llama2-70b-chat-v1',
   'modelName': 'Llama 2 Chat 70B',
   'providerName': 'Meta',
   'inputModalities': ['TEXT'],
   'outputModalities': ['TEXT'],
   'responseStreamingSupported': True,
   'customizationsSupported': [],
   'inferenceTypesSupported': ['ON_DEMAND'],
   'modelLifecycle': {'status': 'LEGACY'}},
  {'modelArn': 'arn:aws:bedrock:us-west-2::foundation-model/meta.llama2-13b-v1:0:4k',
   'modelId': 'meta.llama2-13b-v1:0:4k',
   'modelName': 'Llama 2 13B',
   'providerName': 'Meta',
   'inputModalities': ['TEXT'],
   'outputModalities': ['TEXT'],
   'responseStreamingSupported': True,
   'customizationsSupported': ['FINE_TUNING'],
   'inferenceTypesSupported': [],
   'modelLifecycle': {'status': 'LEGACY'}},
  {'modelArn': 'arn:aws:bedrock:us-west-2::foundation-model/meta.llama2-13b-v1',
   'modelId': 'meta.llama2-13b-v1',
   'modelName': 'Llama 2 13B',
   'providerName': 'Meta',
   'inputModalities': ['TEXT'],
   'outputModalities': ['TEXT'],
   'responseStreamingSupported': True,
   'customizationsSupported': [],
   'inferenceTypesSupported': [],
   'modelLifecycle': {'status': 'LEGACY'}},
  {'modelArn': 'arn:aws:bedrock:us-west-2::foundation-model/meta.llama2-70b-v1:0:4k',
   'modelId': 'meta.llama2-70b-v1:0:4k',
   'modelName': 'Llama 2 70B',
   'providerName': 'Meta',
   'inputModalities': ['TEXT'],
   'outputModalities': ['TEXT'],
   'responseStreamingSupported': True,
   'customizationsSupported': ['FINE_TUNING'],
   'inferenceTypesSupported': [],
   'modelLifecycle': {'status': 'LEGACY'}},
  {'modelArn': 'arn:aws:bedrock:us-west-2::foundation-model/meta.llama2-70b-v1',
   'modelId': 'meta.llama2-70b-v1',
   'modelName': 'Llama 2 70B',
   'providerName': 'Meta',
   'inputModalities': ['TEXT'],
   'outputModalities': ['TEXT'],
   'responseStreamingSupported': True,
   'customizationsSupported': [],
   'inferenceTypesSupported': [],
   'modelLifecycle': {'status': 'LEGACY'}},
  {'modelArn': 'arn:aws:bedrock:us-west-2::foundation-model/meta.llama3-8b-instruct-v1:0',
   'modelId': 'meta.llama3-8b-instruct-v1:0',
   'modelName': 'Llama 3 8B Instruct',
   'providerName': 'Meta',
   'inputModalities': ['TEXT'],
   'outputModalities': ['TEXT'],
   'responseStreamingSupported': True,
   'customizationsSupported': [],
   'inferenceTypesSupported': ['ON_DEMAND'],
   'modelLifecycle': {'status': 'ACTIVE'}},
  {'modelArn': 'arn:aws:bedrock:us-west-2::foundation-model/meta.llama3-70b-instruct-v1:0',
   'modelId': 'meta.llama3-70b-instruct-v1:0',
   'modelName': 'Llama 3 70B Instruct',
   'providerName': 'Meta',
   'inputModalities': ['TEXT'],
   'outputModalities': ['TEXT'],
   'responseStreamingSupported': True,
   'customizationsSupported': [],
   'inferenceTypesSupported': ['ON_DEMAND'],
   'modelLifecycle': {'status': 'ACTIVE'}},
  {'modelArn': 'arn:aws:bedrock:us-west-2::foundation-model/meta.llama3-1-8b-instruct-v1:0',
   'modelId': 'meta.llama3-1-8b-instruct-v1:0',
   'modelName': 'Llama 3.1 8B Instruct',
   'providerName': 'Meta',
   'inputModalities': ['TEXT'],
   'outputModalities': ['TEXT'],
   'responseStreamingSupported': True,
   'customizationsSupported': [],
   'inferenceTypesSupported': ['ON_DEMAND'],
   'modelLifecycle': {'status': 'ACTIVE'}},
  {'modelArn': 'arn:aws:bedrock:us-west-2::foundation-model/meta.llama3-1-70b-instruct-v1:0',
   'modelId': 'meta.llama3-1-70b-instruct-v1:0',
   'modelName': 'Llama 3.1 70B Instruct',
   'providerName': 'Meta',
   'inputModalities': ['TEXT'],
   'outputModalities': ['TEXT'],
   'responseStreamingSupported': True,
   'customizationsSupported': [],
   'inferenceTypesSupported': ['ON_DEMAND'],
   'modelLifecycle': {'status': 'ACTIVE'}},
  {'modelArn': 'arn:aws:bedrock:us-west-2::foundation-model/meta.llama3-1-405b-instruct-v1:0',
   'modelId': 'meta.llama3-1-405b-instruct-v1:0',
   'modelName': 'Llama 3.1 405B Instruct',
   'providerName': 'Meta',
   'inputModalities': ['TEXT'],
   'outputModalities': ['TEXT'],
   'responseStreamingSupported': True,
   'customizationsSupported': [],
   'inferenceTypesSupported': ['ON_DEMAND'],
   'modelLifecycle': {'status': 'ACTIVE'}},
  {'modelArn': 'arn:aws:bedrock:us-west-2::foundation-model/meta.llama3-2-11b-instruct-v1:0',
   'modelId': 'meta.llama3-2-11b-instruct-v1:0',
   'modelName': 'Llama 3.2 11B Instruct',
   'providerName': 'Meta',
   'inputModalities': ['TEXT', 'IMAGE'],
   'outputModalities': ['TEXT'],
   'responseStreamingSupported': True,
   'customizationsSupported': [],
   'inferenceTypesSupported': ['INFERENCE_PROFILE'],
   'modelLifecycle': {'status': 'ACTIVE'}},
  {'modelArn': 'arn:aws:bedrock:us-west-2::foundation-model/meta.llama3-2-90b-instruct-v1:0',
   'modelId': 'meta.llama3-2-90b-instruct-v1:0',
   'modelName': 'Llama 3.2 90B Instruct',
   'providerName': 'Meta',
   'inputModalities': ['TEXT', 'IMAGE'],
   'outputModalities': ['TEXT'],
   'responseStreamingSupported': True,
   'customizationsSupported': [],
   'inferenceTypesSupported': ['INFERENCE_PROFILE'],
   'modelLifecycle': {'status': 'ACTIVE'}},
  {'modelArn': 'arn:aws:bedrock:us-west-2::foundation-model/meta.llama3-2-1b-instruct-v1:0',
   'modelId': 'meta.llama3-2-1b-instruct-v1:0',
   'modelName': 'Llama 3.2 1B Instruct',
   'providerName': 'Meta',
   'inputModalities': ['TEXT'],
   'outputModalities': ['TEXT'],
   'responseStreamingSupported': True,
   'customizationsSupported': [],
   'inferenceTypesSupported': ['INFERENCE_PROFILE'],
   'modelLifecycle': {'status': 'ACTIVE'}},
  {'modelArn': 'arn:aws:bedrock:us-west-2::foundation-model/meta.llama3-2-3b-instruct-v1:0',
   'modelId': 'meta.llama3-2-3b-instruct-v1:0',
   'modelName': 'Llama 3.2 3B Instruct',
   'providerName': 'Meta',
   'inputModalities': ['TEXT'],
   'outputModalities': ['TEXT'],
   'responseStreamingSupported': True,
   'customizationsSupported': [],
   'inferenceTypesSupported': ['INFERENCE_PROFILE'],
   'modelLifecycle': {'status': 'ACTIVE'}},
  {'modelArn': 'arn:aws:bedrock:us-west-2::foundation-model/mistral.mistral-7b-instruct-v0:2',
   'modelId': 'mistral.mistral-7b-instruct-v0:2',
   'modelName': 'Mistral 7B Instruct',
   'providerName': 'Mistral AI',
   'inputModalities': ['TEXT'],
   'outputModalities': ['TEXT'],
   'responseStreamingSupported': True,
   'customizationsSupported': [],
   'inferenceTypesSupported': ['ON_DEMAND'],
   'modelLifecycle': {'status': 'ACTIVE'}},
  {'modelArn': 'arn:aws:bedrock:us-west-2::foundation-model/mistral.mixtral-8x7b-instruct-v0:1',
   'modelId': 'mistral.mixtral-8x7b-instruct-v0:1',
   'modelName': 'Mixtral 8x7B Instruct',
   'providerName': 'Mistral AI',
   'inputModalities': ['TEXT'],
   'outputModalities': ['TEXT'],
   'responseStreamingSupported': True,
   'customizationsSupported': [],
   'inferenceTypesSupported': ['ON_DEMAND'],
   'modelLifecycle': {'status': 'ACTIVE'}},
  {'modelArn': 'arn:aws:bedrock:us-west-2::foundation-model/mistral.mistral-large-2402-v1:0',
   'modelId': 'mistral.mistral-large-2402-v1:0',
   'modelName': 'Mistral Large (2402)',
   'providerName': 'Mistral AI',
   'inputModalities': ['TEXT'],
   'outputModalities': ['TEXT'],
   'responseStreamingSupported': True,
   'customizationsSupported': [],
   'inferenceTypesSupported': ['ON_DEMAND'],
   'modelLifecycle': {'status': 'ACTIVE'}},
  {'modelArn': 'arn:aws:bedrock:us-west-2::foundation-model/mistral.mistral-large-2407-v1:0',
   'modelId': 'mistral.mistral-large-2407-v1:0',
   'modelName': 'Mistral Large (2407)',
   'providerName': 'Mistral AI',
   'inputModalities': ['TEXT'],
   'outputModalities': ['TEXT'],
   'responseStreamingSupported': True,
   'customizationsSupported': [],
   'inferenceTypesSupported': ['ON_DEMAND'],
   'modelLifecycle': {'status': 'ACTIVE'}}]}
</code></pre> <hr> <h2 id=invokemodel-body-and-output><code>InvokeModel</code> body and output</h2> <p>The <code>invoke_model()</code> method of the Amazon Bedrock client (<code>InvokeModel</code> API) will be the primary method we use for most of our Text Generation and Processing tasks - whichever model we're using.</p> <p>Although the method is shared, the format of input and output varies depending on the foundation model used - as described below:</p> <h3 id=anthropic-claude>Anthropic Claude</h3> <h4 id=input>Input</h4> <div class=highlight><pre><span></span><code><span class=p>{</span>
<span class=w>    </span><span class=nt>&quot;prompt&quot;</span><span class=p>:</span><span class=w> </span><span class=s2>&quot;\n\nHuman:&lt;prompt&gt;\n\Assistant:&quot;</span><span class=p>,</span>
<span class=w>    </span><span class=nt>&quot;max_tokens_to_sample&quot;</span><span class=p>:</span><span class=w> </span><span class=mi>300</span><span class=p>,</span>
<span class=w>    </span><span class=nt>&quot;temperature&quot;</span><span class=p>:</span><span class=w> </span><span class=mf>0.5</span><span class=p>,</span>
<span class=w>    </span><span class=nt>&quot;top_k&quot;</span><span class=p>:</span><span class=w> </span><span class=mi>250</span><span class=p>,</span>
<span class=w>    </span><span class=nt>&quot;top_p&quot;</span><span class=p>:</span><span class=w> </span><span class=mi>1</span><span class=p>,</span>
<span class=w>    </span><span class=nt>&quot;stop_sequences&quot;</span><span class=p>:</span><span class=w> </span><span class=p>[</span><span class=s2>&quot;\n\nHuman:&quot;</span><span class=p>]</span>
<span class=p>}</span>
</code></pre></div> <h4 id=output>Output</h4> <div class=highlight><pre><span></span><code><span class=p>{</span>
<span class=w>    </span><span class=nt>&quot;completion&quot;</span><span class=p>:</span><span class=w> </span><span class=s2>&quot;&lt;output&gt;&quot;</span><span class=p>,</span>
<span class=w>    </span><span class=nt>&quot;stop_reason&quot;</span><span class=p>:</span><span class=w> </span><span class=s2>&quot;stop_sequence&quot;</span>
<span class=p>}</span>
</code></pre></div> <hr> <h2 id=common-inference-parameter-definitions>Common inference parameter definitions</h2> <h3 id=randomness-and-diversity>Randomness and Diversity</h3> <p>Foundation models support the following parameters to control randomness and diversity in the response.</p> <p><strong>Temperature</strong> – Large language models use probability to construct the words in a sequence. For any given next word, there is a probability distribution of options for the next word in the sequence. When you set the temperature closer to zero, the model tends to select the higher-probability words. When you set the temperature further away from zero, the model may select a lower-probability word.</p> <p>In technical terms, the temperature modulates the probability density function for the next tokens, implementing the temperature sampling technique. This parameter can deepen or flatten the density function curve. A lower value results in a steeper curve with more deterministic responses, and a higher value results in a flatter curve with more random responses.</p> <p><strong>Top K</strong> – Temperature defines the probability distribution of potential words, and Top K defines the cut off where the model no longer selects the words. For example, if K=50, the model selects from 50 of the most probable words that could be next in a given sequence. This reduces the probability that an unusual word gets selected next in a sequence. In technical terms, Top K is the number of the highest-probability vocabulary tokens to keep for Top- K-filtering - This limits the distribution of probable tokens, so the model chooses one of the highest- probability tokens.</p> <p><strong>Top P</strong> – Top P defines a cut off based on the sum of probabilities of the potential choices. If you set Top P below 1.0, the model considers the most probable options and ignores less probable ones. Top P is similar to Top K, but instead of capping the number of choices, it caps choices based on the sum of their probabilities. For the example prompt "I hear the hoof beats of ," you may want the model to provide "horses," "zebras" or "unicorns" as the next word. If you set the temperature to its maximum, without capping Top K or Top P, you increase the probability of getting unusual results such as "unicorns." If you set the temperature to 0, you increase the probability of "horses." If you set a high temperature and set Top K or Top P to the maximum, you increase the probability of "horses" or "zebras," and decrease the probability of "unicorns."</p> <h3 id=length>Length</h3> <p>The following parameters control the length of the generated response.</p> <p><strong>Response length</strong> – Configures the minimum and maximum number of tokens to use in the generated response.</p> <p><strong>Length penalty</strong> – Length penalty optimizes the model to be more concise in its output by penalizing longer responses. Length penalty differs from response length as the response length is a hard cut off for the minimum or maximum response length.</p> <p>In technical terms, the length penalty penalizes the model exponentially for lengthy responses. 0.0 means no penalty. Set a value less than 0.0 for the model to generate longer sequences, or set a value greater than 0.0 for the model to produce shorter sequences.</p> <h3 id=repetitions>Repetitions</h3> <p>The following parameters help control repetition in the generated response.</p> <p><strong>Repetition penalty (presence penalty)</strong> – Prevents repetitions of the same words (tokens) in responses. 1.0 means no penalty. Greater than 1.0 decreases repetition.</p> <hr> <h2 id=try-out-the-text-generation-model>Try out the text generation model</h2> <p>With some theory out of the way, let's see the models in action! Run the cells below to see how to generate text with the Anthropic Claude Haiku model. </p> <h3 id=client-side-boto3-bedrock-runtime-connection>Client side <code>boto3</code> bedrock-runtime connection</h3> <div class=highlight><pre><span></span><code><span class=n>bedrock_runtime</span> <span class=o>=</span> <span class=n>boto3</span><span class=o>.</span><span class=n>client</span><span class=p>(</span>
    <span class=n>service_name</span><span class=o>=</span><span class=s1>&#39;bedrock-runtime&#39;</span><span class=p>,</span>
    <span class=n>region_name</span><span class=o>=</span><span class=n>region</span><span class=p>,</span>
<span class=p>)</span>
</code></pre></div> <div class=highlight><pre><span></span><code><span class=n>claude3</span> <span class=o>=</span> <span class=s1>&#39;claude3&#39;</span>
<span class=n>llama2</span> <span class=o>=</span> <span class=s1>&#39;llama2&#39;</span>
<span class=n>llama3</span><span class=o>=</span><span class=s1>&#39;llama3&#39;</span>
<span class=n>mistral</span><span class=o>=</span><span class=s1>&#39;mistral&#39;</span>
<span class=n>titan</span><span class=o>=</span><span class=s1>&#39;titan&#39;</span>
<span class=n>models_dict</span> <span class=o>=</span> <span class=p>{</span>
    <span class=n>claude3</span><span class=p>:</span> <span class=s1>&#39;anthropic.claude-3-haiku-20240307-v1:0&#39;</span><span class=p>,</span>  <span class=c1># Updated to Claude Haiku model ID</span>
    <span class=n>llama3</span><span class=p>:</span> <span class=s1>&#39;meta.llama3-8b-instruct-v1:0&#39;</span><span class=p>,</span>
    <span class=n>mistral</span><span class=p>:</span> <span class=s1>&#39;mistral.mistral-7b-instruct-v0:2&#39;</span><span class=p>,</span>
    <span class=n>titan</span><span class=p>:</span> <span class=s1>&#39;amazon.titan-tg1-large&#39;</span>
<span class=p>}</span>
<span class=n>max_tokens_val</span> <span class=o>=</span> <span class=mi>100</span>
<span class=n>temperature_val</span> <span class=o>=</span> <span class=mf>0.1</span>
<span class=n>dict_add_params</span> <span class=o>=</span> <span class=p>{</span>
    <span class=n>llama3</span><span class=p>:</span> <span class=p>{</span><span class=s2>&quot;max_gen_len&quot;</span><span class=p>:</span><span class=n>max_tokens_val</span><span class=p>,</span> <span class=s2>&quot;temperature&quot;</span><span class=p>:</span><span class=n>temperature_val</span><span class=p>}</span> <span class=p>,</span> 
    <span class=n>claude3</span><span class=p>:</span> <span class=p>{</span><span class=s2>&quot;top_k&quot;</span><span class=p>:</span> <span class=mi>200</span><span class=p>,</span>  <span class=s2>&quot;temperature&quot;</span><span class=p>:</span> <span class=n>temperature_val</span><span class=p>,</span> <span class=s2>&quot;max_tokens&quot;</span><span class=p>:</span> <span class=n>max_tokens_val</span><span class=p>},</span>
    <span class=n>mistral</span><span class=p>:</span> <span class=p>{</span><span class=s2>&quot;max_tokens&quot;</span><span class=p>:</span><span class=n>max_tokens_val</span><span class=p>,</span> <span class=s2>&quot;temperature&quot;</span><span class=p>:</span> <span class=n>temperature_val</span><span class=p>}</span> <span class=p>,</span> 
    <span class=n>titan</span><span class=p>:</span>  <span class=p>{</span><span class=s2>&quot;topK&quot;</span><span class=p>:</span> <span class=mi>200</span><span class=p>,</span>  <span class=s2>&quot;maxTokenCount&quot;</span><span class=p>:</span> <span class=n>max_tokens_val</span><span class=p>}</span>
<span class=p>}</span>
</code></pre></div> <h3 id=anthropic-claude-haiku>Anthropic Claude Haiku</h3> <div class=highlight><pre><span></span><code><span class=kn>import</span> <span class=nn>json</span>

<span class=n>PROMPT_DATA</span> <span class=o>=</span> <span class=s1>&#39;&#39;&#39;Human: Write me a blog about making strong business decisions as a leader.</span>

<span class=s1>Assistant:</span>
<span class=s1>&#39;&#39;&#39;</span>
</code></pre></div> <div class=highlight><pre><span></span><code><span class=n>messages_API_body</span> <span class=o>=</span> <span class=p>{</span>
    <span class=s2>&quot;anthropic_version&quot;</span><span class=p>:</span> <span class=s2>&quot;bedrock-2023-05-31&quot;</span><span class=p>,</span> 
    <span class=s2>&quot;max_tokens&quot;</span><span class=p>:</span> <span class=mi>100</span><span class=p>,</span> <span class=c1>#int(500/0.75),</span>
    <span class=s2>&quot;messages&quot;</span><span class=p>:</span> <span class=p>[</span>
        <span class=p>{</span>
            <span class=s2>&quot;role&quot;</span><span class=p>:</span> <span class=s2>&quot;user&quot;</span><span class=p>,</span>
            <span class=s2>&quot;content&quot;</span><span class=p>:</span> <span class=p>[</span>
                <span class=p>{</span>
                    <span class=s2>&quot;type&quot;</span><span class=p>:</span> <span class=s2>&quot;text&quot;</span><span class=p>,</span>
                    <span class=s2>&quot;text&quot;</span><span class=p>:</span> <span class=n>PROMPT_DATA</span>
                <span class=p>}</span>
            <span class=p>]</span>
        <span class=p>}</span>
    <span class=p>]</span>
<span class=p>}</span>
</code></pre></div> <h3 id=ask-claude-to-generate-this-article>Ask claude to generate this article</h3> <div class=highlight><pre><span></span><code><span class=kn>import</span> <span class=nn>json</span>
<span class=kn>from</span> <span class=nn>IPython.display</span> <span class=kn>import</span> <span class=n>clear_output</span><span class=p>,</span> <span class=n>display</span><span class=p>,</span> <span class=n>display_markdown</span><span class=p>,</span> <span class=n>Markdown</span>

<span class=n>body</span> <span class=o>=</span> <span class=n>json</span><span class=o>.</span><span class=n>dumps</span><span class=p>(</span><span class=n>messages_API_body</span><span class=p>)</span>
<span class=n>accept</span> <span class=o>=</span> <span class=s2>&quot;application/json&quot;</span>
<span class=n>contentType</span> <span class=o>=</span> <span class=s2>&quot;application/json&quot;</span>

<span class=c1># Updated model ID to Claude Haiku</span>
<span class=n>modelId</span> <span class=o>=</span> <span class=s2>&quot;anthropic.claude-3-haiku-20240307-v1:0&quot;</span>

<span class=c1># Invoke the model with the request.</span>
<span class=n>response</span> <span class=o>=</span> <span class=n>bedrock_runtime</span><span class=o>.</span><span class=n>invoke_model</span><span class=p>(</span>
    <span class=n>modelId</span><span class=o>=</span><span class=n>modelId</span><span class=p>,</span> <span class=n>body</span><span class=o>=</span><span class=n>body</span>
<span class=p>)</span>

<span class=c1># Extract and print the response text in real-time. Claude Haiku</span>
<span class=n>model_response</span> <span class=o>=</span> <span class=n>json</span><span class=o>.</span><span class=n>loads</span><span class=p>(</span><span class=n>response</span><span class=p>[</span><span class=s2>&quot;body&quot;</span><span class=p>]</span><span class=o>.</span><span class=n>read</span><span class=p>())</span>

<span class=c1># Extract and print the response text.</span>
<span class=n>response_text</span> <span class=o>=</span> <span class=n>model_response</span><span class=p>[</span><span class=s2>&quot;content&quot;</span><span class=p>][</span><span class=mi>0</span><span class=p>][</span><span class=s2>&quot;text&quot;</span><span class=p>]</span>
<span class=n>display</span><span class=p>(</span><span class=n>Markdown</span><span class=p>(</span><span class=n>response_text</span><span class=p>))</span>
</code></pre></div> <p>Here is a draft blog post about making strong business decisions as a leader:</p> <p>Title: 5 Tips for Making Tough Business Decisions as a Leader</p> <p>As a business leader, you are constantly faced with important decisions that can significantly impact the trajectory of your company. Whether it's deciding on a new product strategy, choosing between candidates for a key role, or determining how to allocate limited resources, the choices you make will reverberate throughout your organization. </p> <p>Making tough calls is</p> <h2 id=generate-streaming-output>Generate streaming output</h2> <p>For large language models, it can take noticeable time to generate long output sequences. Rather than waiting for the entire response to be available, latency-sensitive applications may like to <strong>stream</strong> the response to users.</p> <p>Run the code below to see how you can achieve this with Bedrock's <code>invoke_model_with_response_stream()</code> method - returning the response body in separate chunks.</p> <h3 id=each-model-has-its-unique-input-and-output-properties>Each model has its unique input and output properties</h3> <p><strong>Claude models</strong></p> <div class=highlight><pre><span></span><code>for event in streaming_response[&quot;body&quot;]:
    chunk = json.loads(event[&quot;chunk&quot;][&quot;bytes&quot;])
    if chunk[&quot;type&quot;] == &quot;content_block_delta&quot;:
        print(chunk[&quot;delta&quot;].get(&quot;text&quot;, &quot;&quot;), end=&quot;&quot;)
        #display(Markdown(chunk[&quot;delta&quot;].get(&quot;text&quot;, &quot;&quot;)))
</code></pre></div> <p><strong>Llama3</strong> <div class=highlight><pre><span></span><code>for event in streaming_response[&quot;body&quot;]:
    chunk = json.loads(event[&quot;chunk&quot;][&quot;bytes&quot;])
    if &quot;generation&quot; in chunk:
        #print(chunk[&quot;generation&quot;], end=&quot;&quot;)
        display(Markdown(chunk[&quot;generation&quot;]))
</code></pre></div></p> <div class=highlight><pre><span></span><code><span class=kn>import</span> <span class=nn>json</span>
<span class=kn>from</span> <span class=nn>IPython.display</span> <span class=kn>import</span> <span class=n>clear_output</span><span class=p>,</span> <span class=n>display</span><span class=p>,</span> <span class=n>display_markdown</span><span class=p>,</span> <span class=n>Markdown</span>

<span class=n>body</span> <span class=o>=</span> <span class=n>json</span><span class=o>.</span><span class=n>dumps</span><span class=p>(</span><span class=n>messages_API_body</span><span class=p>)</span>
<span class=n>accept</span> <span class=o>=</span> <span class=s2>&quot;application/json&quot;</span>
<span class=n>contentType</span> <span class=o>=</span> <span class=s2>&quot;application/json&quot;</span>

<span class=c1># Updated model ID to Claude Haiku</span>
<span class=n>modelId</span> <span class=o>=</span> <span class=s2>&quot;anthropic.claude-3-haiku-20240307-v1:0&quot;</span>

<span class=c1># Invoke the model with the request using streaming response</span>
<span class=n>streaming_response</span> <span class=o>=</span> <span class=n>bedrock_runtime</span><span class=o>.</span><span class=n>invoke_model_with_response_stream</span><span class=p>(</span>
    <span class=n>modelId</span><span class=o>=</span><span class=n>modelId</span><span class=p>,</span> <span class=n>body</span><span class=o>=</span><span class=n>body</span>
<span class=p>)</span>

<span class=c1># Extract and print the response text in real-time</span>
<span class=k>for</span> <span class=n>event</span> <span class=ow>in</span> <span class=n>streaming_response</span><span class=p>[</span><span class=s2>&quot;body&quot;</span><span class=p>]:</span>
    <span class=n>chunk</span> <span class=o>=</span> <span class=n>json</span><span class=o>.</span><span class=n>loads</span><span class=p>(</span><span class=n>event</span><span class=p>[</span><span class=s2>&quot;chunk&quot;</span><span class=p>][</span><span class=s2>&quot;bytes&quot;</span><span class=p>])</span>

    <span class=k>if</span> <span class=n>chunk</span><span class=p>[</span><span class=s2>&quot;type&quot;</span><span class=p>]</span> <span class=o>==</span> <span class=s2>&quot;content_block_delta&quot;</span><span class=p>:</span>
        <span class=c1># Print the streamed response text incrementally</span>
        <span class=nb>print</span><span class=p>(</span><span class=n>chunk</span><span class=p>[</span><span class=s2>&quot;delta&quot;</span><span class=p>]</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=s2>&quot;text&quot;</span><span class=p>,</span> <span class=s2>&quot;&quot;</span><span class=p>),</span> <span class=n>end</span><span class=o>=</span><span class=s2>&quot;&quot;</span><span class=p>)</span>
        <span class=c1># display(Markdown(chunk[&quot;delta&quot;].get(&quot;text&quot;, &quot;&quot;)))</span>
</code></pre></div> <pre><code>Here is a draft blog post about making strong business decisions as a leader:

Title: 5 Tips for Making Tough Business Decisions as a Leader

As a business leader, you are often faced with difficult decisions that can have a major impact on your company's success. Whether it's deciding on a new strategy, allocating resources, or addressing a crisis, the choices you make as a leader will largely determine the trajectory of your organization.

Making strong, well-informed business
</code></pre> <h3 id=to-solve-this-problem-bedrock-has-now-created-a-converse-api>To solve this problem Bedrock has now created a <code>Converse API</code></h3> <p>but the model decodng params are different</p> <div class=highlight><pre><span></span><code>messages_API_body = {
    &quot;messages&quot;: [
        {
            &quot;role&quot;: &quot;user&quot;,
            &quot;content&quot;: [
                {
                    &quot;text&quot;: &quot;Provide general steps to debug a BSOD on a Windows laptop.&quot;
                }
            ]
        }
    ],
    &quot;system&quot;: [{&quot;text&quot; : &quot;You are a tech support expert who helps resolve technical issues. Signal &#39;SUCCESS&#39; if you can resolve the issue, otherwise &#39;FAILURE&#39;&quot;}],
    &quot;inferenceConfig&quot;: {
        &quot;stopSequences&quot;: [ &quot;SUCCESS&quot;, &quot;FAILURE&quot; ]
    },
    &quot;additionalModelRequestFields&quot;: {
        &quot;top_k&quot;: 200,
        &quot;max_tokens&quot;: 100
    },
    &quot;additionalModelResponseFieldPaths&quot;: [
        &quot;/stop_sequence&quot;
    ]
}
</code></pre></div> <div class=highlight><pre><span></span><code><span class=kn>import</span> <span class=nn>boto3</span>
<span class=kn>import</span> <span class=nn>os</span>
<span class=kn>from</span> <span class=nn>IPython.display</span> <span class=kn>import</span> <span class=n>Markdown</span><span class=p>,</span> <span class=n>display</span>
<span class=kn>import</span> <span class=nn>logging</span>
<span class=kn>from</span> <span class=nn>botocore.exceptions</span> <span class=kn>import</span> <span class=n>ClientError</span>

<span class=n>logger</span> <span class=o>=</span> <span class=n>logging</span><span class=o>.</span><span class=n>getLogger</span><span class=p>(</span><span class=vm>__name__</span><span class=p>)</span>
<span class=n>logging</span><span class=o>.</span><span class=n>basicConfig</span><span class=p>(</span><span class=n>level</span><span class=o>=</span><span class=n>logging</span><span class=o>.</span><span class=n>INFO</span><span class=p>,</span> <span class=nb>format</span><span class=o>=</span><span class=s2>&quot;</span><span class=si>%(levelname)s</span><span class=s2>: </span><span class=si>%(message)s</span><span class=s2>&quot;</span><span class=p>)</span>

<span class=n>region</span> <span class=o>=</span> <span class=n>os</span><span class=o>.</span><span class=n>environ</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=s2>&quot;AWS_REGION&quot;</span><span class=p>)</span>
<span class=n>bedrock_runtime</span> <span class=o>=</span> <span class=n>boto3</span><span class=o>.</span><span class=n>client</span><span class=p>(</span>
    <span class=n>service_name</span><span class=o>=</span><span class=s1>&#39;bedrock-runtime&#39;</span><span class=p>,</span>
    <span class=n>region_name</span><span class=o>=</span><span class=n>region</span><span class=p>,</span>
<span class=p>)</span>

<span class=c1># Model identifiers</span>
<span class=n>claude3</span> <span class=o>=</span> <span class=s1>&#39;claude3&#39;</span>
<span class=n>llama2</span> <span class=o>=</span> <span class=s1>&#39;llama2&#39;</span>
<span class=n>llama3</span> <span class=o>=</span> <span class=s1>&#39;llama3&#39;</span>
<span class=n>mistral</span> <span class=o>=</span> <span class=s1>&#39;mistral&#39;</span>
<span class=n>titan</span> <span class=o>=</span> <span class=s1>&#39;titan&#39;</span>

<span class=c1># Updated model dictionary with correct model IDs</span>
<span class=n>models_dict</span> <span class=o>=</span> <span class=p>{</span>
    <span class=n>claude3</span><span class=p>:</span> <span class=s1>&#39;anthropic.claude-3-haiku-20240307-v1:0&#39;</span><span class=p>,</span>  <span class=c1># Updated to Claude Haiku model ID</span>
    <span class=n>llama2</span><span class=p>:</span> <span class=s1>&#39;meta.llama2-13b-chat-v1&#39;</span><span class=p>,</span>
    <span class=n>llama3</span><span class=p>:</span> <span class=s1>&#39;meta.llama3-8b-instruct-v1:0&#39;</span><span class=p>,</span>
    <span class=n>mistral</span><span class=p>:</span> <span class=s1>&#39;mistral.mistral-7b-instruct-v0:2&#39;</span><span class=p>,</span>
    <span class=n>titan</span><span class=p>:</span> <span class=s1>&#39;amazon.titan-text-premier-v1:0&#39;</span>
<span class=p>}</span>

<span class=n>max_tokens_val</span> <span class=o>=</span> <span class=mi>100</span>
<span class=n>temperature_val</span> <span class=o>=</span> <span class=mf>0.1</span>

<span class=c1># Additional parameters for different models</span>
<span class=n>dict_add_params</span> <span class=o>=</span> <span class=p>{</span>
    <span class=n>llama3</span><span class=p>:</span> <span class=p>{},</span>  <span class=c1># Adjust additional params if needed</span>
    <span class=n>claude3</span><span class=p>:</span> <span class=p>{</span><span class=s2>&quot;top_k&quot;</span><span class=p>:</span> <span class=mi>200</span><span class=p>},</span>
    <span class=n>mistral</span><span class=p>:</span> <span class=p>{},</span>
    <span class=n>titan</span><span class=p>:</span> <span class=p>{</span><span class=s2>&quot;topK&quot;</span><span class=p>:</span> <span class=mi>200</span><span class=p>},</span>
<span class=p>}</span>

<span class=c1># Base inference configuration</span>
<span class=n>inference_config</span> <span class=o>=</span> <span class=p>{</span>
    <span class=s2>&quot;temperature&quot;</span><span class=p>:</span> <span class=n>temperature_val</span><span class=p>,</span>
    <span class=s2>&quot;maxTokens&quot;</span><span class=p>:</span> <span class=n>max_tokens_val</span><span class=p>,</span>
    <span class=s2>&quot;topP&quot;</span><span class=p>:</span> <span class=mf>0.9</span>
<span class=p>}</span>

<span class=k>def</span> <span class=nf>generate_conversation</span><span class=p>(</span><span class=n>bedrock_client</span><span class=p>,</span> <span class=n>model_id</span><span class=p>,</span> <span class=n>system_text</span><span class=p>,</span> <span class=n>input_text</span><span class=p>):</span>
<span class=w>    </span><span class=sd>&quot;&quot;&quot;</span>
<span class=sd>    Sends a message to a model.</span>
<span class=sd>    Args:</span>
<span class=sd>        bedrock_client: The Boto3 Bedrock runtime client.</span>
<span class=sd>        model_id (str): The model ID to use.</span>
<span class=sd>        system_text (JSON): The system prompt.</span>
<span class=sd>        input_text (str): The input message.</span>

<span class=sd>    Returns:</span>
<span class=sd>        response (JSON): The conversation that the model generated.</span>
<span class=sd>    &quot;&quot;&quot;</span>

    <span class=n>logger</span><span class=o>.</span><span class=n>info</span><span class=p>(</span><span class=s2>&quot;Generating message with model </span><span class=si>%s</span><span class=s2>&quot;</span><span class=p>,</span> <span class=n>model_id</span><span class=p>)</span>

    <span class=c1># Message to send</span>
    <span class=n>message</span> <span class=o>=</span> <span class=p>{</span>
        <span class=s2>&quot;role&quot;</span><span class=p>:</span> <span class=s2>&quot;user&quot;</span><span class=p>,</span>
        <span class=s2>&quot;content&quot;</span><span class=p>:</span> <span class=p>[{</span><span class=s2>&quot;text&quot;</span><span class=p>:</span> <span class=n>input_text</span><span class=p>}]</span>
    <span class=p>}</span>
    <span class=n>messages</span> <span class=o>=</span> <span class=p>[</span><span class=n>message</span><span class=p>]</span>
    <span class=n>system_prompts</span> <span class=o>=</span> <span class=p>[{</span><span class=s2>&quot;text&quot;</span><span class=p>:</span> <span class=n>system_text</span><span class=p>}]</span>

    <span class=k>if</span> <span class=n>model_id</span> <span class=ow>in</span> <span class=p>[</span><span class=n>models_dict</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=n>mistral</span><span class=p>),</span> <span class=n>models_dict</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=n>titan</span><span class=p>)]:</span>
        <span class=n>system_prompts</span> <span class=o>=</span> <span class=p>[]</span>  <span class=c1># system prompts not supported for these models</span>

    <span class=c1># Send the message</span>
    <span class=n>response</span> <span class=o>=</span> <span class=n>bedrock_client</span><span class=o>.</span><span class=n>converse</span><span class=p>(</span>
        <span class=n>modelId</span><span class=o>=</span><span class=n>model_id</span><span class=p>,</span>
        <span class=n>messages</span><span class=o>=</span><span class=n>messages</span><span class=p>,</span>
        <span class=n>system</span><span class=o>=</span><span class=n>system_prompts</span><span class=p>,</span>
        <span class=n>inferenceConfig</span><span class=o>=</span><span class=n>inference_config</span><span class=p>,</span>
        <span class=n>additionalModelRequestFields</span><span class=o>=</span><span class=n>get_additional_model_fields</span><span class=p>(</span><span class=n>model_id</span><span class=p>)</span>
    <span class=p>)</span>

    <span class=k>return</span> <span class=n>response</span>

<span class=k>def</span> <span class=nf>get_additional_model_fields</span><span class=p>(</span><span class=n>model_id</span><span class=p>):</span>
<span class=w>    </span><span class=sd>&quot;&quot;&quot;</span>
<span class=sd>    Retrieves additional model fields based on the model_id.</span>
<span class=sd>    &quot;&quot;&quot;</span>
    <span class=k>return</span> <span class=n>dict_add_params</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=n>model_id</span><span class=p>,</span> <span class=p>{})</span>

<span class=k>def</span> <span class=nf>get_converse_output</span><span class=p>(</span><span class=n>response_obj</span><span class=p>):</span>
<span class=w>    </span><span class=sd>&quot;&quot;&quot;</span>
<span class=sd>    Parses the output from the conversation.</span>
<span class=sd>    &quot;&quot;&quot;</span>
    <span class=n>ret_messages</span> <span class=o>=</span> <span class=p>[]</span>
    <span class=n>output_message</span> <span class=o>=</span> <span class=n>response_obj</span><span class=p>[</span><span class=s1>&#39;output&#39;</span><span class=p>][</span><span class=s1>&#39;message&#39;</span><span class=p>]</span>
    <span class=n>role_out</span> <span class=o>=</span> <span class=n>output_message</span><span class=p>[</span><span class=s1>&#39;role&#39;</span><span class=p>]</span>

    <span class=k>for</span> <span class=n>content</span> <span class=ow>in</span> <span class=n>output_message</span><span class=p>[</span><span class=s1>&#39;content&#39;</span><span class=p>]:</span>
        <span class=n>ret_messages</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>content</span><span class=p>[</span><span class=s1>&#39;text&#39;</span><span class=p>])</span>

    <span class=k>return</span> <span class=n>ret_messages</span><span class=p>,</span> <span class=n>role_out</span>

<span class=c1># Example response metadata extraction</span>
<span class=n>response_metadata</span> <span class=o>=</span> <span class=p>{</span>
    <span class=s1>&#39;ResponseMetadata&#39;</span><span class=p>:</span> <span class=p>{</span>
        <span class=s1>&#39;RequestId&#39;</span><span class=p>:</span> <span class=s1>&#39;bf55ac64-9df7-4e34-b423-39af447235d7&#39;</span><span class=p>,</span>
        <span class=s1>&#39;HTTPStatusCode&#39;</span><span class=p>:</span> <span class=mi>200</span><span class=p>,</span>
        <span class=s1>&#39;HTTPHeaders&#39;</span><span class=p>:</span> <span class=p>{</span>
            <span class=s1>&#39;date&#39;</span><span class=p>:</span> <span class=s1>&#39;Mon, 09 Sep 2024 15:42:38 GMT&#39;</span><span class=p>,</span>
            <span class=s1>&#39;content-type&#39;</span><span class=p>:</span> <span class=s1>&#39;application/json&#39;</span><span class=p>,</span>
            <span class=s1>&#39;content-length&#39;</span><span class=p>:</span> <span class=s1>&#39;29744&#39;</span><span class=p>,</span>
            <span class=s1>&#39;connection&#39;</span><span class=p>:</span> <span class=s1>&#39;keep-alive&#39;</span><span class=p>,</span>
            <span class=s1>&#39;x-amzn-requestid&#39;</span><span class=p>:</span> <span class=s1>&#39;bf55ac64-9df7-4e34-b423-39af447235d7&#39;</span>
        <span class=p>},</span>
        <span class=s1>&#39;RetryAttempts&#39;</span><span class=p>:</span> <span class=mi>0</span>
    <span class=p>},</span>
    <span class=s1>&#39;modelSummaries&#39;</span><span class=p>:</span> <span class=p>[</span>
        <span class=c1># Summaries for different models</span>
        <span class=p>{</span><span class=s1>&#39;modelArn&#39;</span><span class=p>:</span> <span class=s1>&#39;arn:aws:bedrock:us-west-2::foundation-model/anthropic.claude-3-haiku-20240307-v1:0&#39;</span><span class=p>,</span>
         <span class=s1>&#39;modelId&#39;</span><span class=p>:</span> <span class=s1>&#39;anthropic.claude-3-haiku-20240307-v1:0&#39;</span><span class=p>,</span>
         <span class=s1>&#39;modelName&#39;</span><span class=p>:</span> <span class=s1>&#39;Claude 3 Haiku&#39;</span><span class=p>,</span>
         <span class=s1>&#39;providerName&#39;</span><span class=p>:</span> <span class=s1>&#39;Anthropic&#39;</span><span class=p>,</span>
         <span class=s1>&#39;inputModalities&#39;</span><span class=p>:</span> <span class=p>[</span><span class=s1>&#39;TEXT&#39;</span><span class=p>],</span>
         <span class=s1>&#39;outputModalities&#39;</span><span class=p>:</span> <span class=p>[</span><span class=s1>&#39;TEXT&#39;</span><span class=p>],</span>
         <span class=s1>&#39;responseStreamingSupported&#39;</span><span class=p>:</span> <span class=kc>True</span><span class=p>,</span>
         <span class=s1>&#39;customizationsSupported&#39;</span><span class=p>:</span> <span class=p>[],</span>
         <span class=s1>&#39;inferenceTypesSupported&#39;</span><span class=p>:</span> <span class=p>[</span><span class=s1>&#39;ON_DEMAND&#39;</span><span class=p>],</span>
         <span class=s1>&#39;modelLifecycle&#39;</span><span class=p>:</span> <span class=p>{</span><span class=s1>&#39;status&#39;</span><span class=p>:</span> <span class=s1>&#39;ACTIVE&#39;</span><span class=p>}}</span>
    <span class=p>]</span>
<span class=p>}</span>
</code></pre></div> <div class=highlight><pre><span></span><code><span class=kn>import</span> <span class=nn>logging</span>
<span class=kn>import</span> <span class=nn>boto3</span>
<span class=kn>from</span> <span class=nn>botocore.exceptions</span> <span class=kn>import</span> <span class=n>ClientError</span>
<span class=kn>from</span> <span class=nn>IPython.display</span> <span class=kn>import</span> <span class=n>Markdown</span><span class=p>,</span> <span class=n>display</span>

<span class=c1># Logging setup</span>
<span class=n>logger</span> <span class=o>=</span> <span class=n>logging</span><span class=o>.</span><span class=n>getLogger</span><span class=p>(</span><span class=vm>__name__</span><span class=p>)</span>
<span class=n>logging</span><span class=o>.</span><span class=n>basicConfig</span><span class=p>(</span><span class=n>level</span><span class=o>=</span><span class=n>logging</span><span class=o>.</span><span class=n>INFO</span><span class=p>,</span> <span class=nb>format</span><span class=o>=</span><span class=s2>&quot;</span><span class=si>%(levelname)s</span><span class=s2>: </span><span class=si>%(message)s</span><span class=s2>&quot;</span><span class=p>)</span>

<span class=c1># Choose Claude Haiku model for conversation</span>
<span class=n>modelId</span> <span class=o>=</span> <span class=n>models_dict</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=s1>&#39;claude3&#39;</span><span class=p>)</span>  <span class=c1># Updated to Claude Haiku (claude3)</span>

<span class=c1># System and input texts</span>
<span class=n>system_text</span> <span class=o>=</span> <span class=s2>&quot;You are an economist with access to lots of data.&quot;</span>
<span class=n>input_text</span> <span class=o>=</span> <span class=s2>&quot;Write an article about impact of high inflation to GDP of a country.&quot;</span>

<span class=c1># Generate a conversation</span>
<span class=k>try</span><span class=p>:</span>
    <span class=n>response</span> <span class=o>=</span> <span class=n>generate_conversation</span><span class=p>(</span><span class=n>bedrock_runtime</span><span class=p>,</span> <span class=n>modelId</span><span class=p>,</span> <span class=n>system_text</span><span class=p>,</span> <span class=n>input_text</span><span class=p>)</span>
    <span class=n>output_message</span> <span class=o>=</span> <span class=n>response</span><span class=p>[</span><span class=s1>&#39;output&#39;</span><span class=p>][</span><span class=s1>&#39;message&#39;</span><span class=p>]</span>

    <span class=c1># Output the role of the assistant</span>
    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Role: </span><span class=si>{</span><span class=n>output_message</span><span class=p>[</span><span class=s1>&#39;role&#39;</span><span class=p>]</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>

    <span class=c1># Output each text block from the assistant</span>
    <span class=k>for</span> <span class=n>content</span> <span class=ow>in</span> <span class=n>output_message</span><span class=p>[</span><span class=s1>&#39;content&#39;</span><span class=p>]:</span>
        <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Text: </span><span class=si>{</span><span class=n>content</span><span class=p>[</span><span class=s1>&#39;text&#39;</span><span class=p>]</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>

    <span class=c1># Token usage information</span>
    <span class=n>token_usage</span> <span class=o>=</span> <span class=n>response</span><span class=p>[</span><span class=s1>&#39;usage&#39;</span><span class=p>]</span>
    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Input tokens:  </span><span class=si>{</span><span class=n>token_usage</span><span class=p>[</span><span class=s1>&#39;inputTokens&#39;</span><span class=p>]</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Output tokens:  </span><span class=si>{</span><span class=n>token_usage</span><span class=p>[</span><span class=s1>&#39;outputTokens&#39;</span><span class=p>]</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Total tokens:  </span><span class=si>{</span><span class=n>token_usage</span><span class=p>[</span><span class=s1>&#39;totalTokens&#39;</span><span class=p>]</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>

    <span class=c1># Stop reason for the response</span>
    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Stop reason: </span><span class=si>{</span><span class=n>response</span><span class=p>[</span><span class=s1>&#39;stopReason&#39;</span><span class=p>]</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>

    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Finished generating text with model </span><span class=si>{</span><span class=n>modelId</span><span class=si>}</span><span class=s2>.&quot;</span><span class=p>)</span>

    <span class=c1># Display the first part of the generated output as Markdown</span>
    <span class=n>display</span><span class=p>(</span><span class=n>Markdown</span><span class=p>(</span><span class=n>get_converse_output</span><span class=p>(</span><span class=n>response</span><span class=p>)[</span><span class=mi>0</span><span class=p>][</span><span class=mi>0</span><span class=p>]))</span>

<span class=k>except</span> <span class=n>ClientError</span> <span class=k>as</span> <span class=n>e</span><span class=p>:</span>
    <span class=n>logger</span><span class=o>.</span><span class=n>error</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;An error occurred: </span><span class=si>{</span><span class=n>e</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
<span class=k>except</span> <span class=ne>KeyError</span> <span class=k>as</span> <span class=n>e</span><span class=p>:</span>
    <span class=n>logger</span><span class=o>.</span><span class=n>error</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Key error: </span><span class=si>{</span><span class=n>e</span><span class=si>}</span><span class=s2> - possibly missing key in response.&quot;</span><span class=p>)</span>
<span class=k>except</span> <span class=ne>Exception</span> <span class=k>as</span> <span class=n>e</span><span class=p>:</span>
    <span class=n>logger</span><span class=o>.</span><span class=n>error</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Unexpected error: </span><span class=si>{</span><span class=n>e</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</code></pre></div> <pre><code>INFO: Generating message with model anthropic.claude-3-haiku-20240307-v1:0


Role: assistant
Text: Here is a draft article on the impact of high inflation on a country's GDP:

The Impact of High Inflation on GDP

Persistently high inflation can have significant negative consequences for a country's economic growth and overall GDP. As prices rise rapidly across the economy, the purchasing power of consumers and businesses erodes, leading to a slowdown in economic activity.

One of the primary ways high inflation impacts GDP is through its effect on consumer spending. When prices are rising quickly, consumers have
Input tokens:  32
Output tokens:  100
Total tokens:  132
Stop reason: max_tokens
Finished generating text with model anthropic.claude-3-haiku-20240307-v1:0.
</code></pre> <p>Here is a draft article on the impact of high inflation on a country's GDP:</p> <p>The Impact of High Inflation on GDP</p> <p>Persistently high inflation can have significant negative consequences for a country's economic growth and overall GDP. As prices rise rapidly across the economy, the purchasing power of consumers and businesses erodes, leading to a slowdown in economic activity.</p> <p>One of the primary ways high inflation impacts GDP is through its effect on consumer spending. When prices are rising quickly, consumers have</p> <h2 id=generate-embeddings>Generate embeddings</h2> <p>Use text embeddings to convert text into meaningful vector representations. You input a body of text and the output is a (1 x n) vector. You can use embedding vectors for a wide variety of applications. Bedrock currently offers Titan Embeddings for text embedding that supports text similarity (finding the semantic similarity between bodies of text) and text retrieval (such as search).</p> <p>At the time of writing you can use <code>amazon.titan-embed-text-v1</code> as embedding model via the API. The input text size is 8192 tokens and the output vector length is 1536.</p> <p>To use a text embeddings model, use the InvokeModel API operation or the Python SDK. Use InvokeModel to retrieve the vector representation of the input text from the specified model.</p> <h4 id=input_1>Input</h4> <div class=highlight><pre><span></span><code><span class=p>{</span>
<span class=w>    </span><span class=nt>&quot;inputText&quot;</span><span class=p>:</span><span class=w> </span><span class=s2>&quot;&lt;text&gt;&quot;</span>
<span class=p>}</span>
</code></pre></div> <h4 id=output_1>Output</h4> <div class=highlight><pre><span></span><code><span class=p>{</span>
<span class=w>    </span><span class=nt>&quot;embedding&quot;</span><span class=p>:</span><span class=w> </span><span class=p>[]</span>
<span class=p>}</span>
</code></pre></div> <p>Let's see how to generate embeddings of some text:</p> <div class=highlight><pre><span></span><code><span class=n>prompt_data</span> <span class=o>=</span> <span class=s2>&quot;Amazon Bedrock supports foundation models from industry-leading providers such as </span><span class=se>\</span>
<span class=s2>AI21 Labs, Anthropic, Stability AI, and Amazon. Choose the model that is best suited to achieving </span><span class=se>\</span>
<span class=s2>your unique goals.&quot;</span>
</code></pre></div> <div class=highlight><pre><span></span><code><span class=n>body</span> <span class=o>=</span> <span class=n>json</span><span class=o>.</span><span class=n>dumps</span><span class=p>({</span><span class=s2>&quot;inputText&quot;</span><span class=p>:</span> <span class=n>prompt_data</span><span class=p>})</span>
<span class=n>modelId</span> <span class=o>=</span> <span class=s2>&quot;amazon.titan-embed-text-v1&quot;</span>
<span class=n>accept</span> <span class=o>=</span> <span class=s2>&quot;application/json&quot;</span>
<span class=n>contentType</span> <span class=o>=</span> <span class=s2>&quot;application/json&quot;</span>
<span class=n>response</span> <span class=o>=</span> <span class=n>bedrock_runtime</span><span class=o>.</span><span class=n>invoke_model</span><span class=p>(</span>
<span class=n>body</span><span class=o>=</span><span class=n>body</span><span class=p>,</span> <span class=n>modelId</span><span class=o>=</span><span class=n>modelId</span><span class=p>,</span> <span class=n>accept</span><span class=o>=</span><span class=n>accept</span><span class=p>,</span> <span class=n>contentType</span><span class=o>=</span><span class=n>contentType</span>
<span class=p>)</span>
<span class=n>response_body</span> <span class=o>=</span> <span class=n>json</span><span class=o>.</span><span class=n>loads</span><span class=p>(</span><span class=n>response</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=s2>&quot;body&quot;</span><span class=p>)</span><span class=o>.</span><span class=n>read</span><span class=p>())</span>
<span class=n>embedding</span> <span class=o>=</span> <span class=n>response_body</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=s2>&quot;embedding&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;The embedding vector has </span><span class=si>{</span><span class=nb>len</span><span class=p>(</span><span class=n>embedding</span><span class=p>)</span><span class=si>}</span><span class=s2> values</span><span class=se>\n</span><span class=si>{</span><span class=n>embedding</span><span class=p>[</span><span class=mi>0</span><span class=p>:</span><span class=mi>3</span><span class=p>]</span><span class=o>+</span><span class=p>[</span><span class=s1>&#39;...&#39;</span><span class=p>]</span><span class=o>+</span><span class=n>embedding</span><span class=p>[</span><span class=o>-</span><span class=mi>3</span><span class=p>:]</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</code></pre></div> <pre><code>The embedding vector has 1536 values
[0.166015625, 0.236328125, 0.703125, '...', 0.26953125, -0.609375, -0.55078125]
</code></pre> <h4 id=now-let-us-run-a-eval-on-our-models>Now let us run a eval on our models</h4> <h2 id=next-steps>Next steps</h2> <p>In this notebook we have successfully set up our Bedrock compatible environment and showed some basic examples of invoking Amazon Bedrock models using the AWS Python SDK. You're now ready to move on to the next notebook to start building our retrieval augmented generation (RAG) application!</p> <form class=md-feedback name=feedback hidden> <fieldset> <legend class=md-feedback__title> Was this page helpful? </legend> <div class=md-feedback__inner> <div class=md-feedback__list> <button class="md-feedback__icon md-icon" type=submit title="This page was helpful" data-md-value=1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M5 9v12H1V9zm4 12a2 2 0 0 1-2-2V9c0-.55.22-1.05.59-1.41L14.17 1l1.06 1.06c.27.27.44.64.44 1.05l-.03.32L14.69 8H21a2 2 0 0 1 2 2v2c0 .26-.05.5-.14.73l-3.02 7.05C19.54 20.5 18.83 21 18 21zm0-2h9.03L21 12v-2h-8.79l1.13-5.32L9 9.03z"/></svg> </button> <button class="md-feedback__icon md-icon" type=submit title="This page could be improved" data-md-value=0> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M19 15V3h4v12zM15 3a2 2 0 0 1 2 2v10c0 .55-.22 1.05-.59 1.41L9.83 23l-1.06-1.06c-.27-.27-.44-.64-.44-1.06l.03-.31.95-4.57H3a2 2 0 0 1-2-2v-2c0-.26.05-.5.14-.73l3.02-7.05C4.46 3.5 5.17 3 6 3zm0 2H5.97L3 12v2h8.78l-1.13 5.32L15 14.97z"/></svg> </button> </div> <div class=md-feedback__note> <div data-md-value=1 hidden> Thanks for your feedback! </div> <div data-md-value=0 hidden> Thanks for your feedback! Help us improve this page by <a href="https://github.com/aws-samples/amazon-bedrock-samples/issues/new?title=[Online Feedback]: Short-Summary-of-Issue&body=Page URL: /workshop/open-source-l200/01_workshop_setup/" target=_blank rel=noopener>creating an issue</a>. </div> </div> </div> </fieldset> </form> </article> </div> <script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script> </div> </main> <footer class=md-footer> <div class="md-footer-meta md-typeset"> <div class="md-footer-meta__inner md-grid"> <div class=md-copyright> <div class=md-copyright__highlight> Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved. </div> </div> <div class=md-social> <a href=https://github.com/aws-samples/amazon-bedrock-samples/tree/main target=_blank rel=noopener title=github.com class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 496 512"><!-- Font Awesome Free 6.7.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8M97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg> </a> </div> </div> </div> </footer> </div> <div class=md-dialog data-md-component=dialog> <div class="md-dialog__inner md-typeset"></div> </div> <script id=__config type=application/json>{"base": "../../..", "features": ["tags", "toc.integrate", "content.code.copy", "content.code.select", "content.code.annotate", "navigation.footer", "search.highlight", "search.suggest"], "search": "../../../assets/javascripts/workers/search.6ce7567c.min.js", "tags": {"Compatibility": "compat"}, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script> <script src=../../../assets/javascripts/bundle.88dd0f4e.min.js></script> <script src=../../../javascript/feedback.js></script> </body> </html>