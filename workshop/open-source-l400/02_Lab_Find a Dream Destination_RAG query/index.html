<!doctype html><html lang=en class=no-js> <head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="Amazon Bedrock cookbook website"><meta name=author content=Bedrock-GTM><link href=https://github.amazon-bedrock-samples.com/workshop/open-source-l400/02_Lab_Find%20a%20Dream%20Destination_RAG%20query/ rel=canonical><link href=../01_usecase_introduction/ rel=prev><link href=../02_travel_planner_with_langgraph/ rel=next><link rel=icon href=../../../assets/favicon.png><meta name=generator content="mkdocs-1.6.1, mkdocs-material-9.5.49"><title>Advanced RAG for Agents - Amazon Bedrock Recipes</title><link rel=stylesheet href=../../../assets/stylesheets/main.6f8fc17f.min.css><link rel=stylesheet href=../../../assets/stylesheets/palette.06af60db.min.css><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback"><style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style><script>__md_scope=new URL("../../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script></head> <body dir=ltr data-md-color-scheme=default data-md-color-primary=white data-md-color-accent=purple> <input class=md-toggle data-md-toggle=drawer type=checkbox id=__drawer autocomplete=off> <input class=md-toggle data-md-toggle=search type=checkbox id=__search autocomplete=off> <label class=md-overlay for=__drawer></label> <div data-md-component=skip> </div> <div data-md-component=announce> </div> <header class="md-header md-header--shadow" data-md-component=header> <nav class="md-header__inner md-grid" aria-label=Header> <a href=../../.. title="Amazon Bedrock Recipes" class="md-header__button md-logo" aria-label="Amazon Bedrock Recipes" data-md-component=logo> <img src=../../../logo.png alt=logo> </a> <label class="md-header__button md-icon" for=__drawer> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg> </label> <div class=md-header__title data-md-component=header-title> <div class=md-header__ellipsis> <div class=md-header__topic> <span class=md-ellipsis> Amazon Bedrock Recipes </span> </div> <div class=md-header__topic data-md-component=header-topic> <span class=md-ellipsis> Advanced RAG for Agents </span> </div> </div> </div> <form class=md-header__option data-md-component=palette> <input class=md-option data-md-color-media data-md-color-scheme=default data-md-color-primary=white data-md-color-accent=purple aria-hidden=true type=radio name=__palette id=__palette_0> </form> <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script> <label class="md-header__button md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg> </label> <div class=md-search data-md-component=search role=dialog> <label class=md-search__overlay for=__search></label> <div class=md-search__inner role=search> <form class=md-search__form name=search> <input type=text class=md-search__input name=query aria-label=Search placeholder=Search autocapitalize=off autocorrect=off autocomplete=off spellcheck=false data-md-component=search-query required> <label class="md-search__icon md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg> </label> <nav class=md-search__options aria-label=Search> <button type=reset class="md-search__icon md-icon" title=Clear aria-label=Clear tabindex=-1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg> </button> </nav> <div class=md-search__suggest data-md-component=search-suggest></div> </form> <div class=md-search__output> <div class=md-search__scrollwrap tabindex=0 data-md-scrollfix> <div class=md-search-result data-md-component=search-result> <div class=md-search-result__meta> Initializing search </div> <ol class=md-search-result__list role=presentation></ol> </div> </div> </div> </div> </div> <div class=md-header__source> <a href=https://github.com/aws-samples/amazon-bedrock-samples/tree/main title="Go to repository" class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 6.7.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81"/></svg> </div> <div class=md-source__repository> Github: Amazon-Bedrock-Samples </div> </a> </div> </nav> </header> <div class=md-container data-md-component=container> <main class=md-main data-md-component=main> <div class="md-main__inner md-grid"> <div class="md-sidebar md-sidebar--primary" data-md-component=sidebar data-md-type=navigation> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--primary md-nav--integrated" aria-label=Navigation data-md-level=0> <label class=md-nav__title for=__drawer> <a href=../../.. title="Amazon Bedrock Recipes" class="md-nav__button md-logo" aria-label="Amazon Bedrock Recipes" data-md-component=logo> <img src=../../../logo.png alt=logo> </a> Amazon Bedrock Recipes </label> <div class=md-nav__source> <a href=https://github.com/aws-samples/amazon-bedrock-samples/tree/main title="Go to repository" class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 6.7.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81"/></svg> </div> <div class=md-source__repository> Github: Amazon-Bedrock-Samples </div> </a> </div> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../.. class=md-nav__link> <span class=md-ellipsis> Home </span> </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2> <label class=md-nav__link for=__nav_2 id=__nav_2_label tabindex=0> <span class=md-ellipsis> Features </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_2_label aria-expanded=false> <label class=md-nav__title for=__nav_2> <span class="md-nav__icon md-icon"></span> Features </label> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2_1> <label class=md-nav__link for=__nav_2_1 id=__nav_2_1_label tabindex=0> <span class=md-ellipsis> Intro to Amazon Bedrock </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_2_1_label aria-expanded=false> <label class=md-nav__title for=__nav_2_1> <span class="md-nav__icon md-icon"></span> Intro to Amazon Bedrock </label> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2_1_1> <label class=md-nav__link for=__nav_2_1_1 id=__nav_2_1_1_label tabindex=0> <span class=md-ellipsis> API Usage </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=3 aria-labelledby=__nav_2_1_1_label aria-expanded=false> <label class=md-nav__title for=__nav_2_1_1> <span class="md-nav__icon md-icon"></span> API Usage </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../introduction-to-bedrock/bedrock_apis/01_invoke_api/ class=md-nav__link> <span class=md-ellipsis> Invoke Model API Example </span> </a> </li> <li class=md-nav__item> <a href=../../../introduction-to-bedrock/bedrock_apis/04_agents_api/ class=md-nav__link> <span class=md-ellipsis> Agents API Example </span> </a> </li> <li class=md-nav__item> <a href=../../../introduction-to-bedrock/bedrock_apis/03_knowledgebases_api/ class=md-nav__link> <span class=md-ellipsis> Knowledge Bases API Example </span> </a> </li> <li class=md-nav__item> <a href=../../../introduction-to-bedrock/bedrock_apis/02_guardrails_api/ class=md-nav__link> <span class=md-ellipsis> Guardrail API Example </span> </a> </li> <li class=md-nav__item> <a href=../../../introduction-to-bedrock/converse_api/01_converse_api/ class=md-nav__link> <span class=md-ellipsis> Converse API Example </span> </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2_2> <label class=md-nav__link for=__nav_2_2 id=__nav_2_2_label tabindex=0> <span class=md-ellipsis> Agents </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_2_2_label aria-expanded=false> <label class=md-nav__title for=__nav_2_2> <span class="md-nav__icon md-icon"></span> Agents </label> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2_2_1> <label class=md-nav__link for=__nav_2_2_1 id=__nav_2_2_1_label tabindex=0> <span class=md-ellipsis> Amazon Bedrock Agents </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=3 aria-labelledby=__nav_2_2_1_label aria-expanded=false> <label class=md-nav__title for=__nav_2_2_1> <span class="md-nav__icon md-icon"></span> Amazon Bedrock Agents </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../agents-and-function-calling/introduction-to-agents/how_to_create_custom_agents/ class=md-nav__link> <span class=md-ellipsis> How to create an Agent </span> </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2_2_1_2> <label class=md-nav__link for=__nav_2_2_1_2 id=__nav_2_2_1_2_label tabindex=0> <span class=md-ellipsis> Bedrock Agent Features </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=4 aria-labelledby=__nav_2_2_1_2_label aria-expanded=false> <label class=md-nav__title for=__nav_2_2_1_2> <span class="md-nav__icon md-icon"></span> Bedrock Agent Features </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../agents-and-function-calling/bedrock-agents/features-examples/01-create-agent-with-function-definition/01-create-agent-with-function-definition/ class=md-nav__link> <span class=md-ellipsis> Create Agent with Function Definition </span> </a> </li> <li class=md-nav__item> <a href=../../../agents-and-function-calling/bedrock-agents/features-examples/02-create-agent-with-api-schema/02-create-agent-with-api-schema/ class=md-nav__link> <span class=md-ellipsis> Create Agent with API Schema </span> </a> </li> <li class=md-nav__item> <a href=../../../agents-and-function-calling/bedrock-agents/features-examples/03-create-agent-with-return-of-control/03-create-agent-with-return-of-control/ class=md-nav__link> <span class=md-ellipsis> Create Agent with Return of Control </span> </a> </li> <li class=md-nav__item> <a href=../../../agents-and-function-calling/bedrock-agents/features-examples/04-create-agent-with-single-knowledge-base/04-create-agent-with-single-knowledge-base/ class=md-nav__link> <span class=md-ellipsis> Create Agent with Single Knowledge Base </span> </a> </li> <li class=md-nav__item> <a href=../../../agents-and-function-calling/bedrock-agents/features-examples/05-create-agent-with-knowledge-base-and-action-group/05-create-agent-with-knowledge-base-and-action-group/ class=md-nav__link> <span class=md-ellipsis> Create Agent with Knowledge Base and Action Group </span> </a> </li> <li class=md-nav__item> <a href=../../../agents-and-function-calling/bedrock-agents/features-examples/06-prompt-and-session-attributes/06-prompt-and-session-attributes/ class=md-nav__link> <span class=md-ellipsis> Prompt and Session Attributes </span> </a> </li> <li class=md-nav__item> <a href=../../../agents-and-function-calling/bedrock-agents/features-examples/07-advanced-prompts-and-custom-parsers/07-custom-prompt-and-lambda-parsers/ class=md-nav__link> <span class=md-ellipsis> Custom Prompt and Lambda Parsers </span> </a> </li> <li class=md-nav__item> <a href=../../../agents-and-function-calling/bedrock-agents/features-examples/08-create-agent-with-guardrails/08-create-agent-with-guardrails/ class=md-nav__link> <span class=md-ellipsis> Create Agent with Guardrails </span> </a> </li> <li class=md-nav__item> <a href=../../../agents-and-function-calling/bedrock-agents/features-examples/09-create-agent-with-memory/09-create-agent-with-memory/ class=md-nav__link> <span class=md-ellipsis> Create Agent with Memory </span> </a> </li> <li class=md-nav__item> <a href=../../../agents-and-function-calling/bedrock-agents/features-examples/10-create-agent-with-code-interpreter/10-create-agent-with-code-interpreter/ class=md-nav__link> <span class=md-ellipsis> Create Agent with Code Interpreter </span> </a> </li> <li class=md-nav__item> <a href=../../../agents-and-function-calling/bedrock-agents/features-examples/14-create-agent-with-custom-orchestration/custom_orchestration_example/ class=md-nav__link> <span class=md-ellipsis> Create Agent with Custom Orchestration </span> </a> </li> <li class=md-nav__item> <a href=../../../agents-and-function-calling/bedrock-agents/features-examples/15-invoke-inline-agents/inline-agent-api-usage/ class=md-nav__link> <span class=md-ellipsis> Create Dynamic Tooling Inline Agents </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2_2_1_3> <label class=md-nav__link for=__nav_2_2_1_3 id=__nav_2_2_1_3_label tabindex=0> <span class=md-ellipsis> Bedrock Flows </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=4 aria-labelledby=__nav_2_2_1_3_label aria-expanded=false> <label class=md-nav__title for=__nav_2_2_1_3> <span class="md-nav__icon md-icon"></span> Bedrock Flows </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../agents-and-function-calling/bedrock-agents/bedrock-flows/Getting_started_with_Prompt_Management_Flows/ class=md-nav__link> <span class=md-ellipsis> Getting Started with Prompt Management Flows </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2_2_1_4> <label class=md-nav__link for=__nav_2_2_1_4 id=__nav_2_2_1_4_label tabindex=0> <span class=md-ellipsis> Use Case Examples </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=4 aria-labelledby=__nav_2_2_1_4_label aria-expanded=false> <label class=md-nav__title for=__nav_2_2_1_4> <span class="md-nav__icon md-icon"></span> Use Case Examples </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../agents-and-function-calling/bedrock-agents/use-case-examples/text-2-sql-agent/create_and_invoke_sql_agent/ class=md-nav__link> <span class=md-ellipsis> Text to SQL Agent </span> </a> </li> <li class=md-nav__item> <a href=../../../agents-and-function-calling/bedrock-agents/use-case-examples/agentsforbedrock-retailagent/workshop/test_retailagent_agentsforbedrock/ class=md-nav__link> <span class=md-ellipsis> Retail Agent Workshop </span> </a> </li> <li class=md-nav__item> <a href=../../../agents-and-function-calling/bedrock-agents/use-case-examples/product-review-agent/main/ class=md-nav__link> <span class=md-ellipsis> Product Review Agent </span> </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2_2_2> <label class=md-nav__link for=__nav_2_2_2 id=__nav_2_2_2_label tabindex=0> <span class=md-ellipsis> Function Calling </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=3 aria-labelledby=__nav_2_2_2_label aria-expanded=false> <label class=md-nav__title for=__nav_2_2_2> <span class="md-nav__icon md-icon"></span> Function Calling </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../agents-and-function-calling/function-calling/function_calling_with_converse/function_calling_with_converse/ class=md-nav__link> <span class=md-ellipsis> Function Calling with Converse </span> </a> </li> <li class=md-nav__item> <a href=../../../agents-and-function-calling/function-calling/function_calling_with_invoke/function_calling_model_with_invoke/ class=md-nav__link> <span class=md-ellipsis> Function Calling with Invoke </span> </a> </li> <li class=md-nav__item> <a href=../../../agents-and-function-calling/function-calling/return_of_control/return_of_control/ class=md-nav__link> <span class=md-ellipsis> Return of Control </span> </a> </li> <li class=md-nav__item> <a href=../../../agents-and-function-calling/function-calling/tool_binding/tool_bindings/ class=md-nav__link> <span class=md-ellipsis> Tool Binding </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2_2_3> <label class=md-nav__link for=__nav_2_2_3 id=__nav_2_2_3_label tabindex=0> <span class=md-ellipsis> Open Source </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=3 aria-labelledby=__nav_2_2_3_label aria-expanded=false> <label class=md-nav__title for=__nav_2_2_3> <span class="md-nav__icon md-icon"></span> Open Source </label> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2_2_3_1> <label class=md-nav__link for=__nav_2_2_3_1 id=__nav_2_2_3_1_label tabindex=0> <span class=md-ellipsis> CrewAI </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=4 aria-labelledby=__nav_2_2_3_1_label aria-expanded=false> <label class=md-nav__title for=__nav_2_2_3_1> <span class="md-nav__icon md-icon"></span> CrewAI </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../agents-and-function-calling/open-source-agents/crew.ai/Find%20dream%20destination%20with%20CrewAI/ class=md-nav__link> <span class=md-ellipsis> Find Dream Destination with CrewAI </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2_2_3_2> <label class=md-nav__link for=__nav_2_2_3_2 id=__nav_2_2_3_2_label tabindex=0> <span class=md-ellipsis> LangGraph </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=4 aria-labelledby=__nav_2_2_3_2_label aria-expanded=false> <label class=md-nav__title for=__nav_2_2_3_2> <span class="md-nav__icon md-icon"></span> LangGraph </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../agents-and-function-calling/open-source-agents/langgraph/langgraph-single-agent/ class=md-nav__link> <span class=md-ellipsis> LangGraph Agent with Function Calling </span> </a> </li> <li class=md-nav__item> <a href=../../../agents-and-function-calling/open-source-agents/langgraph/langgraph-agents-multimodal/ class=md-nav__link> <span class=md-ellipsis> LangGraph Multi-Modal Agent with Function Calling </span> </a> </li> <li class=md-nav__item> <a href=../../../agents-and-function-calling/open-source-agents/langgraph/langgraph-multi-agent-sql-tools/ class=md-nav__link> <span class=md-ellipsis> LangGraph Multi Agent Orchestration </span> </a> </li> <li class=md-nav__item> <a href=../../../agents-and-function-calling/open-source-agents/langgraph/02_medibot_V3_agents/ class=md-nav__link> <span class=md-ellipsis> LangGraph Multi Agent For Medical Chatbot </span> </a> </li> <li class=md-nav__item> <a href=../../../agents-and-function-calling/open-source-agents/langgraph/langgraph-fact-checker-feedback-loop/ class=md-nav__link> <span class=md-ellipsis> LangGraph Fact Checker with Multi Agent </span> </a> </li> <li class=md-nav__item> <a href=../../../agents-and-function-calling/open-source-agents/langgraph/langgraph-multi-agent-sql-tools/ class=md-nav__link> <span class=md-ellipsis> LangGraph Multi Agent Orchestration </span> </a> </li> <li class=md-nav__item> <a href=../../../agents-and-function-calling/open-source-agents/langgraph/03_langgraph_agents_of_agent/ class=md-nav__link> <span class=md-ellipsis> LangGraph Multi Agent with tools </span> </a> </li> <li class=md-nav__item> <a href=../../../agents-and-function-calling/open-source-agents/langgraph/Travel_planner_with_langgraph/ class=md-nav__link> <span class=md-ellipsis> Managing Memory for Multi Agents </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2_2_3_3> <label class=md-nav__link for=__nav_2_2_3_3 id=__nav_2_2_3_3_label tabindex=0> <span class=md-ellipsis> Multi Agent </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=4 aria-labelledby=__nav_2_2_3_3_label aria-expanded=false> <label class=md-nav__title for=__nav_2_2_3_3> <span class="md-nav__icon md-icon"></span> Multi Agent </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../agents-and-function-calling/introduction-to-agents/how_to_create_multi_agents_from_custom_agents/ class=md-nav__link> <span class=md-ellipsis> Multi Agent Orchestration </span> </a> </li> </ul> </nav> </li> </ul> </nav> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2_3> <label class=md-nav__link for=__nav_2_3 id=__nav_2_3_label tabindex=0> <span class=md-ellipsis> RAG </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_2_3_label aria-expanded=false> <label class=md-nav__title for=__nav_2_3> <span class="md-nav__icon md-icon"></span> RAG </label> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2_3_1> <label class=md-nav__link for=__nav_2_3_1 id=__nav_2_3_1_label tabindex=0> <span class=md-ellipsis> Amazon Bedrock Knowledge Bases </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=3 aria-labelledby=__nav_2_3_1_label aria-expanded=false> <label class=md-nav__title for=__nav_2_3_1> <span class="md-nav__icon md-icon"></span> Amazon Bedrock Knowledge Bases </label> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2_3_1_1> <label class=md-nav__link for=__nav_2_3_1_1 id=__nav_2_3_1_1_label tabindex=0> <span class=md-ellipsis> Zero Setup </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=4 aria-labelledby=__nav_2_3_1_1_label aria-expanded=false> <label class=md-nav__title for=__nav_2_3_1_1> <span class="md-nav__icon md-icon"></span> Zero Setup </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../rag/knowledge-bases/features-examples/00-zero-setup-chat-with-your-document/chat_with_document_kb/ class=md-nav__link> <span class=md-ellipsis> Chat with Your Document </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2_3_1_2> <label class=md-nav__link for=__nav_2_3_1_2 id=__nav_2_3_1_2_label tabindex=0> <span class=md-ellipsis> RAG Concepts </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=4 aria-labelledby=__nav_2_3_1_2_label aria-expanded=false> <label class=md-nav__title for=__nav_2_3_1_2> <span class="md-nav__icon md-icon"></span> RAG Concepts </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../rag/knowledge-bases/features-examples/01-rag-concepts/01_create_ingest_documents_test_kb_multi_ds/ class=md-nav__link> <span class=md-ellipsis> Create and Ingest Documents with Multi-Data Sources </span> </a> </li> <li class=md-nav__item> <a href=../../../rag/knowledge-bases/features-examples/01-rag-concepts/02_managed_rag_custom_prompting_and_no_of_results/ class=md-nav__link> <span class=md-ellipsis> Managed RAG with Custom Prompting </span> </a> </li> <li class=md-nav__item> <a href=../../../rag/knowledge-bases/features-examples/01-rag-concepts/03_customized-rag-retreive-api-hybrid-search-claude-3-sonnet-langchain/ class=md-nav__link> <span class=md-ellipsis> Customized RAG with Claude 3 and Langchain </span> </a> </li> <li class=md-nav__item> <a href=../../../rag/knowledge-bases/features-examples/01-rag-concepts/04_customized-rag-retreive-api-langchain-claude-evaluation-ragas/ class=md-nav__link> <span class=md-ellipsis> RAG Evaluation with Langchain and RAGAS </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2_3_1_3> <label class=md-nav__link for=__nav_2_3_1_3 id=__nav_2_3_1_3_label tabindex=0> <span class=md-ellipsis> Optimizing Retrieval Results </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=4 aria-labelledby=__nav_2_3_1_3_label aria-expanded=false> <label class=md-nav__title for=__nav_2_3_1_3> <span class="md-nav__icon md-icon"></span> Optimizing Retrieval Results </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../rag/knowledge-bases/features-examples/02-optimizing-accuracy-retrieved-results/advanced_chunking_options/ class=md-nav__link> <span class=md-ellipsis> Advanced Chunking Options </span> </a> </li> <li class=md-nav__item> <a href=../../../rag/knowledge-bases/features-examples/02-optimizing-accuracy-retrieved-results/csv_metadata_customization/ class=md-nav__link> <span class=md-ellipsis> CSV Metadata Customization </span> </a> </li> <li class=md-nav__item> <a href=../../../rag/knowledge-bases/features-examples/02-optimizing-accuracy-retrieved-results/query_reformulation/ class=md-nav__link> <span class=md-ellipsis> Query Reformulation </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2_3_1_4> <label class=md-nav__link for=__nav_2_3_1_4 id=__nav_2_3_1_4_label tabindex=0> <span class=md-ellipsis> Advanced Concepts </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=4 aria-labelledby=__nav_2_3_1_4_label aria-expanded=false> <label class=md-nav__title for=__nav_2_3_1_4> <span class="md-nav__icon md-icon"></span> Advanced Concepts </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../rag/knowledge-bases/features-examples/03-advanced-concepts/dynamic-metadata-filtering/dynamic-metadata-filtering-KB/ class=md-nav__link> <span class=md-ellipsis> Dynamic Metadata Filtering </span> </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2_3_1_4_2> <label class=md-nav__link for=__nav_2_3_1_4_2 id=__nav_2_3_1_4_2_label tabindex=0> <span class=md-ellipsis> Reranking </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=5 aria-labelledby=__nav_2_3_1_4_2_label aria-expanded=false> <label class=md-nav__title for=__nav_2_3_1_4_2> <span class="md-nav__icon md-icon"></span> Reranking </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../rag/knowledge-bases/features-examples/03-advanced-concepts/reranking/01_deploy-reranking-model-sm/ class=md-nav__link> <span class=md-ellipsis> Deploy Reranking Model </span> </a> </li> <li class=md-nav__item> <a href=../../../rag/knowledge-bases/features-examples/03-advanced-concepts/reranking/02_kb-reranker/ class=md-nav__link> <span class=md-ellipsis> Knowledge Base Reranker </span> </a> </li> <li class=md-nav__item> <a href=../../../rag/knowledge-bases/features-examples/03-advanced-concepts/reranking/qa-generator/ class=md-nav__link> <span class=md-ellipsis> QA Generator </span> </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2_3_1_5> <label class=md-nav__link for=__nav_2_3_1_5 id=__nav_2_3_1_5_label tabindex=0> <span class=md-ellipsis> Responsible AI </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=4 aria-labelledby=__nav_2_3_1_5_label aria-expanded=false> <label class=md-nav__title for=__nav_2_3_1_5> <span class="md-nav__icon md-icon"></span> Responsible AI </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../rag/knowledge-bases/features-examples/05-responsible-ai/contextual-grounding/ class=md-nav__link> <span class=md-ellipsis> Contextual Grounding </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2_3_1_6> <label class=md-nav__link for=__nav_2_3_1_6 id=__nav_2_3_1_6_label tabindex=0> <span class=md-ellipsis> Use Case Examples </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=4 aria-labelledby=__nav_2_3_1_6_label aria-expanded=false> <label class=md-nav__title for=__nav_2_3_1_6> <span class="md-nav__icon md-icon"></span> Use Case Examples </label> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2_3_1_6_1> <label class=md-nav__link for=__nav_2_3_1_6_1 id=__nav_2_3_1_6_1_label tabindex=0> <span class=md-ellipsis> Metadata Filter Access Control </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=5 aria-labelledby=__nav_2_3_1_6_1_label aria-expanded=false> <label class=md-nav__title for=__nav_2_3_1_6_1> <span class="md-nav__icon md-icon"></span> Metadata Filter Access Control </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../rag/knowledge-bases/use-case-examples/metadata-filter-access-control/kb-end-to-end-acl/ class=md-nav__link> <span class=md-ellipsis> End-to-End ACL with Knowledge Base </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2_3_1_6_2> <label class=md-nav__link for=__nav_2_3_1_6_2 id=__nav_2_3_1_6_2_label tabindex=0> <span class=md-ellipsis> RAG with Structured and Unstructured Data </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=5 aria-labelledby=__nav_2_3_1_6_2_label aria-expanded=false> <label class=md-nav__title for=__nav_2_3_1_6_2> <span class="md-nav__icon md-icon"></span> RAG with Structured and Unstructured Data </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../rag/knowledge-bases/use-case-examples/rag-using-structured-unstructured-data/0-create-dummy-structured-data/ class=md-nav__link> <span class=md-ellipsis> Create Dummy Structured Data </span> </a> </li> <li class=md-nav__item> <a href=../../../rag/knowledge-bases/use-case-examples/rag-using-structured-unstructured-data/1_create_sql_dataset_optional/ class=md-nav__link> <span class=md-ellipsis> Create SQL Dataset (Optional) </span> </a> </li> <li class=md-nav__item> <a href=../../../rag/knowledge-bases/use-case-examples/rag-using-structured-unstructured-data/2_rag_with_structured_unstructured_data/ class=md-nav__link> <span class=md-ellipsis> RAG with Structured and Unstructured Data </span> </a> </li> </ul> </nav> </li> </ul> </nav> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2_3_2> <label class=md-nav__link for=__nav_2_3_2 id=__nav_2_3_2_label tabindex=0> <span class=md-ellipsis> Open Source </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=3 aria-labelledby=__nav_2_3_2_label aria-expanded=false> <label class=md-nav__title for=__nav_2_3_2> <span class="md-nav__icon md-icon"></span> Open Source </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../rag/open-source/chatbots/qa_chatbot_langchain_bedrock/ class=md-nav__link> <span class=md-ellipsis> Chatbot using Langchain </span> </a> </li> <li class=md-nav__item> <a href=../../../rag/open-source/chunking/rag_chunking_strategies_langchain_bedrock/ class=md-nav__link> <span class=md-ellipsis> Chunking strategies for RAG applications </span> </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2_3_2_3> <label class=md-nav__link for=__nav_2_3_2_3 id=__nav_2_3_2_3_label tabindex=0> <span class=md-ellipsis> Vector Stores </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=4 aria-labelledby=__nav_2_3_2_3_label aria-expanded=false> <label class=md-nav__title for=__nav_2_3_2_3> <span class="md-nav__icon md-icon"></span> Vector Stores </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../rag/open-source/vector_stores/rag_langchain_bedrock_opensearch/ class=md-nav__link> <span class=md-ellipsis> Langchain Chatbot with Opensearch </span> </a> </li> </ul> </nav> </li> </ul> </nav> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2_4> <label class=md-nav__link for=__nav_2_4 id=__nav_2_4_label tabindex=0> <span class=md-ellipsis> Model Customization </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_2_4_label aria-expanded=false> <label class=md-nav__title for=__nav_2_4> <span class="md-nav__icon md-icon"></span> Model Customization </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../custom-models/model-distillation/Historical_invocation_distillation/ class=md-nav__link> <span class=md-ellipsis> Model Distillation with Invocation Logs </span> </a> </li> <li class=md-nav__item> <a href=../../../custom-models/model-distillation/Distillation-via-S3-input/ class=md-nav__link> <span class=md-ellipsis> Model Distillation with S3 Data </span> </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_3> <label class=md-nav__link for=__nav_3 id=__nav_3_label tabindex=0> <span class=md-ellipsis> Gen AI Usecases </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_3_label aria-expanded=false> <label class=md-nav__title for=__nav_3> <span class="md-nav__icon md-icon"></span> Gen AI Usecases </label> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_3_1> <label class=md-nav__link for=__nav_3_1 id=__nav_3_1_label tabindex=0> <span class=md-ellipsis> Text Generation </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_3_1_label aria-expanded=false> <label class=md-nav__title for=__nav_3_1> <span class="md-nav__icon md-icon"></span> Text Generation </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../genai-use-cases/text-generation/how_to_work_with_text_generation_w_bedrock/ class=md-nav__link> <span class=md-ellipsis> Streaming Response with Converse </span> </a> </li> <li class=md-nav__item> <a href=../../../genai-use-cases/text-generation/how_to_work_with_code_generation_w_bedrock/ class=md-nav__link> <span class=md-ellipsis> Generate Python Code with Converse </span> </a> </li> <li class=md-nav__item> <a href=../../../genai-use-cases/text-generation/how_to_work_with_text_translation_w_bedrock/ class=md-nav__link> <span class=md-ellipsis> Text Translation with Converse </span> </a> </li> <li class=md-nav__item> <a href=../../../genai-use-cases/text-generation/how_to_work_with_text-summarization-titan%2Bclaude/ class=md-nav__link> <span class=md-ellipsis> Text summarization with Converse </span> </a> </li> <li class=md-nav__item> <a href=../../../genai-use-cases/text-generation/how_to_work_with_batch_example_for_multi_threaded_invocation/ class=md-nav__link> <span class=md-ellipsis> Generate Bulk Emails with Batch Inference </span> </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--active md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_4 checked> <label class=md-nav__link for=__nav_4 id=__nav_4_label tabindex=0> <span class=md-ellipsis> Workshops </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_4_label aria-expanded=true> <label class=md-nav__title for=__nav_4> <span class="md-nav__icon md-icon"></span> Workshops </label> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--active md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_4_1 checked> <label class=md-nav__link for=__nav_4_1 id=__nav_4_1_label tabindex=0> <span class=md-ellipsis> Open-source L400 </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_4_1_label aria-expanded=true> <label class=md-nav__title for=__nav_4_1> <span class="md-nav__icon md-icon"></span> Open-source L400 </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../01_usecase_introduction/ class=md-nav__link> <span class=md-ellipsis> Introduction to the Use Case </span> </a> </li> <li class="md-nav__item md-nav__item--active"> <input class="md-nav__toggle md-toggle" type=checkbox id=__toc> <a href=./ class="md-nav__link md-nav__link--active"> <span class=md-ellipsis> Advanced RAG for Agents </span> </a> </li> <li class=md-nav__item> <a href=../02_travel_planner_with_langgraph/ class=md-nav__link> <span class=md-ellipsis> Conversational Memory in Agents </span> </a> </li> <li class=md-nav__item> <a href=../03_travel_agent_with_tools/ class=md-nav__link> <span class=md-ellipsis> Multi-Modal and Types of Agents </span> </a> </li> <li class=md-nav__item> <a href=../04_travel_booking_multi_agent/ class=md-nav__link> <span class=md-ellipsis> Multi-Agent Collaboration with Human-in-loop </span> </a> </li> <li class=md-nav__item> <a href=../05_dream_destination_with_crewai/ class=md-nav__link> <span class=md-ellipsis> Find Dream Destination with CrewAI </span> </a> </li> <li class=md-nav__item> <a href=../06_agent_evaluation_with_ragas/ class=md-nav__link> <span class=md-ellipsis> RAGAs Agents Evaluation </span> </a> </li> <li class=md-nav__item> <a href=../07_dynamic_tooling_agents/ class=md-nav__link> <span class=md-ellipsis> Dynamic Tool invocation </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_4_2> <label class=md-nav__link for=__nav_4_2 id=__nav_4_2_label tabindex=0> <span class=md-ellipsis> Open-source L200 </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_4_2_label aria-expanded=false> <label class=md-nav__title for=__nav_4_2> <span class="md-nav__icon md-icon"></span> Open-source L200 </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../open-source-l200/02_contextual_text_generation/ class=md-nav__link> <span class=md-ellipsis> Introduction to the Use Case </span> </a> </li> <li class=md-nav__item> <a href=../../open-source-l200/03_retrieval_based_text_application/ class=md-nav__link> <span class=md-ellipsis> Retrieval Based Text Generation </span> </a> </li> <li class=md-nav__item> <a href=../../open-source-l200/04_retrieval_based_chat_application/ class=md-nav__link> <span class=md-ellipsis> Retrieval Based Chat Application </span> </a> </li> <li class=md-nav__item> <a href=../../open-source-l200/05_agent_based_text_generation/ class=md-nav__link> <span class=md-ellipsis> Agent Based Text Generation </span> </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../../../general/tags/ class=md-nav__link> <span class=md-ellipsis> Tags </span> </a> </li> <li class=md-nav__item> <a href=../../../general/license/ class=md-nav__link> <span class=md-ellipsis> License </span> </a> </li> </ul> </nav> </div> </div> </div> <div class=md-content data-md-component=content> <article class="md-content__inner md-typeset"> <nav class=md-tags> <a href=../../../general/tags/#rag class="md-tag md-tag-icon">RAG</a> <a href=../../../general/tags/#prompt-engineering class="md-tag md-tag-icon">Prompt-Engineering</a> <a href=../../../general/tags/#langchain class="md-tag md-tag-icon">Langchain</a> </nav> <h1>Advanced RAG for Agents</h1> <!-- <h2>Complete Document Retrieval and RAG</h2> --> <div class="admonition tip inline end"> <p class=admonition-title><a href=https://github.com/aws-samples/amazon-bedrock-samples/blob/main/workshops/open-source-l400/02_Lab_Find_a_Dream_Destination_RAG_query.pynb target=_blank>Open in github</a></p> </div> <hr> <blockquote> <p><em>PLEASE NOTE: This notebook should work well with the </em><em><code>Data Science 3.0</code></em><em> kernel in SageMaker Studio</em></p> </blockquote> <h2>Overview</h2> <ul> <li><strong>Retrieval Pipeline</strong> With customers having the ability to enter any number of possibilities into the solution, it is helpful to detect intent and normalize the query. Few-shots are a useful tool to tailor the normalization to the nature of the query in-line. </li> <li><strong>Advanced methods</strong> For more complex cases, it can be beneficial to generate hypothetical queries and documents solving for sub-queries and improving the semantic similarity.</li> <li><strong>Model answer generation</strong> Once the model is shown a set of documents, it must generate an answer while staying as closely aligned to the contents of the documents as possible. We cover self-verification and citation as methods giving greater flexibility to the model for a given query and set of retrieved documents.</li> </ul> <h2>Context</h2> <p>Retrieval Augmented Generation (RAG) requires the indexation of relevant unstructured documents into a vector database. Then given a customer query, the relevant are retrieved and past as context to the model, which generates an answer. This can best be described by the following flow.</p> <p><img src=./assets/rag-architecture.png></p> <p>Once our documents (PDFs, CSV, Tables, JSON, ...) have been indexed into our knowledge base, we start working towards retrieval of a relevant subset of documents based on a given query. For many applications, the success of the retrieval is a strong indicator for the performance of the overall response. This notebook assumes you are familiar with the basics of RAG, embedding models and vector databases.</p> <p>In this notebook, we seek to go beyond RAG to generate the model answer by applying other relevant steps in the answer pipeline.</p> <h2>Prerequisites</h2> <p>Before you can use Amazon Bedrock, you must carry out the following steps:</p> <ul> <li>Sign up for an AWS account (if you don't already have one) and IAM Role with the necessary permissions for Amazon Bedrock, see <a href=https://docs.aws.amazon.com/bedrock/latest/userguide/getting-started.html#new-to-aws target=_blank>AWS Account and IAM Role</a>.</li> <li>Request access to the foundation models (FM) that you want to use, see <a href=https://docs.aws.amazon.com/bedrock/latest/userguide/getting-started.html#getting-started-model-access target=_blank>Request access to FMs</a>. </li> </ul> <h2>Setup</h2> <div class=highlight><pre><span></span><code><span class=err>!</span><span class=n>pip3</span> <span class=n>install</span> <span class=n>langchain</span><span class=o>-</span><span class=n>aws</span> <span class=o>--</span><span class=n>quiet</span>
<span class=err>!</span><span class=n>pip3</span> <span class=n>install</span> <span class=n>faiss</span><span class=o>-</span><span class=n>cpu</span> <span class=o>--</span><span class=n>quiet</span>
<span class=err>!</span><span class=n>pip3</span> <span class=n>install</span> <span class=n>wikipedia</span> <span class=o>--</span><span class=n>quiet</span>
</code></pre></div> <p>We import the relevant objects used in this notebook.</p> <div class=highlight><pre><span></span><code><span class=kn>import</span> <span class=nn>boto3</span>
<span class=kn>import</span> <span class=nn>faiss</span>
<span class=kn>import</span> <span class=nn>datetime</span>
<span class=kn>import</span> <span class=nn>re</span>
<span class=kn>from</span> <span class=nn>operator</span> <span class=kn>import</span> <span class=n>itemgetter</span>
<span class=kn>from</span> <span class=nn>typing</span> <span class=kn>import</span> <span class=n>List</span><span class=p>,</span> <span class=n>Iterable</span>
<span class=kn>from</span> <span class=nn>langchain_aws.chat_models.bedrock</span> <span class=kn>import</span> <span class=n>ChatBedrock</span>
<span class=kn>from</span> <span class=nn>langchain_aws</span> <span class=kn>import</span> <span class=n>BedrockEmbeddings</span>
<span class=kn>from</span> <span class=nn>langchain_core.prompts</span> <span class=kn>import</span> <span class=p>(</span>
    <span class=n>ChatPromptTemplate</span><span class=p>,</span>
    <span class=n>FewShotChatMessagePromptTemplate</span><span class=p>,</span>
<span class=p>)</span>
<span class=kn>from</span> <span class=nn>langchain_community.docstore</span> <span class=kn>import</span> <span class=n>InMemoryDocstore</span>
<span class=kn>from</span> <span class=nn>langchain_community.vectorstores</span> <span class=kn>import</span> <span class=n>FAISS</span>
<span class=kn>from</span> <span class=nn>langchain.memory</span> <span class=kn>import</span> <span class=n>VectorStoreRetrieverMemory</span>
<span class=kn>from</span> <span class=nn>typing</span> <span class=kn>import</span> <span class=n>Literal</span><span class=p>,</span> <span class=n>Optional</span><span class=p>,</span> <span class=n>Tuple</span>
<span class=kn>from</span> <span class=nn>langchain_core.pydantic_v1</span> <span class=kn>import</span> <span class=n>BaseModel</span><span class=p>,</span> <span class=n>Field</span>
<span class=kn>from</span> <span class=nn>langchain_core.example_selectors</span> <span class=kn>import</span> <span class=n>SemanticSimilarityExampleSelector</span>
<span class=kn>from</span> <span class=nn>langchain_core.prompts</span> <span class=kn>import</span> <span class=n>FewShotPromptTemplate</span><span class=p>,</span> <span class=n>PromptTemplate</span>
<span class=kn>from</span> <span class=nn>langchain_core.prompts</span> <span class=kn>import</span> <span class=n>HumanMessagePromptTemplate</span><span class=p>,</span> <span class=n>AIMessagePromptTemplate</span>
<span class=kn>from</span> <span class=nn>langchain.output_parsers</span> <span class=kn>import</span> <span class=n>PydanticToolsParser</span>
<span class=kn>from</span> <span class=nn>langchain_community.retrievers</span> <span class=kn>import</span> <span class=n>WikipediaRetriever</span>
<span class=kn>from</span> <span class=nn>langchain_core.output_parsers</span> <span class=kn>import</span> <span class=n>StrOutputParser</span>
<span class=kn>from</span> <span class=nn>langchain_core.messages</span> <span class=kn>import</span> <span class=n>AIMessage</span><span class=p>,</span> <span class=n>AIMessageChunk</span>
<span class=kn>from</span> <span class=nn>langchain_core.documents</span> <span class=kn>import</span> <span class=n>Document</span>
<span class=kn>from</span> <span class=nn>langchain_core.runnables</span> <span class=kn>import</span> <span class=p>(</span>
    <span class=n>RunnableLambda</span><span class=p>,</span>
    <span class=n>RunnableParallel</span><span class=p>,</span>
    <span class=n>RunnablePassthrough</span><span class=p>,</span>
    <span class=n>RunnableBranch</span><span class=p>,</span>
<span class=p>)</span>
</code></pre></div> <p>Although this example leverages Claude 3 Sonnet, Bedrock supports many other models. This full list of models and supported features can be found <a href=https://docs.aws.amazon.com/bedrock/latest/userguide/conversation-inference.html>here</a>. The models are invoked via <code>bedrock-runtime</code>.</p> <div class=highlight><pre><span></span><code><span class=n>region</span> <span class=o>=</span> <span class=s1>&#39;us-west-2&#39;</span>
<span class=n>bedrock</span> <span class=o>=</span> <span class=n>boto3</span><span class=o>.</span><span class=n>client</span><span class=p>(</span>
    <span class=n>service_name</span> <span class=o>=</span> <span class=s1>&#39;bedrock-runtime&#39;</span><span class=p>,</span>
    <span class=n>region_name</span> <span class=o>=</span> <span class=n>region</span><span class=p>,</span>
<span class=p>)</span>
</code></pre></div> <p>We use <code>ChatBedrock</code> and <code>BedrockEmbeddings</code> to interact with the Bedrock API. We enable <code>beta_use_converse_api</code> to use the Converse API.</p> <div class=highlight><pre><span></span><code><span class=n>modelId</span> <span class=o>=</span> <span class=s1>&#39;anthropic.claude-3-haiku-20240307-v1:0&#39;</span>
<span class=n>haiku</span> <span class=o>=</span> <span class=n>ChatBedrock</span><span class=p>(</span>
    <span class=n>model_id</span><span class=o>=</span><span class=n>modelId</span><span class=p>,</span>
    <span class=n>client</span><span class=o>=</span><span class=n>bedrock</span><span class=p>,</span>
    <span class=n>beta_use_converse_api</span><span class=o>=</span><span class=kc>True</span>
<span class=p>)</span>
<span class=n>embeddingId</span> <span class=o>=</span> <span class=s2>&quot;amazon.titan-embed-text-v1&quot;</span>
<span class=n>embeddings</span> <span class=o>=</span> <span class=n>BedrockEmbeddings</span><span class=p>(</span>
    <span class=n>model_id</span><span class=o>=</span><span class=n>embeddingId</span><span class=p>,</span>
    <span class=n>client</span><span class=o>=</span><span class=n>bedrock</span><span class=p>)</span>
</code></pre></div> <p>We correctly get a generic answer message from the model.</p> <div class=highlight><pre><span></span><code><span class=n>haiku</span><span class=o>.</span><span class=n>invoke</span><span class=p>(</span><span class=s2>&quot;Help me with my travel needs today.&quot;</span><span class=p>)</span><span class=o>.</span><span class=n>content</span>
</code></pre></div> <h2>Reformating the initial query</h2> <h3>Intent Detection</h3> <p>In order to limit the scope of answers handled by the solution with RAG, a common first step in the answer pipeline is <strong>Intent Detection or Classification</strong>. This step is important to ensure the relevancy of the question to the indexed content, which works to limit the model's tendancy to answer questions that may not have been accounted for or tested by the application developers.</p> <p>When requesting some information that is irrelevant to the previously stated purpose, we quickly see the model attempting to provide an answer.</p> <div class=highlight><pre><span></span><code><span class=n>haiku</span><span class=o>.</span><span class=n>invoke</span><span class=p>(</span><span class=s2>&quot;I want to learn more about my mom&#39;s pie recipe&quot;</span><span class=p>)</span><span class=o>.</span><span class=n>content</span>
</code></pre></div> <pre><code>"Here are some tips for learning more about your mom's pie recipe:\n\n1. Ask your mom to teach you. The best way to learn her recipe and techniques is to have her walk you through making the pie step-by-step. Ask her to share any tips or tricks she's picked up over the years.\n\n2. Get the recipe from her. See if she's willing to write down the full recipe with measurements and instructions. This will give you the basic framework to start with.\n\n3. Observe her making the pie. Watch closely as she prepares the crust, fillings, and assembles the pie. Note any little details she does that may not be written in the recipe.\n\n4. Take notes. When she's making the pie, jot down any extra tips she shares, like how to tell when the crust is perfectly baked or how to ensure the filling thickens properly.\n\n5. Ask questions. Don't be afraid to ask her why she does certain steps a certain way. Understanding the reasoning behind her methods can help you replicate the recipe accurately.\n\n6. Experiment. Once you have the basic recipe, try making the pie yourself. Adjust small things and see how it affects the final result. This can help you learn her technique.\n\nThe key is to learn from your mom directly if possible. Her personal touches and tricks are what make the recipe uniquely hers. With her guidance, you can master making the pies just the way she does."
</code></pre> <p>Hence, we provide an initial system prompt defining the model's role as an intent classifier. We supply the classes and few-shots to improve performance and ensure the model is aligned to the desired intended output, which needs to include <code>&lt;intention&gt;&lt;/intention&gt;</code> tags.</p> <div class=highlight><pre><span></span><code><span class=n>intent_system_prompt</span> <span class=o>=</span> <span class=s2>&quot;&quot;&quot;You are a precise classifier. Your task is to assess customer intent and categorize customer inquiry into one of the intentions. </span>

<span class=s2>Intentions with their description:</span>
<span class=s2>vacation: Information on vacations, various travel destinations and my recent travels.</span>
<span class=s2>contact: Expressing the desire to talk to support.</span>
<span class=s2>irrelevant: Not related to vacations and travel.</span>

<span class=s2>Here is an example of how to respond in a standard interaction:</span>
<span class=s2>&lt;example&gt;</span>
<span class=s2>    Human: I am seeking a place that is sunny a family friendly.</span>
<span class=s2>    AI: &lt;intention&gt;vacation&lt;/intention&gt;</span>
<span class=s2>&lt;/example&gt;</span>
<span class=s2>&lt;example&gt;</span>
<span class=s2>    Human: I want to learn more about my mom&#39;s pie recipe</span>
<span class=s2>    AI: &lt;intention&gt;irrelevant&lt;/intention&gt;</span>
<span class=s2>&lt;/example&gt;</span>
<span class=s2>&lt;example&gt;</span>
<span class=s2>    Human: I want to talk to a someone.</span>
<span class=s2>    AI: &lt;intention&gt;contact&lt;/intention&gt;</span>
<span class=s2>&lt;/example&gt;</span>

<span class=s2>Think about your answer first before you respond. Think step-by-step and insert the classification in &lt;intention&gt;&lt;/intention&gt; tags and do not include anything after.&quot;&quot;&quot;</span>
</code></pre></div> <p>We supply the prompt as part of <code>ChatPromptTemplate</code>and use the pipe operator to define a chain connecting the model to the resulting prompt.</p> <div class=highlight><pre><span></span><code><span class=n>intent_detection_prompt</span> <span class=o>=</span> <span class=n>ChatPromptTemplate</span><span class=o>.</span><span class=n>from_messages</span><span class=p>(</span>
    <span class=p>[</span>
        <span class=p>(</span><span class=s2>&quot;system&quot;</span><span class=p>,</span> <span class=n>intent_system_prompt</span><span class=p>),</span>
        <span class=p>(</span><span class=s2>&quot;human&quot;</span><span class=p>,</span> <span class=s2>&quot;Here is the customer&#39;s question: &lt;question&gt;</span><span class=si>{question}</span><span class=s2>&lt;/question&gt; How do you answer to the instructions?&quot;</span><span class=p>),</span>
    <span class=p>]</span>
<span class=p>)</span>
<span class=n>intent_detection_chain</span> <span class=o>=</span> <span class=n>intent_detection_prompt</span> <span class=o>|</span> <span class=n>haiku</span>
</code></pre></div> <p>We invoke the model with the same query and notice the classification result. We invite you to try additional questions.</p> <div class=highlight><pre><span></span><code><span class=n>intent_detection_chain</span><span class=o>.</span><span class=n>invoke</span><span class=p>(</span><span class=s2>&quot;Tell me about my mother&#39;s pie recipe&quot;</span><span class=p>)</span><span class=o>.</span><span class=n>content</span>
</code></pre></div> <p>Since we expect the answer to always contain these tags, we can parse it and branch off depending on the model's classification. </p> <h3>Dynamic few-shots</h3> <p>Although static few-shots are helpful, they have two major obstacles. On the one hand, they do not cover the breadth of necessary examples, and on the other, given that any submitted query is rarely relevant to all supplied examples, they often introduce unecessary tokens and noise to the prompt. In constrast, supplying dynamic few-shots from a larger corpus of examples enables us to select a number of the most relevant examples prior to inference. Evidently, these are determined by the nature of the query. Although we apply it to intent classification, dynamic few-shots can be applied anywhere in the RAG pipeline and generally yield stronger results compared to static examples. </p> <p>We bootstrap <code>few_shot_library</code> using examples distilled by <strong>Claude 3.5 Sonnet</strong>. It is important to continuously iterate on the library after the initial deployment. During this phase, it is a general best practice to collect and label real interactions where the model made mistakes and append those to the set of examples.</p> <div class=highlight><pre><span></span><code><span class=n>few_shot_library</span> <span class=o>=</span> <span class=p>[</span>
    <span class=p>{</span>
        <span class=s2>&quot;question&quot;</span><span class=p>:</span> <span class=s2>&quot;Can you recommend some tropical beach destinations?&quot;</span><span class=p>,</span>
        <span class=s2>&quot;class&quot;</span><span class=p>:</span> <span class=s2>&quot;vacation&quot;</span>
    <span class=p>},</span>
    <span class=p>{</span>
        <span class=s2>&quot;question&quot;</span><span class=p>:</span> <span class=s2>&quot;I need to speak with a customer service representative.&quot;</span><span class=p>,</span>
        <span class=s2>&quot;class&quot;</span><span class=p>:</span> <span class=s2>&quot;contact&quot;</span>
    <span class=p>},</span>
    <span class=p>{</span>
        <span class=s2>&quot;question&quot;</span><span class=p>:</span> <span class=s2>&quot;What&#39;s the best way to cook spaghetti?&quot;</span><span class=p>,</span>
        <span class=s2>&quot;class&quot;</span><span class=p>:</span> <span class=s2>&quot;irrelevant&quot;</span>
    <span class=p>},</span>
    <span class=p>{</span>
        <span class=s2>&quot;question&quot;</span><span class=p>:</span> <span class=s2>&quot;Are there any family-friendly resorts in Florida?&quot;</span><span class=p>,</span>
        <span class=s2>&quot;class&quot;</span><span class=p>:</span> <span class=s2>&quot;vacation&quot;</span>
    <span class=p>},</span>
    <span class=p>{</span>
        <span class=s2>&quot;question&quot;</span><span class=p>:</span> <span class=s2>&quot;How do I file a complaint about my recent stay?&quot;</span><span class=p>,</span>
        <span class=s2>&quot;class&quot;</span><span class=p>:</span> <span class=s2>&quot;contact&quot;</span>
    <span class=p>},</span>
    <span class=p>{</span>
        <span class=s2>&quot;question&quot;</span><span class=p>:</span> <span class=s2>&quot;What&#39;s the weather like in Paris in June?&quot;</span><span class=p>,</span>
        <span class=s2>&quot;class&quot;</span><span class=p>:</span> <span class=s2>&quot;vacation&quot;</span>
    <span class=p>},</span>
    <span class=p>{</span>
        <span class=s2>&quot;question&quot;</span><span class=p>:</span> <span class=s2>&quot;Can you help me with my car insurance claim?&quot;</span><span class=p>,</span>
        <span class=s2>&quot;class&quot;</span><span class=p>:</span> <span class=s2>&quot;irrelevant&quot;</span>
    <span class=p>},</span>
    <span class=p>{</span>
        <span class=s2>&quot;question&quot;</span><span class=p>:</span> <span class=s2>&quot;I&#39;d like to book an all-inclusive Caribbean cruise.&quot;</span><span class=p>,</span>
        <span class=s2>&quot;class&quot;</span><span class=p>:</span> <span class=s2>&quot;vacation&quot;</span>
    <span class=p>},</span>
    <span class=p>{</span>
        <span class=s2>&quot;question&quot;</span><span class=p>:</span> <span class=s2>&quot;Is there a phone number for your reservations team?&quot;</span><span class=p>,</span>
        <span class=s2>&quot;class&quot;</span><span class=p>:</span> <span class=s2>&quot;contact&quot;</span>
    <span class=p>},</span>
    <span class=p>{</span>
        <span class=s2>&quot;question&quot;</span><span class=p>:</span> <span class=s2>&quot;What&#39;s the best way to learn a new language?&quot;</span><span class=p>,</span>
        <span class=s2>&quot;class&quot;</span><span class=p>:</span> <span class=s2>&quot;irrelevant&quot;</span>
    <span class=p>},</span>
    <span class=p>{</span>
        <span class=s2>&quot;question&quot;</span><span class=p>:</span> <span class=s2>&quot;Are there any good hiking trails in Yellowstone?&quot;</span><span class=p>,</span>
        <span class=s2>&quot;class&quot;</span><span class=p>:</span> <span class=s2>&quot;vacation&quot;</span>
    <span class=p>},</span>
    <span class=p>{</span>
        <span class=s2>&quot;question&quot;</span><span class=p>:</span> <span class=s2>&quot;I need to update my billing information.&quot;</span><span class=p>,</span>
        <span class=s2>&quot;class&quot;</span><span class=p>:</span> <span class=s2>&quot;contact&quot;</span>
    <span class=p>},</span>
    <span class=p>{</span>
        <span class=s2>&quot;question&quot;</span><span class=p>:</span> <span class=s2>&quot;How do I make homemade bread?&quot;</span><span class=p>,</span>
        <span class=s2>&quot;class&quot;</span><span class=p>:</span> <span class=s2>&quot;irrelevant&quot;</span>
    <span class=p>},</span>
    <span class=p>{</span>
        <span class=s2>&quot;question&quot;</span><span class=p>:</span> <span class=s2>&quot;What are some popular tourist attractions in Rome?&quot;</span><span class=p>,</span>
        <span class=s2>&quot;class&quot;</span><span class=p>:</span> <span class=s2>&quot;vacation&quot;</span>
    <span class=p>},</span>
    <span class=p>{</span>
        <span class=s2>&quot;question&quot;</span><span class=p>:</span> <span class=s2>&quot;Can I speak with a manager about my recent experience?&quot;</span><span class=p>,</span>
        <span class=s2>&quot;class&quot;</span><span class=p>:</span> <span class=s2>&quot;contact&quot;</span>
    <span class=p>},</span>
    <span class=p>{</span>
        <span class=s2>&quot;question&quot;</span><span class=p>:</span> <span class=s2>&quot;What&#39;s the best time to visit Japan?&quot;</span><span class=p>,</span>
        <span class=s2>&quot;class&quot;</span><span class=p>:</span> <span class=s2>&quot;vacation&quot;</span>
    <span class=p>},</span>
    <span class=p>{</span>
        <span class=s2>&quot;question&quot;</span><span class=p>:</span> <span class=s2>&quot;How do I reset my Netflix password?&quot;</span><span class=p>,</span>
        <span class=s2>&quot;class&quot;</span><span class=p>:</span> <span class=s2>&quot;irrelevant&quot;</span>
    <span class=p>},</span>
    <span class=p>{</span>
        <span class=s2>&quot;question&quot;</span><span class=p>:</span> <span class=s2>&quot;Are there any good ski resorts in Colorado?&quot;</span><span class=p>,</span>
        <span class=s2>&quot;class&quot;</span><span class=p>:</span> <span class=s2>&quot;vacation&quot;</span>
    <span class=p>},</span>
    <span class=p>{</span>
        <span class=s2>&quot;question&quot;</span><span class=p>:</span> <span class=s2>&quot;I need help with my online booking.&quot;</span><span class=p>,</span>
        <span class=s2>&quot;class&quot;</span><span class=p>:</span> <span class=s2>&quot;contact&quot;</span>
    <span class=p>},</span>
    <span class=p>{</span>
        <span class=s2>&quot;question&quot;</span><span class=p>:</span> <span class=s2>&quot;What&#39;s the plot of the latest Marvel movie?&quot;</span><span class=p>,</span>
        <span class=s2>&quot;class&quot;</span><span class=p>:</span> <span class=s2>&quot;irrelevant&quot;</span>
    <span class=p>},</span>
    <span class=p>{</span>
        <span class=s2>&quot;question&quot;</span><span class=p>:</span> <span class=s2>&quot;Can you suggest some budget-friendly European cities?&quot;</span><span class=p>,</span>
        <span class=s2>&quot;class&quot;</span><span class=p>:</span> <span class=s2>&quot;vacation&quot;</span>
    <span class=p>},</span>
    <span class=p>{</span>
        <span class=s2>&quot;question&quot;</span><span class=p>:</span> <span class=s2>&quot;How do I request a refund for my canceled trip?&quot;</span><span class=p>,</span>
        <span class=s2>&quot;class&quot;</span><span class=p>:</span> <span class=s2>&quot;contact&quot;</span>
    <span class=p>},</span>
    <span class=p>{</span>
        <span class=s2>&quot;question&quot;</span><span class=p>:</span> <span class=s2>&quot;What&#39;s the best way to train a puppy?&quot;</span><span class=p>,</span>
        <span class=s2>&quot;class&quot;</span><span class=p>:</span> <span class=s2>&quot;irrelevant&quot;</span>
    <span class=p>},</span>
    <span class=p>{</span>
        <span class=s2>&quot;question&quot;</span><span class=p>:</span> <span class=s2>&quot;Are there any good wildlife safaris in Africa?&quot;</span><span class=p>,</span>
        <span class=s2>&quot;class&quot;</span><span class=p>:</span> <span class=s2>&quot;vacation&quot;</span>
    <span class=p>},</span>
    <span class=p>{</span>
        <span class=s2>&quot;question&quot;</span><span class=p>:</span> <span class=s2>&quot;I need to change my flight reservation.&quot;</span><span class=p>,</span>
        <span class=s2>&quot;class&quot;</span><span class=p>:</span> <span class=s2>&quot;contact&quot;</span>
    <span class=p>},</span>
    <span class=p>{</span>
        <span class=s2>&quot;question&quot;</span><span class=p>:</span> <span class=s2>&quot;What are some must-see landmarks in New York City?&quot;</span><span class=p>,</span>
        <span class=s2>&quot;class&quot;</span><span class=p>:</span> <span class=s2>&quot;vacation&quot;</span>
    <span class=p>},</span>
    <span class=p>{</span>
        <span class=s2>&quot;question&quot;</span><span class=p>:</span> <span class=s2>&quot;How do I fix a leaky faucet?&quot;</span><span class=p>,</span>
        <span class=s2>&quot;class&quot;</span><span class=p>:</span> <span class=s2>&quot;irrelevant&quot;</span>
    <span class=p>},</span>
    <span class=p>{</span>
        <span class=s2>&quot;question&quot;</span><span class=p>:</span> <span class=s2>&quot;Can you recommend some romantic getaways for couples?&quot;</span><span class=p>,</span>
        <span class=s2>&quot;class&quot;</span><span class=p>:</span> <span class=s2>&quot;vacation&quot;</span>
    <span class=p>},</span>
    <span class=p>{</span>
        <span class=s2>&quot;question&quot;</span><span class=p>:</span> <span class=s2>&quot;I have a question about my loyalty points balance.&quot;</span><span class=p>,</span>
        <span class=s2>&quot;class&quot;</span><span class=p>:</span> <span class=s2>&quot;contact&quot;</span>
    <span class=p>},</span>
    <span class=p>{</span>
        <span class=s2>&quot;question&quot;</span><span class=p>:</span> <span class=s2>&quot;What&#39;s the best way to prepare for a job interview?&quot;</span><span class=p>,</span>
        <span class=s2>&quot;class&quot;</span><span class=p>:</span> <span class=s2>&quot;irrelevant&quot;</span>
    <span class=p>},</span>
    <span class=p>{</span>
        <span class=s2>&quot;question&quot;</span><span class=p>:</span> <span class=s2>&quot;Tell me about my travel history&quot;</span><span class=p>,</span>
        <span class=s2>&quot;class&quot;</span><span class=p>:</span> <span class=s2>&quot;vacation&quot;</span>
    <span class=p>},</span>

<span class=p>]</span>
</code></pre></div> <p>In this notebook, we use FAISS (Facebook AI Similarity Search) <a href=https://github.com/facebookresearch/faiss>(github)</a>, which is an open-source library developed by Facebook AI Research for efficient similarity search and clustering of dense vector embeddings. We call the Lanchain's <code>FAISS</code> object to interact with the in-memory vector store.</p> <p>We embed the examples using the Titan Embedding model.</p> <div class=highlight><pre><span></span><code><span class=n>embedding_size</span> <span class=o>=</span> <span class=mi>1536</span>
<span class=n>index</span> <span class=o>=</span> <span class=n>faiss</span><span class=o>.</span><span class=n>IndexFlatL2</span><span class=p>(</span><span class=n>embedding_size</span><span class=p>)</span>
<span class=n>embedding_fn</span> <span class=o>=</span> <span class=n>embeddings</span><span class=o>.</span><span class=n>embed_query</span>
<span class=n>vectorstore</span> <span class=o>=</span> <span class=n>FAISS</span><span class=p>(</span><span class=n>embedding_fn</span><span class=p>,</span> <span class=n>index</span><span class=p>,</span> <span class=n>InMemoryDocstore</span><span class=p>({}),</span> <span class=p>{})</span>
</code></pre></div> <pre><code>`embedding_function` is expected to be an Embeddings object, support for passing in a function will soon be removed.
</code></pre> <p>We use <code>SemanticSimilarityExampleSelector</code> to dynamically select the <code>k</code> most relevant examples based on our query. When instantiated, this object embeds the set of examples into our vector store of choice. <code>FewShotChatMessagePromptTemplate</code> defines the formatting of the selected examples into a given prompt. We define the template to be consistent with what will be generated by the model during intent classification.</p> <div class=highlight><pre><span></span><code><span class=n>example_selector</span> <span class=o>=</span> <span class=n>SemanticSimilarityExampleSelector</span><span class=o>.</span><span class=n>from_examples</span><span class=p>(</span>
    <span class=n>few_shot_library</span><span class=p>,</span>
    <span class=n>embeddings</span><span class=p>,</span>
    <span class=n>vectorstore</span><span class=p>,</span>
    <span class=n>k</span><span class=o>=</span><span class=mi>5</span><span class=p>,</span>
<span class=p>)</span>

<span class=n>few_shot_prompt</span> <span class=o>=</span> <span class=n>FewShotChatMessagePromptTemplate</span><span class=p>(</span>
    <span class=n>example_selector</span><span class=o>=</span><span class=n>example_selector</span><span class=p>,</span>
    <span class=n>example_prompt</span><span class=o>=</span><span class=p>(</span>
        <span class=n>HumanMessagePromptTemplate</span><span class=o>.</span><span class=n>from_template</span><span class=p>(</span><span class=s2>&quot;</span><span class=si>{question}</span><span class=s2>&quot;</span><span class=p>)</span>
        <span class=o>+</span> <span class=n>AIMessagePromptTemplate</span><span class=o>.</span><span class=n>from_template</span><span class=p>(</span><span class=s2>&quot;&lt;intention&gt;</span><span class=si>{class}</span><span class=s2>&lt;/intention&gt;&quot;</span><span class=p>)</span>
    <span class=p>),</span>
    <span class=n>input_variables</span><span class=o>=</span><span class=p>[</span><span class=s2>&quot;question&quot;</span><span class=p>],</span>
<span class=p>)</span>
</code></pre></div> <p>We print the relevant examples for a given query. Notice that the distribution of labels will change based on the nature of the query. This helps further align the model with our expectations.</p> <div class=highlight><pre><span></span><code><span class=nb>print</span><span class=p>(</span><span class=n>few_shot_prompt</span><span class=o>.</span><span class=n>format</span><span class=p>(</span><span class=n>question</span><span class=o>=</span><span class=s2>&quot;tell me about my travels&quot;</span><span class=p>))</span>
</code></pre></div> <pre><code>Human: Tell me about my travel history
AI: &lt;intention&gt;vacation&lt;/intention&gt;
Human: I'd like to book an all-inclusive Caribbean cruise.
AI: &lt;intention&gt;vacation&lt;/intention&gt;
Human: Can you suggest some budget-friendly European cities?
AI: &lt;intention&gt;vacation&lt;/intention&gt;
Human: Can I speak with a manager about my recent experience?
AI: &lt;intention&gt;contact&lt;/intention&gt;
Human: How do I request a refund for my canceled trip?
AI: &lt;intention&gt;contact&lt;/intention&gt;
</code></pre> <p>We redefine the system prompt to accomodate for the dynamic few-shots.</p> <div class=highlight><pre><span></span><code><span class=n>few_shot_intent_system_prompt</span> <span class=o>=</span> <span class=s2>&quot;&quot;&quot;You are a precise classifier. Your task is to assess customer intent and categorize customer inquiry into one of the intentions. </span>

<span class=s2>Intentions with their description:</span>
<span class=s2>vacation: Information on vacations, various travel destinations and my recent travels.</span>
<span class=s2>contact: Expressing the desire to talk to support.</span>
<span class=s2>irrelevant: Not related to vacations and travel.</span>

<span class=s2>Here is an example of how to respond in a standard interaction:</span>
<span class=s2>&quot;&quot;&quot;</span>
</code></pre></div> <p>We redefine the prompt template to accomodate for the dynamic few-shots. As expected, the final string created from <code>intent_detection_prompt</code> will change based on message similarity to previous examples.</p> <div class=highlight><pre><span></span><code><span class=n>few_shot_intent_detection_prompt</span> <span class=o>=</span> <span class=n>ChatPromptTemplate</span><span class=o>.</span><span class=n>from_messages</span><span class=p>(</span>
    <span class=p>[</span>
        <span class=p>(</span><span class=s2>&quot;system&quot;</span><span class=p>,</span> <span class=n>few_shot_intent_system_prompt</span><span class=p>),</span>
        <span class=n>few_shot_prompt</span><span class=p>,</span>
        <span class=p>(</span><span class=s2>&quot;human&quot;</span><span class=p>,</span> <span class=s2>&quot;Think step-by-step and always ensure you insert the classification in &lt;intention&gt;&lt;/intention&gt; tags and do not include anything after.</span><span class=se>\</span>
<span class=s2>        Here is the customer&#39;s question: &lt;question&gt;</span><span class=si>{question}</span><span class=s2>&lt;/question&gt; How do you answer to the instructions?&quot;</span><span class=p>),</span>
    <span class=p>]</span>
<span class=p>)</span>
<span class=n>few_shot_intent_chain</span> <span class=o>=</span> <span class=n>intent_detection_prompt</span> <span class=o>|</span> <span class=n>haiku</span>
</code></pre></div> <p>We test the newly created chain.</p> <div class=highlight><pre><span></span><code><span class=n>few_shot_intent_chain</span><span class=o>.</span><span class=n>invoke</span><span class=p>({</span><span class=s2>&quot;question&quot;</span><span class=p>:</span> <span class=s2>&quot;tell me about my travel history&quot;</span><span class=p>})</span><span class=o>.</span><span class=n>content</span>
</code></pre></div> <h3>Normalizing the user message</h3> <p>We may want to restrict the queries that are sent to downstream inference without restricting the user experience. Normalizing messages enables us to do exactly this. It can often be used to set a certain tone, reduce length and extract the specific purpose of the message while reducing unecessary noise. Notice the role the rule book plays in determining the nature of the returned message.</p> <p>Alternatively, it is common to supply few-shot examples as we have done in the previous step. We again return the resulting message in between tags.</p> <div class=highlight><pre><span></span><code><span class=n>norm_system_prompt</span> <span class=o>=</span> <span class=s2>&quot;&quot;&quot;You are a precise message synthesizer. Your task is to write a condensed message encompassing the latest original message&#39;s intent and main keywords. </span>
<span class=s2>The condensed message must follow the rule book.</span>

<span class=s2>Rule book:</span>
<span class=s2>- Must be a complete sentence formulated as a request from the perspective of the original requester.</span>
<span class=s2>- No longer than 2 short sentences with no concatination.</span>
<span class=s2>- Never include names.</span>
<span class=s2>- It is safe to reformulate questions with only keyword as looking for information on the place they mention.</span>

<span class=s2>Think about your answer first before you respond. Think step-by-step and the condensed message in &lt;condensed_message&gt;&lt;/condensed message&gt; tags and do not include anything after.&quot;&quot;&quot;</span>
</code></pre></div> <p>We define the prompt template incorporating the system prompt with the user defined message. </p> <div class=highlight><pre><span></span><code><span class=n>norm_prompt</span> <span class=o>=</span> <span class=n>ChatPromptTemplate</span><span class=o>.</span><span class=n>from_messages</span><span class=p>(</span>
    <span class=p>[</span>
        <span class=p>(</span><span class=s2>&quot;system&quot;</span><span class=p>,</span> <span class=n>norm_system_prompt</span><span class=p>),</span>
        <span class=p>(</span><span class=s2>&quot;human&quot;</span><span class=p>,</span> <span class=s2>&quot;Here is the customer&#39;s question: &lt;question&gt;</span><span class=si>{question}</span><span class=s2>&lt;/question&gt; How do you answer to the instructions?&quot;</span><span class=p>),</span>
    <span class=p>]</span>
<span class=p>)</span>
<span class=n>norm_chain</span> <span class=o>=</span> <span class=n>norm_prompt</span> <span class=o>|</span> <span class=n>haiku</span>
</code></pre></div> <p>When executing the chain on a longer query, the returned message pulls out only the information necessary to the task at hand.</p> <div class=highlight><pre><span></span><code><span class=n>norm_chain</span><span class=o>.</span><span class=n>invoke</span><span class=p>({</span><span class=s2>&quot;question&quot;</span><span class=p>:</span> <span class=s2>&quot;&quot;&quot;I have been all around the world seing a bunch of stuff. </span>
<span class=s2>I met a bunch of people like Bernard and Tamy. Tell me about my travel history&quot;&quot;&quot;</span><span class=p>})</span><span class=o>.</span><span class=n>content</span>
</code></pre></div> <p>When executing the chain on a query that only has keywords, the model fills in the gap to provide additional context. Although the initial queries are quite different, notice that their resulting output is quite similar.</p> <div class=highlight><pre><span></span><code><span class=n>norm_chain</span><span class=o>.</span><span class=n>invoke</span><span class=p>({</span><span class=s2>&quot;question&quot;</span><span class=p>:</span> <span class=s2>&quot;&quot;&quot;New York&quot;&quot;&quot;</span><span class=p>})</span><span class=o>.</span><span class=n>content</span>
</code></pre></div> <p>Once we have detected the message's intent and normalized it to some extent, we are able to have much greater assurance as to the nature of the messages sent to subsequent steps, namely the retrieval.</p> <h2>Advanced methods of retrieval</h2> <p>The main driver of performance for RAG pipelines is the retrieval mechanism. This step involves identifying a subset of documents that are most relevant to the original query. The common baseline is generally to embed the query in its original form and pull the top-K nearest documents. However, for some datasets this begins to fall short in cases where queries address multiple topics or, more generally, are phrased in a way that is incompatible or is dissimilar to the documents that should be retrieved. We look at how it is possible to improve on these types of queries. </p> <p>Given the increase complexity of the tasks in this section, we choose to leverage Claude 3 Sonnet in this part of the pipeline. </p> <div class=highlight><pre><span></span><code><span class=n>modelId</span> <span class=o>=</span> <span class=s1>&#39;anthropic.claude-3-sonnet-20240229-v1:0&#39;</span>
<span class=n>sonnet</span> <span class=o>=</span> <span class=n>ChatBedrock</span><span class=p>(</span>
    <span class=n>model_id</span><span class=o>=</span><span class=n>modelId</span><span class=p>,</span>
    <span class=n>client</span><span class=o>=</span><span class=n>bedrock</span><span class=p>,</span>
    <span class=n>beta_use_converse_api</span><span class=o>=</span><span class=kc>True</span>
<span class=p>)</span>
</code></pre></div> <h3>Decomposition</h3> <p>For more complex queries, it may be helpful to breakdown the original question into sub-problems each having their own retrieval step. We perform query decomposition to return the original question or an equivalent set of questions each with a single target.</p> <p>This process is driven by the underlying model. We define the system prompt describing the intended task and supply static few-shot examples to enable the model to better generalize. Removing these examples yields results that are less robust.</p> <div class=highlight><pre><span></span><code><span class=n>decomp_system_prompt</span> <span class=o>=</span> <span class=s2>&quot;&quot;&quot;You are a expert assistant that prepares queries that will be sent to a search component. </span>
<span class=s2>These queries may be very complex. Your job is to simplify complex queries into multiple queries that can be answered in isolation to eachother.</span>

<span class=s2>If the query is simple, then keep it as it is.</span>

<span class=s2>If there are acronyms or words you are not familiar with, do not try to rephrase them.</span>
<span class=s2>Here is an example of how to respond in a standard interaction:</span>
<span class=s2>&lt;example&gt;</span>
<span class=s2>- Query: Did Meta or Nvidia make more money last year?</span>
<span class=s2>Decomposed Questions: [SubQuery(sub_query=&#39;How much profit did Meta make last year?&#39;), SubQuery(sub_query&#39;How much profit did Nvidia make last year?&#39;)]</span>
<span class=s2>&lt;/example&gt;</span>
<span class=s2>&lt;example&gt;</span>
<span class=s2>- Query: What is the capital of France?</span>
<span class=s2>Decomposed Questions: [SubQuery(sub_query=&#39;What is the capital of France?&#39;)]</span>
<span class=s2>&lt;/example&gt;&quot;&quot;&quot;</span>
</code></pre></div> <p>To ensure a consistent format is returned for subsequent steps, we use Pydantic, a data-validation library. We rely on a Pydantic-based helper function for doing the tool config translation for us in a way that ensures we avoid potential mistakes when defining our tool config schema in a JSON dictionary.</p> <p>We define <code>SubQuery</code> to be a query corresponding to a subset of the points of a larger parent query. </p> <div class=highlight><pre><span></span><code><span class=k>class</span> <span class=nc>SubQuery</span><span class=p>(</span><span class=n>BaseModel</span><span class=p>):</span>
<span class=w>    </span><span class=sd>&quot;&quot;&quot;You have performed query decomposition to generate a subquery of a question&quot;&quot;&quot;</span>

    <span class=n>sub_query</span><span class=p>:</span> <span class=nb>str</span> <span class=o>=</span> <span class=n>Field</span><span class=p>(</span><span class=n>description</span><span class=o>=</span><span class=s2>&quot;A unique subquery of the original question.&quot;</span><span class=p>)</span>
</code></pre></div> <p>We define the prompt template leveraging the previously defined system prompt. We then expose <code>SubQuery</code> as a tool the model can leverage. This enables to model to format one or more requests to this tool.</p> <div class=highlight><pre><span></span><code><span class=n>query_decomposition_prompt</span> <span class=o>=</span> <span class=n>ChatPromptTemplate</span><span class=o>.</span><span class=n>from_messages</span><span class=p>(</span>
    <span class=p>[</span>
        <span class=p>(</span><span class=s2>&quot;system&quot;</span><span class=p>,</span> <span class=n>decomp_system_prompt</span><span class=p>),</span>
        <span class=p>(</span><span class=s2>&quot;human&quot;</span><span class=p>,</span> <span class=s2>&quot;Here is the customer&#39;s question: &lt;question&gt;</span><span class=si>{question}</span><span class=s2>&lt;/question&gt; How do you answer to the instructions?&quot;</span><span class=p>),</span>
    <span class=p>]</span>
<span class=p>)</span>

<span class=n>llm_with_tools</span> <span class=o>=</span> <span class=n>sonnet</span><span class=o>.</span><span class=n>bind_tools</span><span class=p>([</span><span class=n>SubQuery</span><span class=p>])</span>
<span class=n>decomp_query_analyzer</span> <span class=o>=</span> <span class=n>query_decomposition_prompt</span> <span class=o>|</span> <span class=n>llm_with_tools</span> <span class=o>|</span> <span class=n>PydanticToolsParser</span><span class=p>(</span><span class=n>tools</span><span class=o>=</span><span class=p>[</span><span class=n>SubQuery</span><span class=p>])</span>
</code></pre></div> <p>We asking a broad question about multiple destinations, the model chooses to return multiple calls to <code>SubQuery</code>. Each can be sent for document retrieval in parallel, thus ensuring we do not encure additional latency beyond that of the model inferencing. </p> <div class=highlight><pre><span></span><code><span class=n>queries</span> <span class=o>=</span> <span class=n>decomp_query_analyzer</span><span class=o>.</span><span class=n>invoke</span><span class=p>({</span><span class=s2>&quot;question&quot;</span><span class=p>:</span> <span class=s2>&quot;How do go on vacation in thailand and in California?&quot;</span><span class=p>})</span>
<span class=n>queries</span>
</code></pre></div> <h3>Expansion</h3> <p>Query expansion is similar to decomposition in that it produces multiple queries as a strategy to improve the odds of hitting a relevant result. However, expansion returns multiple different wordings of the original query. </p> <p>We define the system prompt to consistently return 3 versions of the original query. </p> <div class=highlight><pre><span></span><code><span class=n>paraphrase_system_prompt</span> <span class=o>=</span> <span class=s2>&quot;&quot;&quot;You are an expert at converting user questions into database queries. </span>
<span class=s2>You have access to a database of travel destinations and a list of recent destinations for travelers. </span>

<span class=s2>Perform query expansion. If there are multiple common ways of phrasing a user question </span>
<span class=s2>or common synonyms for key words in the question, make sure to return multiple versions </span>
<span class=s2>of the query with the different phrasings.</span>

<span class=s2>If there are acronyms or words you are not familiar with, do not try to rephrase them.</span>

<span class=s2>Always return at least 3 versions of the question.&quot;&quot;&quot;</span>
</code></pre></div> <p>We define the prompt template leveraging the previously defined system prompt. We then expose <code>ParaphrasedQuery</code> as a tool the model can leverage. This enables to model to format one or more requests to this tool.</p> <div class=highlight><pre><span></span><code><span class=k>class</span> <span class=nc>ParaphrasedQuery</span><span class=p>(</span><span class=n>BaseModel</span><span class=p>):</span>
<span class=w>    </span><span class=sd>&quot;&quot;&quot;You have performed query expansion to generate a paraphrasing of a question.&quot;&quot;&quot;</span>

    <span class=n>paraphrased_query</span><span class=p>:</span> <span class=nb>str</span> <span class=o>=</span> <span class=n>Field</span><span class=p>(</span><span class=n>description</span><span class=o>=</span><span class=s2>&quot;A unique paraphrasing of the original question.&quot;</span><span class=p>)</span>
</code></pre></div> <p>We define the prompt template leveraging the previously defined system prompt. We then expose <code>ParaphrasedQuery</code> as a tool the model can leverage. This enables to model to format one or more requests to this tool.</p> <div class=highlight><pre><span></span><code><span class=n>query_expansion_prompt</span> <span class=o>=</span> <span class=n>ChatPromptTemplate</span><span class=o>.</span><span class=n>from_messages</span><span class=p>(</span>
    <span class=p>[</span>
        <span class=p>(</span><span class=s2>&quot;system&quot;</span><span class=p>,</span> <span class=n>paraphrase_system_prompt</span><span class=p>),</span>
        <span class=p>(</span><span class=s2>&quot;human&quot;</span><span class=p>,</span> <span class=s2>&quot;Here is the customer&#39;s question: &lt;question&gt;</span><span class=si>{question}</span><span class=s2>&lt;/question&gt; How do you answer to the instructions?&quot;</span><span class=p>),</span>
    <span class=p>]</span>
<span class=p>)</span>
<span class=n>llm_with_tools</span> <span class=o>=</span> <span class=n>sonnet</span><span class=o>.</span><span class=n>bind_tools</span><span class=p>([</span><span class=n>ParaphrasedQuery</span><span class=p>])</span>
<span class=n>query_expansion</span> <span class=o>=</span> <span class=n>query_expansion_prompt</span> <span class=o>|</span> <span class=n>llm_with_tools</span> <span class=o>|</span> <span class=n>PydanticToolsParser</span><span class=p>(</span><span class=n>tools</span><span class=o>=</span><span class=p>[</span><span class=n>ParaphrasedQuery</span><span class=p>])</span>
</code></pre></div> <p>Now no matter the nature of the query, the model generates alternatives that can be sent for retrieval in parallel.</p> <div class=highlight><pre><span></span><code><span class=n>query_expansion</span><span class=o>.</span><span class=n>invoke</span><span class=p>({</span><span class=s2>&quot;question&quot;</span><span class=p>:</span> <span class=s2>&quot;how to use travel to Canada and to Mexico?&quot;</span><span class=p>})</span>
</code></pre></div> <h3>Hypothetical Document Embeddings (HyDE)</h3> <p>Given that models have been trained large volumes of data, we can generate a relevant hypothetical document to answer the user question. Then for retrieval, this new (or <em>hypethetical</em>) document can be embedded with the original query. This approach has been shown in <a href=https://arxiv.org/abs/2212.10496>Precise Zero-Shot Dense Retrieval without Relevance Labels</a> to improve recall. We define the system prompt relevant to this task.</p> <div class=highlight><pre><span></span><code><span class=n>hyde_system_prompt</span> <span class=o>=</span> <span class=s2>&quot;&quot;&quot;You are an expert about travel destinations all over the worlds. Your task is to provide your best response based on the question.</span>
<span class=s2>You need to produce a high-quality and complete sentence hyper focused on answer the question. </span>
<span class=s2>Do not answer in bulletpoints.</span>

<span class=s2>Think about your answer first before you respond. Think step-by-step and the answer in &lt;hyde&gt;&lt;/hyde&gt; tags and do not include anything after.&quot;&quot;&quot;</span>
</code></pre></div> <p>We define the prompt template leveraging the previously defined system prompt.</p> <div class=highlight><pre><span></span><code><span class=n>hyde_prompt</span> <span class=o>=</span> <span class=n>ChatPromptTemplate</span><span class=o>.</span><span class=n>from_messages</span><span class=p>(</span>
    <span class=p>[</span>
        <span class=p>(</span><span class=s2>&quot;system&quot;</span><span class=p>,</span> <span class=n>hyde_system_prompt</span><span class=p>),</span>
        <span class=p>(</span><span class=s2>&quot;human&quot;</span><span class=p>,</span> <span class=s2>&quot;Here is the customer&#39;s question: &lt;question&gt;</span><span class=si>{question}</span><span class=s2>&lt;/question&gt; How do you answer to the instructions?&quot;</span><span class=p>),</span>
    <span class=p>]</span>
<span class=p>)</span>
<span class=n>hyde_chain</span> <span class=o>=</span> <span class=n>hyde_prompt</span> <span class=o>|</span> <span class=n>sonnet</span> <span class=o>|</span> <span class=n>StrOutputParser</span><span class=p>()</span>
</code></pre></div> <p>We produce a document for the query in between tags that is be appended at retrieval time.</p> <div class=highlight><pre><span></span><code><span class=n>queries</span> <span class=o>=</span> <span class=n>hyde_chain</span><span class=o>.</span><span class=n>invoke</span><span class=p>({</span><span class=s2>&quot;question&quot;</span><span class=p>:</span> <span class=s2>&quot;How do go on vacation in thailand and in California?&quot;</span><span class=p>})</span>
<span class=nb>print</span><span class=p>(</span><span class=n>queries</span><span class=p>)</span>
</code></pre></div> <pre><code>To answer this question while following the instructions, I would think step-by-step:
&lt;hyde&gt;To go on vacation in Thailand and California, you will need to plan two separate trips - one to Southeast Asia for Thailand and one to the western United States for California, as they are in very different regions of the world. For Thailand, you'll want to research top destinations like Bangkok, Phuket, Chiang Mai, and the islands in the Thai Gulf. Book flights, accommodations, tours/activities, and obtain any necessary travel documents. For California, some highlights include Los Angeles, San Francisco, Yosemite National Park, wine country in Napa/Sonoma, the beaches, and national parks like Joshua Tree. Again, you'll need to book airfare, lodging, transportation, and plan your itinerary based on your interests and travel dates. Be sure to look into any visa requirements for Thailand and factor in costs, jet lag, and travel time between the two very distant locations.&lt;/hyde&gt;
</code></pre> <p>In this section we demonstrated the possiblity of augmented the original message to produce stronger results. Naturally, this LLM-driven approach requires an additional inference, which introduces some additional latency. </p> <h2>Model answer generation</h2> <p>In most RAG pipelines, the number of documents shown to the model is driven by the retrieval mechanism. This generally returns up to some static number of documents provided they meeting the necessary similarity treshold. Often, this results in irrelevant documents being sent to the model for inference. Although we can easily intruct the model to ignore irrelevant documents, it is often useful for the model to explicitly call-out the documents it did use. Furthermore, many lines of research have demonstrated the effectiveness of enabling the model to correct itself. In both cases, we make an additional call to the model once an initial answer is generated in order to improve the output for the end-user. </p> <h3>Citation</h3> <p>We generate an output with <code>answer</code> and <code>docs</code> keys. <code>docs</code> contains a list of Langchain <code>Document</code> objects. These are the documents the model has picked as being relevant to answering the original query. Although the documents are currently returned with title and summaries, these keys are part of a <code>metadata</code> attribute letting you determine any number of field that may be relevant to be used by your application such as author, source URL, etc... </p> <p>We define the system prompt to generate the model answer. Note that this is a simple template that can be further augmented with additional sections better describing our task and intended output.</p> <div class=highlight><pre><span></span><code><span class=n>citation_system_prompt</span> <span class=o>=</span> <span class=s2>&quot;&quot;&quot;You&#39;re a helpful AI assistant. Given a user question and some article snippets, answer the user question. </span>
<span class=s2>If none of the articles answer the question, just say you don&#39;t know.</span>

<span class=s2>Here are the articles: </span><span class=si>{context}</span>
<span class=s2>&quot;&quot;&quot;</span>
</code></pre></div> <p>This prompt is past as part the broader chat template.</p> <div class=highlight><pre><span></span><code><span class=n>citation_prompt</span> <span class=o>=</span> <span class=n>ChatPromptTemplate</span><span class=o>.</span><span class=n>from_messages</span><span class=p>(</span>
    <span class=p>[</span>
        <span class=p>(</span><span class=s2>&quot;system&quot;</span><span class=p>,</span> <span class=n>citation_system_prompt</span><span class=p>),</span>
        <span class=p>(</span><span class=s2>&quot;human&quot;</span><span class=p>,</span> <span class=s2>&quot;Here is the customer&#39;s question: &lt;question&gt;</span><span class=si>{question}</span><span class=s2>&lt;/question&gt; How do you answer to the instructions?&quot;</span><span class=p>),</span>
    <span class=p>]</span>
<span class=p>)</span>

<span class=n>answer_generator</span> <span class=o>=</span> <span class=n>citation_prompt</span> <span class=o>|</span> <span class=n>sonnet</span> <span class=o>|</span> <span class=n>StrOutputParser</span><span class=p>()</span>
</code></pre></div> <p>Lets use the <code>WikipediaRetriever</code> allowing us to interact with the Wikipedia API.</p> <div class=highlight><pre><span></span><code><span class=n>wiki</span> <span class=o>=</span> <span class=n>WikipediaRetriever</span><span class=p>(</span><span class=n>top_k_results</span><span class=o>=</span><span class=mi>6</span><span class=p>,</span> <span class=n>doc_content_chars_max</span><span class=o>=</span><span class=mi>2000</span><span class=p>)</span>
</code></pre></div> <p>The <code>format_docs</code> helper function is used to format the documents returned by the retriever to make them more friendly to the model. We supply the document's title and summary snippet. At the end, we pass the function to a child of Lanchain's <code>Runnable</code> class. This simply enables us to call the function with a standard API (invoke, batch, stream, transform and compose). Many object in Langchain implement this interface including <code>BaseModel</code>. </p> <p>To demonstrate the power of citations, we also append an additional obviously irrelevant document to the formatted documents.</p> <div class=highlight><pre><span></span><code><span class=k>def</span> <span class=nf>format_docs</span><span class=p>(</span><span class=n>docs</span><span class=p>:</span> <span class=n>List</span><span class=p>[</span><span class=n>Document</span><span class=p>])</span> <span class=o>-&gt;</span> <span class=nb>str</span><span class=p>:</span>
<span class=w>    </span><span class=sd>&quot;&quot;&quot;Convert Documents to a single string.:&quot;&quot;&quot;</span>
    <span class=n>formatted</span> <span class=o>=</span> <span class=p>[</span>
        <span class=sa>f</span><span class=s2>&quot;Article Title: </span><span class=si>{</span><span class=n>doc</span><span class=o>.</span><span class=n>metadata</span><span class=p>[</span><span class=s1>&#39;title&#39;</span><span class=p>]</span><span class=si>}</span><span class=se>\n</span><span class=s2>Article Snippet: </span><span class=si>{</span><span class=n>doc</span><span class=o>.</span><span class=n>page_content</span><span class=si>}</span><span class=s2>&quot;</span>
        <span class=k>for</span> <span class=n>doc</span> <span class=ow>in</span> <span class=n>docs</span>
    <span class=p>]</span>
    <span class=n>formatted</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=s2>&quot;Article Title: This is an irrelevant document </span><span class=se>\</span>
<span class=s2>    Article Snippet: The document is most irrelevant.&quot;</span><span class=p>)</span>
    <span class=k>return</span> <span class=s2>&quot;</span><span class=se>\n\n</span><span class=s2>&quot;</span> <span class=o>+</span> <span class=s2>&quot;</span><span class=se>\n\n</span><span class=s2>&quot;</span><span class=o>.</span><span class=n>join</span><span class=p>(</span><span class=n>formatted</span><span class=p>)</span>


<span class=nb>format</span> <span class=o>=</span> <span class=n>itemgetter</span><span class=p>(</span><span class=s2>&quot;docs&quot;</span><span class=p>)</span> <span class=o>|</span> <span class=n>RunnableLambda</span><span class=p>(</span><span class=n>format_docs</span><span class=p>)</span>
</code></pre></div> <p>We define a chain as <code>RunnableParallel</code> object, which is an extention of <code>Runnable</code> that runs a mapping of Runnables in parallel, and returns a mapping of their outputs. We set the question property using <code>RunnablePassthrough</code>. This passes the input unchanged. Then, we assign values to keys in the prompt templates. </p> <div class=highlight><pre><span></span><code><span class=n>citation_chain</span> <span class=o>=</span> <span class=p>(</span>
    <span class=n>RunnableParallel</span><span class=p>(</span><span class=n>question</span><span class=o>=</span><span class=n>RunnablePassthrough</span><span class=p>(),</span> <span class=n>docs</span><span class=o>=</span><span class=n>wiki</span><span class=p>)</span>
    <span class=o>.</span><span class=n>assign</span><span class=p>(</span><span class=n>context</span><span class=o>=</span><span class=nb>format</span><span class=p>)</span>
    <span class=o>.</span><span class=n>assign</span><span class=p>(</span><span class=n>answer</span><span class=o>=</span><span class=n>answer_generator</span><span class=p>)</span>
    <span class=o>.</span><span class=n>pick</span><span class=p>([</span><span class=s2>&quot;answer&quot;</span><span class=p>,</span> <span class=s2>&quot;docs&quot;</span><span class=p>])</span>
<span class=p>)</span>
</code></pre></div> <p>When invoking the chain, it returns the original answer and the documents used for generation. Notice that some documents are relevant to the final answer and some are not. We can address this challenge with further LLM or metadata document filtering.</p> <div class=highlight><pre><span></span><code><span class=n>citation_chain</span><span class=o>.</span><span class=n>invoke</span><span class=p>(</span><span class=s2>&quot;How do go on vacation in thailand and in California?&quot;</span><span class=p>)</span>
</code></pre></div> <h3>Self-validation</h3> <p>Giving the model an opportunity to correct itself has been shown to increase performance on a number of tasks. We perform self-validation and define a set of formatting rules that align with the conversational tone we expect to have from our application. We define a system prompt with this task and set of rules.</p> <div class=highlight><pre><span></span><code><span class=n>valid_system_prompt</span> <span class=o>=</span> <span class=s2>&quot;&quot;&quot;You are a validator and message synthesize. </span>
<span class=s2>Your task is to create one coherent answer and double check the original responses to the question </span><span class=si>{question}</span><span class=s2> for common mistakes, including:</span>
<span class=s2>- Answer in bullet points. It should be a complete paragraph instead.</span>
<span class=s2>- Inaccuracies or things that seem impossible</span>

<span class=s2>If there are any of the above mistakes, rewrite the response. If there are no mistakes, just reproduce the original response.</span>
<span class=s2>Think about your answer first before you respond. </span>
<span class=s2>If some exist, put all the issues and then put your final response in &lt;validation&gt;&lt;/validation&gt; tags and do not include anything after.</span>
<span class=s2>&quot;&quot;&quot;</span>
</code></pre></div> <p>We define the prompt template with the system prompt and original model answer.</p> <div class=highlight><pre><span></span><code><span class=n>validation_prompt</span> <span class=o>=</span> <span class=n>ChatPromptTemplate</span><span class=o>.</span><span class=n>from_messages</span><span class=p>(</span>
    <span class=p>[</span>
        <span class=p>(</span><span class=s2>&quot;system&quot;</span><span class=p>,</span> <span class=n>valid_system_prompt</span><span class=p>),</span> 
        <span class=p>(</span><span class=s2>&quot;human&quot;</span><span class=p>,</span> <span class=s2>&quot;Here is the original message produced: &lt;orignal_message&gt;</span><span class=si>{original}</span><span class=s2>&lt;/orignal_message&gt; How do you answer to the instructions?&quot;</span><span class=p>)]</span>
<span class=p>)</span>
<span class=n>validation_chain</span> <span class=o>=</span> <span class=n>validation_prompt</span> <span class=o>|</span> <span class=n>sonnet</span> <span class=o>|</span> <span class=n>StrOutputParser</span><span class=p>()</span>
</code></pre></div> <p>We invoke model, which points out obvious issues in the original document and answers with a more consistent alternative. </p> <div class=highlight><pre><span></span><code><span class=n>validation</span> <span class=o>=</span> <span class=n>validation_chain</span><span class=o>.</span><span class=n>invoke</span><span class=p>({</span>
    <span class=s2>&quot;question&quot;</span> <span class=p>:</span> <span class=s2>&quot;how to go to thailand from Montreal?&quot;</span><span class=p>,</span>
    <span class=s2>&quot;original&quot;</span><span class=p>:</span> <span class=s2>&quot;1- by plane 2-by car.&quot;</span><span class=p>,</span>
<span class=p>})</span>
<span class=nb>print</span><span class=p>(</span><span class=n>validation</span><span class=p>)</span>
</code></pre></div> <h2>Putting it all together</h2> <p>The previous components offer important primitives to build a performant RAG solution. They act as building blocks of a broader solution. We provide an example showcasing how they can be brought together in a single chain to improve response accuracy. To minimize latency and improve accuracy, we use Claude Haiku for simpler tasks and Claude Sonnet where we need more performance. The pipeline is described by the following diagram.</p> <p><img src=./assets/rag-pipeline.png width=400 height=400></p> <p>First, we create helper functions to parse the return messages for the relevant section that can be found in between tags.</p> <div class=highlight><pre><span></span><code><span class=k>def</span> <span class=nf>parse_intent</span><span class=p>(</span><span class=n>ai_message</span><span class=p>:</span> <span class=n>AIMessage</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=nb>str</span><span class=p>:</span>
<span class=w>    </span><span class=sd>&quot;&quot;&quot;Parse the AI message.&quot;&quot;&quot;</span>
    <span class=n>intent_pattern</span> <span class=o>=</span> <span class=sa>r</span><span class=s2>&quot;&lt;intention&gt;(.*?)&lt;/intention&gt;&quot;</span>
    <span class=n>intent_match</span> <span class=o>=</span> <span class=n>re</span><span class=o>.</span><span class=n>findall</span><span class=p>(</span><span class=n>intent_pattern</span><span class=p>,</span> <span class=n>ai_message</span><span class=o>.</span><span class=n>content</span><span class=p>,</span> <span class=n>flags</span><span class=o>=</span><span class=mi>0</span><span class=p>)</span>
    <span class=k>if</span> <span class=n>intent_match</span><span class=p>:</span>
        <span class=k>return</span> <span class=n>intent_match</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span>
    <span class=k>else</span><span class=p>:</span>
        <span class=k>return</span> <span class=s2>&quot;No intention found.&quot;</span>

<span class=k>def</span> <span class=nf>parse_norm_message</span><span class=p>(</span><span class=n>ai_message</span><span class=p>:</span> <span class=n>AIMessage</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=nb>str</span><span class=p>:</span>
<span class=w>    </span><span class=sd>&quot;&quot;&quot;Parse the AI message.&quot;&quot;&quot;</span>
    <span class=n>norm_pattern</span> <span class=o>=</span> <span class=sa>r</span><span class=s2>&quot;&lt;condensed_message&gt;(.*?)&lt;/condensed_message&gt;&quot;</span>
    <span class=n>norm_match</span> <span class=o>=</span> <span class=n>re</span><span class=o>.</span><span class=n>findall</span><span class=p>(</span><span class=n>norm_pattern</span><span class=p>,</span> <span class=n>ai_message</span><span class=p>[</span><span class=s1>&#39;question&#39;</span><span class=p>]</span><span class=o>.</span><span class=n>content</span><span class=p>,</span> <span class=n>flags</span><span class=o>=</span><span class=mi>0</span><span class=p>)</span>
    <span class=k>if</span> <span class=n>norm_match</span><span class=p>:</span>
        <span class=k>return</span> <span class=n>norm_match</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span>
    <span class=k>else</span><span class=p>:</span>
        <span class=k>return</span> <span class=s2>&quot;Message could not be successfully normalized.&quot;</span>
</code></pre></div> <p>We define an end-to-end RAG chain primairly using LangChain Expression Language (LCEL), which allows us to define <code>Runnable</code> objects in success to one another. The resulting chain reuses many of the components we previously defined including intent detection with <strong>dynamic few-shots, message normalization and citation</strong>. </p> <div class=highlight><pre><span></span><code><span class=n>rag_chain</span> <span class=o>=</span> <span class=n>RunnableParallel</span><span class=p>(</span>
    <span class=n>question</span><span class=o>=</span><span class=n>RunnablePassthrough</span><span class=p>(),</span>
    <span class=n>intent</span><span class=o>=</span><span class=n>few_shot_intent_detection_prompt</span> <span class=o>|</span> <span class=n>haiku</span> <span class=o>|</span> <span class=n>parse_intent</span>
<span class=p>)</span> <span class=o>|</span> <span class=n>RunnableBranch</span><span class=p>(</span>
    <span class=p>(</span><span class=k>lambda</span> <span class=n>payload</span><span class=p>:</span> <span class=s2>&quot;vacation&quot;</span> <span class=o>==</span> <span class=n>payload</span><span class=p>[</span><span class=s2>&quot;intent&quot;</span><span class=p>]</span><span class=o>.</span><span class=n>lower</span><span class=p>(),</span> <span class=k>lambda</span> <span class=n>x</span><span class=p>:</span> <span class=p>(</span>
        <span class=n>RunnablePassthrough</span><span class=p>()</span><span class=o>.</span><span class=n>pick</span><span class=p>([</span><span class=s2>&quot;question&quot;</span><span class=p>])</span>
        <span class=o>.</span><span class=n>assign</span><span class=p>(</span><span class=n>question</span><span class=o>=</span><span class=n>norm_chain</span><span class=p>)</span>
        <span class=o>.</span><span class=n>assign</span><span class=p>(</span><span class=n>question</span><span class=o>=</span><span class=n>parse_norm_message</span><span class=p>)</span>
        <span class=o>.</span><span class=n>assign</span><span class=p>(</span><span class=n>context</span><span class=o>=</span><span class=k>lambda</span> <span class=n>inputs</span><span class=p>:</span> <span class=n>wiki</span><span class=o>.</span><span class=n>invoke</span><span class=p>(</span><span class=n>inputs</span><span class=p>[</span><span class=s2>&quot;question&quot;</span><span class=p>]))</span>
        <span class=o>.</span><span class=n>assign</span><span class=p>(</span><span class=n>answer</span><span class=o>=</span><span class=n>answer_generator</span><span class=p>)</span>
        <span class=o>.</span><span class=n>pick</span><span class=p>([</span><span class=s2>&quot;answer&quot;</span><span class=p>,</span> <span class=s2>&quot;context&quot;</span><span class=p>])</span>
    <span class=p>)),</span>
    <span class=p>(</span><span class=k>lambda</span> <span class=n>payload</span><span class=p>:</span> <span class=s2>&quot;irrelevant&quot;</span> <span class=o>==</span> <span class=n>payload</span><span class=p>[</span><span class=s2>&quot;intent&quot;</span><span class=p>]</span><span class=o>.</span><span class=n>lower</span><span class=p>(),</span> <span class=k>lambda</span> <span class=n>x</span><span class=p>:</span> <span class=n>AIMessage</span><span class=p>(</span><span class=n>content</span><span class=o>=</span><span class=s2>&quot;I am only able to answer questions about travel and vacations.&quot;</span><span class=p>)),</span>
    <span class=p>(</span><span class=k>lambda</span> <span class=n>payload</span><span class=p>:</span> <span class=s2>&quot;contact&quot;</span> <span class=o>==</span> <span class=n>payload</span><span class=p>[</span><span class=s2>&quot;intent&quot;</span><span class=p>]</span><span class=o>.</span><span class=n>lower</span><span class=p>(),</span> <span class=k>lambda</span> <span class=n>x</span><span class=p>:</span> <span class=n>AIMessage</span><span class=p>(</span><span class=n>content</span><span class=o>=</span><span class=s2>&quot;I am transfering you to an agent now...&quot;</span><span class=p>)),</span>
    <span class=k>lambda</span> <span class=n>payload</span><span class=p>:</span> <span class=n>AIMessage</span><span class=p>(</span><span class=n>content</span><span class=o>=</span><span class=s2>&quot;I am only able to answer questions about travel and vacations.&quot;</span> <span class=p>)</span>
<span class=p>)</span>

<span class=nb>print</span><span class=p>(</span><span class=n>rag_chain</span><span class=o>.</span><span class=n>invoke</span><span class=p>(</span><span class=s2>&quot;I want to know more about how to plan a vacation?&quot;</span><span class=p>))</span>
</code></pre></div> <p>It is evident that latency is increased in corralation with the number calls being made in succession. Hence, it is optimal to make calls in parallel where possible to reduce overall time to execute the entire pipeline. Notice in in our example that the intent detection could be made in parallel to message normalization and citation (model inference).</p> <p>Additionally, it may be benifitial to modify the pipeline to include a query augmentation step for reasons described earlier in the notebook.</p> <h2>Next steps</h2> <p>Where RAG enables single-turn conversations where users and agents alternate sending eachother messages, agents supply the ability to the application developer to build increased complexity into the conversation flow. These applications are characterized by increase <strong>autonomy, reactivity, proactiveness, adaptability and situatedness</strong>. They typically have some form of validation, the ability to loop back and call external functions to improve outputs. You can dive deeper into agents in the next lab of this workshop.</p> <h2>Clean up</h2> <p>There is no necessary clean up for this notebook.</p> <form class=md-feedback name=feedback hidden> <fieldset> <legend class=md-feedback__title> Was this page helpful? </legend> <div class=md-feedback__inner> <div class=md-feedback__list> <button class="md-feedback__icon md-icon" type=submit title="This page was helpful" data-md-value=1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M5 9v12H1V9zm4 12a2 2 0 0 1-2-2V9c0-.55.22-1.05.59-1.41L14.17 1l1.06 1.06c.27.27.44.64.44 1.05l-.03.32L14.69 8H21a2 2 0 0 1 2 2v2c0 .26-.05.5-.14.73l-3.02 7.05C19.54 20.5 18.83 21 18 21zm0-2h9.03L21 12v-2h-8.79l1.13-5.32L9 9.03z"/></svg> </button> <button class="md-feedback__icon md-icon" type=submit title="This page could be improved" data-md-value=0> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M19 15V3h4v12zM15 3a2 2 0 0 1 2 2v10c0 .55-.22 1.05-.59 1.41L9.83 23l-1.06-1.06c-.27-.27-.44-.64-.44-1.06l.03-.31.95-4.57H3a2 2 0 0 1-2-2v-2c0-.26.05-.5.14-.73l3.02-7.05C4.46 3.5 5.17 3 6 3zm0 2H5.97L3 12v2h8.78l-1.13 5.32L15 14.97z"/></svg> </button> </div> <div class=md-feedback__note> <div data-md-value=1 hidden> Thanks for your feedback! </div> <div data-md-value=0 hidden> Thanks for your feedback! Help us improve this page by <a href="https://github.com/aws-samples/amazon-bedrock-samples/issues/new?title=[Online Feedback]: Short-Summary-of-Issue&body=Page URL: /workshop/open-source-l400/02_Lab_Find%20a%20Dream%20Destination_RAG%20query/" target=_blank rel=noopener>creating an issue</a>. </div> </div> </div> </fieldset> </form> </article> </div> <script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script> </div> </main> <footer class=md-footer> <nav class="md-footer__inner md-grid" aria-label=Footer> <a href=../01_usecase_introduction/ class="md-footer__link md-footer__link--prev" aria-label="Previous: Introduction to the Use Case"> <div class="md-footer__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg> </div> <div class=md-footer__title> <span class=md-footer__direction> Previous </span> <div class=md-ellipsis> Introduction to the Use Case </div> </div> </a> <a href=../02_travel_planner_with_langgraph/ class="md-footer__link md-footer__link--next" aria-label="Next: Conversational Memory in Agents"> <div class=md-footer__title> <span class=md-footer__direction> Next </span> <div class=md-ellipsis> Conversational Memory in Agents </div> </div> <div class="md-footer__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11z"/></svg> </div> </a> </nav> <div class="md-footer-meta md-typeset"> <div class="md-footer-meta__inner md-grid"> <div class=md-copyright> <div class=md-copyright__highlight> Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved. </div> </div> <div class=md-social> <a href=https://github.com/aws-samples/amazon-bedrock-samples/tree/main target=_blank rel=noopener title=github.com class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 496 512"><!-- Font Awesome Free 6.7.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8M97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg> </a> </div> </div> </div> </footer> </div> <div class=md-dialog data-md-component=dialog> <div class="md-dialog__inner md-typeset"></div> </div> <script id=__config type=application/json>{"base": "../../..", "features": ["tags", "toc.integrate", "content.code.copy", "content.code.select", "content.code.annotate", "navigation.footer", "search.highlight", "search.suggest"], "search": "../../../assets/javascripts/workers/search.6ce7567c.min.js", "tags": {"Compatibility": "compat"}, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script> <script src=../../../assets/javascripts/bundle.88dd0f4e.min.js></script> <script src=../../../javascript/feedback.js></script> </body> </html>