import io
import os
import re
import time
import boto3
import string
import random
import streamlit as st
from datetime import datetime

os.environ['TZ'] = 'US/Pacific'
time.tzset()

def session_generator():
    # Generate random characters and digits
    digits = ''.join(random.choice(string.digits) for _ in range(4))  # Generating 4 random digits
    chars = ''.join(random.choice(string.ascii_lowercase) for _ in range(3))  # Generating 3 random characters

    # Construct the pattern (1a23b-4c)
    pattern = f"{digits[0]}{chars[0]}{digits[1:3]}{chars[1]}-{digits[3]}{chars[2]}"
    print("Session ID: " + str(pattern))

    return pattern

# Bedrock Variable
agentId = os.environ['BEDROCK_AGENT_ID']
agentAliasId = os.environ['BEDROCK_AGENT_ALIAS_ID']
profile_name = os.environ['PROFILE_NAME']

# AWS Session and Clients Instantiation
agent_client = boto3.Session(profile_name=profile_name).client('bedrock-agent-runtime')
s3_client = boto3.Session(profile_name=profile_name).client('s3')

# Streamlit CSS
custom_css = """
    <style>
        .text-with-bg {
        color: white;
            background-color: #1c2e4a; /* Change this to your desired background color */
            padding: 10px;
            border-radius: 5px;
        }

        .stSpinner {
            position: fixed;
            bottom: 20px;
            z-index: 10;
        }

        .st-emotion-cache-1ru4d5d, .st-emotion-cache-139wi93 {
            max-width: 70rem;
        }
        .st-emotion-cache-1dp5vir {
            background-image: linear-gradient(90deg, rgb(148, 241, 246), rgb(148, 189, 246));
        }
        .st-emotion-cache-1ghhuty {
            background-color: #87CEEB;
        }
        .st-co, .st-cn, .st-cm, .st-cm {
            border-bottom-color: rgba(28, 131, 225);
            border-top-color: rgba(28, 131, 225);
            border-right-color: rgba(28, 131, 225);
            border-left-color: rgba(28, 131, 225);
        }
    </style>
"""

# Streamlit App Layout
st.set_page_config(
    page_title="Titan Text Premier Demo"
)
st.title('Titan Text Premier- HR Assistant')
st.info("**DISCLAIMER:** This demo uses an Amazon Bedrock foundation model and is not intended to collect any personally identifiable information (PII) from users. Please do not provide any PII when interacting with this demo. The content generated by this demo is for informational purposes only.")
st.markdown(custom_css, unsafe_allow_html=True)
st.markdown(
    """
<style>
    .st-emotion-cache-4oy321 {
        padding: 1rem;
    }
</style>
""",
    unsafe_allow_html=True,
)

# Invoke Agent
def bedrock_agent(query, sessionId):
    ref=None
    if query is not None:
        agent_query = {
            "inputText": query,
            "enableTrace": True,
        }

        # invoke the agent API
        agentResponse = agent_client.invoke_agent(
            inputText=query,
            agentId=agentId,
            agentAliasId=agentAliasId,
            sessionId=sessionId,
            enableTrace=True
        )
        event_stream = agentResponse['completion']
        agent_answer = ""
        try:
            for event in event_stream:
                if 'chunk' in event:
                    data = event['chunk']['bytes']
                    print(f"Final answer ->\n{data.decode('utf8')}")
                    agent_answer = data.decode('utf8')
                elif 'trace' in event:
                    print(event['trace'])
                    if 'orchestrationTrace' in event['trace']['trace'].keys():
                        if 'observation' in event['trace']['trace']['orchestrationTrace'].keys():
                            if 'knowledgeBaseLookupOutput' in event['trace']['trace']['orchestrationTrace']['observation'].keys():
                                refs = event['trace']['trace']['orchestrationTrace']['observation']['knowledgeBaseLookupOutput']['retrievedReferences']
                                ref = refs[0]['location']['s3Location']['uri']
                                print(ref)
                else:
                    print("unexpected event.", event)
        except Exception as e:
            print("unexpected event.", e)
            agent_answer = str(e)
        print(agent_answer)
        agent_answer = agent_answer.replace("$", "\$")
        return agent_answer, ref

# Get S3 file contents
def get_file_from_s3(path):
    bucket_object_pattern = r"s3://([^/]+)/(.+)"
    match = re.match(bucket_object_pattern, path)

    bucket_name, object_key = match.groups()

    response = s3_client.get_object(Bucket=bucket_name, Key=object_key)
    file_content = response["Body"].read()
    return file_content

def render_s3_image(agent_response):
    s3_path_pattern = r"s3://[^\s<.\"]+"
    s3_paths = re.findall(s3_path_pattern, agent_response)
    if s3_paths:
        file_content = get_file_from_s3(s3_paths[0])
        st.image(io.BytesIO(file_content), caption="Image from S3", width=256)

def parse_trace(trace):
    current_step = ""
    if 'trace' in trace:
        trace_message = trace['trace']
        if 'orchestrationTrace' in trace_message:
            orchestration_trace = trace_message['orchestrationTrace']
            print("=======================")
            print(orchestration_trace)
            print("=======================")
            if 'modelInvocationInput' in orchestration_trace:
                current_step = "Executing orchestration step..."
                modelInvocationInput = orchestration_trace['modelInvocationInput']
                if 'type' in modelInvocationInput:
                    modelInvocationType = modelInvocationInput['type']
                    if modelInvocationType == "PRE_PROCESSING":
                        current_step = "Executing pre-processsing step"
                    elif modelInvocationType == "ORCHESTRATION":
                        current_step = "Thinking about next step..."
                    elif modelInvocationType == "KNOWLEDGE_BASE_RESPONSE_GENERATION":
                        current_step = "Generating response from knowledge base"
                    elif modelInvocationType == "POST_PROCESSING":
                        current_step = "Executing post-processsing step"
            elif 'rationale' in orchestration_trace:
                rationale = orchestration_trace['rationale']
                current_step = ""
                if rationale['text']:
                    current_step = "Reasoning for next steps: " + rationale['text'].replace("\n", " ")
            elif 'invocationInput' in orchestration_trace:
                invocationInput = orchestration_trace['invocationInput']
                current_step = "Invoking action group or knowledge base"
                if 'invocationType' in invocationInput:
                    invocationType = invocationInput['invocationType']
                    if invocationType == "KNOWLEDGE_BASE":
                        current_step = "Invoking knowledge base"
                        if 'knowledgeBaseLookupInput' in invocationInput:
                            knowledgeBaseLookupInput = invocationInput['knowledgeBaseLookupInput']
                            if knowledgeBaseLookupInput['text']:
                                current_step = "Searching knowledge base for \"" + knowledgeBaseLookupInput['text'].replace("\n", " ") + "\""
                    elif invocationType == "ACTION_GROUP":
                        current_step = "Invoking action group"
                        if 'actionGroupInvocationInput' in invocationInput:
                            actionGroupInvocationInput = invocationInput['actionGroupInvocationInput']
                            if actionGroupInvocationInput['apiPath']:
                                current_step = "Invoking action group API " + actionGroupInvocationInput['apiPath'].replace("\n", " ")
            elif 'observation' in orchestration_trace:
                observation = orchestration_trace['observation']
                current_step = "Processing the output of an action group, knowledge base, or the response"
                if 'type' in observation:
                    observationType = observation['type']
                    if observationType == "ACTION_GROUP":
                        current_step = "Processing action group output"
                    elif observationType == "KNOWLEDGE_BASE":
                        current_step = "Processing knowledge base output"
                    elif observationType == "FINISH":
                        current_step = "Generating final response"
        elif 'postProcessingTrace' in trace_message:
            current_step = "Executing post-processing step, shaping the response"
        elif 'preProcessingTrace' in trace_message:
            current_step = "Executing pre-processing step, contextualing and categorizing the inputs"
    return current_step


timestamp_string = "<p style='text-align: right;'><small>{}</small></p>"
def main():
    # Initialize chat history
    turn_counter=0
    if "messages" not in st.session_state:
        st.session_state.messages = []
    # Display chat messages from history on app rerun
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.write(message["content"], unsafe_allow_html=True)
        render_s3_image(message["content"])

    # Accept user input
    if prompt := st.chat_input("Enter prompt here"):
        turn_counter=turn_counter+1
        # Add user message to chat history
        user_now = datetime.now()
        user_current_time = timestamp_string.format(user_now.strftime("%H:%M:%S"))
        st.session_state.messages.append({"role": "user", "content": prompt, "timestamp": user_current_time})
        # Display user message in chat message container
        with st.chat_message("user"):
            st.write(prompt, unsafe_allow_html=True)

        if "session_id" not in st.session_state:
            st.session_state["session_id"] = session_generator()
        sessionId = st.session_state["session_id"]

        with st.spinner("Agent is researching..."):
            agent_response, ref = bedrock_agent(prompt, sessionId)

        agent_now = datetime.now()
        agent_current_time = timestamp_string.format(agent_now.strftime("%H:%M:%S"))
        with st.chat_message("assistant"):
            if ref is not None and turn_counter<2:
                # from streamlit_extras.mention import mention
                file = ref.split('/')[-1]
                s3_bucket = ref.split('//')[1].split('/')[0]
                s3_url = f'https://us-east-1.console.aws.amazon.com/s3/object/{s3_bucket}?region=us-east-1&bucketType=general&prefix={file}'
                s3_url = s3_url.replace(' ', '')
                agent_response += f'[[1]]({s3_url})'
            st.write(agent_response, unsafe_allow_html=True)
        render_s3_image(agent_response)

        st.session_state.messages.append({"role": "assistant", "content": agent_response, "timestamp": agent_current_time})

# Call the main function to run the app
if __name__ == "__main__":
    main()