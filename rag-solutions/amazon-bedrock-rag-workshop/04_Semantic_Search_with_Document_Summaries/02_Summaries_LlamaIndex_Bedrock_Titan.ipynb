{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ade42be5-7813-4aa6-9f4f-aad4318d4175",
   "metadata": {},
   "source": [
    "# Llama Document Summary Index With Amazon Bedrock Titan Model\n",
    "\n",
    "This demo showcases the document summary index, over IRS Forms.\n",
    "\n",
    "The document summary index will extract a summary from each document and store that summary, as well as all nodes corresponding to the document.\n",
    "\n",
    "Retrieval can be performed through the LLM or embeddings. We first select the relevant documents to the query based on their summaries. All retrieved nodes corresponding to the selected documents are retrieved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302280ea-beb4-4742-afa1-1e197a1052cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!cd .. && ./download-dependencies.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c907a463-ccf3-4970-9ab6-a54c88f5c5f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import subprocess\n",
    "\n",
    "botocore_whl_filename = glob.glob(\"../dependencies/botocore-*-py3-none-any.whl\")[0]\n",
    "boto3_whl_filename = glob.glob(\"../dependencies/boto3-*-py3-none-any.whl\")[0]\n",
    "\n",
    "subprocess.Popen(['pip', 'install', botocore_whl_filename, boto3_whl_filename, '--force-reinstall'], bufsize=1, universal_newlines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fef77a51-1820-48c9-b1f4-c9b072a801ba",
   "metadata": {},
   "source": [
    "This notebook demonstrates invoking Bedrock models directly using the AWS SDK, but for later notebooks in the workshop you'll also need to install [LangChain](https://github.com/hwchase17/langchain):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaba4dd7-664e-41d0-bbe5-2f2971be66b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%pip install pydantic==1.10.12 --force-reinstall "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a89172a-70f1-4b53-ab43-7b6785e4aa20",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# langchain==0.0.266 is required by llama-index==0.8.8\n",
    "%pip install langchain==0.0.266 \\\n",
    "    pypdf==3.15.2 \\\n",
    "    llama-index==0.8.8 \\\n",
    "    sentence_transformers==2.2.2 --force-reinstall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b6d4d55-2a2f-41d5-aa32-159d6bc406fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb7288e-22f8-4753-a6ea-197cf2f8aba5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from llama_index import (\n",
    "    SimpleDirectoryReader,\n",
    "    LLMPredictor,\n",
    "    ServiceContext,\n",
    "    get_response_synthesizer,\n",
    "    set_global_service_context\n",
    ")\n",
    "from llama_index.indices.document_summary import DocumentSummaryIndex"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c391a70-7690-4bbd-a2dc-f95b845991a7",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9839db6-257f-4c7f-9713-e7fa74ca4f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p ./data\n",
    "\n",
    "from urllib.request import urlretrieve\n",
    "urls = [\n",
    "    'https://s2.q4cdn.com/299287126/files/doc_financials/2023/ar/2022-Shareholder-Letter.pdf',\n",
    "    'https://s2.q4cdn.com/299287126/files/doc_financials/2022/ar/2021-Shareholder-Letter.pdf',\n",
    "    'https://s2.q4cdn.com/299287126/files/doc_financials/2021/ar/Amazon-2020-Shareholder-Letter-and-1997-Shareholder-Letter.pdf',\n",
    "    'https://s2.q4cdn.com/299287126/files/doc_financials/2020/ar/2019-Shareholder-Letter.pdf'\n",
    "]\n",
    "\n",
    "filenames = [\n",
    "    'AMZN-2022-Shareholder-Letter.pdf',\n",
    "    'AMZN-2021-Shareholder-Letter.pdf',\n",
    "    'AMZN-2020-Shareholder-Letter.pdf',\n",
    "    'AMZN-2019-Shareholder-Letter.pdf'\n",
    "]\n",
    "\n",
    "metadata = [\n",
    "    dict(year=2022, source=filenames[0]),\n",
    "    dict(year=2021, source=filenames[1]),\n",
    "    dict(year=2020, source=filenames[2]),\n",
    "    dict(year=2019, source=filenames[3])]\n",
    "\n",
    "data_root = \"./data/\"\n",
    "\n",
    "for idx, url in enumerate(urls):\n",
    "    file_path = data_root + filenames[idx]\n",
    "    urlretrieve(url, file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8546495-df37-43e8-a4cf-c1076fad7a09",
   "metadata": {},
   "source": [
    "As part of Amazon's culture, the CEO always includes a copy of the 1997 Letter to Shareholders with every new release. This will cause repetition, take longer to generate embeddings, and may skew your results. In the next section you will take the downloaded data, trim the 1997 letter (last 3 pages) and overwrite them as processed files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a0b300-0c6c-43be-a2ea-ae16fa0912f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "from pypdf import PdfReader, PdfWriter\n",
    "\n",
    "local_pdfs = glob.glob(data_root + '*.pdf')\n",
    "\n",
    "for local_pdf in local_pdfs:\n",
    "    pdf_reader = PdfReader(local_pdf)\n",
    "    pdf_writer = PdfWriter()\n",
    "    for pagenum in range(len(pdf_reader.pages)-3):\n",
    "        page = pdf_reader.pages[pagenum]\n",
    "        pdf_writer.add_page(page)\n",
    "\n",
    "    with open(local_pdf, 'wb') as new_file:\n",
    "        new_file.seek(0)\n",
    "        pdf_writer.write(new_file)\n",
    "        new_file.truncate()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f14fbe89-348e-48b6-9ac9-ad0ad356db1e",
   "metadata": {},
   "source": [
    "Now that you have clean PDFs to work with, you will enrich your documents with metadata, then use a process called \"chunking\" to break up a larger document into small pieces. These small pieces will allow you to generate embeddings without surpassing the input limit of the embedding model.\n",
    "\n",
    "In this example you will break the document into 1000 character chunks, with a 100 character overlap. This will allow your embeddings to maintain some of its context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4429b839-e244-42b8-9b24-5368c1bb0a21",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "docs = []\n",
    "for filename in filenames:\n",
    "    doc = SimpleDirectoryReader(input_files=[f\"data/{filename}\"]).load_data()\n",
    "    doc[0].doc_id = filename.replace(\".pdf\", \"\")\n",
    "    docs.extend(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef3de855-a3ee-4994-b3c0-0099fa7b5704",
   "metadata": {},
   "source": [
    "### Build Document Summary Index\n",
    "\n",
    "We show two ways of building the index:\n",
    "- default mode of building the document summary index\n",
    "- customizing the summary query\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d912d4ec-69c5-4c27-87a5-610714827c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Un comment the following lines to run from your local environment outside of the AWS account with Bedrock access\n",
    "\n",
    "#import os\n",
    "#os.environ['BEDROCK_ASSUME_ROLE'] = '<YOUR_VALUES>'\n",
    "#os.environ['AWS_PROFILE'] = 'bedrock-user'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "069bdc2d-87c3-4978-afaf-65a880ef1e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import boto3\n",
    "import json\n",
    "import sys\n",
    "\n",
    "module_path = \"..\"\n",
    "sys.path.append(os.path.abspath(module_path))\n",
    "from utils import bedrock, print_ww\n",
    "\n",
    "\n",
    "#os.environ['AWS_DEFAULT_REGION'] = 'us-west-2'\n",
    "boto3_bedrock = bedrock.get_bedrock_client(os.environ.get('BEDROCK_ASSUME_ROLE', None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f1ba5d-9dc0-4710-a7c4-a8ce58a68dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "boto3_bedrock.list_foundation_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30fa1e1a-0fcb-4dba-b4f1-cbdf5c2bf01e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from llama_index import LangchainEmbedding\n",
    "from langchain.llms.bedrock import Bedrock # required until llama_index offers direct Bedrock integration\n",
    "from langchain.embeddings.bedrock import BedrockEmbeddings\n",
    "\n",
    "model_kwargs_titan = { \n",
    "        \"maxTokenCount\": 512,\n",
    "        \"stopSequences\": [],\n",
    "        \"temperature\":0.0,  \n",
    "        \"topP\":0.5\n",
    "}\n",
    "\n",
    "llm = Bedrock(model_id=\"amazon.titan-tg1-large\",\n",
    "              client=boto3_bedrock,\n",
    "              model_kwargs=model_kwargs_titan)\n",
    "\n",
    "embed_model = LangchainEmbedding(\n",
    "  BedrockEmbeddings(model_id=\"amazon.titan-e1t-medium\")\n",
    ")\n",
    "\n",
    "service_context = ServiceContext.from_defaults(llm=llm, \n",
    "                                               embed_model=embed_model, \n",
    "                                               chunk_size=512)\n",
    "set_global_service_context(service_context)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c04d2a82-d636-4134-9332-aed843d221e1",
   "metadata": {},
   "source": [
    "### This will take a few minutes. Please be patient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c531c9-4aee-47ae-a4d2-81af3a6af908",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "response_synthesizer = get_response_synthesizer(\n",
    "    response_mode=\"tree_summarize\", use_async=True\n",
    ")\n",
    "doc_summary_index = DocumentSummaryIndex.from_documents(\n",
    "    docs,\n",
    "    service_context=service_context,\n",
    "    response_synthesizer=response_synthesizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d5ee2a1-c4c0-48ff-b125-f93a83a6ade9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf5d19a2-5fa3-4f1b-aadd-25c209cfeb75",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "doc_summary_index.get_document_summary(\"AMZN-2022-Shareholder-Letter\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "349c2872-2b53-4812-9392-b89e5879e32a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "doc_summary_index.storage_context.persist(\"llama_titan_index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f96e6524-f8ab-4227-ad5a-3dcb3b640532",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from llama_index.indices.loading import load_index_from_storage\n",
    "from llama_index import StorageContext\n",
    "\n",
    "# rebuild storage context\n",
    "storage_context = StorageContext.from_defaults(persist_dir=\"llama_titan_index\")\n",
    "doc_summary_index = load_index_from_storage(storage_context)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f76b3344-8e24-4e72-893b-7accd2a3fa57",
   "metadata": {},
   "source": [
    "### Perform Retrieval from Document Summary Index\n",
    "\n",
    "We show how to execute queries at a high-level. We also show how to perform retrieval at a lower-level so that you can view the parameters that are in place. We show both LLM-based retrieval and embedding-based retrieval using the document summaries."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e3f65a3-482f-4481-9933-19ac55e91719",
   "metadata": {},
   "source": [
    "#### High-level Querying\n",
    "\n",
    "Note: this uses the default, LLM-based form of retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e925b75-0a99-49cc-8e9a-daaf715ee490",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from util.llama_custom_parse_choice_select_answer_fn import custom_parse_choice_select_answer_fn\n",
    "query_engine = doc_summary_index.as_query_engine(\n",
    "    response_mode=\"tree_summarize\", use_async=True, similarity_top_k=10,  verbose=False,\n",
    "    parse_choice_select_answer_fn=custom_parse_choice_select_answer_fn\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c190a1e7-b85c-41cd-af42-e2521d2406a9",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "response = query_engine.query(\"How has AWS evolved?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc5b99c2-06de-4071-9314-eec75c50c5f5",
   "metadata": {},
   "source": [
    "#### LLM-based Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd99ce8-8347-4e6e-88e4-23dd8fcb9084",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from llama_index.indices.document_summary import DocumentSummaryIndexRetriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e397dd-fbb0-4465-994a-7527b3a6dd57",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from util.llama_custom_parse_choice_select_answer_fn import custom_parse_choice_select_answer_fn\n",
    "retriever = DocumentSummaryIndexRetriever(\n",
    "    doc_summary_index,\n",
    "    # choice_select_prompt=choice_select_prompt,\n",
    "    # choice_batch_size=choice_batch_size,\n",
    "    # format_node_batch_fn=format_node_batch_fn,\n",
    "    parse_choice_select_answer_fn=custom_parse_choice_select_answer_fn,\n",
    "    # service_context=service_context\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef31654-27ea-4fb0-b29e-b18e5bf867f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "retrieved_nodes = retriever.retrieve(\"According to the documents, How has AWS evolved?\")\n",
    "print(len(retrieved_nodes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f76e79-1595-43b3-81e7-9ca7547fa2d1",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i, node in enumerate(retrieved_nodes):\n",
    "    print(node.score)\n",
    "    print(node.node.get_text())\n",
    "    print(\"-----------------------------------------------------------------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a215ef33-5d05-42ad-83c5-409ccc288d26",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# use retriever as part of a query engine\n",
    "from llama_index.query_engine import RetrieverQueryEngine\n",
    "\n",
    "# configure response synthesizer\n",
    "response_synthesizer = get_response_synthesizer(response_mode=\"refine\", use_async=True)\n",
    "\n",
    "# assemble query engine\n",
    "query_engine = RetrieverQueryEngine(\n",
    "    retriever=retriever,\n",
    "    response_synthesizer=response_synthesizer,\n",
    ")\n",
    "\n",
    "# query\n",
    "response = query_engine.query(\"How has AWS evolved?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb24cb8-b839-4754-b653-ac40cebfe0bc",
   "metadata": {},
   "source": [
    "#### Embedding-based Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc47dc54-197f-43bb-9298-b2af24c6b095",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from llama_index.indices.document_summary import DocumentSummaryIndexEmbeddingRetriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dcb81cb-0d36-4af8-a0c5-9061a2dce986",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "retriever = DocumentSummaryIndexEmbeddingRetriever(\n",
    "    doc_summary_index,\n",
    "    # choice_select_prompt=choice_select_prompt,\n",
    "    # choice_batch_size=choice_batch_size,\n",
    "    # format_node_batch_fn=format_node_batch_fn,\n",
    "    # parse_choice_select_answer_fn=parse_choice_select_answer_fn,\n",
    "    #service_context=service_context\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48934544-3dde-4231-b41c-540139378751",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "retrieved_nodes = retriever.retrieve(\"Human: How has AWS evolved?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f06e5f6-d62e-4348-8ef5-d4cb6219b54e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(retrieved_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb93c084-411b-40c2-b5d4-6fc2a90b8ecb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i, node in enumerate(retrieved_nodes):\n",
    "    \n",
    "    print(node.node.get_text())\n",
    "    print(\"-----------------------------------------------------------------------------------------------------------------------------------\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d781289-4325-4d5d-933b-010e2ef331e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-west-2:236514542706:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
