# Working with multimodal data using Amazon Bedrock

With the `Amazon Titan Multimodal Embeddings G1` model, you can create embeddings for multimodal data, specifically text and image data. These embeddings can then be used for multimodal search and Retrieval Augmented Generation (RAG) use-cases, for example searching images by text only, images only or a combination of text and images. 


![Amazon Titan Multimodal Embeddings G1](images/titan-embeddings-g1-image.png)

## Contents

- [Multimodal RAG](./rag/) - Multimodal RAG using the [Amazon Berkley Objects](https://amazon-berkeley-objects.s3.amazonaws.com/index.html) dataset. 

## Contributing

We welcome community contributions! Please ensure your sample aligns with AWS [best practices](https://aws.amazon.com/architecture/well-architected/), and please update the **Contents** section of this README file with a link to your sample, along with a description.
