<!doctype html><html lang=en class=no-js> <head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="Amazon Bedrock cookbook website"><meta name=author content=Bedrock-GTM><link href=https://github.amazon-bedrock-samples.com/custom-models/import_models/llama-3/customized-text-to-sql-model/ rel=canonical><link rel=icon href=../../../../assets/favicon.png><meta name=generator content="mkdocs-1.6.1, mkdocs-material-9.5.49"><title>Customized text to sql model - Amazon Bedrock Recipes</title><link rel=stylesheet href=../../../../assets/stylesheets/main.6f8fc17f.min.css><link rel=stylesheet href=../../../../assets/stylesheets/palette.06af60db.min.css><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback"><style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style><script>__md_scope=new URL("../../../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script></head> <body dir=ltr data-md-color-scheme=default data-md-color-primary=white data-md-color-accent=purple> <input class=md-toggle data-md-toggle=drawer type=checkbox id=__drawer autocomplete=off> <input class=md-toggle data-md-toggle=search type=checkbox id=__search autocomplete=off> <label class=md-overlay for=__drawer></label> <div data-md-component=skip> </div> <div data-md-component=announce> </div> <header class="md-header md-header--shadow" data-md-component=header> <nav class="md-header__inner md-grid" aria-label=Header> <a href=../../../.. title="Amazon Bedrock Recipes" class="md-header__button md-logo" aria-label="Amazon Bedrock Recipes" data-md-component=logo> <img src=../../../../logo.png alt=logo> </a> <label class="md-header__button md-icon" for=__drawer> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg> </label> <div class=md-header__title data-md-component=header-title> <div class=md-header__ellipsis> <div class=md-header__topic> <span class=md-ellipsis> Amazon Bedrock Recipes </span> </div> <div class=md-header__topic data-md-component=header-topic> <span class=md-ellipsis> Customized text to sql model </span> </div> </div> </div> <form class=md-header__option data-md-component=palette> <input class=md-option data-md-color-media data-md-color-scheme=default data-md-color-primary=white data-md-color-accent=purple aria-hidden=true type=radio name=__palette id=__palette_0> </form> <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script> <label class="md-header__button md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg> </label> <div class=md-search data-md-component=search role=dialog> <label class=md-search__overlay for=__search></label> <div class=md-search__inner role=search> <form class=md-search__form name=search> <input type=text class=md-search__input name=query aria-label=Search placeholder=Search autocapitalize=off autocorrect=off autocomplete=off spellcheck=false data-md-component=search-query required> <label class="md-search__icon md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg> </label> <nav class=md-search__options aria-label=Search> <button type=reset class="md-search__icon md-icon" title=Clear aria-label=Clear tabindex=-1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg> </button> </nav> <div class=md-search__suggest data-md-component=search-suggest></div> </form> <div class=md-search__output> <div class=md-search__scrollwrap tabindex=0 data-md-scrollfix> <div class=md-search-result data-md-component=search-result> <div class=md-search-result__meta> Initializing search </div> <ol class=md-search-result__list role=presentation></ol> </div> </div> </div> </div> </div> <div class=md-header__source> <a href=https://github.com/aws-samples/amazon-bedrock-samples/tree/main title="Go to repository" class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 6.7.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81"/></svg> </div> <div class=md-source__repository> Github: Amazon-Bedrock-Samples </div> </a> </div> </nav> </header> <div class=md-container data-md-component=container> <main class=md-main data-md-component=main> <div class="md-main__inner md-grid"> <div class="md-sidebar md-sidebar--primary" data-md-component=sidebar data-md-type=navigation> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--primary md-nav--integrated" aria-label=Navigation data-md-level=0> <label class=md-nav__title for=__drawer> <a href=../../../.. title="Amazon Bedrock Recipes" class="md-nav__button md-logo" aria-label="Amazon Bedrock Recipes" data-md-component=logo> <img src=../../../../logo.png alt=logo> </a> Amazon Bedrock Recipes </label> <div class=md-nav__source> <a href=https://github.com/aws-samples/amazon-bedrock-samples/tree/main title="Go to repository" class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 6.7.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81"/></svg> </div> <div class=md-source__repository> Github: Amazon-Bedrock-Samples </div> </a> </div> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../.. class=md-nav__link> <span class=md-ellipsis> Home </span> </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2> <label class=md-nav__link for=__nav_2 id=__nav_2_label tabindex=0> <span class=md-ellipsis> Features </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_2_label aria-expanded=false> <label class=md-nav__title for=__nav_2> <span class="md-nav__icon md-icon"></span> Features </label> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2_1> <label class=md-nav__link for=__nav_2_1 id=__nav_2_1_label tabindex=0> <span class=md-ellipsis> Intro to Amazon Bedrock </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_2_1_label aria-expanded=false> <label class=md-nav__title for=__nav_2_1> <span class="md-nav__icon md-icon"></span> Intro to Amazon Bedrock </label> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2_1_1> <label class=md-nav__link for=__nav_2_1_1 id=__nav_2_1_1_label tabindex=0> <span class=md-ellipsis> API Usage </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=3 aria-labelledby=__nav_2_1_1_label aria-expanded=false> <label class=md-nav__title for=__nav_2_1_1> <span class="md-nav__icon md-icon"></span> API Usage </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../../introduction-to-bedrock/bedrock_apis/01_invoke_api/ class=md-nav__link> <span class=md-ellipsis> Invoke Model API Example </span> </a> </li> <li class=md-nav__item> <a href=../../../../introduction-to-bedrock/bedrock_apis/04_agents_api/ class=md-nav__link> <span class=md-ellipsis> Agents API Example </span> </a> </li> <li class=md-nav__item> <a href=../../../../introduction-to-bedrock/bedrock_apis/03_knowledgebases_api/ class=md-nav__link> <span class=md-ellipsis> Knowledge Bases API Example </span> </a> </li> <li class=md-nav__item> <a href=../../../../introduction-to-bedrock/bedrock_apis/02_guardrails_api/ class=md-nav__link> <span class=md-ellipsis> Guardrail API Example </span> </a> </li> <li class=md-nav__item> <a href=../../../../introduction-to-bedrock/converse_api/01_converse_api/ class=md-nav__link> <span class=md-ellipsis> Converse API Example </span> </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2_2> <label class=md-nav__link for=__nav_2_2 id=__nav_2_2_label tabindex=0> <span class=md-ellipsis> Agents </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_2_2_label aria-expanded=false> <label class=md-nav__title for=__nav_2_2> <span class="md-nav__icon md-icon"></span> Agents </label> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2_2_1> <label class=md-nav__link for=__nav_2_2_1 id=__nav_2_2_1_label tabindex=0> <span class=md-ellipsis> Amazon Bedrock Agents </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=3 aria-labelledby=__nav_2_2_1_label aria-expanded=false> <label class=md-nav__title for=__nav_2_2_1> <span class="md-nav__icon md-icon"></span> Amazon Bedrock Agents </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../../agents-and-function-calling/introduction-to-agents/how_to_create_custom_agents/ class=md-nav__link> <span class=md-ellipsis> How to create an Agent </span> </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2_2_1_2> <label class=md-nav__link for=__nav_2_2_1_2 id=__nav_2_2_1_2_label tabindex=0> <span class=md-ellipsis> Bedrock Agent Features </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=4 aria-labelledby=__nav_2_2_1_2_label aria-expanded=false> <label class=md-nav__title for=__nav_2_2_1_2> <span class="md-nav__icon md-icon"></span> Bedrock Agent Features </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../../agents-and-function-calling/bedrock-agents/features-examples/01-create-agent-with-function-definition/01-create-agent-with-function-definition/ class=md-nav__link> <span class=md-ellipsis> Create Agent with Function Definition </span> </a> </li> <li class=md-nav__item> <a href=../../../../agents-and-function-calling/bedrock-agents/features-examples/02-create-agent-with-api-schema/02-create-agent-with-api-schema/ class=md-nav__link> <span class=md-ellipsis> Create Agent with API Schema </span> </a> </li> <li class=md-nav__item> <a href=../../../../agents-and-function-calling/bedrock-agents/features-examples/03-create-agent-with-return-of-control/03-create-agent-with-return-of-control/ class=md-nav__link> <span class=md-ellipsis> Create Agent with Return of Control </span> </a> </li> <li class=md-nav__item> <a href=../../../../agents-and-function-calling/bedrock-agents/features-examples/04-create-agent-with-single-knowledge-base/04-create-agent-with-single-knowledge-base/ class=md-nav__link> <span class=md-ellipsis> Create Agent with Single Knowledge Base </span> </a> </li> <li class=md-nav__item> <a href=../../../../agents-and-function-calling/bedrock-agents/features-examples/05-create-agent-with-knowledge-base-and-action-group/05-create-agent-with-knowledge-base-and-action-group/ class=md-nav__link> <span class=md-ellipsis> Create Agent with Knowledge Base and Action Group </span> </a> </li> <li class=md-nav__item> <a href=../../../../agents-and-function-calling/bedrock-agents/features-examples/06-prompt-and-session-attributes/06-prompt-and-session-attributes/ class=md-nav__link> <span class=md-ellipsis> Prompt and Session Attributes </span> </a> </li> <li class=md-nav__item> <a href=../../../../agents-and-function-calling/bedrock-agents/features-examples/07-advanced-prompts-and-custom-parsers/07-custom-prompt-and-lambda-parsers/ class=md-nav__link> <span class=md-ellipsis> Custom Prompt and Lambda Parsers </span> </a> </li> <li class=md-nav__item> <a href=../../../../agents-and-function-calling/bedrock-agents/features-examples/08-create-agent-with-guardrails/08-create-agent-with-guardrails/ class=md-nav__link> <span class=md-ellipsis> Create Agent with Guardrails </span> </a> </li> <li class=md-nav__item> <a href=../../../../agents-and-function-calling/bedrock-agents/features-examples/09-create-agent-with-memory/09-create-agent-with-memory/ class=md-nav__link> <span class=md-ellipsis> Create Agent with Memory </span> </a> </li> <li class=md-nav__item> <a href=../../../../agents-and-function-calling/bedrock-agents/features-examples/10-create-agent-with-code-interpreter/10-create-agent-with-code-interpreter/ class=md-nav__link> <span class=md-ellipsis> Create Agent with Code Interpreter </span> </a> </li> <li class=md-nav__item> <a href=../../../../agents-and-function-calling/bedrock-agents/features-examples/14-create-agent-with-custom-orchestration/custom_orchestration_example/ class=md-nav__link> <span class=md-ellipsis> Create Agent with Custom Orchestration </span> </a> </li> <li class=md-nav__item> <a href=../../../../agents-and-function-calling/bedrock-agents/features-examples/15-invoke-inline-agents/inline-agent-api-usage/ class=md-nav__link> <span class=md-ellipsis> Create Dynamic Tooling Inline Agents </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2_2_1_3> <label class=md-nav__link for=__nav_2_2_1_3 id=__nav_2_2_1_3_label tabindex=0> <span class=md-ellipsis> Bedrock Flows </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=4 aria-labelledby=__nav_2_2_1_3_label aria-expanded=false> <label class=md-nav__title for=__nav_2_2_1_3> <span class="md-nav__icon md-icon"></span> Bedrock Flows </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../../agents-and-function-calling/bedrock-agents/bedrock-flows/Getting_started_with_Prompt_Management_Flows/ class=md-nav__link> <span class=md-ellipsis> Getting Started with Prompt Management Flows </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2_2_1_4> <label class=md-nav__link for=__nav_2_2_1_4 id=__nav_2_2_1_4_label tabindex=0> <span class=md-ellipsis> Use Case Examples </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=4 aria-labelledby=__nav_2_2_1_4_label aria-expanded=false> <label class=md-nav__title for=__nav_2_2_1_4> <span class="md-nav__icon md-icon"></span> Use Case Examples </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../../agents-and-function-calling/bedrock-agents/use-case-examples/text-2-sql-agent/create_and_invoke_sql_agent/ class=md-nav__link> <span class=md-ellipsis> Text to SQL Agent </span> </a> </li> <li class=md-nav__item> <a href=../../../../agents-and-function-calling/bedrock-agents/use-case-examples/agentsforbedrock-retailagent/workshop/test_retailagent_agentsforbedrock/ class=md-nav__link> <span class=md-ellipsis> Retail Agent Workshop </span> </a> </li> <li class=md-nav__item> <a href=../../../../agents-and-function-calling/bedrock-agents/use-case-examples/product-review-agent/main/ class=md-nav__link> <span class=md-ellipsis> Product Review Agent </span> </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2_2_2> <label class=md-nav__link for=__nav_2_2_2 id=__nav_2_2_2_label tabindex=0> <span class=md-ellipsis> Function Calling </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=3 aria-labelledby=__nav_2_2_2_label aria-expanded=false> <label class=md-nav__title for=__nav_2_2_2> <span class="md-nav__icon md-icon"></span> Function Calling </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../../agents-and-function-calling/function-calling/function_calling_with_converse/function_calling_with_converse/ class=md-nav__link> <span class=md-ellipsis> Function Calling with Converse </span> </a> </li> <li class=md-nav__item> <a href=../../../../agents-and-function-calling/function-calling/function_calling_with_invoke/function_calling_model_with_invoke/ class=md-nav__link> <span class=md-ellipsis> Function Calling with Invoke </span> </a> </li> <li class=md-nav__item> <a href=../../../../agents-and-function-calling/function-calling/return_of_control/return_of_control/ class=md-nav__link> <span class=md-ellipsis> Return of Control </span> </a> </li> <li class=md-nav__item> <a href=../../../../agents-and-function-calling/function-calling/tool_binding/tool_bindings/ class=md-nav__link> <span class=md-ellipsis> Tool Binding </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2_2_3> <label class=md-nav__link for=__nav_2_2_3 id=__nav_2_2_3_label tabindex=0> <span class=md-ellipsis> Open Source </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=3 aria-labelledby=__nav_2_2_3_label aria-expanded=false> <label class=md-nav__title for=__nav_2_2_3> <span class="md-nav__icon md-icon"></span> Open Source </label> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2_2_3_1> <label class=md-nav__link for=__nav_2_2_3_1 id=__nav_2_2_3_1_label tabindex=0> <span class=md-ellipsis> CrewAI </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=4 aria-labelledby=__nav_2_2_3_1_label aria-expanded=false> <label class=md-nav__title for=__nav_2_2_3_1> <span class="md-nav__icon md-icon"></span> CrewAI </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../../agents-and-function-calling/open-source-agents/crew.ai/Find%20dream%20destination%20with%20CrewAI/ class=md-nav__link> <span class=md-ellipsis> Find Dream Destination with CrewAI </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2_2_3_2> <label class=md-nav__link for=__nav_2_2_3_2 id=__nav_2_2_3_2_label tabindex=0> <span class=md-ellipsis> LangGraph </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=4 aria-labelledby=__nav_2_2_3_2_label aria-expanded=false> <label class=md-nav__title for=__nav_2_2_3_2> <span class="md-nav__icon md-icon"></span> LangGraph </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../../agents-and-function-calling/open-source-agents/langgraph/langgraph-single-agent/ class=md-nav__link> <span class=md-ellipsis> LangGraph Agent with Function Calling </span> </a> </li> <li class=md-nav__item> <a href=../../../../agents-and-function-calling/open-source-agents/langgraph/langgraph-agents-multimodal/ class=md-nav__link> <span class=md-ellipsis> LangGraph Multi-Modal Agent with Function Calling </span> </a> </li> <li class=md-nav__item> <a href=../../../../agents-and-function-calling/open-source-agents/langgraph/langgraph-multi-agent-sql-tools/ class=md-nav__link> <span class=md-ellipsis> LangGraph Multi Agent Orchestration </span> </a> </li> <li class=md-nav__item> <a href=../../../../agents-and-function-calling/open-source-agents/langgraph/02_medibot_V3_agents/ class=md-nav__link> <span class=md-ellipsis> LangGraph Multi Agent For Medical Chatbot </span> </a> </li> <li class=md-nav__item> <a href=../../../../agents-and-function-calling/open-source-agents/langgraph/langgraph-fact-checker-feedback-loop/ class=md-nav__link> <span class=md-ellipsis> LangGraph Fact Checker with Multi Agent </span> </a> </li> <li class=md-nav__item> <a href=../../../../agents-and-function-calling/open-source-agents/langgraph/langgraph-multi-agent-sql-tools/ class=md-nav__link> <span class=md-ellipsis> LangGraph Multi Agent Orchestration </span> </a> </li> <li class=md-nav__item> <a href=../../../../agents-and-function-calling/open-source-agents/langgraph/03_langgraph_agents_of_agent/ class=md-nav__link> <span class=md-ellipsis> LangGraph Multi Agent with tools </span> </a> </li> <li class=md-nav__item> <a href=../../../../agents-and-function-calling/open-source-agents/langgraph/Travel_planner_with_langgraph/ class=md-nav__link> <span class=md-ellipsis> Managing Memory for Multi Agents </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2_2_3_3> <label class=md-nav__link for=__nav_2_2_3_3 id=__nav_2_2_3_3_label tabindex=0> <span class=md-ellipsis> Multi Agent </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=4 aria-labelledby=__nav_2_2_3_3_label aria-expanded=false> <label class=md-nav__title for=__nav_2_2_3_3> <span class="md-nav__icon md-icon"></span> Multi Agent </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../../agents-and-function-calling/introduction-to-agents/how_to_create_multi_agents_from_custom_agents/ class=md-nav__link> <span class=md-ellipsis> Multi Agent Orchestration </span> </a> </li> </ul> </nav> </li> </ul> </nav> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2_3> <label class=md-nav__link for=__nav_2_3 id=__nav_2_3_label tabindex=0> <span class=md-ellipsis> RAG </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_2_3_label aria-expanded=false> <label class=md-nav__title for=__nav_2_3> <span class="md-nav__icon md-icon"></span> RAG </label> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2_3_1> <label class=md-nav__link for=__nav_2_3_1 id=__nav_2_3_1_label tabindex=0> <span class=md-ellipsis> Amazon Bedrock Knowledge Bases </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=3 aria-labelledby=__nav_2_3_1_label aria-expanded=false> <label class=md-nav__title for=__nav_2_3_1> <span class="md-nav__icon md-icon"></span> Amazon Bedrock Knowledge Bases </label> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2_3_1_1> <label class=md-nav__link for=__nav_2_3_1_1 id=__nav_2_3_1_1_label tabindex=0> <span class=md-ellipsis> Zero Setup </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=4 aria-labelledby=__nav_2_3_1_1_label aria-expanded=false> <label class=md-nav__title for=__nav_2_3_1_1> <span class="md-nav__icon md-icon"></span> Zero Setup </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../../rag/knowledge-bases/features-examples/00-zero-setup-chat-with-your-document/chat_with_document_kb/ class=md-nav__link> <span class=md-ellipsis> Chat with Your Document </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2_3_1_2> <label class=md-nav__link for=__nav_2_3_1_2 id=__nav_2_3_1_2_label tabindex=0> <span class=md-ellipsis> RAG Concepts </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=4 aria-labelledby=__nav_2_3_1_2_label aria-expanded=false> <label class=md-nav__title for=__nav_2_3_1_2> <span class="md-nav__icon md-icon"></span> RAG Concepts </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../../rag/knowledge-bases/features-examples/01-rag-concepts/01_create_ingest_documents_test_kb_multi_ds/ class=md-nav__link> <span class=md-ellipsis> Create and Ingest Documents with Multi-Data Sources </span> </a> </li> <li class=md-nav__item> <a href=../../../../rag/knowledge-bases/features-examples/01-rag-concepts/02_managed_rag_custom_prompting_and_no_of_results/ class=md-nav__link> <span class=md-ellipsis> Managed RAG with Custom Prompting </span> </a> </li> <li class=md-nav__item> <a href=../../../../rag/knowledge-bases/features-examples/01-rag-concepts/03_customized-rag-retreive-api-hybrid-search-claude-3-sonnet-langchain/ class=md-nav__link> <span class=md-ellipsis> Customized RAG with Claude 3 and Langchain </span> </a> </li> <li class=md-nav__item> <a href=../../../../rag/knowledge-bases/features-examples/01-rag-concepts/04_customized-rag-retreive-api-langchain-claude-evaluation-ragas/ class=md-nav__link> <span class=md-ellipsis> RAG Evaluation with Langchain and RAGAS </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2_3_1_3> <label class=md-nav__link for=__nav_2_3_1_3 id=__nav_2_3_1_3_label tabindex=0> <span class=md-ellipsis> Optimizing Retrieval Results </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=4 aria-labelledby=__nav_2_3_1_3_label aria-expanded=false> <label class=md-nav__title for=__nav_2_3_1_3> <span class="md-nav__icon md-icon"></span> Optimizing Retrieval Results </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../../rag/knowledge-bases/features-examples/02-optimizing-accuracy-retrieved-results/advanced_chunking_options/ class=md-nav__link> <span class=md-ellipsis> Advanced Chunking Options </span> </a> </li> <li class=md-nav__item> <a href=../../../../rag/knowledge-bases/features-examples/02-optimizing-accuracy-retrieved-results/csv_metadata_customization/ class=md-nav__link> <span class=md-ellipsis> CSV Metadata Customization </span> </a> </li> <li class=md-nav__item> <a href=../../../../rag/knowledge-bases/features-examples/02-optimizing-accuracy-retrieved-results/query_reformulation/ class=md-nav__link> <span class=md-ellipsis> Query Reformulation </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2_3_1_4> <label class=md-nav__link for=__nav_2_3_1_4 id=__nav_2_3_1_4_label tabindex=0> <span class=md-ellipsis> Advanced Concepts </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=4 aria-labelledby=__nav_2_3_1_4_label aria-expanded=false> <label class=md-nav__title for=__nav_2_3_1_4> <span class="md-nav__icon md-icon"></span> Advanced Concepts </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../../rag/knowledge-bases/features-examples/03-advanced-concepts/dynamic-metadata-filtering/dynamic-metadata-filtering-KB/ class=md-nav__link> <span class=md-ellipsis> Dynamic Metadata Filtering </span> </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2_3_1_4_2> <label class=md-nav__link for=__nav_2_3_1_4_2 id=__nav_2_3_1_4_2_label tabindex=0> <span class=md-ellipsis> Reranking </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=5 aria-labelledby=__nav_2_3_1_4_2_label aria-expanded=false> <label class=md-nav__title for=__nav_2_3_1_4_2> <span class="md-nav__icon md-icon"></span> Reranking </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../../rag/knowledge-bases/features-examples/03-advanced-concepts/reranking/01_deploy-reranking-model-sm/ class=md-nav__link> <span class=md-ellipsis> Deploy Reranking Model </span> </a> </li> <li class=md-nav__item> <a href=../../../../rag/knowledge-bases/features-examples/03-advanced-concepts/reranking/02_kb-reranker/ class=md-nav__link> <span class=md-ellipsis> Knowledge Base Reranker </span> </a> </li> <li class=md-nav__item> <a href=../../../../rag/knowledge-bases/features-examples/03-advanced-concepts/reranking/qa-generator/ class=md-nav__link> <span class=md-ellipsis> QA Generator </span> </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2_3_1_5> <label class=md-nav__link for=__nav_2_3_1_5 id=__nav_2_3_1_5_label tabindex=0> <span class=md-ellipsis> Responsible AI </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=4 aria-labelledby=__nav_2_3_1_5_label aria-expanded=false> <label class=md-nav__title for=__nav_2_3_1_5> <span class="md-nav__icon md-icon"></span> Responsible AI </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../../rag/knowledge-bases/features-examples/05-responsible-ai/contextual-grounding/ class=md-nav__link> <span class=md-ellipsis> Contextual Grounding </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2_3_1_6> <label class=md-nav__link for=__nav_2_3_1_6 id=__nav_2_3_1_6_label tabindex=0> <span class=md-ellipsis> Use Case Examples </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=4 aria-labelledby=__nav_2_3_1_6_label aria-expanded=false> <label class=md-nav__title for=__nav_2_3_1_6> <span class="md-nav__icon md-icon"></span> Use Case Examples </label> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2_3_1_6_1> <label class=md-nav__link for=__nav_2_3_1_6_1 id=__nav_2_3_1_6_1_label tabindex=0> <span class=md-ellipsis> Metadata Filter Access Control </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=5 aria-labelledby=__nav_2_3_1_6_1_label aria-expanded=false> <label class=md-nav__title for=__nav_2_3_1_6_1> <span class="md-nav__icon md-icon"></span> Metadata Filter Access Control </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../../rag/knowledge-bases/use-case-examples/metadata-filter-access-control/kb-end-to-end-acl/ class=md-nav__link> <span class=md-ellipsis> End-to-End ACL with Knowledge Base </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2_3_1_6_2> <label class=md-nav__link for=__nav_2_3_1_6_2 id=__nav_2_3_1_6_2_label tabindex=0> <span class=md-ellipsis> RAG with Structured and Unstructured Data </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=5 aria-labelledby=__nav_2_3_1_6_2_label aria-expanded=false> <label class=md-nav__title for=__nav_2_3_1_6_2> <span class="md-nav__icon md-icon"></span> RAG with Structured and Unstructured Data </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../../rag/knowledge-bases/use-case-examples/rag-using-structured-unstructured-data/0-create-dummy-structured-data/ class=md-nav__link> <span class=md-ellipsis> Create Dummy Structured Data </span> </a> </li> <li class=md-nav__item> <a href=../../../../rag/knowledge-bases/use-case-examples/rag-using-structured-unstructured-data/1_create_sql_dataset_optional/ class=md-nav__link> <span class=md-ellipsis> Create SQL Dataset (Optional) </span> </a> </li> <li class=md-nav__item> <a href=../../../../rag/knowledge-bases/use-case-examples/rag-using-structured-unstructured-data/2_rag_with_structured_unstructured_data/ class=md-nav__link> <span class=md-ellipsis> RAG with Structured and Unstructured Data </span> </a> </li> </ul> </nav> </li> </ul> </nav> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2_3_2> <label class=md-nav__link for=__nav_2_3_2 id=__nav_2_3_2_label tabindex=0> <span class=md-ellipsis> Open Source </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=3 aria-labelledby=__nav_2_3_2_label aria-expanded=false> <label class=md-nav__title for=__nav_2_3_2> <span class="md-nav__icon md-icon"></span> Open Source </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../../rag/open-source/chatbots/qa_chatbot_langchain_bedrock/ class=md-nav__link> <span class=md-ellipsis> Chatbot using Langchain </span> </a> </li> <li class=md-nav__item> <a href=../../../../rag/open-source/chunking/rag_chunking_strategies_langchain_bedrock/ class=md-nav__link> <span class=md-ellipsis> Chunking strategies for RAG applications </span> </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2_3_2_3> <label class=md-nav__link for=__nav_2_3_2_3 id=__nav_2_3_2_3_label tabindex=0> <span class=md-ellipsis> Vector Stores </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=4 aria-labelledby=__nav_2_3_2_3_label aria-expanded=false> <label class=md-nav__title for=__nav_2_3_2_3> <span class="md-nav__icon md-icon"></span> Vector Stores </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../../rag/open-source/vector_stores/rag_langchain_bedrock_opensearch/ class=md-nav__link> <span class=md-ellipsis> Langchain Chatbot with Opensearch </span> </a> </li> </ul> </nav> </li> </ul> </nav> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2_4> <label class=md-nav__link for=__nav_2_4 id=__nav_2_4_label tabindex=0> <span class=md-ellipsis> Model Customization </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_2_4_label aria-expanded=false> <label class=md-nav__title for=__nav_2_4> <span class="md-nav__icon md-icon"></span> Model Customization </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../model-distillation/Historical_invocation_distillation/ class=md-nav__link> <span class=md-ellipsis> Model Distillation with Invocation Logs </span> </a> </li> <li class=md-nav__item> <a href=../../../model-distillation/Distillation-via-S3-input/ class=md-nav__link> <span class=md-ellipsis> Model Distillation with S3 Data </span> </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_3> <label class=md-nav__link for=__nav_3 id=__nav_3_label tabindex=0> <span class=md-ellipsis> Gen AI Usecases </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_3_label aria-expanded=false> <label class=md-nav__title for=__nav_3> <span class="md-nav__icon md-icon"></span> Gen AI Usecases </label> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_3_1> <label class=md-nav__link for=__nav_3_1 id=__nav_3_1_label tabindex=0> <span class=md-ellipsis> Text Generation </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_3_1_label aria-expanded=false> <label class=md-nav__title for=__nav_3_1> <span class="md-nav__icon md-icon"></span> Text Generation </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../../genai-use-cases/text-generation/how_to_work_with_text_generation_w_bedrock/ class=md-nav__link> <span class=md-ellipsis> Streaming Response with Converse </span> </a> </li> <li class=md-nav__item> <a href=../../../../genai-use-cases/text-generation/how_to_work_with_code_generation_w_bedrock/ class=md-nav__link> <span class=md-ellipsis> Generate Python Code with Converse </span> </a> </li> <li class=md-nav__item> <a href=../../../../genai-use-cases/text-generation/how_to_work_with_text_translation_w_bedrock/ class=md-nav__link> <span class=md-ellipsis> Text Translation with Converse </span> </a> </li> <li class=md-nav__item> <a href=../../../../genai-use-cases/text-generation/how_to_work_with_text-summarization-titan%2Bclaude/ class=md-nav__link> <span class=md-ellipsis> Text summarization with Converse </span> </a> </li> <li class=md-nav__item> <a href=../../../../genai-use-cases/text-generation/how_to_work_with_batch_example_for_multi_threaded_invocation/ class=md-nav__link> <span class=md-ellipsis> Generate Bulk Emails with Batch Inference </span> </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_4> <label class=md-nav__link for=__nav_4 id=__nav_4_label tabindex=0> <span class=md-ellipsis> Workshops </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_4_label aria-expanded=false> <label class=md-nav__title for=__nav_4> <span class="md-nav__icon md-icon"></span> Workshops </label> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_4_1> <label class=md-nav__link for=__nav_4_1 id=__nav_4_1_label tabindex=0> <span class=md-ellipsis> Open-source L400 </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_4_1_label aria-expanded=false> <label class=md-nav__title for=__nav_4_1> <span class="md-nav__icon md-icon"></span> Open-source L400 </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../../workshop/open-source-l400/01_usecase_introduction/ class=md-nav__link> <span class=md-ellipsis> Introduction to the Use Case </span> </a> </li> <li class=md-nav__item> <a href=../../../../workshop/open-source-l400/02_Lab_Find%20a%20Dream%20Destination_RAG%20query/ class=md-nav__link> <span class=md-ellipsis> Advanced RAG for Agents </span> </a> </li> <li class=md-nav__item> <a href=../../../../workshop/open-source-l400/02_travel_planner_with_langgraph/ class=md-nav__link> <span class=md-ellipsis> Conversational Memory in Agents </span> </a> </li> <li class=md-nav__item> <a href=../../../../workshop/open-source-l400/03_travel_agent_with_tools/ class=md-nav__link> <span class=md-ellipsis> Multi-Modal and Types of Agents </span> </a> </li> <li class=md-nav__item> <a href=../../../../workshop/open-source-l400/04_travel_booking_multi_agent/ class=md-nav__link> <span class=md-ellipsis> Multi-Agent Collaboration with Human-in-loop </span> </a> </li> <li class=md-nav__item> <a href=../../../../workshop/open-source-l400/05_dream_destination_with_crewai/ class=md-nav__link> <span class=md-ellipsis> Find Dream Destination with CrewAI </span> </a> </li> <li class=md-nav__item> <a href=../../../../workshop/open-source-l400/06_agent_evaluation_with_ragas/ class=md-nav__link> <span class=md-ellipsis> RAGAs Agents Evaluation </span> </a> </li> <li class=md-nav__item> <a href=../../../../workshop/open-source-l400/07_dynamic_tooling_agents/ class=md-nav__link> <span class=md-ellipsis> Dynamic Tool invocation </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_4_2> <label class=md-nav__link for=__nav_4_2 id=__nav_4_2_label tabindex=0> <span class=md-ellipsis> Open-source L200 </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_4_2_label aria-expanded=false> <label class=md-nav__title for=__nav_4_2> <span class="md-nav__icon md-icon"></span> Open-source L200 </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../../workshop/open-source-l200/02_contextual_text_generation/ class=md-nav__link> <span class=md-ellipsis> Introduction to the Use Case </span> </a> </li> <li class=md-nav__item> <a href=../../../../workshop/open-source-l200/03_retrieval_based_text_application/ class=md-nav__link> <span class=md-ellipsis> Retrieval Based Text Generation </span> </a> </li> <li class=md-nav__item> <a href=../../../../workshop/open-source-l200/04_retrieval_based_chat_application/ class=md-nav__link> <span class=md-ellipsis> Retrieval Based Chat Application </span> </a> </li> <li class=md-nav__item> <a href=../../../../workshop/open-source-l200/05_agent_based_text_generation/ class=md-nav__link> <span class=md-ellipsis> Agent Based Text Generation </span> </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../../../../general/tags/ class=md-nav__link> <span class=md-ellipsis> Tags </span> </a> </li> <li class=md-nav__item> <a href=../../../../general/license/ class=md-nav__link> <span class=md-ellipsis> License </span> </a> </li> </ul> </nav> </div> </div> </div> <div class=md-content data-md-component=content> <article class="md-content__inner md-typeset"> <h1> Fine tuning and deploying Llama 3 8B to Amazon Bedrock using Custom Model Import </h1> <h2> Overview </h2> <p>This notebook illustrates the process of fine tuning <a href=https://huggingface.co/meta-llama/Meta-Llama-3-8B>Llama 3 8B</a> and deploying the custom model in Amazon Bedrock using Custom Model Import (CMI). </p> <p>This notebook will use an Amazon SageMaker training job to fine tune Llama 3 8B. The training script uses <a href=https://pytorch.org/docs/stable/fsdp.html>PyTorch FSDP</a> and QLoRA for parameter efficient fine tuning. Once trained, the adapters are <strong>merged</strong> back into the original model to get an updated set of weights persisted as <code>safetensors</code> files (Bedrock custom model import does not support separate LoRA adapters). The resulting files are later imported into Bedrock using the <a href=https://docs.aws.amazon.com/bedrock/latest/userguide/model-customization-import-model.html>custom model import</a> option.</p> <p>This notebook is inspired by <a href=https://www.philschmid.de/fsdp-qlora-llama3>Philipp Schmid's Blog</a>.</p> <h3> Model License Information </h3> <p>In this notebook we use the Meta Llama 3 model from HuggingFace. This model is a gated model within HuggingFace repository. To use this model you have to agree to the <a href=https://llama.meta.com/llama3/license>license agreement</a> and request access before the model can be used in this notebook.</p> <h2> Usecase </h2> <p>The usecase for this example will be LLM code generation, the code generation scenario will be text to SQL generation, which is sometimes needed to improve the quality of the generated queries or when using a non-standard SQL dialect. The same script can be adapted to other code generation scenarios by changing the fine tuning instructions and the dataset.</p> <h2> Amazon Bedrock Custom Model Import (CMI) </h2> <p>The resulting model files are imported into Amazon Bedrock via <a href=https://docs.aws.amazon.com/bedrock/latest/userguide/model-customization-import-model.html>Custom Model Import (CMI)</a>. </p> <p>Bedrock Custom Model Import allows for importing foundation models that have been customized in other environments outside of Amazon Bedrock, such as Amazon Sagemaker, EC2, etc. </p> <h2> Architecture Diagram </h2> <p><img alt="text-to-sql architecture" src=../images/text-to-sql-architecture.png></p> <h2> Notebook code with comments: </h2> <h3> Installing pre-requisites </h3> <div class=highlight><pre><span></span><code><span class=err>!</span><span class=n>pip</span> <span class=n>uninstall</span> <span class=n>autogluon</span> <span class=n>autogluon</span><span class=o>-</span><span class=n>multimodal</span> <span class=o>-</span><span class=n>y</span>
<span class=err>!</span><span class=n>pip</span> <span class=n>install</span> <span class=n>sagemaker</span> <span class=n>huggingface_hub</span> <span class=n>datasets</span> <span class=o>--</span><span class=n>upgrade</span> <span class=o>--</span><span class=n>quiet</span>
</code></pre></div> <pre><code>[33mWARNING: Skipping autogluon as it is not installed.[0m[33m
[0m[33mWARNING: Skipping autogluon-multimodal as it is not installed.[0m[33m
[0m[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv[0m[33m
[0m[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv[0m[33m
[0m
</code></pre> <div class=highlight><pre><span></span><code><span class=o>%</span><span class=n>pip</span> <span class=nb>list</span> <span class=o>|</span> <span class=n>grep</span> <span class=o>-</span><span class=n>e</span> <span class=n>torch</span> <span class=o>-</span><span class=n>e</span> <span class=n>datasets</span>
</code></pre></div> <pre><code>datasets                             2.20.0
Note: you may need to restart the kernel to use updated packages.
</code></pre> <p>Llama 3 8B is a gated model on the Hugging Face Hub. You will need to request access and then authenticate on this notebook by entering your Hugging Face access token.</p> <div class=highlight><pre><span></span><code><span class=kn>from</span> <span class=nn>huggingface_hub</span> <span class=kn>import</span> <span class=n>notebook_login</span>

<span class=n>notebook_login</span><span class=p>()</span>
</code></pre></div> <pre><code>VBox(children=(HTML(value='&lt;center&gt; &lt;img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦
</code></pre> <p><h3> Setup </h3></p> <p>Loading the information from this SageMaker session.</p> <div class=highlight><pre><span></span><code><span class=kn>import</span> <span class=nn>sagemaker</span>
<span class=kn>import</span> <span class=nn>boto3</span>

<span class=n>sess</span> <span class=o>=</span> <span class=n>sagemaker</span><span class=o>.</span><span class=n>Session</span><span class=p>()</span>

<span class=n>sagemaker_session_bucket</span><span class=o>=</span><span class=kc>None</span>
<span class=k>if</span> <span class=n>sagemaker_session_bucket</span> <span class=ow>is</span> <span class=kc>None</span> <span class=ow>and</span> <span class=n>sess</span> <span class=ow>is</span> <span class=ow>not</span> <span class=kc>None</span><span class=p>:</span>
    <span class=n>sagemaker_session_bucket</span> <span class=o>=</span> <span class=n>sess</span><span class=o>.</span><span class=n>default_bucket</span><span class=p>()</span>

<span class=k>try</span><span class=p>:</span>
    <span class=n>role</span> <span class=o>=</span> <span class=n>sagemaker</span><span class=o>.</span><span class=n>get_execution_role</span><span class=p>()</span>
<span class=k>except</span> <span class=ne>ValueError</span><span class=p>:</span>
    <span class=n>iam</span> <span class=o>=</span> <span class=n>boto3</span><span class=o>.</span><span class=n>client</span><span class=p>(</span><span class=s1>&#39;iam&#39;</span><span class=p>)</span>
    <span class=n>role</span> <span class=o>=</span> <span class=n>iam</span><span class=o>.</span><span class=n>get_role</span><span class=p>(</span><span class=n>RoleName</span><span class=o>=</span><span class=s1>&#39;sagemaker_execution_role&#39;</span><span class=p>)[</span><span class=s1>&#39;Role&#39;</span><span class=p>][</span><span class=s1>&#39;Arn&#39;</span><span class=p>]</span>

<span class=n>sess</span> <span class=o>=</span> <span class=n>sagemaker</span><span class=o>.</span><span class=n>Session</span><span class=p>(</span><span class=n>default_bucket</span><span class=o>=</span><span class=n>sagemaker_session_bucket</span><span class=p>)</span>

<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;sagemaker role arn: </span><span class=si>{</span><span class=n>role</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;sagemaker bucket: </span><span class=si>{</span><span class=n>sess</span><span class=o>.</span><span class=n>default_bucket</span><span class=p>()</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;sagemaker session region: </span><span class=si>{</span><span class=n>sess</span><span class=o>.</span><span class=n>boto_region_name</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</code></pre></div> <pre><code>sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml
sagemaker.config INFO - Not applying SDK defaults from location: /root/.config/sagemaker/config.yaml
sagemaker role arn: arn:aws:iam::425576326687:role/SageMakerStudioDomainNoAuth-SageMakerExecutionRole-3RBLN6GPZ46O
sagemaker bucket: sagemaker-us-east-1-425576326687
sagemaker session region: us-east-1
</code></pre> <div class=highlight><pre><span></span><code><span class=c1># S3 prefix for fine tuning training data</span>
<span class=n>training_input_path</span> <span class=o>=</span> <span class=sa>f</span><span class=s1>&#39;s3://</span><span class=si>{</span><span class=n>sess</span><span class=o>.</span><span class=n>default_bucket</span><span class=p>()</span><span class=si>}</span><span class=s1>/datasets/sql-context&#39;</span>
</code></pre></div> <h3> Preparing the data set </h3> <p>We are going to use the <a href=https://huggingface.co/datasets/b-mc2/sql-create-context>sql-create-context</a> available on Hugging Face to train this model. The data set contains 78,577 records, and we will use 99% of them for training. The data set has three columns:</p> <ul> <li><em>question</em>: The question made by a user in natural language</li> <li><em>content</em>: Schema of the relevant table(s)</li> <li><em>answer</em>: The SQL query</li> </ul> <p>Please refer to the <a href=https://huggingface.co/datasets/b-mc2/sql-create-context>Licensing Information</a> regarding this dataset before proceeding further.</p> <div class=highlight><pre><span></span><code><span class=kn>from</span> <span class=nn>datasets</span> <span class=kn>import</span> <span class=n>load_dataset</span><span class=p>,</span> <span class=n>DatasetDict</span>

<span class=n>system_message</span> <span class=o>=</span> <span class=s2>&quot;&quot;&quot;You are a powerful text-to-SQL model. Your job is to answer questions about a database.&quot;&quot;&quot;</span>

<span class=k>def</span> <span class=nf>create_conversation</span><span class=p>(</span><span class=n>record</span><span class=p>):</span>
    <span class=n>sample</span> <span class=o>=</span> <span class=p>{</span><span class=s2>&quot;messages&quot;</span><span class=p>:</span> <span class=p>[</span>
        <span class=p>{</span><span class=s2>&quot;role&quot;</span><span class=p>:</span> <span class=s2>&quot;system&quot;</span><span class=p>,</span> <span class=s2>&quot;content&quot;</span><span class=p>:</span> <span class=n>system_message</span> <span class=o>+</span> <span class=sa>f</span><span class=s2>&quot;&quot;&quot;You can use the following table schema for context: </span><span class=si>{</span><span class=n>record</span><span class=p>[</span><span class=s2>&quot;context&quot;</span><span class=p>]</span><span class=si>}</span><span class=s2>&quot;&quot;&quot;</span><span class=p>},</span>
        <span class=p>{</span><span class=s2>&quot;role&quot;</span><span class=p>:</span> <span class=s2>&quot;user&quot;</span><span class=p>,</span> <span class=s2>&quot;content&quot;</span><span class=p>:</span> <span class=sa>f</span><span class=s2>&quot;&quot;&quot;Return the SQL query that answers the following question: </span><span class=si>{</span><span class=n>record</span><span class=p>[</span><span class=s2>&quot;question&quot;</span><span class=p>]</span><span class=si>}</span><span class=s2>&quot;&quot;&quot;</span><span class=p>},</span>
        <span class=p>{</span><span class=s2>&quot;role&quot;</span> <span class=p>:</span> <span class=s2>&quot;assistant&quot;</span><span class=p>,</span> <span class=s2>&quot;content&quot;</span><span class=p>:</span> <span class=sa>f</span><span class=s2>&quot;&quot;&quot;</span><span class=si>{</span><span class=n>record</span><span class=p>[</span><span class=s2>&quot;answer&quot;</span><span class=p>]</span><span class=si>}</span><span class=s2>&quot;&quot;&quot;</span><span class=p>}</span>
    <span class=p>]}</span>
    <span class=k>return</span> <span class=n>sample</span>

<span class=n>dataset</span> <span class=o>=</span> <span class=n>load_dataset</span><span class=p>(</span><span class=s2>&quot;b-mc2/sql-create-context&quot;</span><span class=p>)</span>
<span class=n>dataset</span> <span class=o>=</span> <span class=n>dataset</span><span class=o>.</span><span class=n>map</span><span class=p>(</span><span class=n>create_conversation</span><span class=p>,</span> <span class=n>batched</span><span class=o>=</span><span class=kc>False</span><span class=p>)</span><span class=o>.</span><span class=n>remove_columns</span><span class=p>([</span><span class=s1>&#39;answer&#39;</span><span class=p>,</span> <span class=s1>&#39;question&#39;</span><span class=p>,</span> <span class=s1>&#39;context&#39;</span><span class=p>])</span>

<span class=n>train_test_split</span> <span class=o>=</span> <span class=n>dataset</span><span class=p>[</span><span class=s2>&quot;train&quot;</span><span class=p>]</span><span class=o>.</span><span class=n>train_test_split</span><span class=p>(</span><span class=n>test_size</span><span class=o>=</span><span class=mf>0.01</span><span class=p>,</span> <span class=n>seed</span><span class=o>=</span><span class=mi>42</span><span class=p>)</span> <span class=c1># only 1% for testing</span>
<span class=c1># Training and test sets</span>
<span class=n>training_data</span> <span class=o>=</span> <span class=n>train_test_split</span><span class=p>[</span><span class=s2>&quot;train&quot;</span><span class=p>]</span>
<span class=n>test_data</span> <span class=o>=</span> <span class=n>train_test_split</span><span class=p>[</span><span class=s2>&quot;test&quot;</span><span class=p>]</span>

<span class=n>training_data</span><span class=o>.</span><span class=n>to_json</span><span class=p>(</span><span class=s2>&quot;data/train_dataset.json&quot;</span><span class=p>,</span> <span class=n>orient</span><span class=o>=</span><span class=s2>&quot;records&quot;</span><span class=p>,</span> <span class=n>force_ascii</span><span class=o>=</span><span class=kc>False</span><span class=p>)</span>
<span class=n>test_data</span><span class=o>.</span><span class=n>to_json</span><span class=p>(</span><span class=s2>&quot;data/test_dataset.json&quot;</span><span class=p>,</span> <span class=n>orient</span><span class=o>=</span><span class=s2>&quot;records&quot;</span><span class=p>,</span> <span class=n>force_ascii</span><span class=o>=</span><span class=kc>False</span><span class=p>)</span>
</code></pre></div> <pre><code>Creating json from Arrow format:   0%|          | 0/78 [00:00&lt;?, ?ba/s]



Creating json from Arrow format:   0%|          | 0/1 [00:00&lt;?, ?ba/s]





409031
</code></pre> <div class=highlight><pre><span></span><code><span class=c1># Upload train and test data sets to S3</span>
<span class=n>train_s3_path</span> <span class=o>=</span> <span class=n>sagemaker</span><span class=o>.</span><span class=n>s3</span><span class=o>.</span><span class=n>S3Uploader</span><span class=o>.</span><span class=n>upload</span><span class=p>(</span><span class=s2>&quot;data/train_dataset.json&quot;</span><span class=p>,</span> <span class=n>training_input_path</span><span class=p>)</span>
<span class=n>test_s3_path</span> <span class=o>=</span> <span class=n>sagemaker</span><span class=o>.</span><span class=n>s3</span><span class=o>.</span><span class=n>S3Uploader</span><span class=o>.</span><span class=n>upload</span><span class=p>(</span><span class=s2>&quot;data/test_dataset.json&quot;</span><span class=p>,</span> <span class=n>training_input_path</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=s2>&quot;Training data uploaded to &quot;</span><span class=p>,</span> <span class=n>train_s3_path</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=s2>&quot;Test data uploaded to &quot;</span><span class=p>,</span> <span class=n>test_s3_path</span><span class=p>)</span>
</code></pre></div> <h3> Fine tuning the model </h3> <p>In this step we are going to fine tune Llama 3 8B using PyTorch FSDP and QLora, with the help of the Hugging Face <a href=https://huggingface.co/docs/trl/index>TRL</a>, <a href=https://huggingface.co/docs/transformers/index>Tranformers</a>, <a href=https://huggingface.co/docs/peft/index>PEFT</a>, and <a href=https://huggingface.co/docs/datasets/index>dadtasets</a> libraries. The code will be packaged to run inside a SageMaker training job.</p> <div class=highlight><pre><span></span><code><span class=n>model_id</span> <span class=o>=</span> <span class=s2>&quot;meta-llama/Meta-Llama-3-8B&quot;</span>
<span class=n>use_bf16</span> <span class=o>=</span> <span class=kc>True</span>  <span class=c1># use bfloat16 precision</span>
</code></pre></div> <div class=highlight><pre><span></span><code><span class=err>!</span><span class=n>rm</span> <span class=o>-</span><span class=n>rf</span> <span class=n>scripts</span> <span class=o>&amp;&amp;</span> <span class=n>mkdir</span> <span class=n>scripts</span> <span class=o>&amp;&amp;</span> <span class=n>mkdir</span> <span class=n>scripts</span><span class=o>/</span><span class=n>trl</span>
</code></pre></div> <div class=highlight><pre><span></span><code><span class=o>%%</span><span class=n>writefile</span> <span class=n>scripts</span><span class=o>/</span><span class=n>trl</span><span class=o>/</span><span class=n>requirements</span><span class=o>.</span><span class=n>txt</span>
<span class=n>torch</span><span class=o>==</span><span class=mf>2.2.2</span>
<span class=n>transformers</span><span class=o>==</span><span class=mf>4.40.2</span>
<span class=n>sagemaker</span><span class=o>&gt;=</span><span class=mf>2.190.0</span>
<span class=n>datasets</span><span class=o>==</span><span class=mf>2.18.0</span>
<span class=n>accelerate</span><span class=o>==</span><span class=mf>0.29.3</span>
<span class=n>evaluate</span><span class=o>==</span><span class=mf>0.4.1</span>
<span class=n>bitsandbytes</span><span class=o>==</span><span class=mf>0.43.1</span>
<span class=n>trl</span><span class=o>==</span><span class=mf>0.8.6</span>
<span class=n>peft</span><span class=o>==</span><span class=mf>0.10.0</span>
</code></pre></div> <div class=highlight><pre><span></span><code><span class=o>%%</span><span class=n>writefile</span> <span class=n>scripts</span><span class=o>/</span><span class=n>trl</span><span class=o>/</span><span class=n>run_fsdp_qlora</span><span class=o>.</span><span class=n>py</span>
<span class=kn>import</span> <span class=nn>logging</span>
<span class=kn>from</span> <span class=nn>dataclasses</span> <span class=kn>import</span> <span class=n>dataclass</span><span class=p>,</span> <span class=n>field</span>
<span class=kn>import</span> <span class=nn>os</span>

<span class=k>try</span><span class=p>:</span>
    <span class=n>os</span><span class=o>.</span><span class=n>system</span><span class=p>(</span><span class=s2>&quot;pip install flash-attn --no-build-isolation --upgrade&quot;</span><span class=p>)</span>
<span class=k>except</span><span class=p>:</span>
    <span class=nb>print</span><span class=p>(</span><span class=s2>&quot;flash-attn failed to install&quot;</span><span class=p>)</span>

<span class=kn>import</span> <span class=nn>random</span>
<span class=kn>import</span> <span class=nn>torch</span>
<span class=kn>from</span> <span class=nn>datasets</span> <span class=kn>import</span> <span class=n>load_dataset</span>
<span class=kn>from</span> <span class=nn>tqdm</span> <span class=kn>import</span> <span class=n>tqdm</span>
<span class=kn>from</span> <span class=nn>trl.commands.cli_utils</span> <span class=kn>import</span>  <span class=n>TrlParser</span>
<span class=kn>from</span> <span class=nn>transformers</span> <span class=kn>import</span> <span class=p>(</span>
    <span class=n>AutoModelForCausalLM</span><span class=p>,</span>
    <span class=n>AutoTokenizer</span><span class=p>,</span>
    <span class=n>TrainingArguments</span><span class=p>,</span>
    <span class=n>HfArgumentParser</span><span class=p>,</span>
    <span class=n>BitsAndBytesConfig</span><span class=p>,</span>
        <span class=n>set_seed</span><span class=p>,</span>

<span class=p>)</span>
<span class=kn>from</span> <span class=nn>trl</span> <span class=kn>import</span> <span class=n>setup_chat_format</span>
<span class=kn>from</span> <span class=nn>peft</span> <span class=kn>import</span> <span class=n>LoraConfig</span>


<span class=kn>from</span> <span class=nn>trl</span> <span class=kn>import</span> <span class=p>(</span>
   <span class=n>SFTTrainer</span><span class=p>)</span>

<span class=c1># Anthropic/Vicuna like template without the need for special tokens</span>
<span class=c1># Use the same template in inference</span>
<span class=n>LLAMA_3_CHAT_TEMPLATE</span> <span class=o>=</span> <span class=p>(</span>
    <span class=s2>&quot;{</span><span class=si>% f</span><span class=s2>or message in messages %}&quot;</span>
        <span class=s2>&quot;{</span><span class=si>% i</span><span class=s2>f message[&#39;role&#39;] == &#39;system&#39; %}&quot;</span>
            <span class=s2>&quot;{{ message[&#39;content&#39;] }}&quot;</span>
        <span class=s2>&quot;{</span><span class=si>% e</span><span class=s2>lif message[&#39;role&#39;] == &#39;user&#39; %}&quot;</span>
            <span class=s2>&quot;{{ &#39;</span><span class=se>\n\n</span><span class=s2>Human: &#39; + message[&#39;content&#39;] +  eos_token }}&quot;</span>
        <span class=s2>&quot;{</span><span class=si>% e</span><span class=s2>lif message[&#39;role&#39;] == &#39;assistant&#39; %}&quot;</span>
            <span class=s2>&quot;{{ &#39;</span><span class=se>\n\n</span><span class=s2>Assistant: &#39;  + message[&#39;content&#39;] +  eos_token  }}&quot;</span>
        <span class=s2>&quot;{</span><span class=si>% e</span><span class=s2>ndif %}&quot;</span>
    <span class=s2>&quot;{</span><span class=si>% e</span><span class=s2>ndfor %}&quot;</span>
    <span class=s2>&quot;{</span><span class=si>% i</span><span class=s2>f add_generation_prompt %}&quot;</span>
    <span class=s2>&quot;{{ &#39;</span><span class=se>\n\n</span><span class=s2>Assistant: &#39; }}&quot;</span>
    <span class=s2>&quot;{</span><span class=si>% e</span><span class=s2>ndif %}&quot;</span>
<span class=p>)</span>


<span class=n>tqdm</span><span class=o>.</span><span class=n>pandas</span><span class=p>()</span>

<span class=nd>@dataclass</span>
<span class=k>class</span> <span class=nc>ScriptArguments</span><span class=p>:</span>
    <span class=n>dataset_path</span><span class=p>:</span> <span class=nb>str</span> <span class=o>=</span> <span class=n>field</span><span class=p>(</span>
        <span class=n>default</span><span class=o>=</span><span class=kc>None</span><span class=p>,</span>
        <span class=n>metadata</span><span class=o>=</span><span class=p>{</span>
            <span class=s2>&quot;help&quot;</span><span class=p>:</span> <span class=s2>&quot;Path to the dataset&quot;</span>
        <span class=p>},</span>
    <span class=p>)</span>
    <span class=n>model_id</span><span class=p>:</span> <span class=nb>str</span> <span class=o>=</span> <span class=n>field</span><span class=p>(</span>
        <span class=n>default</span><span class=o>=</span><span class=kc>None</span><span class=p>,</span> <span class=n>metadata</span><span class=o>=</span><span class=p>{</span><span class=s2>&quot;help&quot;</span><span class=p>:</span> <span class=s2>&quot;Model ID to use for SFT training&quot;</span><span class=p>}</span>
    <span class=p>)</span>
    <span class=n>max_seq_length</span><span class=p>:</span> <span class=nb>int</span> <span class=o>=</span> <span class=n>field</span><span class=p>(</span>
        <span class=n>default</span><span class=o>=</span><span class=mi>512</span><span class=p>,</span> <span class=n>metadata</span><span class=o>=</span><span class=p>{</span><span class=s2>&quot;help&quot;</span><span class=p>:</span> <span class=s2>&quot;The maximum sequence length for SFT Trainer&quot;</span><span class=p>}</span>
    <span class=p>)</span>
    <span class=n>use_qlora</span><span class=p>:</span> <span class=nb>bool</span> <span class=o>=</span> <span class=n>field</span><span class=p>(</span><span class=n>default</span><span class=o>=</span><span class=kc>False</span><span class=p>,</span> <span class=n>metadata</span><span class=o>=</span><span class=p>{</span><span class=s2>&quot;help&quot;</span><span class=p>:</span> <span class=s2>&quot;Whether to use QLORA&quot;</span><span class=p>})</span>
    <span class=n>merge_adapters</span><span class=p>:</span> <span class=nb>bool</span> <span class=o>=</span> <span class=n>field</span><span class=p>(</span>
        <span class=n>metadata</span><span class=o>=</span><span class=p>{</span><span class=s2>&quot;help&quot;</span><span class=p>:</span> <span class=s2>&quot;Whether to merge weights for LoRA.&quot;</span><span class=p>},</span>
        <span class=n>default</span><span class=o>=</span><span class=kc>False</span><span class=p>,</span>
    <span class=p>)</span>


<span class=k>def</span> <span class=nf>training_function</span><span class=p>(</span><span class=n>script_args</span><span class=p>,</span> <span class=n>training_args</span><span class=p>):</span>
    <span class=c1>################</span>
    <span class=c1># Dataset</span>
    <span class=c1>################</span>

    <span class=n>train_dataset</span> <span class=o>=</span> <span class=n>load_dataset</span><span class=p>(</span>
        <span class=s2>&quot;json&quot;</span><span class=p>,</span>
        <span class=n>data_files</span><span class=o>=</span><span class=n>os</span><span class=o>.</span><span class=n>path</span><span class=o>.</span><span class=n>join</span><span class=p>(</span><span class=n>script_args</span><span class=o>.</span><span class=n>dataset_path</span><span class=p>,</span> <span class=s2>&quot;train_dataset.json&quot;</span><span class=p>),</span>
        <span class=n>split</span><span class=o>=</span><span class=s2>&quot;train&quot;</span><span class=p>,</span>
    <span class=p>)</span>
    <span class=n>test_dataset</span> <span class=o>=</span> <span class=n>load_dataset</span><span class=p>(</span>
        <span class=s2>&quot;json&quot;</span><span class=p>,</span>
        <span class=n>data_files</span><span class=o>=</span><span class=n>os</span><span class=o>.</span><span class=n>path</span><span class=o>.</span><span class=n>join</span><span class=p>(</span><span class=n>script_args</span><span class=o>.</span><span class=n>dataset_path</span><span class=p>,</span> <span class=s2>&quot;test_dataset.json&quot;</span><span class=p>),</span>
        <span class=n>split</span><span class=o>=</span><span class=s2>&quot;train&quot;</span><span class=p>,</span>
    <span class=p>)</span>

    <span class=c1>################</span>
    <span class=c1># Model &amp; Tokenizer</span>
    <span class=c1>################</span>

    <span class=c1># Tokenizer        </span>
    <span class=n>tokenizer</span> <span class=o>=</span> <span class=n>AutoTokenizer</span><span class=o>.</span><span class=n>from_pretrained</span><span class=p>(</span><span class=n>script_args</span><span class=o>.</span><span class=n>model_id</span><span class=p>,</span> <span class=n>use_fast</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
    <span class=n>tokenizer</span><span class=o>.</span><span class=n>pad_token</span> <span class=o>=</span> <span class=n>tokenizer</span><span class=o>.</span><span class=n>eos_token</span>
    <span class=n>tokenizer</span><span class=o>.</span><span class=n>chat_template</span> <span class=o>=</span> <span class=n>LLAMA_3_CHAT_TEMPLATE</span>

    <span class=c1># template dataset</span>
    <span class=k>def</span> <span class=nf>template_dataset</span><span class=p>(</span><span class=n>examples</span><span class=p>):</span>
        <span class=k>return</span><span class=p>{</span><span class=s2>&quot;text&quot;</span><span class=p>:</span>  <span class=n>tokenizer</span><span class=o>.</span><span class=n>apply_chat_template</span><span class=p>(</span><span class=n>examples</span><span class=p>[</span><span class=s2>&quot;messages&quot;</span><span class=p>],</span> <span class=n>tokenize</span><span class=o>=</span><span class=kc>False</span><span class=p>)}</span>

    <span class=n>train_dataset</span> <span class=o>=</span> <span class=n>train_dataset</span><span class=o>.</span><span class=n>map</span><span class=p>(</span><span class=n>template_dataset</span><span class=p>,</span> <span class=n>remove_columns</span><span class=o>=</span><span class=p>[</span><span class=s2>&quot;messages&quot;</span><span class=p>])</span>
    <span class=n>test_dataset</span> <span class=o>=</span> <span class=n>test_dataset</span><span class=o>.</span><span class=n>map</span><span class=p>(</span><span class=n>template_dataset</span><span class=p>,</span> <span class=n>remove_columns</span><span class=o>=</span><span class=p>[</span><span class=s2>&quot;messages&quot;</span><span class=p>])</span>

    <span class=c1># print random sample</span>
    <span class=k>with</span> <span class=n>training_args</span><span class=o>.</span><span class=n>main_process_first</span><span class=p>(</span>
        <span class=n>desc</span><span class=o>=</span><span class=s2>&quot;Log a few random samples from the processed training set&quot;</span>
    <span class=p>):</span>
        <span class=k>for</span> <span class=n>index</span> <span class=ow>in</span> <span class=n>random</span><span class=o>.</span><span class=n>sample</span><span class=p>(</span><span class=nb>range</span><span class=p>(</span><span class=nb>len</span><span class=p>(</span><span class=n>train_dataset</span><span class=p>)),</span> <span class=mi>2</span><span class=p>):</span>
            <span class=nb>print</span><span class=p>(</span><span class=n>train_dataset</span><span class=p>[</span><span class=n>index</span><span class=p>][</span><span class=s2>&quot;text&quot;</span><span class=p>])</span>

    <span class=c1># Model    </span>
    <span class=n>torch_dtype</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>bfloat16</span> <span class=k>if</span> <span class=n>training_args</span><span class=o>.</span><span class=n>bf16</span> <span class=k>else</span> <span class=n>torch</span><span class=o>.</span><span class=n>float32</span>
    <span class=n>quant_storage_dtype</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>bfloat16</span>

    <span class=k>if</span> <span class=n>script_args</span><span class=o>.</span><span class=n>use_qlora</span><span class=p>:</span>
        <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Using QLoRA - </span><span class=si>{</span><span class=n>torch_dtype</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
        <span class=n>quantization_config</span> <span class=o>=</span> <span class=n>BitsAndBytesConfig</span><span class=p>(</span>
                <span class=n>load_in_4bit</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span>
                <span class=n>bnb_4bit_use_double_quant</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span>
                <span class=n>bnb_4bit_quant_type</span><span class=o>=</span><span class=s2>&quot;nf4&quot;</span><span class=p>,</span>
                <span class=n>bnb_4bit_compute_dtype</span><span class=o>=</span><span class=n>torch_dtype</span><span class=p>,</span>
                <span class=n>bnb_4bit_quant_storage</span><span class=o>=</span><span class=n>quant_storage_dtype</span><span class=p>,</span>
            <span class=p>)</span>
    <span class=k>else</span><span class=p>:</span>
        <span class=n>quantization_config</span> <span class=o>=</span> <span class=kc>None</span>

    <span class=n>model</span> <span class=o>=</span> <span class=n>AutoModelForCausalLM</span><span class=o>.</span><span class=n>from_pretrained</span><span class=p>(</span>
        <span class=n>script_args</span><span class=o>.</span><span class=n>model_id</span><span class=p>,</span>
        <span class=n>quantization_config</span><span class=o>=</span><span class=n>quantization_config</span><span class=p>,</span>
        <span class=c1>#device_map=&quot;auto&quot;,</span>
        <span class=n>device_map</span><span class=o>=</span><span class=p>{</span><span class=s1>&#39;&#39;</span><span class=p>:</span><span class=n>torch</span><span class=o>.</span><span class=n>cuda</span><span class=o>.</span><span class=n>current_device</span><span class=p>()},</span>
        <span class=n>attn_implementation</span><span class=o>=</span><span class=s2>&quot;flash_attention_2&quot;</span><span class=p>,</span> <span class=c1># use sdpa, alternatively use &quot;flash_attention_2&quot;</span>
        <span class=n>torch_dtype</span><span class=o>=</span><span class=n>quant_storage_dtype</span><span class=p>,</span>
        <span class=n>use_cache</span><span class=o>=</span><span class=kc>False</span> <span class=k>if</span> <span class=n>training_args</span><span class=o>.</span><span class=n>gradient_checkpointing</span> <span class=k>else</span> <span class=kc>True</span><span class=p>,</span>  <span class=c1># this is needed for gradient checkpointing</span>
    <span class=p>)</span>

    <span class=k>if</span> <span class=n>training_args</span><span class=o>.</span><span class=n>gradient_checkpointing</span><span class=p>:</span>
        <span class=n>model</span><span class=o>.</span><span class=n>gradient_checkpointing_enable</span><span class=p>()</span>

    <span class=c1>################</span>
    <span class=c1># PEFT</span>
    <span class=c1>################</span>

    <span class=c1># LoRA config based on QLoRA paper &amp; Sebastian Raschka experiment</span>
    <span class=n>peft_config</span> <span class=o>=</span> <span class=n>LoraConfig</span><span class=p>(</span>
        <span class=n>lora_alpha</span><span class=o>=</span><span class=mi>8</span><span class=p>,</span>
        <span class=n>lora_dropout</span><span class=o>=</span><span class=mf>0.05</span><span class=p>,</span>
        <span class=n>r</span><span class=o>=</span><span class=mi>16</span><span class=p>,</span>
        <span class=n>bias</span><span class=o>=</span><span class=s2>&quot;none&quot;</span><span class=p>,</span>
        <span class=n>target_modules</span><span class=o>=</span><span class=s2>&quot;all-linear&quot;</span><span class=p>,</span>
        <span class=n>task_type</span><span class=o>=</span><span class=s2>&quot;CAUSAL_LM&quot;</span><span class=p>,</span>
    <span class=p>)</span>

    <span class=c1>################</span>
    <span class=c1># Training</span>
    <span class=c1>################</span>
    <span class=n>trainer</span> <span class=o>=</span> <span class=n>SFTTrainer</span><span class=p>(</span>
        <span class=n>model</span><span class=o>=</span><span class=n>model</span><span class=p>,</span>
        <span class=n>args</span><span class=o>=</span><span class=n>training_args</span><span class=p>,</span>
        <span class=n>train_dataset</span><span class=o>=</span><span class=n>train_dataset</span><span class=p>,</span>
        <span class=n>dataset_text_field</span><span class=o>=</span><span class=s2>&quot;text&quot;</span><span class=p>,</span>
        <span class=n>eval_dataset</span><span class=o>=</span><span class=n>test_dataset</span><span class=p>,</span>
        <span class=n>peft_config</span><span class=o>=</span><span class=n>peft_config</span><span class=p>,</span>
        <span class=n>max_seq_length</span><span class=o>=</span><span class=n>script_args</span><span class=o>.</span><span class=n>max_seq_length</span><span class=p>,</span>
        <span class=n>tokenizer</span><span class=o>=</span><span class=n>tokenizer</span><span class=p>,</span>
        <span class=n>packing</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span>
        <span class=n>dataset_kwargs</span><span class=o>=</span><span class=p>{</span>
            <span class=s2>&quot;add_special_tokens&quot;</span><span class=p>:</span> <span class=kc>False</span><span class=p>,</span>  <span class=c1># We template with special tokens</span>
            <span class=s2>&quot;append_concat_token&quot;</span><span class=p>:</span> <span class=kc>False</span><span class=p>,</span>  <span class=c1># No need to add additional separator token</span>
        <span class=p>},</span>
    <span class=p>)</span>
    <span class=k>if</span> <span class=n>trainer</span><span class=o>.</span><span class=n>accelerator</span><span class=o>.</span><span class=n>is_main_process</span><span class=p>:</span>
        <span class=n>trainer</span><span class=o>.</span><span class=n>model</span><span class=o>.</span><span class=n>print_trainable_parameters</span><span class=p>()</span>

    <span class=c1>##########################</span>
    <span class=c1># Train model</span>
    <span class=c1>##########################</span>
    <span class=n>checkpoint</span> <span class=o>=</span> <span class=kc>None</span>
    <span class=k>if</span> <span class=n>training_args</span><span class=o>.</span><span class=n>resume_from_checkpoint</span> <span class=ow>is</span> <span class=ow>not</span> <span class=kc>None</span><span class=p>:</span>
        <span class=n>checkpoint</span> <span class=o>=</span> <span class=n>training_args</span><span class=o>.</span><span class=n>resume_from_checkpoint</span>
    <span class=n>trainer</span><span class=o>.</span><span class=n>train</span><span class=p>(</span><span class=n>resume_from_checkpoint</span><span class=o>=</span><span class=n>checkpoint</span><span class=p>)</span>

    <span class=c1>##########################</span>
    <span class=c1># SAVE MODEL FOR SAGEMAKER</span>
    <span class=c1>##########################</span>
    <span class=n>sagemaker_save_dir</span> <span class=o>=</span> <span class=s2>&quot;/opt/ml/model&quot;</span>

    <span class=k>if</span> <span class=n>trainer</span><span class=o>.</span><span class=n>is_fsdp_enabled</span><span class=p>:</span>
        <span class=n>trainer</span><span class=o>.</span><span class=n>accelerator</span><span class=o>.</span><span class=n>state</span><span class=o>.</span><span class=n>fsdp_plugin</span><span class=o>.</span><span class=n>set_state_dict_type</span><span class=p>(</span><span class=s2>&quot;FULL_STATE_DICT&quot;</span><span class=p>)</span>

    <span class=k>if</span> <span class=n>script_args</span><span class=o>.</span><span class=n>merge_adapters</span><span class=p>:</span>
        <span class=c1># persist tokenizer</span>
        <span class=n>trainer</span><span class=o>.</span><span class=n>tokenizer</span><span class=o>.</span><span class=n>save_pretrained</span><span class=p>(</span><span class=n>sagemaker_save_dir</span><span class=p>)</span>
        <span class=c1># merge adapter weights with base model and save</span>
        <span class=c1># save int 4 model</span>
        <span class=nb>print</span><span class=p>(</span><span class=s1>&#39;########## Merging Adapters  ##########&#39;</span><span class=p>)</span>
        <span class=n>trainer</span><span class=o>.</span><span class=n>model</span><span class=o>.</span><span class=n>save_pretrained</span><span class=p>(</span><span class=n>training_args</span><span class=o>.</span><span class=n>output_dir</span><span class=p>)</span>
        <span class=n>trainer</span><span class=o>.</span><span class=n>tokenizer</span><span class=o>.</span><span class=n>save_pretrained</span><span class=p>(</span><span class=n>training_args</span><span class=o>.</span><span class=n>output_dir</span><span class=p>)</span>
        <span class=c1># clear memory</span>
        <span class=k>del</span> <span class=n>model</span>
        <span class=k>del</span> <span class=n>trainer</span>
        <span class=n>torch</span><span class=o>.</span><span class=n>cuda</span><span class=o>.</span><span class=n>empty_cache</span><span class=p>()</span>

        <span class=kn>from</span> <span class=nn>peft</span> <span class=kn>import</span> <span class=n>AutoPeftModelForCausalLM</span>

        <span class=c1># load PEFT model</span>
        <span class=n>model</span> <span class=o>=</span> <span class=n>AutoPeftModelForCausalLM</span><span class=o>.</span><span class=n>from_pretrained</span><span class=p>(</span>
            <span class=n>training_args</span><span class=o>.</span><span class=n>output_dir</span><span class=p>,</span>
            <span class=n>low_cpu_mem_usage</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span>
            <span class=n>torch_dtype</span><span class=o>=</span><span class=n>torch</span><span class=o>.</span><span class=n>float16</span>
        <span class=p>)</span>
        <span class=c1># Merge LoRA and base model and persist weights</span>
        <span class=n>model</span> <span class=o>=</span> <span class=n>model</span><span class=o>.</span><span class=n>merge_and_unload</span><span class=p>()</span>
        <span class=n>model</span><span class=o>.</span><span class=n>save_pretrained</span><span class=p>(</span>
            <span class=n>sagemaker_save_dir</span><span class=p>,</span> <span class=n>safe_serialization</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span> <span class=n>max_shard_size</span><span class=o>=</span><span class=s2>&quot;2GB&quot;</span>
        <span class=p>)</span>
    <span class=k>else</span><span class=p>:</span>
        <span class=n>trainer</span><span class=o>.</span><span class=n>model</span><span class=o>.</span><span class=n>save_pretrained</span><span class=p>(</span><span class=n>sagemaker_save_dir</span><span class=p>,</span> <span class=n>safe_serialization</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>

<span class=k>if</span> <span class=vm>__name__</span> <span class=o>==</span> <span class=s2>&quot;__main__&quot;</span><span class=p>:</span>
    <span class=n>parser</span> <span class=o>=</span> <span class=n>HfArgumentParser</span><span class=p>((</span><span class=n>ScriptArguments</span><span class=p>,</span> <span class=n>TrainingArguments</span><span class=p>))</span>
    <span class=n>script_args</span><span class=p>,</span> <span class=n>training_args</span> <span class=o>=</span> <span class=n>parser</span><span class=o>.</span><span class=n>parse_args_into_dataclasses</span><span class=p>()</span>    

    <span class=c1># set use reentrant to False</span>
    <span class=k>if</span> <span class=n>training_args</span><span class=o>.</span><span class=n>gradient_checkpointing</span><span class=p>:</span>
        <span class=n>training_args</span><span class=o>.</span><span class=n>gradient_checkpointing_kwargs</span> <span class=o>=</span> <span class=p>{</span><span class=s2>&quot;use_reentrant&quot;</span><span class=p>:</span> <span class=kc>True</span><span class=p>}</span>
    <span class=c1># set seed</span>
    <span class=n>set_seed</span><span class=p>(</span><span class=n>training_args</span><span class=o>.</span><span class=n>seed</span><span class=p>)</span>

    <span class=c1># launch training</span>
    <span class=n>training_function</span><span class=p>(</span><span class=n>script_args</span><span class=p>,</span> <span class=n>training_args</span><span class=p>)</span>
</code></pre></div> <div class=highlight><pre><span></span><code><span class=n>hyperparameters</span> <span class=o>=</span> <span class=p>{</span>
  <span class=c1>### SCRIPT PARAMETERS ###</span>
  <span class=s1>&#39;dataset_path&#39;</span><span class=p>:</span> <span class=s1>&#39;/opt/ml/input/data/training/&#39;</span><span class=p>,</span>    <span class=c1># path where sagemaker will save training dataset</span>
  <span class=s1>&#39;model_id&#39;</span><span class=p>:</span> <span class=n>model_id</span><span class=p>,</span>                              <span class=c1># or `mistralai/Mistral-7B-v0.1`</span>
  <span class=s1>&#39;max_seq_len&#39;</span><span class=p>:</span> <span class=mi>3072</span><span class=p>,</span>                               <span class=c1># max sequence length for model and packing of the dataset</span>
  <span class=s1>&#39;use_qlora&#39;</span><span class=p>:</span> <span class=kc>True</span><span class=p>,</span>                                 <span class=c1># use QLoRA model</span>
  <span class=c1>### TRAINING PARAMETERS ###</span>
  <span class=s1>&#39;num_train_epochs&#39;</span><span class=p>:</span> <span class=mi>2</span><span class=p>,</span>                             <span class=c1># number of training epochs</span>
  <span class=s1>&#39;per_device_train_batch_size&#39;</span><span class=p>:</span> <span class=mi>1</span><span class=p>,</span>                  <span class=c1># batch size per device during training</span>
  <span class=s1>&#39;per_device_eval_batch_size&#39;</span><span class=p>:</span> <span class=mi>1</span><span class=p>,</span>                   <span class=c1># batch size for evaluation    </span>
  <span class=s1>&#39;gradient_accumulation_steps&#39;</span><span class=p>:</span> <span class=mi>4</span><span class=p>,</span>                  <span class=c1># number of steps before performing a backward/update pass</span>
  <span class=s1>&#39;gradient_checkpointing&#39;</span><span class=p>:</span> <span class=kc>True</span><span class=p>,</span>                    <span class=c1># use gradient checkpointing to save memory</span>
  <span class=s1>&#39;optim&#39;</span><span class=p>:</span> <span class=s2>&quot;adamw_torch&quot;</span><span class=p>,</span>                            <span class=c1># use fused adamw optimizer</span>
  <span class=s1>&#39;logging_steps&#39;</span><span class=p>:</span> <span class=mi>10</span><span class=p>,</span>                               <span class=c1># log every 10 steps</span>
  <span class=s1>&#39;save_strategy&#39;</span><span class=p>:</span> <span class=s2>&quot;epoch&quot;</span><span class=p>,</span>                          <span class=c1># save checkpoint every epoch</span>
  <span class=s1>&#39;evaluation_strategy&#39;</span><span class=p>:</span> <span class=s2>&quot;epoch&quot;</span><span class=p>,</span>
  <span class=s1>&#39;learning_rate&#39;</span><span class=p>:</span> <span class=mf>0.0002</span><span class=p>,</span>                           <span class=c1># learning rate, based on QLoRA paper</span>
  <span class=s1>&#39;bf16&#39;</span><span class=p>:</span> <span class=n>use_bf16</span><span class=p>,</span>                                      <span class=c1># use bfloat16 precision</span>
  <span class=s1>&#39;tf32&#39;</span><span class=p>:</span> <span class=kc>True</span><span class=p>,</span>                                      <span class=c1># use tf32 precision</span>
  <span class=s1>&#39;max_grad_norm&#39;</span><span class=p>:</span> <span class=mf>0.3</span><span class=p>,</span>                              <span class=c1># max gradient norm based on QLoRA paper</span>
  <span class=s1>&#39;warmup_ratio&#39;</span><span class=p>:</span> <span class=mf>0.03</span><span class=p>,</span>                              <span class=c1># warmup ratio based on QLoRA paper</span>
  <span class=s1>&#39;lr_scheduler_type&#39;</span><span class=p>:</span> <span class=s2>&quot;constant&quot;</span><span class=p>,</span>                   <span class=c1># use constant learning rate scheduler</span>
  <span class=s1>&#39;report_to&#39;</span><span class=p>:</span> <span class=s2>&quot;tensorboard&quot;</span><span class=p>,</span>                        <span class=c1># report metrics to tensorboard</span>
  <span class=s1>&#39;output_dir&#39;</span><span class=p>:</span> <span class=s1>&#39;/tmp/tun&#39;</span><span class=p>,</span>                          <span class=c1># Temporary output directory for model checkpoints</span>
  <span class=s1>&#39;merge_adapters&#39;</span><span class=p>:</span> <span class=kc>True</span><span class=p>,</span>                            <span class=c1># merge LoRA adapters into model for easier deployment</span>
  <span class=s1>&#39;fsdp&#39;</span><span class=p>:</span> <span class=s1>&#39;&quot;full_shard auto_wrap offload&quot;&#39;</span><span class=p>,</span>
<span class=p>}</span>
</code></pre></div> <div class=highlight><pre><span></span><code><span class=kn>from</span> <span class=nn>sagemaker.huggingface</span> <span class=kn>import</span> <span class=n>HuggingFace</span>
<span class=kn>from</span> <span class=nn>huggingface_hub</span> <span class=kn>import</span> <span class=n>HfFolder</span> 
<span class=kn>import</span> <span class=nn>time</span>

<span class=c1># define Training Job Name</span>
<span class=n>job_name</span> <span class=o>=</span> <span class=sa>f</span><span class=s1>&#39;</span><span class=si>{</span><span class=n>model_id</span><span class=o>.</span><span class=n>replace</span><span class=p>(</span><span class=s2>&quot;/&quot;</span><span class=p>,</span><span class=w> </span><span class=s2>&quot;-&quot;</span><span class=p>)</span><span class=si>}</span><span class=s1>-</span><span class=si>{</span><span class=s2>&quot;bf16&quot;</span><span class=w> </span><span class=k>if</span><span class=w> </span><span class=n>use_bf16</span><span class=w> </span><span class=k>else</span><span class=w> </span><span class=s2>&quot;f32&quot;</span><span class=w> </span><span class=si>}</span><span class=s1>-</span><span class=si>{</span><span class=n>time</span><span class=o>.</span><span class=n>strftime</span><span class=p>(</span><span class=s2>&quot;%Y-%m-</span><span class=si>%d</span><span class=s2>-%H-%M-%S&quot;</span><span class=p>,</span><span class=w> </span><span class=n>time</span><span class=o>.</span><span class=n>localtime</span><span class=p>())</span><span class=si>}</span><span class=s1>&#39;</span>
</code></pre></div> <div class=highlight><pre><span></span><code><span class=c1># create the Estimator</span>
<span class=n>huggingface_estimator</span> <span class=o>=</span> <span class=n>HuggingFace</span><span class=p>(</span>
    <span class=n>entry_point</span>          <span class=o>=</span> <span class=s1>&#39;run_fsdp_qlora.py&#39;</span><span class=p>,</span>    <span class=c1># train script</span>
    <span class=n>source_dir</span>           <span class=o>=</span> <span class=s1>&#39;scripts/trl/&#39;</span><span class=p>,</span>      <span class=c1># directory which includes all the files needed for training</span>
    <span class=n>instance_type</span>        <span class=o>=</span> <span class=s1>&#39;ml.g5.12xlarge&#39;</span><span class=p>,</span>   <span class=c1># instances type used for the training job</span>
    <span class=n>instance_count</span>       <span class=o>=</span> <span class=mi>1</span><span class=p>,</span>                 <span class=c1># the number of instances used for training</span>
    <span class=n>max_run</span>              <span class=o>=</span> <span class=mi>2</span><span class=o>*</span><span class=mi>24</span><span class=o>*</span><span class=mi>60</span><span class=o>*</span><span class=mi>60</span><span class=p>,</span>        <span class=c1># maximum runtime in seconds (days * hours * minutes * seconds)</span>
    <span class=n>base_job_name</span>        <span class=o>=</span> <span class=n>job_name</span><span class=p>,</span>          <span class=c1># the name of the training job</span>
    <span class=n>role</span>                 <span class=o>=</span> <span class=n>role</span><span class=p>,</span>              <span class=c1># Iam role used in training job to access AWS ressources, e.g. S3</span>
    <span class=n>volume_size</span>          <span class=o>=</span> <span class=mi>300</span><span class=p>,</span>               <span class=c1># the size of the EBS volume in GB</span>
    <span class=n>transformers_version</span> <span class=o>=</span> <span class=s1>&#39;4.36.0&#39;</span><span class=p>,</span>            <span class=c1># the transformers version used in the training job</span>
    <span class=n>pytorch_version</span>      <span class=o>=</span> <span class=s1>&#39;2.1.0&#39;</span><span class=p>,</span>             <span class=c1># the pytorch_version version used in the training job</span>
    <span class=n>py_version</span>           <span class=o>=</span> <span class=s1>&#39;py310&#39;</span><span class=p>,</span>           <span class=c1># the python version used in the training job</span>
    <span class=n>hyperparameters</span>      <span class=o>=</span>  <span class=n>hyperparameters</span><span class=p>,</span>  <span class=c1># the hyperparameters passed to the training job</span>
    <span class=n>disable_output_compression</span> <span class=o>=</span> <span class=kc>True</span><span class=p>,</span>        <span class=c1># not compress output to save training time and cost</span>
    <span class=n>distribution</span><span class=o>=</span><span class=p>{</span><span class=s2>&quot;torch_distributed&quot;</span><span class=p>:</span> <span class=p>{</span><span class=s2>&quot;enabled&quot;</span><span class=p>:</span> <span class=kc>True</span><span class=p>}},</span>
    <span class=n>environment</span>          <span class=o>=</span> <span class=p>{</span>
        <span class=s2>&quot;HUGGINGFACE_HUB_CACHE&quot;</span><span class=p>:</span> <span class=s2>&quot;/tmp/.cache&quot;</span><span class=p>,</span> <span class=c1># set env variable to cache models in /tmp</span>
        <span class=s2>&quot;HF_TOKEN&quot;</span><span class=p>:</span> <span class=n>HfFolder</span><span class=o>.</span><span class=n>get_token</span><span class=p>(),</span>       <span class=c1># Retrieve HuggingFace Token to be used for downloading base models from</span>
        <span class=s2>&quot;ACCELERATE_USE_FSDP&quot;</span><span class=p>:</span><span class=s2>&quot;1&quot;</span><span class=p>,</span> 
        <span class=s2>&quot;FSDP_CPU_RAM_EFFICIENT_LOADING&quot;</span><span class=p>:</span><span class=s2>&quot;1&quot;</span>
    <span class=p>},</span>
<span class=p>)</span>
</code></pre></div> <div class=highlight><pre><span></span><code><span class=c1># define a data input dictonary with our uploaded s3 uris</span>
<span class=n>data</span> <span class=o>=</span> <span class=p>{</span><span class=s1>&#39;training&#39;</span><span class=p>:</span> <span class=n>training_input_path</span><span class=p>}</span>

<span class=c1># starting the train job with our uploaded datasets as input</span>
<span class=n>huggingface_estimator</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span><span class=n>data</span><span class=p>,</span> <span class=n>wait</span><span class=o>=</span><span class=kc>False</span><span class=p>)</span>
</code></pre></div> <pre><code>INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.
INFO:sagemaker:Creating training-job with name: meta-llama-Meta-Llama-3-8B-bf16-2024-06-2024-06-14-21-00-52-677
</code></pre> <div class=highlight><pre><span></span><code><span class=n>s3_files_path</span> <span class=o>=</span> <span class=n>huggingface_estimator</span><span class=o>.</span><span class=n>model_data</span><span class=p>[</span><span class=s2>&quot;S3DataSource&quot;</span><span class=p>][</span><span class=s2>&quot;S3Uri&quot;</span><span class=p>]</span>
<span class=nb>print</span><span class=p>(</span><span class=s2>&quot;Model artifacts stored in: &quot;</span><span class=p>,</span> <span class=n>s3_files_path</span><span class=p>)</span>
</code></pre></div> <h3> Deploy the model </h3> <p>Go to the AWS console and, on the left-hand size, click on <code>Imported models</code> under <code>Foundation models</code>.</p> <p><img alt="imported models" src=../images/text-2-sql-imported-models-menu.png></p> <p>Click on <code>Import model</code>.</p> <p><img alt="import model" src=../images/text-2-sql-import-model-button.png></p> <p>Use <code>llama-3-8b-text-to-sql</code> as the <code>Model name</code>, and enter the S3 location from above. Click on <code>Import model</code>.</p> <p><img alt="import model job" src=../images/text-2-sql-import-model-job.png></p> <p>When the import job completes, click on <code>Models</code> to see your model. Copy the ARN because we will need it in the next steps.</p> <p><img alt="import model job" src=../images/text-2-sql-take-model-arn.png></p> <p>You can test the model using the <code>Bedrock Playground</code>. Select your model and enter a question, as shown below.</p> <p><img alt="test model playground" src=../images/text-2-sql-demo.gif></p> <h3> Invoke the model </h3> <p>We are going to use the <code>InvokeModel</code> API from the Bedrock runtime to call the model on our test data set. Pleace enter your custom model ARN under <code>model_id</code>.</p> <div class=highlight><pre><span></span><code><span class=kn>import</span> <span class=nn>boto3</span>
<span class=kn>import</span> <span class=nn>json</span>

<span class=n>region</span> <span class=o>=</span> <span class=n>sess</span><span class=o>.</span><span class=n>boto_region_name</span>
<span class=n>client</span> <span class=o>=</span> <span class=n>boto3</span><span class=o>.</span><span class=n>client</span><span class=p>(</span><span class=s2>&quot;bedrock-runtime&quot;</span><span class=p>,</span> <span class=n>region_name</span><span class=o>=</span><span class=n>region</span><span class=p>)</span>
<span class=n>model_id</span> <span class=o>=</span> <span class=s2>&quot;&lt;ENTER_YOUR_MODEL_ARN_HERE&gt;&quot;</span>

<span class=k>assert</span> <span class=n>model_id</span> <span class=o>!=</span> <span class=s2>&quot;&lt;ENTER_YOUR_MODEL_ARN_HERE&gt;&quot;</span><span class=p>,</span> <span class=s2>&quot;ERROR: Please enter your model id&quot;</span>

<span class=k>def</span> <span class=nf>get_sql_query</span><span class=p>(</span><span class=n>system_prompt</span><span class=p>,</span> <span class=n>user_question</span><span class=p>):</span>
<span class=w>    </span><span class=sd>&quot;&quot;&quot;</span>
<span class=sd>    Generate a SQL query using Llama 3 8B</span>
<span class=sd>    Remember to use the same template used in fine tuning</span>
<span class=sd>    &quot;&quot;&quot;</span>
    <span class=n>formatted_prompt</span> <span class=o>=</span> <span class=sa>f</span><span class=s2>&quot;&lt;s&gt;[INST] &lt;&lt;SYS&gt;&gt;</span><span class=si>{</span><span class=n>system_prompt</span><span class=si>}</span><span class=s2>&lt;&lt;/SYS&gt;&gt;</span><span class=se>\n\n</span><span class=s2>[INST]Human: </span><span class=si>{</span><span class=n>user_question</span><span class=si>}</span><span class=s2>[/INST]</span><span class=se>\n\n</span><span class=s2>Assistant:&quot;</span>
    <span class=n>native_request</span> <span class=o>=</span> <span class=p>{</span>
        <span class=s2>&quot;prompt&quot;</span><span class=p>:</span> <span class=n>formatted_prompt</span><span class=p>,</span>
        <span class=s2>&quot;max_tokens&quot;</span><span class=p>:</span> <span class=mi>100</span><span class=p>,</span>
        <span class=s2>&quot;top_p&quot;</span><span class=p>:</span> <span class=mf>0.9</span><span class=p>,</span>
        <span class=s2>&quot;temperature&quot;</span><span class=p>:</span> <span class=mf>0.1</span>
    <span class=p>}</span>
    <span class=n>response</span> <span class=o>=</span> <span class=n>client</span><span class=o>.</span><span class=n>invoke_model</span><span class=p>(</span><span class=n>modelId</span><span class=o>=</span><span class=n>model_id</span><span class=p>,</span>
                                   <span class=n>body</span><span class=o>=</span><span class=n>json</span><span class=o>.</span><span class=n>dumps</span><span class=p>(</span><span class=n>native_request</span><span class=p>))</span>
    <span class=n>response_text</span> <span class=o>=</span> <span class=n>json</span><span class=o>.</span><span class=n>loads</span><span class=p>(</span><span class=n>response</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=s1>&#39;body&#39;</span><span class=p>)</span><span class=o>.</span><span class=n>read</span><span class=p>())[</span><span class=s2>&quot;outputs&quot;</span><span class=p>][</span><span class=mi>0</span><span class=p>][</span><span class=s2>&quot;text&quot;</span><span class=p>]</span>

    <span class=k>return</span> <span class=n>response_text</span>
</code></pre></div> <p>Let us try a sample invocation ...</p> <div class=highlight><pre><span></span><code><span class=n>system_prompt</span> <span class=o>=</span> <span class=s2>&quot;You are a powerful text-to-SQL model. Your job is to answer questions about a database. You can use the following table schema for context: CREATE TABLE table_name_11 (tournament VARCHAR)&quot;</span>
<span class=n>user_question</span> <span class=o>=</span> <span class=s2>&quot;Return the SQL query that answers the following question: Which Tournament has A in 1987?&quot;</span>

<span class=n>query</span> <span class=o>=</span> <span class=n>get_sql_query</span><span class=p>(</span><span class=n>system_prompt</span><span class=p>,</span> <span class=n>user_question</span><span class=p>)</span><span class=o>.</span><span class=n>strip</span><span class=p>()</span>
<span class=nb>print</span><span class=p>(</span><span class=n>query</span><span class=p>)</span>
</code></pre></div> <pre><code>&lt;s&gt;[INST] &lt;&lt;SYS&gt;&gt;You are a powerful text-to-SQL model. Your job is to answer questions about a database. You can use the following table schema for context: CREATE TABLE table_name_11 (tournament VARCHAR)&lt;&lt;/SYS&gt;&gt;

[INST]Human: Return the SQL query that answers the following question: Which Tournament has A in 1987?[/INST]

Assistant:
SELECT tournament FROM table_name_11 WHERE 1987 = "a"
</code></pre> <p>Now let us go through the test data set and, using an LLM as a judge, we'll quantify how well the model approximates the correct SQL queries given in the data set. Since using an LLM as a judge takes time, we will only process 100 records for testing.</p> <div class=highlight><pre><span></span><code><span class=kn>import</span> <span class=nn>pandas</span> <span class=k>as</span> <span class=nn>pd</span>

<span class=n>test_df</span> <span class=o>=</span> <span class=n>pd</span><span class=o>.</span><span class=n>read_json</span><span class=p>(</span><span class=s2>&quot;data/test_dataset.json&quot;</span><span class=p>,</span> <span class=n>lines</span><span class=o>=</span><span class=kc>True</span><span class=p>)[</span><span class=s2>&quot;messages&quot;</span><span class=p>]</span>

<span class=k>def</span> <span class=nf>extract_content</span><span class=p>(</span><span class=n>dicts</span><span class=p>,</span> <span class=n>role</span><span class=p>):</span>
    <span class=k>for</span> <span class=n>d</span> <span class=ow>in</span> <span class=n>dicts</span><span class=p>:</span>
        <span class=k>if</span> <span class=n>d</span><span class=p>[</span><span class=s1>&#39;role&#39;</span><span class=p>]</span> <span class=o>==</span> <span class=n>role</span><span class=p>:</span>
            <span class=k>return</span> <span class=n>d</span><span class=p>[</span><span class=s1>&#39;content&#39;</span><span class=p>]</span>
    <span class=k>return</span> <span class=kc>None</span>

<span class=n>df</span> <span class=o>=</span> <span class=n>pd</span><span class=o>.</span><span class=n>DataFrame</span><span class=p>()</span>
<span class=k>for</span> <span class=n>role</span> <span class=ow>in</span> <span class=p>[</span><span class=s1>&#39;system&#39;</span><span class=p>,</span> <span class=s1>&#39;user&#39;</span><span class=p>,</span> <span class=s1>&#39;assistant&#39;</span><span class=p>]:</span>
    <span class=n>df</span><span class=p>[</span><span class=n>role</span><span class=p>]</span> <span class=o>=</span> <span class=n>test_df</span><span class=o>.</span><span class=n>apply</span><span class=p>(</span><span class=k>lambda</span> <span class=n>x</span><span class=p>:</span> <span class=n>extract_content</span><span class=p>(</span><span class=n>x</span><span class=p>,</span> <span class=n>role</span><span class=p>))</span>
<span class=k>del</span> <span class=n>test_df</span>

<span class=n>df</span> <span class=o>=</span> <span class=n>df</span><span class=p>[:</span><span class=mi>100</span><span class=p>]</span>
</code></pre></div> <div class=highlight><pre><span></span><code><span class=n>df</span><span class=p>[</span><span class=s1>&#39;llama&#39;</span><span class=p>]</span> <span class=o>=</span> <span class=n>df</span><span class=o>.</span><span class=n>apply</span><span class=p>(</span><span class=k>lambda</span> <span class=n>row</span><span class=p>:</span> <span class=n>get_sql_query</span><span class=p>(</span><span class=n>row</span><span class=p>[</span><span class=s1>&#39;system&#39;</span><span class=p>],</span> <span class=n>row</span><span class=p>[</span><span class=s1>&#39;user&#39;</span><span class=p>]),</span> <span class=n>axis</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span>
</code></pre></div> <div class=highlight><pre><span></span><code><span class=n>df</span><span class=o>.</span><span class=n>head</span><span class=p>()</span>
</code></pre></div> <div> <style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style> <table border=1 class=dataframe> <thead> <tr style="text-align: right;"> <th></th> <th>system</th> <th>user</th> <th>assistant</th> <th>llama</th> </tr> </thead> <tbody> <tr> <th>0</th> <td>You are a powerful text-to-SQL model. Your job...</td> <td>Return the SQL query that answers the followin...</td> <td>SELECT venue FROM table_name_50 WHERE away_tea...</td> <td>SELECT venue FROM table_name_50 WHERE away_te...</td> </tr> <tr> <th>1</th> <td>You are a powerful text-to-SQL model. Your job...</td> <td>Return the SQL query that answers the followin...</td> <td>SELECT MIN(game) FROM table_name_61 WHERE oppo...</td> <td>SELECT MIN(game) FROM table_name_61 WHERE opp...</td> </tr> <tr> <th>2</th> <td>You are a powerful text-to-SQL model. Your job...</td> <td>Return the SQL query that answers the followin...</td> <td>SELECT opponent FROM table_name_37 WHERE week ...</td> <td>SELECT opponent FROM table_name_37 WHERE week...</td> </tr> <tr> <th>3</th> <td>You are a powerful text-to-SQL model. Your job...</td> <td>Return the SQL query that answers the followin...</td> <td>SELECT SUM(points) FROM table_name_70 WHERE to...</td> <td>SELECT AVG(points) FROM table_name_70 WHERE t...</td> </tr> <tr> <th>4</th> <td>You are a powerful text-to-SQL model. Your job...</td> <td>Return the SQL query that answers the followin...</td> <td>SELECT name FROM table_name_83 WHERE nat = "sc...</td> <td>SELECT name FROM table_name_83 WHERE nat = "s...</td> </tr> </tbody> </table> </div> <h3> Evaluation using an LLM as a judge </h3> <p>Since we have access to the "right" answer, we can evaluate similarity between the SQL queries returned by the fine-tuned Llama model and the right answer. Evaluation can be a bit tricky, since there is no single metric that evaluates semantic and syntactic similarity between two SQL queries. One alternative is to use a more powerful LLM, like Claude 3 Sonnet, to measure the similarity between the two SQL queries (LLM as a judge).</p> <div class=highlight><pre><span></span><code><span class=c1># Helper function because Claude requires the Messages API</span>

<span class=c1>#for connecting with Bedrock, use Boto3</span>
<span class=kn>import</span> <span class=nn>boto3</span><span class=o>,</span> <span class=nn>time</span><span class=o>,</span> <span class=nn>json</span>
<span class=kn>from</span> <span class=nn>botocore.config</span> <span class=kn>import</span> <span class=n>Config</span>

<span class=n>my_config</span> <span class=o>=</span> <span class=n>Config</span><span class=p>(</span><span class=n>connect_timeout</span><span class=o>=</span><span class=mi>60</span><span class=o>*</span><span class=mi>3</span><span class=p>,</span> <span class=n>read_timeout</span><span class=o>=</span><span class=mi>60</span><span class=o>*</span><span class=mi>3</span><span class=p>)</span>
<span class=n>bedrock</span> <span class=o>=</span> <span class=n>boto3</span><span class=o>.</span><span class=n>client</span><span class=p>(</span><span class=n>service_name</span><span class=o>=</span><span class=s1>&#39;bedrock-runtime&#39;</span><span class=p>,</span><span class=n>config</span><span class=o>=</span><span class=n>my_config</span><span class=p>)</span>
<span class=n>bedrock_service</span> <span class=o>=</span> <span class=n>boto3</span><span class=o>.</span><span class=n>client</span><span class=p>(</span><span class=n>service_name</span><span class=o>=</span><span class=s1>&#39;bedrock&#39;</span><span class=p>,</span><span class=n>config</span><span class=o>=</span><span class=n>my_config</span><span class=p>)</span>

<span class=n>MAX_ATTEMPTS</span> <span class=o>=</span> <span class=mi>3</span> <span class=c1>#how many times to retry if Claude is not working.</span>

<span class=k>def</span> <span class=nf>ask_claude</span><span class=p>(</span><span class=n>messages</span><span class=p>,</span><span class=n>system</span><span class=o>=</span><span class=s2>&quot;&quot;</span><span class=p>,</span> <span class=n>model_version</span><span class=o>=</span><span class=s2>&quot;haiku&quot;</span><span class=p>):</span>
<span class=w>    </span><span class=sd>&#39;&#39;&#39;</span>
<span class=sd>    Send a prompt to Bedrock, and return the response</span>
<span class=sd>    &#39;&#39;&#39;</span>
    <span class=n>raw_prompt_text</span> <span class=o>=</span> <span class=nb>str</span><span class=p>(</span><span class=n>messages</span><span class=p>)</span>

    <span class=k>if</span> <span class=nb>type</span><span class=p>(</span><span class=n>messages</span><span class=p>)</span><span class=o>==</span><span class=nb>str</span><span class=p>:</span>
        <span class=n>messages</span> <span class=o>=</span> <span class=p>[{</span><span class=s2>&quot;role&quot;</span><span class=p>:</span> <span class=s2>&quot;user&quot;</span><span class=p>,</span> <span class=s2>&quot;content&quot;</span><span class=p>:</span> <span class=n>messages</span><span class=p>}]</span>

    <span class=n>promt_json</span> <span class=o>=</span> <span class=p>{</span>
        <span class=s2>&quot;system&quot;</span><span class=p>:</span><span class=n>system</span><span class=p>,</span>
        <span class=s2>&quot;messages&quot;</span><span class=p>:</span> <span class=n>messages</span><span class=p>,</span>
        <span class=s2>&quot;max_tokens&quot;</span><span class=p>:</span> <span class=mi>3000</span><span class=p>,</span>
        <span class=s2>&quot;temperature&quot;</span><span class=p>:</span> <span class=mf>0.7</span><span class=p>,</span>
        <span class=s2>&quot;anthropic_version&quot;</span><span class=p>:</span><span class=s2>&quot;&quot;</span><span class=p>,</span>
        <span class=s2>&quot;top_k&quot;</span><span class=p>:</span> <span class=mi>250</span><span class=p>,</span>
        <span class=s2>&quot;top_p&quot;</span><span class=p>:</span> <span class=mf>0.7</span><span class=p>,</span>
        <span class=s2>&quot;stop_sequences&quot;</span><span class=p>:</span> <span class=p>[</span><span class=s2>&quot;</span><span class=se>\n\n</span><span class=s2>Human:&quot;</span><span class=p>]</span>
    <span class=p>}</span>

    <span class=n>modelId</span> <span class=o>=</span> <span class=s1>&#39;anthropic.claude-3-sonnet-20240229-v1:0&#39;</span>

    <span class=n>attempt</span> <span class=o>=</span> <span class=mi>1</span>
    <span class=k>while</span> <span class=kc>True</span><span class=p>:</span>
        <span class=k>try</span><span class=p>:</span>
            <span class=n>response</span> <span class=o>=</span> <span class=n>bedrock</span><span class=o>.</span><span class=n>invoke_model</span><span class=p>(</span><span class=n>body</span><span class=o>=</span><span class=n>json</span><span class=o>.</span><span class=n>dumps</span><span class=p>(</span><span class=n>promt_json</span><span class=p>),</span> <span class=n>modelId</span><span class=o>=</span><span class=n>modelId</span><span class=p>,</span> <span class=n>accept</span><span class=o>=</span><span class=s1>&#39;application/json&#39;</span><span class=p>,</span> <span class=n>contentType</span><span class=o>=</span><span class=s1>&#39;application/json&#39;</span><span class=p>)</span>
            <span class=n>response_body</span> <span class=o>=</span> <span class=n>json</span><span class=o>.</span><span class=n>loads</span><span class=p>(</span><span class=n>response</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=s1>&#39;body&#39;</span><span class=p>)</span><span class=o>.</span><span class=n>read</span><span class=p>())</span>
            <span class=n>results</span> <span class=o>=</span> <span class=n>response_body</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=s2>&quot;content&quot;</span><span class=p>)[</span><span class=mi>0</span><span class=p>]</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=s2>&quot;text&quot;</span><span class=p>)</span>
            <span class=k>break</span>
        <span class=k>except</span> <span class=ne>Exception</span> <span class=k>as</span> <span class=n>e</span><span class=p>:</span>
            <span class=nb>print</span><span class=p>(</span><span class=s2>&quot;Error with calling Bedrock: &quot;</span><span class=o>+</span><span class=nb>str</span><span class=p>(</span><span class=n>e</span><span class=p>))</span>
            <span class=n>attempt</span><span class=o>+=</span><span class=mi>1</span>
            <span class=k>if</span> <span class=n>attempt</span><span class=o>&gt;</span><span class=n>MAX_ATTEMPTS</span><span class=p>:</span>
                <span class=nb>print</span><span class=p>(</span><span class=s2>&quot;Max attempts reached!&quot;</span><span class=p>)</span>
                <span class=n>results</span> <span class=o>=</span> <span class=nb>str</span><span class=p>(</span><span class=n>e</span><span class=p>)</span>
                <span class=k>break</span>
            <span class=k>else</span><span class=p>:</span> <span class=c1>#retry in 2 seconds</span>
                <span class=n>time</span><span class=o>.</span><span class=n>sleep</span><span class=p>(</span><span class=mi>2</span><span class=p>)</span>
    <span class=k>return</span> <span class=p>[</span><span class=n>raw_prompt_text</span><span class=p>,</span><span class=n>results</span><span class=p>]</span>
</code></pre></div> <div class=highlight><pre><span></span><code><span class=kn>import</span> <span class=nn>re</span>

<span class=k>def</span> <span class=nf>get_score</span><span class=p>(</span><span class=n>system</span><span class=p>,</span> <span class=n>user</span><span class=p>,</span> <span class=n>assistant</span><span class=p>,</span> <span class=n>llama</span><span class=p>):</span>
    <span class=n>db_schema</span> <span class=o>=</span> <span class=n>system</span><span class=p>[</span><span class=mi>139</span><span class=p>:]</span> <span class=c1># Remove generic instructions</span>
    <span class=n>question</span> <span class=o>=</span> <span class=n>user</span><span class=p>[</span><span class=mi>58</span><span class=p>:]</span> <span class=c1># Remove generic instructions</span>
    <span class=n>correct_answer</span> <span class=o>=</span> <span class=n>assistant</span>
    <span class=n>test_answer</span> <span class=o>=</span> <span class=n>llama</span>
    <span class=n>formatted_prompt</span> <span class=o>=</span> <span class=sa>f</span><span class=s2>&quot;&quot;&quot;You are a data science teacher that is introducing students to SQL. Consider the following question and schema:</span>
<span class=s2>&lt;question&gt;</span><span class=si>{</span><span class=n>question</span><span class=si>}</span><span class=s2>&lt;/question&gt;</span>
<span class=s2>&lt;schema&gt;</span><span class=si>{</span><span class=n>db_schema</span><span class=si>}</span><span class=s2>&lt;/schema&gt;</span>

<span class=s2>Here is the correct answer:</span>
<span class=s2>&lt;correct_answer&gt;</span><span class=si>{</span><span class=n>correct_answer</span><span class=si>}</span><span class=s2>&lt;/correct_answer&gt;</span>

<span class=s2>Here is the student&#39;s answer:</span>
<span class=s2>&lt;student_answer&gt;</span><span class=si>{</span><span class=n>test_answer</span><span class=si>}</span><span class=s2>&lt;student_answer&gt;</span>

<span class=s2>Please provide a numeric score from 0 to 100 on how well the student&#39;s answer matches the correct answer for this question.</span>
<span class=s2>The score should be high if the answers say essentially the same thing.</span>
<span class=s2>The score should be lower if some parts are missing, or if extra unnecessary parts have been included.</span>
<span class=s2>The score should be 0 for an entirely wrong answer. Put the score in &lt;SCORE&gt; XML tags.</span>
<span class=s2>Do not consider your own answer to the question, but instead score based only on the correct answer above.</span>
<span class=s2>&quot;&quot;&quot;</span>
    <span class=n>_</span><span class=p>,</span> <span class=n>result</span> <span class=o>=</span> <span class=n>ask_claude</span><span class=p>(</span><span class=n>formatted_prompt</span><span class=p>,</span> <span class=n>model_version</span><span class=o>=</span><span class=s2>&quot;sonnet&quot;</span><span class=p>)</span>
    <span class=n>pattern</span> <span class=o>=</span> <span class=sa>r</span><span class=s1>&#39;&lt;SCORE&gt;(.*?)&lt;/SCORE&gt;&#39;</span>
    <span class=n>match</span> <span class=o>=</span> <span class=n>re</span><span class=o>.</span><span class=n>search</span> <span class=p>(</span><span class=n>pattern</span><span class=p>,</span> <span class=n>result</span><span class=p>)</span>

    <span class=k>return</span> <span class=n>match</span><span class=o>.</span><span class=n>group</span><span class=p>(</span><span class=mi>1</span><span class=p>)</span>
</code></pre></div> <div class=highlight><pre><span></span><code><span class=n>scores</span> <span class=o>=</span> <span class=p>[]</span>
<span class=k>for</span> <span class=n>ix</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=nb>len</span><span class=p>(</span><span class=n>df</span><span class=p>)):</span>
    <span class=n>response</span> <span class=o>=</span> <span class=nb>float</span><span class=p>(</span><span class=n>get_score</span><span class=p>(</span><span class=n>df</span><span class=p>[</span><span class=s2>&quot;system&quot;</span><span class=p>][</span><span class=n>ix</span><span class=p>],</span> <span class=n>df</span><span class=p>[</span><span class=s2>&quot;user&quot;</span><span class=p>][</span><span class=n>ix</span><span class=p>],</span> <span class=n>df</span><span class=p>[</span><span class=s2>&quot;assistant&quot;</span><span class=p>][</span><span class=n>ix</span><span class=p>],</span> <span class=n>df</span><span class=p>[</span><span class=s2>&quot;llama&quot;</span><span class=p>][</span><span class=n>ix</span><span class=p>]))</span>
    <span class=n>scores</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>response</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=s2>&quot;Assigned scores: &quot;</span><span class=p>,</span> <span class=n>scores</span><span class=p>)</span>
</code></pre></div> <pre><code>Assigned scores:  [100.0, 100.0, 90.0, 50.0, 100.0, 100.0, 100.0, 100.0, 90.0, 100.0, 100.0, 100.0, 100.0, 100.0, 95.0, 100.0, 75.0, 90.0, 100.0, 100.0, 95.0, 80.0, 100.0, 100.0, 90.0, 100.0, 100.0, 100.0, 90.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 90.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 90.0, 100.0, 100.0, 90.0, 80.0, 100.0, 100.0, 100.0, 80.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 90.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 90.0, 100.0, 100.0, 100.0, 100.0, 100.0, 95.0, 100.0, 100.0, 100.0, 100.0, 100.0, 95.0, 25.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 95.0, 100.0, 100.0, 100.0, 100.0]
</code></pre> <div class=highlight><pre><span></span><code><span class=nb>print</span><span class=p>(</span><span class=s2>&quot;The average score of the fine tuned model is: &quot;</span><span class=p>,</span> <span class=nb>sum</span><span class=p>(</span><span class=n>scores</span><span class=p>)</span><span class=o>/</span><span class=nb>float</span><span class=p>(</span><span class=nb>len</span><span class=p>(</span><span class=n>scores</span><span class=p>)))</span>
</code></pre></div> <pre><code>The average score of the fine tuned model is:  96.65
</code></pre> <p>The average score given to this fine-tuned Llama 3 8B model is 96.65%, which is very good for a relatively small language model.</p> <h2> Clean Up </h2> <p>You can delete your Imported Model in the console as shown in the image below:</p> <p><img alt=Delete src=../images/delete.png title=Delete></p> <p>Ensure to shut down your instance/compute that you have run this notebook on.</p> <p><strong>END OF NOTEBOOK</strong></p> <form class=md-feedback name=feedback hidden> <fieldset> <legend class=md-feedback__title> Was this page helpful? </legend> <div class=md-feedback__inner> <div class=md-feedback__list> <button class="md-feedback__icon md-icon" type=submit title="This page was helpful" data-md-value=1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M5 9v12H1V9zm4 12a2 2 0 0 1-2-2V9c0-.55.22-1.05.59-1.41L14.17 1l1.06 1.06c.27.27.44.64.44 1.05l-.03.32L14.69 8H21a2 2 0 0 1 2 2v2c0 .26-.05.5-.14.73l-3.02 7.05C19.54 20.5 18.83 21 18 21zm0-2h9.03L21 12v-2h-8.79l1.13-5.32L9 9.03z"/></svg> </button> <button class="md-feedback__icon md-icon" type=submit title="This page could be improved" data-md-value=0> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M19 15V3h4v12zM15 3a2 2 0 0 1 2 2v10c0 .55-.22 1.05-.59 1.41L9.83 23l-1.06-1.06c-.27-.27-.44-.64-.44-1.06l.03-.31.95-4.57H3a2 2 0 0 1-2-2v-2c0-.26.05-.5.14-.73l3.02-7.05C4.46 3.5 5.17 3 6 3zm0 2H5.97L3 12v2h8.78l-1.13 5.32L15 14.97z"/></svg> </button> </div> <div class=md-feedback__note> <div data-md-value=1 hidden> Thanks for your feedback! </div> <div data-md-value=0 hidden> Thanks for your feedback! Help us improve this page by <a href="https://github.com/aws-samples/amazon-bedrock-samples/issues/new?title=[Online Feedback]: Short-Summary-of-Issue&body=Page URL: /custom-models/import_models/llama-3/customized-text-to-sql-model/" target=_blank rel=noopener>creating an issue</a>. </div> </div> </div> </fieldset> </form> </article> </div> <script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script> </div> </main> <footer class=md-footer> <div class="md-footer-meta md-typeset"> <div class="md-footer-meta__inner md-grid"> <div class=md-copyright> <div class=md-copyright__highlight> Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved. </div> </div> <div class=md-social> <a href=https://github.com/aws-samples/amazon-bedrock-samples/tree/main target=_blank rel=noopener title=github.com class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 496 512"><!-- Font Awesome Free 6.7.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8M97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg> </a> </div> </div> </div> </footer> </div> <div class=md-dialog data-md-component=dialog> <div class="md-dialog__inner md-typeset"></div> </div> <script id=__config type=application/json>{"base": "../../../..", "features": ["tags", "toc.integrate", "content.code.copy", "content.code.select", "content.code.annotate", "navigation.footer", "search.highlight", "search.suggest"], "search": "../../../../assets/javascripts/workers/search.6ce7567c.min.js", "tags": {"Compatibility": "compat"}, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script> <script src=../../../../assets/javascripts/bundle.88dd0f4e.min.js></script> <script src=../../../../javascript/feedback.js></script> </body> </html>