<!doctype html><html lang=en class=no-js> <head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="Amazon Bedrock cookbook website"><meta name=author content=Bedrock-GTM><link href=https://github.amazon-bedrock-samples.com/custom-models/import_models/llama-3/llama3-ngrammedqa-fine-tuning/ rel=canonical><link rel=icon href=../../../../assets/favicon.png><meta name=generator content="mkdocs-1.6.1, mkdocs-material-9.5.49"><title>Llama3 ngrammedqa fine tuning - Amazon Bedrock Recipes</title><link rel=stylesheet href=../../../../assets/stylesheets/main.6f8fc17f.min.css><link rel=stylesheet href=../../../../assets/stylesheets/palette.06af60db.min.css><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback"><style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style><script>__md_scope=new URL("../../../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script></head> <body dir=ltr data-md-color-scheme=default data-md-color-primary=white data-md-color-accent=purple> <input class=md-toggle data-md-toggle=drawer type=checkbox id=__drawer autocomplete=off> <input class=md-toggle data-md-toggle=search type=checkbox id=__search autocomplete=off> <label class=md-overlay for=__drawer></label> <div data-md-component=skip> </div> <div data-md-component=announce> </div> <header class="md-header md-header--shadow" data-md-component=header> <nav class="md-header__inner md-grid" aria-label=Header> <a href=../../../.. title="Amazon Bedrock Recipes" class="md-header__button md-logo" aria-label="Amazon Bedrock Recipes" data-md-component=logo> <img src=../../../../logo.png alt=logo> </a> <label class="md-header__button md-icon" for=__drawer> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg> </label> <div class=md-header__title data-md-component=header-title> <div class=md-header__ellipsis> <div class=md-header__topic> <span class=md-ellipsis> Amazon Bedrock Recipes </span> </div> <div class=md-header__topic data-md-component=header-topic> <span class=md-ellipsis> Llama3 ngrammedqa fine tuning </span> </div> </div> </div> <form class=md-header__option data-md-component=palette> <input class=md-option data-md-color-media data-md-color-scheme=default data-md-color-primary=white data-md-color-accent=purple aria-hidden=true type=radio name=__palette id=__palette_0> </form> <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script> <label class="md-header__button md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg> </label> <div class=md-search data-md-component=search role=dialog> <label class=md-search__overlay for=__search></label> <div class=md-search__inner role=search> <form class=md-search__form name=search> <input type=text class=md-search__input name=query aria-label=Search placeholder=Search autocapitalize=off autocorrect=off autocomplete=off spellcheck=false data-md-component=search-query required> <label class="md-search__icon md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg> </label> <nav class=md-search__options aria-label=Search> <button type=reset class="md-search__icon md-icon" title=Clear aria-label=Clear tabindex=-1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg> </button> </nav> <div class=md-search__suggest data-md-component=search-suggest></div> </form> <div class=md-search__output> <div class=md-search__scrollwrap tabindex=0 data-md-scrollfix> <div class=md-search-result data-md-component=search-result> <div class=md-search-result__meta> Initializing search </div> <ol class=md-search-result__list role=presentation></ol> </div> </div> </div> </div> </div> <div class=md-header__source> <a href=https://github.com/aws-samples/amazon-bedrock-samples/tree/main title="Go to repository" class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 6.7.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81"/></svg> </div> <div class=md-source__repository> Github: Amazon-Bedrock-Samples </div> </a> </div> </nav> </header> <div class=md-container data-md-component=container> <main class=md-main data-md-component=main> <div class="md-main__inner md-grid"> <div class="md-sidebar md-sidebar--primary" data-md-component=sidebar data-md-type=navigation> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--primary md-nav--integrated" aria-label=Navigation data-md-level=0> <label class=md-nav__title for=__drawer> <a href=../../../.. title="Amazon Bedrock Recipes" class="md-nav__button md-logo" aria-label="Amazon Bedrock Recipes" data-md-component=logo> <img src=../../../../logo.png alt=logo> </a> Amazon Bedrock Recipes </label> <div class=md-nav__source> <a href=https://github.com/aws-samples/amazon-bedrock-samples/tree/main title="Go to repository" class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 6.7.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81"/></svg> </div> <div class=md-source__repository> Github: Amazon-Bedrock-Samples </div> </a> </div> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../.. class=md-nav__link> <span class=md-ellipsis> Home </span> </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2> <label class=md-nav__link for=__nav_2 id=__nav_2_label tabindex=0> <span class=md-ellipsis> Features </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_2_label aria-expanded=false> <label class=md-nav__title for=__nav_2> <span class="md-nav__icon md-icon"></span> Features </label> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2_1> <label class=md-nav__link for=__nav_2_1 id=__nav_2_1_label tabindex=0> <span class=md-ellipsis> Intro to Amazon Bedrock </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_2_1_label aria-expanded=false> <label class=md-nav__title for=__nav_2_1> <span class="md-nav__icon md-icon"></span> Intro to Amazon Bedrock </label> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2_1_1> <label class=md-nav__link for=__nav_2_1_1 id=__nav_2_1_1_label tabindex=0> <span class=md-ellipsis> API Usage </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=3 aria-labelledby=__nav_2_1_1_label aria-expanded=false> <label class=md-nav__title for=__nav_2_1_1> <span class="md-nav__icon md-icon"></span> API Usage </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../../introduction-to-bedrock/bedrock_apis/01_invoke_api/ class=md-nav__link> <span class=md-ellipsis> Invoke Model API Example </span> </a> </li> <li class=md-nav__item> <a href=../../../../introduction-to-bedrock/bedrock_apis/04_agents_api/ class=md-nav__link> <span class=md-ellipsis> Agents API Example </span> </a> </li> <li class=md-nav__item> <a href=../../../../introduction-to-bedrock/bedrock_apis/03_knowledgebases_api/ class=md-nav__link> <span class=md-ellipsis> Knowledge Bases API Example </span> </a> </li> <li class=md-nav__item> <a href=../../../../introduction-to-bedrock/bedrock_apis/02_guardrails_api/ class=md-nav__link> <span class=md-ellipsis> Guardrail API Example </span> </a> </li> <li class=md-nav__item> <a href=../../../../introduction-to-bedrock/converse_api/01_converse_api/ class=md-nav__link> <span class=md-ellipsis> Converse API Example </span> </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2_2> <label class=md-nav__link for=__nav_2_2 id=__nav_2_2_label tabindex=0> <span class=md-ellipsis> Agents </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_2_2_label aria-expanded=false> <label class=md-nav__title for=__nav_2_2> <span class="md-nav__icon md-icon"></span> Agents </label> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2_2_1> <label class=md-nav__link for=__nav_2_2_1 id=__nav_2_2_1_label tabindex=0> <span class=md-ellipsis> Amazon Bedrock Agents </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=3 aria-labelledby=__nav_2_2_1_label aria-expanded=false> <label class=md-nav__title for=__nav_2_2_1> <span class="md-nav__icon md-icon"></span> Amazon Bedrock Agents </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../../agents-and-function-calling/introduction-to-agents/how_to_create_custom_agents/ class=md-nav__link> <span class=md-ellipsis> How to create an Agent </span> </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2_2_1_2> <label class=md-nav__link for=__nav_2_2_1_2 id=__nav_2_2_1_2_label tabindex=0> <span class=md-ellipsis> Bedrock Agent Features </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=4 aria-labelledby=__nav_2_2_1_2_label aria-expanded=false> <label class=md-nav__title for=__nav_2_2_1_2> <span class="md-nav__icon md-icon"></span> Bedrock Agent Features </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../../agents-and-function-calling/bedrock-agents/features-examples/01-create-agent-with-function-definition/01-create-agent-with-function-definition/ class=md-nav__link> <span class=md-ellipsis> Create Agent with Function Definition </span> </a> </li> <li class=md-nav__item> <a href=../../../../agents-and-function-calling/bedrock-agents/features-examples/02-create-agent-with-api-schema/02-create-agent-with-api-schema/ class=md-nav__link> <span class=md-ellipsis> Create Agent with API Schema </span> </a> </li> <li class=md-nav__item> <a href=../../../../agents-and-function-calling/bedrock-agents/features-examples/03-create-agent-with-return-of-control/03-create-agent-with-return-of-control/ class=md-nav__link> <span class=md-ellipsis> Create Agent with Return of Control </span> </a> </li> <li class=md-nav__item> <a href=../../../../agents-and-function-calling/bedrock-agents/features-examples/04-create-agent-with-single-knowledge-base/04-create-agent-with-single-knowledge-base/ class=md-nav__link> <span class=md-ellipsis> Create Agent with Single Knowledge Base </span> </a> </li> <li class=md-nav__item> <a href=../../../../agents-and-function-calling/bedrock-agents/features-examples/05-create-agent-with-knowledge-base-and-action-group/05-create-agent-with-knowledge-base-and-action-group/ class=md-nav__link> <span class=md-ellipsis> Create Agent with Knowledge Base and Action Group </span> </a> </li> <li class=md-nav__item> <a href=../../../../agents-and-function-calling/bedrock-agents/features-examples/06-prompt-and-session-attributes/06-prompt-and-session-attributes/ class=md-nav__link> <span class=md-ellipsis> Prompt and Session Attributes </span> </a> </li> <li class=md-nav__item> <a href=../../../../agents-and-function-calling/bedrock-agents/features-examples/07-advanced-prompts-and-custom-parsers/07-custom-prompt-and-lambda-parsers/ class=md-nav__link> <span class=md-ellipsis> Custom Prompt and Lambda Parsers </span> </a> </li> <li class=md-nav__item> <a href=../../../../agents-and-function-calling/bedrock-agents/features-examples/08-create-agent-with-guardrails/08-create-agent-with-guardrails/ class=md-nav__link> <span class=md-ellipsis> Create Agent with Guardrails </span> </a> </li> <li class=md-nav__item> <a href=../../../../agents-and-function-calling/bedrock-agents/features-examples/09-create-agent-with-memory/09-create-agent-with-memory/ class=md-nav__link> <span class=md-ellipsis> Create Agent with Memory </span> </a> </li> <li class=md-nav__item> <a href=../../../../agents-and-function-calling/bedrock-agents/features-examples/10-create-agent-with-code-interpreter/10-create-agent-with-code-interpreter/ class=md-nav__link> <span class=md-ellipsis> Create Agent with Code Interpreter </span> </a> </li> <li class=md-nav__item> <a href=../../../../agents-and-function-calling/bedrock-agents/features-examples/14-create-agent-with-custom-orchestration/custom_orchestration_example/ class=md-nav__link> <span class=md-ellipsis> Create Agent with Custom Orchestration </span> </a> </li> <li class=md-nav__item> <a href=../../../../agents-and-function-calling/bedrock-agents/features-examples/15-invoke-inline-agents/inline-agent-api-usage/ class=md-nav__link> <span class=md-ellipsis> Create Dynamic Tooling Inline Agents </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2_2_1_3> <label class=md-nav__link for=__nav_2_2_1_3 id=__nav_2_2_1_3_label tabindex=0> <span class=md-ellipsis> Bedrock Flows </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=4 aria-labelledby=__nav_2_2_1_3_label aria-expanded=false> <label class=md-nav__title for=__nav_2_2_1_3> <span class="md-nav__icon md-icon"></span> Bedrock Flows </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../../agents-and-function-calling/bedrock-agents/bedrock-flows/Getting_started_with_Prompt_Management_Flows/ class=md-nav__link> <span class=md-ellipsis> Getting Started with Prompt Management Flows </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2_2_1_4> <label class=md-nav__link for=__nav_2_2_1_4 id=__nav_2_2_1_4_label tabindex=0> <span class=md-ellipsis> Use Case Examples </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=4 aria-labelledby=__nav_2_2_1_4_label aria-expanded=false> <label class=md-nav__title for=__nav_2_2_1_4> <span class="md-nav__icon md-icon"></span> Use Case Examples </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../../agents-and-function-calling/bedrock-agents/use-case-examples/text-2-sql-agent/create_and_invoke_sql_agent/ class=md-nav__link> <span class=md-ellipsis> Text to SQL Agent </span> </a> </li> <li class=md-nav__item> <a href=../../../../agents-and-function-calling/bedrock-agents/use-case-examples/agentsforbedrock-retailagent/workshop/test_retailagent_agentsforbedrock/ class=md-nav__link> <span class=md-ellipsis> Retail Agent Workshop </span> </a> </li> <li class=md-nav__item> <a href=../../../../agents-and-function-calling/bedrock-agents/use-case-examples/product-review-agent/main/ class=md-nav__link> <span class=md-ellipsis> Product Review Agent </span> </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2_2_2> <label class=md-nav__link for=__nav_2_2_2 id=__nav_2_2_2_label tabindex=0> <span class=md-ellipsis> Function Calling </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=3 aria-labelledby=__nav_2_2_2_label aria-expanded=false> <label class=md-nav__title for=__nav_2_2_2> <span class="md-nav__icon md-icon"></span> Function Calling </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../../agents-and-function-calling/function-calling/function_calling_with_converse/function_calling_with_converse/ class=md-nav__link> <span class=md-ellipsis> Function Calling with Converse </span> </a> </li> <li class=md-nav__item> <a href=../../../../agents-and-function-calling/function-calling/function_calling_with_invoke/function_calling_model_with_invoke/ class=md-nav__link> <span class=md-ellipsis> Function Calling with Invoke </span> </a> </li> <li class=md-nav__item> <a href=../../../../agents-and-function-calling/function-calling/return_of_control/return_of_control/ class=md-nav__link> <span class=md-ellipsis> Return of Control </span> </a> </li> <li class=md-nav__item> <a href=../../../../agents-and-function-calling/function-calling/tool_binding/tool_bindings/ class=md-nav__link> <span class=md-ellipsis> Tool Binding </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2_2_3> <label class=md-nav__link for=__nav_2_2_3 id=__nav_2_2_3_label tabindex=0> <span class=md-ellipsis> Open Source </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=3 aria-labelledby=__nav_2_2_3_label aria-expanded=false> <label class=md-nav__title for=__nav_2_2_3> <span class="md-nav__icon md-icon"></span> Open Source </label> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2_2_3_1> <label class=md-nav__link for=__nav_2_2_3_1 id=__nav_2_2_3_1_label tabindex=0> <span class=md-ellipsis> CrewAI </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=4 aria-labelledby=__nav_2_2_3_1_label aria-expanded=false> <label class=md-nav__title for=__nav_2_2_3_1> <span class="md-nav__icon md-icon"></span> CrewAI </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../../agents-and-function-calling/open-source-agents/crew.ai/Find%20dream%20destination%20with%20CrewAI/ class=md-nav__link> <span class=md-ellipsis> Find Dream Destination with CrewAI </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2_2_3_2> <label class=md-nav__link for=__nav_2_2_3_2 id=__nav_2_2_3_2_label tabindex=0> <span class=md-ellipsis> LangGraph </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=4 aria-labelledby=__nav_2_2_3_2_label aria-expanded=false> <label class=md-nav__title for=__nav_2_2_3_2> <span class="md-nav__icon md-icon"></span> LangGraph </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../../agents-and-function-calling/open-source-agents/langgraph/langgraph-single-agent/ class=md-nav__link> <span class=md-ellipsis> LangGraph Agent with Function Calling </span> </a> </li> <li class=md-nav__item> <a href=../../../../agents-and-function-calling/open-source-agents/langgraph/langgraph-agents-multimodal/ class=md-nav__link> <span class=md-ellipsis> LangGraph Multi-Modal Agent with Function Calling </span> </a> </li> <li class=md-nav__item> <a href=../../../../agents-and-function-calling/open-source-agents/langgraph/langgraph-multi-agent-sql-tools/ class=md-nav__link> <span class=md-ellipsis> LangGraph Multi Agent Orchestration </span> </a> </li> <li class=md-nav__item> <a href=../../../../agents-and-function-calling/open-source-agents/langgraph/02_medibot_V3_agents/ class=md-nav__link> <span class=md-ellipsis> LangGraph Multi Agent For Medical Chatbot </span> </a> </li> <li class=md-nav__item> <a href=../../../../agents-and-function-calling/open-source-agents/langgraph/langgraph-fact-checker-feedback-loop/ class=md-nav__link> <span class=md-ellipsis> LangGraph Fact Checker with Multi Agent </span> </a> </li> <li class=md-nav__item> <a href=../../../../agents-and-function-calling/open-source-agents/langgraph/langgraph-multi-agent-sql-tools/ class=md-nav__link> <span class=md-ellipsis> LangGraph Multi Agent Orchestration </span> </a> </li> <li class=md-nav__item> <a href=../../../../agents-and-function-calling/open-source-agents/langgraph/03_langgraph_agents_of_agent/ class=md-nav__link> <span class=md-ellipsis> LangGraph Multi Agent with tools </span> </a> </li> <li class=md-nav__item> <a href=../../../../agents-and-function-calling/open-source-agents/langgraph/Travel_planner_with_langgraph/ class=md-nav__link> <span class=md-ellipsis> Managing Memory for Multi Agents </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2_2_3_3> <label class=md-nav__link for=__nav_2_2_3_3 id=__nav_2_2_3_3_label tabindex=0> <span class=md-ellipsis> Multi Agent </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=4 aria-labelledby=__nav_2_2_3_3_label aria-expanded=false> <label class=md-nav__title for=__nav_2_2_3_3> <span class="md-nav__icon md-icon"></span> Multi Agent </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../../agents-and-function-calling/introduction-to-agents/how_to_create_multi_agents_from_custom_agents/ class=md-nav__link> <span class=md-ellipsis> Multi Agent Orchestration </span> </a> </li> </ul> </nav> </li> </ul> </nav> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2_3> <label class=md-nav__link for=__nav_2_3 id=__nav_2_3_label tabindex=0> <span class=md-ellipsis> RAG </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_2_3_label aria-expanded=false> <label class=md-nav__title for=__nav_2_3> <span class="md-nav__icon md-icon"></span> RAG </label> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2_3_1> <label class=md-nav__link for=__nav_2_3_1 id=__nav_2_3_1_label tabindex=0> <span class=md-ellipsis> Amazon Bedrock Knowledge Bases </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=3 aria-labelledby=__nav_2_3_1_label aria-expanded=false> <label class=md-nav__title for=__nav_2_3_1> <span class="md-nav__icon md-icon"></span> Amazon Bedrock Knowledge Bases </label> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2_3_1_1> <label class=md-nav__link for=__nav_2_3_1_1 id=__nav_2_3_1_1_label tabindex=0> <span class=md-ellipsis> Zero Setup </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=4 aria-labelledby=__nav_2_3_1_1_label aria-expanded=false> <label class=md-nav__title for=__nav_2_3_1_1> <span class="md-nav__icon md-icon"></span> Zero Setup </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../../rag/knowledge-bases/features-examples/00-zero-setup-chat-with-your-document/chat_with_document_kb/ class=md-nav__link> <span class=md-ellipsis> Chat with Your Document </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2_3_1_2> <label class=md-nav__link for=__nav_2_3_1_2 id=__nav_2_3_1_2_label tabindex=0> <span class=md-ellipsis> RAG Concepts </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=4 aria-labelledby=__nav_2_3_1_2_label aria-expanded=false> <label class=md-nav__title for=__nav_2_3_1_2> <span class="md-nav__icon md-icon"></span> RAG Concepts </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../../rag/knowledge-bases/features-examples/01-rag-concepts/01_create_ingest_documents_test_kb_multi_ds/ class=md-nav__link> <span class=md-ellipsis> Create and Ingest Documents with Multi-Data Sources </span> </a> </li> <li class=md-nav__item> <a href=../../../../rag/knowledge-bases/features-examples/01-rag-concepts/02_managed_rag_custom_prompting_and_no_of_results/ class=md-nav__link> <span class=md-ellipsis> Managed RAG with Custom Prompting </span> </a> </li> <li class=md-nav__item> <a href=../../../../rag/knowledge-bases/features-examples/01-rag-concepts/03_customized-rag-retreive-api-hybrid-search-claude-3-sonnet-langchain/ class=md-nav__link> <span class=md-ellipsis> Customized RAG with Claude 3 and Langchain </span> </a> </li> <li class=md-nav__item> <a href=../../../../rag/knowledge-bases/features-examples/01-rag-concepts/04_customized-rag-retreive-api-langchain-claude-evaluation-ragas/ class=md-nav__link> <span class=md-ellipsis> RAG Evaluation with Langchain and RAGAS </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2_3_1_3> <label class=md-nav__link for=__nav_2_3_1_3 id=__nav_2_3_1_3_label tabindex=0> <span class=md-ellipsis> Optimizing Retrieval Results </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=4 aria-labelledby=__nav_2_3_1_3_label aria-expanded=false> <label class=md-nav__title for=__nav_2_3_1_3> <span class="md-nav__icon md-icon"></span> Optimizing Retrieval Results </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../../rag/knowledge-bases/features-examples/02-optimizing-accuracy-retrieved-results/advanced_chunking_options/ class=md-nav__link> <span class=md-ellipsis> Advanced Chunking Options </span> </a> </li> <li class=md-nav__item> <a href=../../../../rag/knowledge-bases/features-examples/02-optimizing-accuracy-retrieved-results/csv_metadata_customization/ class=md-nav__link> <span class=md-ellipsis> CSV Metadata Customization </span> </a> </li> <li class=md-nav__item> <a href=../../../../rag/knowledge-bases/features-examples/02-optimizing-accuracy-retrieved-results/query_reformulation/ class=md-nav__link> <span class=md-ellipsis> Query Reformulation </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2_3_1_4> <label class=md-nav__link for=__nav_2_3_1_4 id=__nav_2_3_1_4_label tabindex=0> <span class=md-ellipsis> Advanced Concepts </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=4 aria-labelledby=__nav_2_3_1_4_label aria-expanded=false> <label class=md-nav__title for=__nav_2_3_1_4> <span class="md-nav__icon md-icon"></span> Advanced Concepts </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../../rag/knowledge-bases/features-examples/03-advanced-concepts/dynamic-metadata-filtering/dynamic-metadata-filtering-KB/ class=md-nav__link> <span class=md-ellipsis> Dynamic Metadata Filtering </span> </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2_3_1_4_2> <label class=md-nav__link for=__nav_2_3_1_4_2 id=__nav_2_3_1_4_2_label tabindex=0> <span class=md-ellipsis> Reranking </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=5 aria-labelledby=__nav_2_3_1_4_2_label aria-expanded=false> <label class=md-nav__title for=__nav_2_3_1_4_2> <span class="md-nav__icon md-icon"></span> Reranking </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../../rag/knowledge-bases/features-examples/03-advanced-concepts/reranking/01_deploy-reranking-model-sm/ class=md-nav__link> <span class=md-ellipsis> Deploy Reranking Model </span> </a> </li> <li class=md-nav__item> <a href=../../../../rag/knowledge-bases/features-examples/03-advanced-concepts/reranking/02_kb-reranker/ class=md-nav__link> <span class=md-ellipsis> Knowledge Base Reranker </span> </a> </li> <li class=md-nav__item> <a href=../../../../rag/knowledge-bases/features-examples/03-advanced-concepts/reranking/qa-generator/ class=md-nav__link> <span class=md-ellipsis> QA Generator </span> </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2_3_1_5> <label class=md-nav__link for=__nav_2_3_1_5 id=__nav_2_3_1_5_label tabindex=0> <span class=md-ellipsis> Responsible AI </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=4 aria-labelledby=__nav_2_3_1_5_label aria-expanded=false> <label class=md-nav__title for=__nav_2_3_1_5> <span class="md-nav__icon md-icon"></span> Responsible AI </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../../rag/knowledge-bases/features-examples/05-responsible-ai/contextual-grounding/ class=md-nav__link> <span class=md-ellipsis> Contextual Grounding </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2_3_1_6> <label class=md-nav__link for=__nav_2_3_1_6 id=__nav_2_3_1_6_label tabindex=0> <span class=md-ellipsis> Use Case Examples </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=4 aria-labelledby=__nav_2_3_1_6_label aria-expanded=false> <label class=md-nav__title for=__nav_2_3_1_6> <span class="md-nav__icon md-icon"></span> Use Case Examples </label> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2_3_1_6_1> <label class=md-nav__link for=__nav_2_3_1_6_1 id=__nav_2_3_1_6_1_label tabindex=0> <span class=md-ellipsis> Metadata Filter Access Control </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=5 aria-labelledby=__nav_2_3_1_6_1_label aria-expanded=false> <label class=md-nav__title for=__nav_2_3_1_6_1> <span class="md-nav__icon md-icon"></span> Metadata Filter Access Control </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../../rag/knowledge-bases/use-case-examples/metadata-filter-access-control/kb-end-to-end-acl/ class=md-nav__link> <span class=md-ellipsis> End-to-End ACL with Knowledge Base </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2_3_1_6_2> <label class=md-nav__link for=__nav_2_3_1_6_2 id=__nav_2_3_1_6_2_label tabindex=0> <span class=md-ellipsis> RAG with Structured and Unstructured Data </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=5 aria-labelledby=__nav_2_3_1_6_2_label aria-expanded=false> <label class=md-nav__title for=__nav_2_3_1_6_2> <span class="md-nav__icon md-icon"></span> RAG with Structured and Unstructured Data </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../../rag/knowledge-bases/use-case-examples/rag-using-structured-unstructured-data/0-create-dummy-structured-data/ class=md-nav__link> <span class=md-ellipsis> Create Dummy Structured Data </span> </a> </li> <li class=md-nav__item> <a href=../../../../rag/knowledge-bases/use-case-examples/rag-using-structured-unstructured-data/1_create_sql_dataset_optional/ class=md-nav__link> <span class=md-ellipsis> Create SQL Dataset (Optional) </span> </a> </li> <li class=md-nav__item> <a href=../../../../rag/knowledge-bases/use-case-examples/rag-using-structured-unstructured-data/2_rag_with_structured_unstructured_data/ class=md-nav__link> <span class=md-ellipsis> RAG with Structured and Unstructured Data </span> </a> </li> </ul> </nav> </li> </ul> </nav> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2_3_2> <label class=md-nav__link for=__nav_2_3_2 id=__nav_2_3_2_label tabindex=0> <span class=md-ellipsis> Open Source </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=3 aria-labelledby=__nav_2_3_2_label aria-expanded=false> <label class=md-nav__title for=__nav_2_3_2> <span class="md-nav__icon md-icon"></span> Open Source </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../../rag/open-source/chatbots/qa_chatbot_langchain_bedrock/ class=md-nav__link> <span class=md-ellipsis> Chatbot using Langchain </span> </a> </li> <li class=md-nav__item> <a href=../../../../rag/open-source/chunking/rag_chunking_strategies_langchain_bedrock/ class=md-nav__link> <span class=md-ellipsis> Chunking strategies for RAG applications </span> </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2_3_2_3> <label class=md-nav__link for=__nav_2_3_2_3 id=__nav_2_3_2_3_label tabindex=0> <span class=md-ellipsis> Vector Stores </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=4 aria-labelledby=__nav_2_3_2_3_label aria-expanded=false> <label class=md-nav__title for=__nav_2_3_2_3> <span class="md-nav__icon md-icon"></span> Vector Stores </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../../rag/open-source/vector_stores/rag_langchain_bedrock_opensearch/ class=md-nav__link> <span class=md-ellipsis> Langchain Chatbot with Opensearch </span> </a> </li> </ul> </nav> </li> </ul> </nav> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2_4> <label class=md-nav__link for=__nav_2_4 id=__nav_2_4_label tabindex=0> <span class=md-ellipsis> Model Customization </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_2_4_label aria-expanded=false> <label class=md-nav__title for=__nav_2_4> <span class="md-nav__icon md-icon"></span> Model Customization </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../model-distillation/Historical_invocation_distillation/ class=md-nav__link> <span class=md-ellipsis> Model Distillation with Invocation Logs </span> </a> </li> <li class=md-nav__item> <a href=../../../model-distillation/Distillation-via-S3-input/ class=md-nav__link> <span class=md-ellipsis> Model Distillation with S3 Data </span> </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_3> <label class=md-nav__link for=__nav_3 id=__nav_3_label tabindex=0> <span class=md-ellipsis> Gen AI Usecases </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_3_label aria-expanded=false> <label class=md-nav__title for=__nav_3> <span class="md-nav__icon md-icon"></span> Gen AI Usecases </label> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_3_1> <label class=md-nav__link for=__nav_3_1 id=__nav_3_1_label tabindex=0> <span class=md-ellipsis> Text Generation </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_3_1_label aria-expanded=false> <label class=md-nav__title for=__nav_3_1> <span class="md-nav__icon md-icon"></span> Text Generation </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../../genai-use-cases/text-generation/how_to_work_with_text_generation_w_bedrock/ class=md-nav__link> <span class=md-ellipsis> Streaming Response with Converse </span> </a> </li> <li class=md-nav__item> <a href=../../../../genai-use-cases/text-generation/how_to_work_with_code_generation_w_bedrock/ class=md-nav__link> <span class=md-ellipsis> Generate Python Code with Converse </span> </a> </li> <li class=md-nav__item> <a href=../../../../genai-use-cases/text-generation/how_to_work_with_text_translation_w_bedrock/ class=md-nav__link> <span class=md-ellipsis> Text Translation with Converse </span> </a> </li> <li class=md-nav__item> <a href=../../../../genai-use-cases/text-generation/how_to_work_with_text-summarization-titan%2Bclaude/ class=md-nav__link> <span class=md-ellipsis> Text summarization with Converse </span> </a> </li> <li class=md-nav__item> <a href=../../../../genai-use-cases/text-generation/how_to_work_with_batch_example_for_multi_threaded_invocation/ class=md-nav__link> <span class=md-ellipsis> Generate Bulk Emails with Batch Inference </span> </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_4> <label class=md-nav__link for=__nav_4 id=__nav_4_label tabindex=0> <span class=md-ellipsis> Workshops </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_4_label aria-expanded=false> <label class=md-nav__title for=__nav_4> <span class="md-nav__icon md-icon"></span> Workshops </label> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_4_1> <label class=md-nav__link for=__nav_4_1 id=__nav_4_1_label tabindex=0> <span class=md-ellipsis> Open-source L400 </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_4_1_label aria-expanded=false> <label class=md-nav__title for=__nav_4_1> <span class="md-nav__icon md-icon"></span> Open-source L400 </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../../workshop/open-source-l400/01_usecase_introduction/ class=md-nav__link> <span class=md-ellipsis> Introduction to the Use Case </span> </a> </li> <li class=md-nav__item> <a href=../../../../workshop/open-source-l400/02_Lab_Find%20a%20Dream%20Destination_RAG%20query/ class=md-nav__link> <span class=md-ellipsis> Advanced RAG for Agents </span> </a> </li> <li class=md-nav__item> <a href=../../../../workshop/open-source-l400/02_travel_planner_with_langgraph/ class=md-nav__link> <span class=md-ellipsis> Conversational Memory in Agents </span> </a> </li> <li class=md-nav__item> <a href=../../../../workshop/open-source-l400/03_travel_agent_with_tools/ class=md-nav__link> <span class=md-ellipsis> Multi-Modal and Types of Agents </span> </a> </li> <li class=md-nav__item> <a href=../../../../workshop/open-source-l400/04_travel_booking_multi_agent/ class=md-nav__link> <span class=md-ellipsis> Multi-Agent Collaboration with Human-in-loop </span> </a> </li> <li class=md-nav__item> <a href=../../../../workshop/open-source-l400/05_dream_destination_with_crewai/ class=md-nav__link> <span class=md-ellipsis> Find Dream Destination with CrewAI </span> </a> </li> <li class=md-nav__item> <a href=../../../../workshop/open-source-l400/06_agent_evaluation_with_ragas/ class=md-nav__link> <span class=md-ellipsis> RAGAs Agents Evaluation </span> </a> </li> <li class=md-nav__item> <a href=../../../../workshop/open-source-l400/07_dynamic_tooling_agents/ class=md-nav__link> <span class=md-ellipsis> Dynamic Tool invocation </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_4_2> <label class=md-nav__link for=__nav_4_2 id=__nav_4_2_label tabindex=0> <span class=md-ellipsis> Open-source L200 </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_4_2_label aria-expanded=false> <label class=md-nav__title for=__nav_4_2> <span class="md-nav__icon md-icon"></span> Open-source L200 </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../../workshop/open-source-l200/02_contextual_text_generation/ class=md-nav__link> <span class=md-ellipsis> Introduction to the Use Case </span> </a> </li> <li class=md-nav__item> <a href=../../../../workshop/open-source-l200/03_retrieval_based_text_application/ class=md-nav__link> <span class=md-ellipsis> Retrieval Based Text Generation </span> </a> </li> <li class=md-nav__item> <a href=../../../../workshop/open-source-l200/04_retrieval_based_chat_application/ class=md-nav__link> <span class=md-ellipsis> Retrieval Based Chat Application </span> </a> </li> <li class=md-nav__item> <a href=../../../../workshop/open-source-l200/05_agent_based_text_generation/ class=md-nav__link> <span class=md-ellipsis> Agent Based Text Generation </span> </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../../../../general/tags/ class=md-nav__link> <span class=md-ellipsis> Tags </span> </a> </li> <li class=md-nav__item> <a href=../../../../general/license/ class=md-nav__link> <span class=md-ellipsis> License </span> </a> </li> </ul> </nav> </div> </div> </div> <div class=md-content data-md-component=content> <article class="md-content__inner md-typeset"> <h1> Continuous Fine-Tuning of LlaMA 3 and Importing into Bedrock: A Step-by-Step Instructional Guide </h1> <h2> Overview </h2> <p>In this notebook we will walk through how to <em>continuously</em> fine-tune a Llama-3 LLM on Amazon SageMaker using PyTorch FSDP and Flash Attention 2 including Q-LORA and PEFT. This notebook also explains using PEFT and merging the adapters. To demonstrate continous fine tuning we will take a Llama-3 Base Model fine tune using English dataset and then fine tune again using a Portuguese language dataset. Each of the fine tuned model will be imported into Bedrock. This demonstrates the ability to iteratively fine tune a model as new data originates or when there is a need to expand out further (ex: language addition in this example).</p> <h2> Usecase </h2> <p>We will quantize the model as bf16 model. We use <a href=https://huggingface.co/docs/trl/sft_trainer>Supervised Fine-tuning Trainer</a> (SFT) for fine tuning the model. We will use Anthropic/Vicuna like Chat Template with User: and Assistant: roles to fine tune the model. We will use <a href=https://huggingface.co/datasets/ngram/medchat-qa>ngram/medchat-qa</a> dataset for fine tuning the model. This is a high-quality dataset of 10,000 instructions and demonstrations created by skilled human annotators. Using <a href=https://pytorch.org/docs/main/fsdp.html>FSDP</a> and <a href=https://arxiv.org/abs/2305.14314>Q-Lora</a> allows us to fine tune Llama-3 models on 2x consumer GPU's. FSDP enables sharding model parameters, optimizer states and gradients across data parallel workers. Q- LORA helps reduce the memmory usage for finetuning LLM while preserving full 16-bit task performance. For fine tuning in this notebook we use ml.g5.12xlarge as a SageMaker Training Job. </p> <p><a href=https://aws.amazon.com/sagemaker>Amazon SageMaker</a> provides a fully managed service that enables build, train and deploy ML models at scale using tools like notebooks, debuggers, profilers, pipelines, MLOps, and more – all in one integrated development environment (IDE). <a href=https://aws.amazon.com/sagemaker/train/ >SageMaker Model Training</a> reduces the time and cost to train and tune machine learning (ML) models at scale without the need to manage infrastructure.</p> <p>In this notebook you will leverage the ability of SageMaker Training job to download training data to download the fine tuned Large Language Model for further fine tuning.</p> <p>For detailed instructions please refer to <a href=https://docs.aws.amazon.com/bedrock/latest/userguide/model-customization-import-model.html>Importing a model with customer model import Bedrock Documentation</a>.</p> <p>This notebook is inspired by Philipp Schmid Blog - https://www.philschmid.de/fsdp-qlora-llama3</p> <h3> Model License information </h3> <p>In this notebook we use the Meta Llama3 model from HuggingFace. This model is a gated model within HuggingFace repository. To use this model you have to agree to the license agreement (https://llama.meta.com/llama3/license) and request access to the model before it can be used in this notebook.</p> <h2> Notebook code with comments: </h2> <h3> Install the Pre-Requisites </h3> <div class=highlight><pre><span></span><code><span class=c1>### !rm -fR /opt/conda/lib/python3.10/site-packages # Run if you are getting conflicts with fsspec packages.</span>
<span class=err>!</span><span class=n>pip3</span> <span class=n>uninstall</span> <span class=n>autogluon</span> <span class=n>autogluon</span><span class=o>-</span><span class=n>multimodal</span> <span class=o>--</span><span class=n>y</span>
<span class=err>!</span><span class=n>pip3</span> <span class=n>install</span> <span class=n>transformers</span> <span class=s2>&quot;sagemaker&gt;=2.190.0&quot;</span> <span class=s2>&quot;huggingface_hub&quot;</span> <span class=s2>&quot;datasets[s3]==2.18.0&quot;</span> <span class=o>--</span><span class=n>upgrade</span> <span class=o>--</span><span class=n>quiet</span>
<span class=err>!</span><span class=n>pip3</span> <span class=n>install</span> <span class=n>boto3</span> <span class=n>s3fs</span> <span class=s2>&quot;aiobotocore==2.11.0&quot;</span> <span class=o>--</span><span class=n>upgrade</span> <span class=o>--</span><span class=n>quiet</span>
</code></pre></div> <p>Logging into the HuggingFace Hub and requesting access to the meta-llama/Meta-Llama-3-8B is required to download the model and finetune the same. Please follow the <a href=https://huggingface.co/docs/hub/en/security-tokens>HuggingFace User Token Documentation</a> to request tokens to be provided in the textbox appearning below after you run the cell.</p> <div class=highlight><pre><span></span><code><span class=kn>from</span> <span class=nn>huggingface_hub</span> <span class=kn>import</span> <span class=n>notebook_login</span>
<span class=n>notebook_login</span><span class=p>()</span>
</code></pre></div> <h3> Setup </h3> <p>We will initialize the SageMaker Session required to finetune the model.</p> <div class=highlight><pre><span></span><code><span class=kn>import</span> <span class=nn>sagemaker</span>
<span class=kn>import</span> <span class=nn>boto3</span>
<span class=n>sess</span> <span class=o>=</span> <span class=n>sagemaker</span><span class=o>.</span><span class=n>Session</span><span class=p>()</span>
<span class=c1># sagemaker session bucket -&gt; used for uploading data, models and logs</span>
<span class=c1># sagemaker will automatically create this bucket if it not exists</span>
<span class=n>sagemaker_session_bucket</span><span class=o>=</span><span class=kc>None</span>
<span class=k>if</span> <span class=n>sagemaker_session_bucket</span> <span class=ow>is</span> <span class=kc>None</span> <span class=ow>and</span> <span class=n>sess</span> <span class=ow>is</span> <span class=ow>not</span> <span class=kc>None</span><span class=p>:</span>
    <span class=c1># set to default bucket if a bucket name is not given</span>
    <span class=n>sagemaker_session_bucket</span> <span class=o>=</span> <span class=n>sess</span><span class=o>.</span><span class=n>default_bucket</span><span class=p>()</span>

<span class=k>try</span><span class=p>:</span>
    <span class=n>role</span> <span class=o>=</span> <span class=n>sagemaker</span><span class=o>.</span><span class=n>get_execution_role</span><span class=p>()</span>
<span class=k>except</span> <span class=ne>ValueError</span><span class=p>:</span>
    <span class=n>iam</span> <span class=o>=</span> <span class=n>boto3</span><span class=o>.</span><span class=n>client</span><span class=p>(</span><span class=s1>&#39;iam&#39;</span><span class=p>)</span>
    <span class=n>role</span> <span class=o>=</span> <span class=n>iam</span><span class=o>.</span><span class=n>get_role</span><span class=p>(</span><span class=n>RoleName</span><span class=o>=</span><span class=s1>&#39;sagemaker_execution_role&#39;</span><span class=p>)[</span><span class=s1>&#39;Role&#39;</span><span class=p>][</span><span class=s1>&#39;Arn&#39;</span><span class=p>]</span>

<span class=n>sess</span> <span class=o>=</span> <span class=n>sagemaker</span><span class=o>.</span><span class=n>Session</span><span class=p>(</span><span class=n>default_bucket</span><span class=o>=</span><span class=n>sagemaker_session_bucket</span><span class=p>)</span>

<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;sagemaker role arn: </span><span class=si>{</span><span class=n>role</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;sagemaker bucket: </span><span class=si>{</span><span class=n>sess</span><span class=o>.</span><span class=n>default_bucket</span><span class=p>()</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;sagemaker session region: </span><span class=si>{</span><span class=n>sess</span><span class=o>.</span><span class=n>boto_region_name</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</code></pre></div> <h3> Define the Parameters </h3> <div class=highlight><pre><span></span><code><span class=n>model_id</span> <span class=o>=</span> <span class=s2>&quot;meta-llama/Meta-Llama-3-8B&quot;</span>
<span class=c1># save train_dataset to s3 using our SageMaker session</span>
<span class=n>training_input_base_path</span> <span class=o>=</span> <span class=sa>f</span><span class=s2>&quot;s3://</span><span class=si>{</span><span class=n>sess</span><span class=o>.</span><span class=n>default_bucket</span><span class=p>()</span><span class=si>}</span><span class=s2>/datasets/ngram/medchat-qa/&quot;</span>
<span class=n>training_input_path</span> <span class=o>=</span> <span class=sa>f</span><span class=s2>&quot;</span><span class=si>{</span><span class=n>training_input_base_path</span><span class=si>}</span><span class=s2>finetune_ip&quot;</span>
<span class=n>use_bf16</span> <span class=o>=</span> <span class=kc>True</span>
</code></pre></div> <h3> Dataset Prepare </h3> <p>We will use <a href=https://huggingface.co/datasets/ngram/medchat-qa>ngram/medchat-qa</a> dataset to finetune the Llama 3 model. Kindly refer to the <a href=https://huggingface.co/datasets/ngram/medchat-qa>Licensing Information</a> regarding this dataset before proceeding further.</p> <p>We will transform the messages to OAI format and split the data into Train and Test set. The Train and Test dataset will be uploaded into S3 - SageMaker Session Bucket for use during finetuning.</p> <div class=highlight><pre><span></span><code><span class=kn>from</span> <span class=nn>datasets</span> <span class=kn>import</span> <span class=n>load_dataset</span><span class=p>,</span> <span class=n>VerificationMode</span>
<span class=kn>from</span> <span class=nn>datasets</span> <span class=kn>import</span> <span class=n>load_from_disk</span>

<span class=kn>import</span> <span class=nn>aiobotocore.session</span>
<span class=n>s3_session</span> <span class=o>=</span> <span class=n>aiobotocore</span><span class=o>.</span><span class=n>session</span><span class=o>.</span><span class=n>AioSession</span><span class=p>()</span>
<span class=n>storage_options</span> <span class=o>=</span> <span class=p>{</span><span class=s2>&quot;session&quot;</span><span class=p>:</span> <span class=n>s3_session</span><span class=p>}</span>

<span class=c1># Convert dataset to OAI messages</span>
<span class=n>system_message</span> <span class=o>=</span> <span class=s2>&quot;&quot;&quot;You are Llama, a medical expert tasked with providing the most accurate and succinct answers to specific questions based on detailed medical data. Focus on precision and directness in your responses, ensuring that each answer is factual, concise, and to the point. Avoid unnecessary elaboration and prioritize accuracy over sounding confident.&quot;&quot;&quot;</span>

<span class=k>def</span> <span class=nf>create_conversation</span><span class=p>(</span><span class=n>row</span><span class=p>):</span>
    <span class=n>row</span><span class=p>[</span><span class=s2>&quot;messages&quot;</span><span class=p>]</span> <span class=o>=</span> <span class=p>[{</span>
        <span class=s2>&quot;role&quot;</span><span class=p>:</span> <span class=s2>&quot;system&quot;</span><span class=p>,</span>
        <span class=s2>&quot;content&quot;</span><span class=p>:</span> <span class=n>system_message</span>
    <span class=p>},{</span>
        <span class=s2>&quot;role&quot;</span><span class=p>:</span> <span class=s2>&quot;user&quot;</span><span class=p>,</span>
        <span class=s2>&quot;content&quot;</span><span class=p>:</span> <span class=n>row</span><span class=p>[</span><span class=s2>&quot;question&quot;</span><span class=p>]</span>
    <span class=p>},{</span>
        <span class=s2>&quot;role&quot;</span><span class=p>:</span> <span class=s2>&quot;assistant&quot;</span><span class=p>,</span>
        <span class=s2>&quot;content&quot;</span><span class=p>:</span> <span class=n>row</span><span class=p>[</span><span class=s2>&quot;answer&quot;</span><span class=p>]</span>
    <span class=p>}]</span>
    <span class=k>return</span> <span class=n>row</span>

<span class=c1># Load dataset from the hub</span>
<span class=n>dataset</span> <span class=o>=</span> <span class=n>load_dataset</span><span class=p>(</span><span class=s2>&quot;ngram/medchat-qa&quot;</span><span class=p>,</span> <span class=n>split</span><span class=o>=</span><span class=s2>&quot;train[:100%]&quot;</span><span class=p>)</span>
<span class=n>dataset</span> <span class=o>=</span> <span class=n>dataset</span><span class=o>.</span><span class=n>train_test_split</span><span class=p>(</span><span class=n>test_size</span><span class=o>=</span><span class=mf>0.3</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s1>&#39;Schema for dataset: </span><span class=si>{</span><span class=n>dataset</span><span class=si>}</span><span class=s1>&#39;</span><span class=p>)</span>

<span class=n>dataset</span><span class=o>.</span><span class=n>save_to_disk</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;</span><span class=si>{</span><span class=n>training_input_base_path</span><span class=si>}</span><span class=s2>/en/&quot;</span><span class=p>,</span> <span class=n>storage_options</span><span class=o>=</span><span class=n>storage_options</span><span class=p>)</span>

<span class=c1># Load dataset from the hub</span>
<span class=n>dataset</span> <span class=o>=</span> <span class=n>load_from_disk</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;s3://</span><span class=si>{</span><span class=n>sagemaker_session_bucket</span><span class=si>}</span><span class=s2>/datasets/ngram/medchat-qa/en/&quot;</span>
                         <span class=p>,</span> <span class=n>storage_options</span><span class=o>=</span><span class=n>storage_options</span><span class=p>)</span>

<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s1>&#39;Number of Rows: </span><span class=si>{</span><span class=n>dataset</span><span class=o>.</span><span class=n>num_rows</span><span class=si>}</span><span class=s1>&#39;</span><span class=p>)</span>

<span class=c1># dataset = dataset.train_test_split(test_size=0.3)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s1>&#39;Schema for dataset: </span><span class=si>{</span><span class=n>dataset</span><span class=si>}</span><span class=s1>&#39;</span><span class=p>)</span>

<span class=c1># Add system message to each conversation</span>
<span class=n>columns_to_remove</span> <span class=o>=</span> <span class=nb>list</span><span class=p>(</span><span class=n>dataset</span><span class=p>[</span><span class=s2>&quot;train&quot;</span><span class=p>]</span><span class=o>.</span><span class=n>features</span><span class=p>)</span>
<span class=n>dataset</span> <span class=o>=</span> <span class=n>dataset</span><span class=o>.</span><span class=n>map</span><span class=p>(</span><span class=n>create_conversation</span><span class=p>,</span> <span class=n>remove_columns</span><span class=o>=</span><span class=n>columns_to_remove</span><span class=p>,</span> <span class=n>batched</span><span class=o>=</span><span class=kc>False</span><span class=p>)</span>

<span class=n>dataset</span><span class=p>[</span><span class=s2>&quot;train&quot;</span><span class=p>]</span> <span class=o>=</span> <span class=n>dataset</span><span class=p>[</span><span class=s2>&quot;train&quot;</span><span class=p>]</span><span class=o>.</span><span class=n>filter</span><span class=p>(</span><span class=k>lambda</span> <span class=n>x</span><span class=p>:</span> <span class=nb>len</span><span class=p>(</span><span class=n>x</span><span class=p>[</span><span class=s2>&quot;messages&quot;</span><span class=p>][</span><span class=mi>1</span><span class=p>:])</span> <span class=o>%</span> <span class=mi>2</span> <span class=o>==</span> <span class=mi>0</span><span class=p>)</span>
<span class=n>dataset</span><span class=p>[</span><span class=s2>&quot;test&quot;</span><span class=p>]</span> <span class=o>=</span> <span class=n>dataset</span><span class=p>[</span><span class=s2>&quot;test&quot;</span><span class=p>]</span><span class=o>.</span><span class=n>filter</span><span class=p>(</span><span class=k>lambda</span> <span class=n>x</span><span class=p>:</span> <span class=nb>len</span><span class=p>(</span><span class=n>x</span><span class=p>[</span><span class=s2>&quot;messages&quot;</span><span class=p>][</span><span class=mi>1</span><span class=p>:])</span> <span class=o>%</span> <span class=mi>2</span> <span class=o>==</span> <span class=mi>0</span><span class=p>)</span>

<span class=c1># save datasets to s3</span>
<span class=n>dataset</span><span class=p>[</span><span class=s2>&quot;train&quot;</span><span class=p>]</span><span class=o>.</span><span class=n>to_json</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;</span><span class=si>{</span><span class=n>training_input_path</span><span class=si>}</span><span class=s2>/train_dataset.json&quot;</span><span class=p>,</span> <span class=n>orient</span><span class=o>=</span><span class=s2>&quot;records&quot;</span><span class=p>,</span> <span class=n>force_ascii</span><span class=o>=</span><span class=kc>False</span><span class=p>)</span>
<span class=n>dataset</span><span class=p>[</span><span class=s2>&quot;test&quot;</span><span class=p>]</span><span class=o>.</span><span class=n>to_json</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;</span><span class=si>{</span><span class=n>training_input_path</span><span class=si>}</span><span class=s2>/test_dataset.json&quot;</span><span class=p>,</span> <span class=n>orient</span><span class=o>=</span><span class=s2>&quot;records&quot;</span><span class=p>,</span> <span class=n>force_ascii</span><span class=o>=</span><span class=kc>False</span><span class=p>)</span>

<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Number of Rows: </span><span class=si>{</span><span class=n>dataset</span><span class=o>.</span><span class=n>num_rows</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Training data uploaded to:&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;</span><span class=si>{</span><span class=n>training_input_path</span><span class=si>}</span><span class=s2>/train_dataset.json&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;https://s3.console.aws.amazon.com/s3/buckets/</span><span class=si>{</span><span class=n>sess</span><span class=o>.</span><span class=n>default_bucket</span><span class=p>()</span><span class=si>}</span><span class=s2>/?region=</span><span class=si>{</span><span class=n>sess</span><span class=o>.</span><span class=n>boto_region_name</span><span class=si>}</span><span class=s2>&amp;prefix=</span><span class=si>{</span><span class=n>training_input_path</span><span class=o>.</span><span class=n>split</span><span class=p>(</span><span class=s1>&#39;/&#39;</span><span class=p>,</span><span class=w> </span><span class=mi>3</span><span class=p>)[</span><span class=o>-</span><span class=mi>1</span><span class=p>]</span><span class=si>}</span><span class=s2>/&quot;</span><span class=p>)</span>
</code></pre></div> <h3> Training script and dependencies </h3> <p>Create the scripts directory to hold the training script and dependencies list. This directory will be provided to the trainer.</p> <div class=highlight><pre><span></span><code><span class=kn>import</span> <span class=nn>os</span>
<span class=n>os</span><span class=o>.</span><span class=n>makedirs</span><span class=p>(</span><span class=s2>&quot;scripts/trl&quot;</span><span class=p>,</span> <span class=n>exist_ok</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</code></pre></div> <p>Create the requirements file that will be used by the SageMaker Job container to initialize the dependencies.</p> <div class=highlight><pre><span></span><code><span class=o>%%</span><span class=n>writefile</span> <span class=n>scripts</span><span class=o>/</span><span class=n>trl</span><span class=o>/</span><span class=n>requirements</span><span class=o>.</span><span class=n>txt</span>
<span class=n>torch</span><span class=o>==</span><span class=mf>2.2.2</span>
<span class=n>transformers</span><span class=o>==</span><span class=mf>4.40.2</span>
<span class=n>sagemaker</span><span class=o>&gt;=</span><span class=mf>2.190.0</span>
<span class=n>datasets</span><span class=o>==</span><span class=mf>2.18.0</span>
<span class=n>accelerate</span><span class=o>==</span><span class=mf>0.29.3</span>
<span class=n>evaluate</span><span class=o>==</span><span class=mf>0.4.1</span>
<span class=n>bitsandbytes</span><span class=o>==</span><span class=mf>0.43.1</span>
<span class=n>trl</span><span class=o>==</span><span class=mf>0.8.6</span>
<span class=n>peft</span><span class=o>==</span><span class=mf>0.10.0</span>
</code></pre></div> <p>Training Script that will use PyTorch FSDP, QLORA, PEFT and train the model using SFT Trainer. This script also includes prepping the data to Llama 3 chat template (Anthropic/Vicuna format). This training script is being written to the scripts folder along with the requirements file that will be used by the SageMaker Job.</p> <p>The training script also uses either the HuggingFace Model Id or a local path (script_args.model_id_path) to load the Large Language Model for Fine Tuning the model.</p> <div class=highlight><pre><span></span><code><span class=o>%%</span><span class=n>writefile</span> <span class=n>scripts</span><span class=o>/</span><span class=n>trl</span><span class=o>/</span><span class=n>run_fsdp_qlora</span><span class=o>.</span><span class=n>py</span>
<span class=kn>import</span> <span class=nn>logging</span>
<span class=kn>from</span> <span class=nn>dataclasses</span> <span class=kn>import</span> <span class=n>dataclass</span><span class=p>,</span> <span class=n>field</span>
<span class=kn>import</span> <span class=nn>os</span>
<span class=kn>import</span> <span class=nn>warnings</span>


<span class=k>try</span><span class=p>:</span>
    <span class=n>os</span><span class=o>.</span><span class=n>system</span><span class=p>(</span><span class=s2>&quot;pip install flash-attn --no-build-isolation --upgrade&quot;</span><span class=p>)</span>
<span class=k>except</span><span class=p>:</span>
    <span class=nb>print</span><span class=p>(</span><span class=s2>&quot;flash-attn failed to install&quot;</span><span class=p>)</span>

<span class=kn>import</span> <span class=nn>random</span>
<span class=kn>import</span> <span class=nn>torch</span>
<span class=kn>from</span> <span class=nn>datasets</span> <span class=kn>import</span> <span class=n>load_dataset</span>
<span class=kn>from</span> <span class=nn>tqdm</span> <span class=kn>import</span> <span class=n>tqdm</span>
<span class=kn>from</span> <span class=nn>trl.commands.cli_utils</span> <span class=kn>import</span>  <span class=n>TrlParser</span>
<span class=kn>from</span> <span class=nn>transformers</span> <span class=kn>import</span> <span class=p>(</span>
    <span class=n>AutoModelForCausalLM</span><span class=p>,</span>
    <span class=n>AutoTokenizer</span><span class=p>,</span>
    <span class=n>TrainingArguments</span><span class=p>,</span>
    <span class=n>HfArgumentParser</span><span class=p>,</span>
    <span class=n>BitsAndBytesConfig</span><span class=p>,</span>
    <span class=n>set_seed</span><span class=p>,</span>
    <span class=n>Conv1D</span>
<span class=p>)</span>
<span class=kn>from</span> <span class=nn>transformers</span> <span class=kn>import</span> <span class=n>logging</span> <span class=k>as</span> <span class=n>transf_logging</span>
<span class=kn>from</span> <span class=nn>trl</span> <span class=kn>import</span> <span class=n>setup_chat_format</span>
<span class=kn>from</span> <span class=nn>peft</span> <span class=kn>import</span> <span class=n>LoraConfig</span><span class=p>,</span> <span class=n>prepare_model_for_kbit_training</span>

<span class=kn>from</span> <span class=nn>trl</span> <span class=kn>import</span> <span class=p>(</span>
   <span class=n>SFTTrainer</span><span class=p>)</span>

<span class=c1># Comment in if you want to use the Llama 3 instruct template but make sure to add modules_to_save</span>
<span class=c1># LLAMA_3_CHAT_TEMPLATE=&quot;{% set loop_messages = messages %}{% for message in loop_messages %}{% set content = &#39;&lt;|start_header_id|&gt;&#39; + message[&#39;role&#39;] + &#39;&lt;|end_header_id|&gt;\n\n&#39;+ message[&#39;content&#39;] | trim + &#39;&lt;|eot_id|&gt;&#39; %}{% if loop.index0 == 0 %}{% set content = bos_token + content %}{% endif %}{{ content }}{% endfor %}{% if add_generation_prompt %}{{ &#39;&lt;|start_header_id|&gt;assistant&lt;|end_header_id|&gt;\n\n&#39; }}{% endif %}&quot;</span>

<span class=c1># Anthropic/Vicuna like template without the need for special tokens</span>
<span class=n>LLAMA_3_CHAT_TEMPLATE</span> <span class=o>=</span> <span class=p>(</span>
    <span class=s2>&quot;{</span><span class=si>% f</span><span class=s2>or message in messages %}&quot;</span>
        <span class=s2>&quot;{</span><span class=si>% i</span><span class=s2>f message[&#39;role&#39;] == &#39;system&#39; %}&quot;</span>
            <span class=s2>&quot;{{ message[&#39;content&#39;] }}&quot;</span>
        <span class=s2>&quot;{</span><span class=si>% e</span><span class=s2>lif message[&#39;role&#39;] == &#39;user&#39; %}&quot;</span>
            <span class=s2>&quot;{{ &#39;</span><span class=se>\n\n</span><span class=s2>Human: &#39; + message[&#39;content&#39;] +  eos_token }}&quot;</span>
        <span class=s2>&quot;{</span><span class=si>% e</span><span class=s2>lif message[&#39;role&#39;] == &#39;assistant&#39; %}&quot;</span>
            <span class=s2>&quot;{{ &#39;</span><span class=se>\n\n</span><span class=s2>Assistant: &#39;  + message[&#39;content&#39;] +  eos_token  }}&quot;</span>
        <span class=s2>&quot;{</span><span class=si>% e</span><span class=s2>ndif %}&quot;</span>
    <span class=s2>&quot;{</span><span class=si>% e</span><span class=s2>ndfor %}&quot;</span>
    <span class=s2>&quot;{</span><span class=si>% i</span><span class=s2>f add_generation_prompt %}&quot;</span>
    <span class=s2>&quot;{{ &#39;</span><span class=se>\n\n</span><span class=s2>Assistant: &#39; }}&quot;</span>
    <span class=s2>&quot;{</span><span class=si>% e</span><span class=s2>ndif %}&quot;</span>
<span class=p>)</span>

<span class=n>transf_logging</span><span class=o>.</span><span class=n>set_verbosity_error</span><span class=p>()</span>
<span class=n>tqdm</span><span class=o>.</span><span class=n>pandas</span><span class=p>()</span>

<span class=nd>@dataclass</span>
<span class=k>class</span> <span class=nc>ScriptArguments</span><span class=p>:</span>
    <span class=n>dataset_path</span><span class=p>:</span> <span class=nb>str</span> <span class=o>=</span> <span class=n>field</span><span class=p>(</span>
        <span class=n>default</span><span class=o>=</span><span class=kc>None</span><span class=p>,</span>
        <span class=n>metadata</span><span class=o>=</span><span class=p>{</span>
            <span class=s2>&quot;help&quot;</span><span class=p>:</span> <span class=s2>&quot;Path to the dataset&quot;</span>
        <span class=p>},</span>
    <span class=p>)</span>
    <span class=n>model_id_path</span><span class=p>:</span> <span class=nb>str</span> <span class=o>=</span> <span class=n>field</span><span class=p>(</span>
        <span class=n>default</span><span class=o>=</span><span class=kc>None</span><span class=p>,</span> <span class=n>metadata</span><span class=o>=</span><span class=p>{</span><span class=s2>&quot;help&quot;</span><span class=p>:</span> <span class=s2>&quot;Model S3 Path to use for SFT training&quot;</span><span class=p>}</span>
    <span class=p>)</span>
    <span class=n>max_seq_length</span><span class=p>:</span> <span class=nb>int</span> <span class=o>=</span> <span class=n>field</span><span class=p>(</span>
        <span class=n>default</span><span class=o>=</span><span class=mi>512</span><span class=p>,</span> <span class=n>metadata</span><span class=o>=</span><span class=p>{</span><span class=s2>&quot;help&quot;</span><span class=p>:</span> <span class=s2>&quot;The maximum sequence length for SFT Trainer&quot;</span><span class=p>}</span>
    <span class=p>)</span>
    <span class=n>use_qlora</span><span class=p>:</span> <span class=nb>bool</span> <span class=o>=</span> <span class=n>field</span><span class=p>(</span><span class=n>default</span><span class=o>=</span><span class=kc>False</span><span class=p>,</span> <span class=n>metadata</span><span class=o>=</span><span class=p>{</span><span class=s2>&quot;help&quot;</span><span class=p>:</span> <span class=s2>&quot;Whether to use QLORA&quot;</span><span class=p>})</span>
    <span class=n>merge_adapters</span><span class=p>:</span> <span class=nb>bool</span> <span class=o>=</span> <span class=n>field</span><span class=p>(</span>
        <span class=n>metadata</span><span class=o>=</span><span class=p>{</span><span class=s2>&quot;help&quot;</span><span class=p>:</span> <span class=s2>&quot;Wether to merge weights for LoRA.&quot;</span><span class=p>},</span>
        <span class=n>default</span><span class=o>=</span><span class=kc>False</span><span class=p>,</span>
    <span class=p>)</span>


<span class=k>def</span> <span class=nf>get_specific_layer_names</span><span class=p>(</span><span class=n>model</span><span class=p>):</span>
    <span class=c1># Create a list to store the layer names</span>
    <span class=n>layer_names</span> <span class=o>=</span> <span class=p>[]</span>

    <span class=c1># Recursively visit all modules and submodules</span>
    <span class=k>for</span> <span class=n>name</span><span class=p>,</span> <span class=n>module</span> <span class=ow>in</span> <span class=n>model</span><span class=o>.</span><span class=n>named_modules</span><span class=p>():</span>
        <span class=c1># Check if the module is an instance of the specified layers</span>
        <span class=k>if</span> <span class=nb>isinstance</span><span class=p>(</span><span class=n>module</span><span class=p>,</span> <span class=p>(</span><span class=n>torch</span><span class=o>.</span><span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>,</span> <span class=n>torch</span><span class=o>.</span><span class=n>nn</span><span class=o>.</span><span class=n>Embedding</span><span class=p>,</span> <span class=n>torch</span><span class=o>.</span><span class=n>nn</span><span class=o>.</span><span class=n>Conv2d</span><span class=p>,</span> <span class=n>Conv1D</span><span class=p>)):</span>
            <span class=c1># model name parsing </span>
            <span class=n>layer_names</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=s1>&#39;.&#39;</span><span class=o>.</span><span class=n>join</span><span class=p>(</span><span class=n>name</span><span class=o>.</span><span class=n>split</span><span class=p>(</span><span class=s1>&#39;.&#39;</span><span class=p>)[</span><span class=mi>4</span><span class=p>:])</span><span class=o>.</span><span class=n>split</span><span class=p>(</span><span class=s1>&#39;.&#39;</span><span class=p>)[</span><span class=mi>0</span><span class=p>])</span>

    <span class=k>return</span> <span class=n>layer_names</span>

<span class=k>def</span> <span class=nf>training_function</span><span class=p>(</span><span class=n>script_args</span><span class=p>,</span> <span class=n>training_args</span><span class=p>):</span>
    <span class=c1>################</span>
    <span class=c1># Dataset</span>
    <span class=c1>################</span>

    <span class=n>train_dataset</span> <span class=o>=</span> <span class=n>load_dataset</span><span class=p>(</span>
        <span class=s2>&quot;json&quot;</span><span class=p>,</span>
        <span class=n>data_files</span><span class=o>=</span><span class=n>os</span><span class=o>.</span><span class=n>path</span><span class=o>.</span><span class=n>join</span><span class=p>(</span><span class=n>script_args</span><span class=o>.</span><span class=n>dataset_path</span><span class=p>,</span> <span class=s2>&quot;train_dataset.json&quot;</span><span class=p>),</span>
        <span class=n>split</span><span class=o>=</span><span class=s2>&quot;train&quot;</span><span class=p>,</span>
    <span class=p>)</span>
    <span class=n>test_dataset</span> <span class=o>=</span> <span class=n>load_dataset</span><span class=p>(</span>
        <span class=s2>&quot;json&quot;</span><span class=p>,</span>
        <span class=n>data_files</span><span class=o>=</span><span class=n>os</span><span class=o>.</span><span class=n>path</span><span class=o>.</span><span class=n>join</span><span class=p>(</span><span class=n>script_args</span><span class=o>.</span><span class=n>dataset_path</span><span class=p>,</span> <span class=s2>&quot;test_dataset.json&quot;</span><span class=p>),</span>
        <span class=n>split</span><span class=o>=</span><span class=s2>&quot;train&quot;</span><span class=p>,</span>
    <span class=p>)</span>

    <span class=n>torch</span><span class=o>.</span><span class=n>cuda</span><span class=o>.</span><span class=n>memory_summary</span><span class=p>(</span><span class=n>abbreviated</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span> <span class=c1># Return a human-readable printout of the current memory allocator statistics for a given device.</span>
    <span class=c1>################</span>
    <span class=c1># Model &amp; Tokenizer</span>
    <span class=c1>################</span>

    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;##################     Using model_id_path: </span><span class=si>{</span><span class=n>script_args</span><span class=o>.</span><span class=n>model_id_path</span><span class=si>}</span><span class=s2>        ################&quot;</span><span class=p>)</span>
    <span class=c1># Tokenizer        </span>
    <span class=n>tokenizer</span> <span class=o>=</span> <span class=n>AutoTokenizer</span><span class=o>.</span><span class=n>from_pretrained</span><span class=p>(</span><span class=n>pretrained_model_name_or_path</span><span class=o>=</span><span class=n>script_args</span><span class=o>.</span><span class=n>model_id_path</span>
                                              <span class=p>,</span> <span class=n>use_fast</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
    <span class=n>tokenizer</span><span class=o>.</span><span class=n>pad_token</span> <span class=o>=</span> <span class=n>tokenizer</span><span class=o>.</span><span class=n>eos_token</span>
    <span class=n>tokenizer</span><span class=o>.</span><span class=n>chat_template</span> <span class=o>=</span> <span class=n>LLAMA_3_CHAT_TEMPLATE</span>

    <span class=c1># template dataset</span>
    <span class=k>def</span> <span class=nf>template_dataset</span><span class=p>(</span><span class=n>examples</span><span class=p>):</span>
        <span class=k>return</span><span class=p>{</span><span class=s2>&quot;text&quot;</span><span class=p>:</span>  <span class=n>tokenizer</span><span class=o>.</span><span class=n>apply_chat_template</span><span class=p>(</span><span class=n>examples</span><span class=p>[</span><span class=s2>&quot;messages&quot;</span><span class=p>],</span> <span class=n>tokenize</span><span class=o>=</span><span class=kc>False</span><span class=p>)}</span>

    <span class=n>train_dataset</span> <span class=o>=</span> <span class=n>train_dataset</span><span class=o>.</span><span class=n>map</span><span class=p>(</span><span class=n>template_dataset</span><span class=p>,</span> <span class=n>remove_columns</span><span class=o>=</span><span class=p>[</span><span class=s2>&quot;messages&quot;</span><span class=p>])</span>
    <span class=n>test_dataset</span> <span class=o>=</span> <span class=n>test_dataset</span><span class=o>.</span><span class=n>map</span><span class=p>(</span><span class=n>template_dataset</span><span class=p>,</span> <span class=n>remove_columns</span><span class=o>=</span><span class=p>[</span><span class=s2>&quot;messages&quot;</span><span class=p>])</span>

    <span class=c1># print random sample</span>
    <span class=k>with</span> <span class=n>training_args</span><span class=o>.</span><span class=n>main_process_first</span><span class=p>(</span>
        <span class=n>desc</span><span class=o>=</span><span class=s2>&quot;Log a few random samples from the processed training set&quot;</span>
    <span class=p>):</span>
        <span class=k>for</span> <span class=n>index</span> <span class=ow>in</span> <span class=n>random</span><span class=o>.</span><span class=n>sample</span><span class=p>(</span><span class=nb>range</span><span class=p>(</span><span class=nb>len</span><span class=p>(</span><span class=n>train_dataset</span><span class=p>)),</span> <span class=mi>2</span><span class=p>):</span>
            <span class=nb>print</span><span class=p>(</span><span class=n>train_dataset</span><span class=p>[</span><span class=n>index</span><span class=p>][</span><span class=s2>&quot;text&quot;</span><span class=p>])</span>

    <span class=c1># Model    </span>
    <span class=n>torch_dtype</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>bfloat16</span> <span class=k>if</span> <span class=n>training_args</span><span class=o>.</span><span class=n>bf16</span> <span class=k>else</span> <span class=n>torch</span><span class=o>.</span><span class=n>float32</span>
    <span class=n>quant_storage_dtype</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>bfloat16</span>

    <span class=k>if</span> <span class=n>script_args</span><span class=o>.</span><span class=n>use_qlora</span><span class=p>:</span>
        <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Using QLoRA - </span><span class=si>{</span><span class=n>torch_dtype</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
        <span class=n>quantization_config</span> <span class=o>=</span> <span class=n>BitsAndBytesConfig</span><span class=p>(</span>
                <span class=n>load_in_4bit</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span>
                <span class=n>bnb_4bit_use_double_quant</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span>
                <span class=n>bnb_4bit_quant_type</span><span class=o>=</span><span class=s2>&quot;nf4&quot;</span><span class=p>,</span>
                <span class=n>bnb_4bit_compute_dtype</span><span class=o>=</span><span class=n>torch_dtype</span><span class=p>,</span>
                <span class=n>bnb_4bit_quant_storage</span><span class=o>=</span><span class=n>quant_storage_dtype</span><span class=p>,</span>
            <span class=p>)</span>
        <span class=c1># For 8 bit quantization</span>
        <span class=c1># quantization_config = BitsAndBytesConfig(load_in_8bit=True,</span>
        <span class=c1>#                                          llm_int8_threshold=200.0)</span>
    <span class=k>else</span><span class=p>:</span>
        <span class=n>quantization_config</span> <span class=o>=</span> <span class=kc>None</span>

    <span class=n>model</span> <span class=o>=</span> <span class=n>AutoModelForCausalLM</span><span class=o>.</span><span class=n>from_pretrained</span><span class=p>(</span>
        <span class=n>pretrained_model_name_or_path</span><span class=o>=</span><span class=n>script_args</span><span class=o>.</span><span class=n>model_id_path</span><span class=p>,</span>
        <span class=n>quantization_config</span><span class=o>=</span><span class=n>quantization_config</span><span class=p>,</span>
        <span class=n>device_map</span><span class=o>=</span><span class=p>{</span><span class=s1>&#39;&#39;</span><span class=p>:</span><span class=n>torch</span><span class=o>.</span><span class=n>cuda</span><span class=o>.</span><span class=n>current_device</span><span class=p>()},</span>
        <span class=n>attn_implementation</span><span class=o>=</span><span class=s2>&quot;flash_attention_2&quot;</span><span class=p>,</span> <span class=c1># use sdpa, alternatively use &quot;flash_attention_2&quot;</span>
        <span class=n>torch_dtype</span><span class=o>=</span><span class=n>quant_storage_dtype</span><span class=p>,</span>
        <span class=n>use_cache</span><span class=o>=</span><span class=kc>False</span> <span class=k>if</span> <span class=n>training_args</span><span class=o>.</span><span class=n>gradient_checkpointing</span> <span class=k>else</span> <span class=kc>True</span><span class=p>,</span>  <span class=c1># this is needed for gradient checkpointing</span>
    <span class=p>)</span>

    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Model Layers: </span><span class=si>{</span><span class=nb>list</span><span class=p>(</span><span class=nb>set</span><span class=p>(</span><span class=n>get_specific_layer_names</span><span class=p>(</span><span class=n>model</span><span class=p>)))</span><span class=si>}</span><span class=s2> &quot;</span><span class=p>)</span>

    <span class=k>if</span> <span class=n>training_args</span><span class=o>.</span><span class=n>gradient_checkpointing</span><span class=p>:</span>
        <span class=n>model</span><span class=o>.</span><span class=n>gradient_checkpointing_enable</span><span class=p>()</span>

    <span class=c1>################</span>
    <span class=c1># PEFT</span>
    <span class=c1>################</span>

    <span class=c1># LoRA config based on QLoRA paper &amp; Sebastian Raschka experiment</span>
    <span class=n>peft_config</span> <span class=o>=</span> <span class=n>LoraConfig</span><span class=p>(</span>
        <span class=n>lora_alpha</span><span class=o>=</span><span class=mi>8</span><span class=p>,</span>
        <span class=n>lora_dropout</span><span class=o>=</span><span class=mf>0.05</span><span class=p>,</span>
        <span class=n>r</span><span class=o>=</span><span class=mi>16</span><span class=p>,</span>
        <span class=n>bias</span><span class=o>=</span><span class=s2>&quot;none&quot;</span><span class=p>,</span>
        <span class=c1>#target_modules=&quot;all-linear&quot;,</span>
        <span class=n>target_modules</span><span class=o>=</span><span class=p>[</span><span class=s1>&#39;q_proj&#39;</span><span class=p>,</span> <span class=s1>&#39;v_proj&#39;</span><span class=p>],</span>
        <span class=n>task_type</span><span class=o>=</span><span class=s2>&quot;CAUSAL_LM&quot;</span><span class=p>,</span>
        <span class=c1># target_modules=[&#39;up_proj&#39;, &#39;down_proj&#39;, &#39;gate_proj&#39;, &#39;k_proj&#39;, &#39;q_proj&#39;, &#39;v_proj&#39;, &#39;o_proj&#39;]</span>
        <span class=c1># modules_to_save = [&quot;lm_head&quot;, &quot;embed_tokens&quot;] # add if you want to use the Llama 3 instruct template</span>
    <span class=p>)</span>

    <span class=c1>################</span>
    <span class=c1># Training</span>
    <span class=c1>################</span>
    <span class=n>trainer</span> <span class=o>=</span> <span class=n>SFTTrainer</span><span class=p>(</span>
        <span class=n>model</span><span class=o>=</span><span class=n>model</span><span class=p>,</span>
        <span class=n>args</span><span class=o>=</span><span class=n>training_args</span><span class=p>,</span>
        <span class=n>train_dataset</span><span class=o>=</span><span class=n>train_dataset</span><span class=p>,</span>
        <span class=n>dataset_text_field</span><span class=o>=</span><span class=s2>&quot;text&quot;</span><span class=p>,</span>
        <span class=n>eval_dataset</span><span class=o>=</span><span class=n>test_dataset</span><span class=p>,</span>
        <span class=n>peft_config</span><span class=o>=</span><span class=n>peft_config</span><span class=p>,</span>
        <span class=n>max_seq_length</span><span class=o>=</span><span class=n>script_args</span><span class=o>.</span><span class=n>max_seq_length</span><span class=p>,</span>
        <span class=n>tokenizer</span><span class=o>=</span><span class=n>tokenizer</span><span class=p>,</span>
        <span class=n>packing</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span>
        <span class=n>dataset_kwargs</span><span class=o>=</span><span class=p>{</span>
            <span class=s2>&quot;add_special_tokens&quot;</span><span class=p>:</span> <span class=kc>False</span><span class=p>,</span>  <span class=c1># We template with special tokens</span>
            <span class=s2>&quot;append_concat_token&quot;</span><span class=p>:</span> <span class=kc>False</span><span class=p>,</span>  <span class=c1># No need to add additional separator token</span>
        <span class=p>},</span>
    <span class=p>)</span>
    <span class=k>if</span> <span class=n>trainer</span><span class=o>.</span><span class=n>accelerator</span><span class=o>.</span><span class=n>is_main_process</span><span class=p>:</span>
        <span class=nb>print</span><span class=p>(</span><span class=s2>&quot;###############     Printing Trainable Parameters     ###############&quot;</span><span class=p>)</span>
        <span class=n>trainer</span><span class=o>.</span><span class=n>model</span><span class=o>.</span><span class=n>print_trainable_parameters</span><span class=p>()</span>
        <span class=nb>print</span><span class=p>(</span><span class=s2>&quot;###############     Printing Trainable Parameters - Completed!!!     ###############&quot;</span><span class=p>)</span>

    <span class=c1>##########################</span>
    <span class=c1># Train model</span>
    <span class=c1>##########################</span>
    <span class=n>checkpoint</span> <span class=o>=</span> <span class=kc>None</span>
    <span class=k>if</span> <span class=n>training_args</span><span class=o>.</span><span class=n>resume_from_checkpoint</span> <span class=ow>is</span> <span class=ow>not</span> <span class=kc>None</span><span class=p>:</span>
        <span class=n>checkpoint</span> <span class=o>=</span> <span class=n>training_args</span><span class=o>.</span><span class=n>resume_from_checkpoint</span>
    <span class=n>trainer</span><span class=o>.</span><span class=n>train</span><span class=p>(</span><span class=n>resume_from_checkpoint</span><span class=o>=</span><span class=n>checkpoint</span><span class=p>)</span>

    <span class=c1>##########################</span>
    <span class=c1># SAVE MODEL FOR SAGEMAKER</span>
    <span class=c1>##########################</span>
    <span class=n>sagemaker_save_dir</span> <span class=o>=</span> <span class=s2>&quot;/opt/ml/model&quot;</span>

    <span class=k>if</span> <span class=n>trainer</span><span class=o>.</span><span class=n>is_fsdp_enabled</span><span class=p>:</span>
        <span class=n>trainer</span><span class=o>.</span><span class=n>accelerator</span><span class=o>.</span><span class=n>state</span><span class=o>.</span><span class=n>fsdp_plugin</span><span class=o>.</span><span class=n>set_state_dict_type</span><span class=p>(</span><span class=s2>&quot;FULL_STATE_DICT&quot;</span><span class=p>)</span>

    <span class=k>if</span> <span class=n>script_args</span><span class=o>.</span><span class=n>merge_adapters</span><span class=p>:</span>
        <span class=c1># merge adapter weights with base model and save</span>
        <span class=c1># save int 4 model</span>
        <span class=nb>print</span><span class=p>(</span><span class=s1>&#39;########## Merging Adapters  ##########&#39;</span><span class=p>)</span>
        <span class=n>trainer</span><span class=o>.</span><span class=n>model</span><span class=o>.</span><span class=n>save_pretrained</span><span class=p>(</span><span class=n>training_args</span><span class=o>.</span><span class=n>output_dir</span><span class=p>)</span>
        <span class=n>trainer</span><span class=o>.</span><span class=n>tokenizer</span><span class=o>.</span><span class=n>save_pretrained</span><span class=p>(</span><span class=n>training_args</span><span class=o>.</span><span class=n>output_dir</span><span class=p>)</span>
        <span class=n>trainer</span><span class=o>.</span><span class=n>tokenizer</span><span class=o>.</span><span class=n>save_pretrained</span><span class=p>(</span><span class=n>sagemaker_save_dir</span><span class=p>)</span> 
        <span class=c1># clear memory</span>
        <span class=k>del</span> <span class=n>model</span>
        <span class=k>del</span> <span class=n>trainer</span>
        <span class=n>torch</span><span class=o>.</span><span class=n>cuda</span><span class=o>.</span><span class=n>empty_cache</span><span class=p>()</span>

        <span class=kn>from</span> <span class=nn>peft</span> <span class=kn>import</span> <span class=n>AutoPeftModelForCausalLM</span>

        <span class=c1># list file in output_dir</span>
        <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot; contents of </span><span class=si>{</span><span class=n>training_args</span><span class=o>.</span><span class=n>output_dir</span><span class=si>}</span><span class=s2> : </span><span class=si>{</span><span class=n>os</span><span class=o>.</span><span class=n>listdir</span><span class=p>(</span><span class=n>training_args</span><span class=o>.</span><span class=n>output_dir</span><span class=p>)</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>

        <span class=c1># list files in sagemaker_save_dir</span>
        <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot; contents of </span><span class=si>{</span><span class=n>sagemaker_save_dir</span><span class=si>}</span><span class=s2> : </span><span class=si>{</span><span class=n>os</span><span class=o>.</span><span class=n>listdir</span><span class=p>(</span><span class=n>sagemaker_save_dir</span><span class=p>)</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>

        <span class=c1># load PEFT model</span>
        <span class=n>model</span> <span class=o>=</span> <span class=n>AutoPeftModelForCausalLM</span><span class=o>.</span><span class=n>from_pretrained</span><span class=p>(</span>
            <span class=n>training_args</span><span class=o>.</span><span class=n>output_dir</span><span class=p>,</span>
            <span class=n>low_cpu_mem_usage</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span>
            <span class=n>torch_dtype</span><span class=o>=</span><span class=n>torch</span><span class=o>.</span><span class=n>float16</span><span class=p>,</span> <span class=c1># loading in other precision types gives errors.</span>
            <span class=n>is_trainable</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span> <span class=c1># Setting this to true only will allow further fine tuning.</span>
            <span class=n>device_map</span><span class=o>=</span><span class=p>{</span><span class=s1>&#39;&#39;</span><span class=p>:</span><span class=n>torch</span><span class=o>.</span><span class=n>cuda</span><span class=o>.</span><span class=n>current_device</span><span class=p>()}</span>
        <span class=p>)</span>
        <span class=c1># Merge LoRA and base model and save</span>
        <span class=n>model</span> <span class=o>=</span> <span class=n>model</span><span class=o>.</span><span class=n>merge_and_unload</span><span class=p>()</span>
        <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;#########              Saving Merged Model to </span><span class=si>{</span><span class=n>sagemaker_save_dir</span><span class=si>}</span><span class=s2>               #########&quot;</span><span class=p>)</span>
        <span class=n>model</span><span class=o>.</span><span class=n>save_pretrained</span><span class=p>(</span>
            <span class=n>sagemaker_save_dir</span><span class=p>,</span> <span class=n>safe_serialization</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span> <span class=n>max_shard_size</span><span class=o>=</span><span class=s2>&quot;2GB&quot;</span>
        <span class=p>)</span>
    <span class=k>else</span><span class=p>:</span>
        <span class=n>trainer</span><span class=o>.</span><span class=n>model</span><span class=o>.</span><span class=n>save_pretrained</span><span class=p>(</span><span class=n>sagemaker_save_dir</span><span class=p>,</span> <span class=n>safe_serialization</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>

    <span class=c1># list files in sagemaker_save_dir</span>
    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot; contents of </span><span class=si>{</span><span class=n>sagemaker_save_dir</span><span class=si>}</span><span class=s2> : </span><span class=si>{</span><span class=n>os</span><span class=o>.</span><span class=n>listdir</span><span class=p>(</span><span class=n>sagemaker_save_dir</span><span class=p>)</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>

<span class=k>if</span> <span class=vm>__name__</span> <span class=o>==</span> <span class=s2>&quot;__main__&quot;</span><span class=p>:</span>
    <span class=n>parser</span> <span class=o>=</span> <span class=n>HfArgumentParser</span><span class=p>((</span><span class=n>ScriptArguments</span><span class=p>,</span> <span class=n>TrainingArguments</span><span class=p>))</span>
    <span class=n>script_args</span><span class=p>,</span> <span class=n>training_args</span> <span class=o>=</span> <span class=n>parser</span><span class=o>.</span><span class=n>parse_args_into_dataclasses</span><span class=p>()</span>    

    <span class=c1># set use reentrant to False</span>
    <span class=k>if</span> <span class=n>training_args</span><span class=o>.</span><span class=n>gradient_checkpointing</span><span class=p>:</span>
        <span class=n>training_args</span><span class=o>.</span><span class=n>gradient_checkpointing_kwargs</span> <span class=o>=</span> <span class=p>{</span><span class=s2>&quot;use_reentrant&quot;</span><span class=p>:</span> <span class=kc>True</span><span class=p>}</span>
    <span class=c1># set seed</span>
    <span class=n>set_seed</span><span class=p>(</span><span class=n>training_args</span><span class=o>.</span><span class=n>seed</span><span class=p>)</span>

    <span class=c1># launch training</span>
    <span class=k>with</span> <span class=n>warnings</span><span class=o>.</span><span class=n>catch_warnings</span><span class=p>():</span>
        <span class=n>warnings</span><span class=o>.</span><span class=n>simplefilter</span><span class=p>(</span><span class=s2>&quot;ignore&quot;</span><span class=p>)</span>
        <span class=n>training_function</span><span class=p>(</span><span class=n>script_args</span><span class=p>,</span> <span class=n>training_args</span><span class=p>)</span>
</code></pre></div> <h3> First Iteration of fine tuning </h3> <p>In this iteration of training you will download the Llama-3 base model from HuggingFace repository and fine tune the model using English language version of the dataset.</p> <p>Hyperparameters, which are passed into the training job</p> <div class=highlight><pre><span></span><code><span class=n>hyperparameters</span> <span class=o>=</span> <span class=p>{</span>
  <span class=c1>### SCRIPT PARAMETERS ###</span>
  <span class=s1>&#39;dataset_path&#39;</span><span class=p>:</span> <span class=s1>&#39;/opt/ml/input/data/training/&#39;</span><span class=p>,</span>    <span class=c1># path where sagemaker will save training dataset</span>
  <span class=s1>&#39;model_id_path&#39;</span><span class=p>:</span> <span class=sa>f</span><span class=s2>&quot;</span><span class=si>{</span><span class=n>model_id</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>,</span>         <span class=c1># path where the safetensor model file is downloaded to</span>
  <span class=s1>&#39;max_seq_len&#39;</span><span class=p>:</span> <span class=mi>3072</span><span class=p>,</span>                               <span class=c1># max sequence length for model and packing of the dataset</span>
  <span class=s1>&#39;use_qlora&#39;</span><span class=p>:</span> <span class=kc>True</span><span class=p>,</span>                                 <span class=c1># use QLoRA model</span>
  <span class=c1>### TRAINING PARAMETERS ###</span>
  <span class=s1>&#39;num_train_epochs&#39;</span><span class=p>:</span> <span class=mi>3</span><span class=p>,</span>                             <span class=c1># number of training epochs</span>
  <span class=s1>&#39;per_device_train_batch_size&#39;</span><span class=p>:</span> <span class=mi>1</span><span class=p>,</span>                  <span class=c1># batch size per device during training</span>
  <span class=s1>&#39;per_device_eval_batch_size&#39;</span><span class=p>:</span> <span class=mi>1</span><span class=p>,</span>                   <span class=c1># batch size for evaluation    </span>
  <span class=s1>&#39;gradient_accumulation_steps&#39;</span><span class=p>:</span> <span class=mi>4</span><span class=p>,</span>                  <span class=c1># number of steps before performing a backward/update pass</span>
  <span class=s1>&#39;gradient_checkpointing&#39;</span><span class=p>:</span> <span class=kc>True</span><span class=p>,</span>                    <span class=c1># use gradient checkpointing to save memory</span>
  <span class=s1>&#39;optim&#39;</span><span class=p>:</span> <span class=s2>&quot;adamw_torch&quot;</span><span class=p>,</span>                            <span class=c1># use fused adamw optimizer</span>
  <span class=s1>&#39;logging_steps&#39;</span><span class=p>:</span> <span class=mi>10</span><span class=p>,</span>                               <span class=c1># log every 10 steps</span>
  <span class=s1>&#39;save_strategy&#39;</span><span class=p>:</span> <span class=s2>&quot;epoch&quot;</span><span class=p>,</span>                          <span class=c1># save checkpoint every epoch</span>
  <span class=s1>&#39;evaluation_strategy&#39;</span><span class=p>:</span> <span class=s2>&quot;epoch&quot;</span><span class=p>,</span>
  <span class=s1>&#39;learning_rate&#39;</span><span class=p>:</span> <span class=mf>0.0002</span><span class=p>,</span>                           <span class=c1># learning rate, based on QLoRA paper</span>
  <span class=s1>&#39;bf16&#39;</span><span class=p>:</span> <span class=n>use_bf16</span><span class=p>,</span>                                  <span class=c1># use bfloat16 precision</span>
  <span class=s1>&#39;tf32&#39;</span><span class=p>:</span> <span class=kc>True</span><span class=p>,</span>                                      <span class=c1># use tf32 precision</span>
  <span class=s1>&#39;max_grad_norm&#39;</span><span class=p>:</span> <span class=mf>0.3</span><span class=p>,</span>                              <span class=c1># max gradient norm based on QLoRA paper</span>
  <span class=s1>&#39;warmup_ratio&#39;</span><span class=p>:</span> <span class=mf>0.03</span><span class=p>,</span>                              <span class=c1># warmup ratio based on QLoRA paper</span>
  <span class=s1>&#39;lr_scheduler_type&#39;</span><span class=p>:</span> <span class=s2>&quot;constant&quot;</span><span class=p>,</span>                   <span class=c1># use constant learning rate scheduler</span>
  <span class=s1>&#39;report_to&#39;</span><span class=p>:</span> <span class=s2>&quot;tensorboard&quot;</span><span class=p>,</span>                        <span class=c1># report metrics to tensorboard</span>
  <span class=s1>&#39;output_dir&#39;</span><span class=p>:</span> <span class=s1>&#39;/tmp/tun&#39;</span><span class=p>,</span>                          <span class=c1># Temporary output directory for model checkpoints</span>
  <span class=s1>&#39;merge_adapters&#39;</span><span class=p>:</span> <span class=kc>True</span><span class=p>,</span>                            <span class=c1># merge LoRA adapters into model for easier deployment</span>
  <span class=s1>&#39;fsdp&#39;</span><span class=p>:</span> <span class=s1>&#39;&quot;full_shard auto_wrap offload&quot;&#39;</span><span class=p>,</span>
<span class=p>}</span>
</code></pre></div> <p>Use the SageMaker HuggingFace Estimator to finetune the model passing in the hyperparameters and the scripts directory from above.</p> <div class=highlight><pre><span></span><code><span class=kn>from</span> <span class=nn>sagemaker.huggingface</span> <span class=kn>import</span> <span class=n>HuggingFace</span>
<span class=kn>from</span> <span class=nn>huggingface_hub</span> <span class=kn>import</span> <span class=n>HfFolder</span> 
<span class=kn>import</span> <span class=nn>time</span>

<span class=c1># define Training Job Name</span>
<span class=n>job_name</span> <span class=o>=</span> <span class=sa>f</span><span class=s1>&#39;</span><span class=si>{</span><span class=n>model_id</span><span class=o>.</span><span class=n>replace</span><span class=p>(</span><span class=s2>&quot;/&quot;</span><span class=p>,</span><span class=w> </span><span class=s2>&quot;-&quot;</span><span class=p>)</span><span class=si>}</span><span class=s1>-</span><span class=si>{</span><span class=s2>&quot;bf16&quot;</span><span class=w> </span><span class=k>if</span><span class=w> </span><span class=n>use_bf16</span><span class=w> </span><span class=k>else</span><span class=w> </span><span class=s2>&quot;f32&quot;</span><span class=w> </span><span class=si>}</span><span class=s1>&#39;</span>

<span class=c1># create the Estimator</span>
<span class=n>huggingface_estimator</span> <span class=o>=</span> <span class=n>HuggingFace</span><span class=p>(</span>
    <span class=n>entry_point</span>          <span class=o>=</span> <span class=s1>&#39;run_fsdp_qlora.py&#39;</span><span class=p>,</span>    <span class=c1># train script</span>
    <span class=n>source_dir</span>           <span class=o>=</span> <span class=s1>&#39;scripts/trl/&#39;</span><span class=p>,</span>      <span class=c1># directory which includes all the files needed for training</span>
    <span class=n>instance_type</span>        <span class=o>=</span> <span class=s1>&#39;ml.g5.24xlarge&#39;</span><span class=p>,</span>   <span class=c1># instances type used for the training job</span>
    <span class=n>instance_count</span>       <span class=o>=</span> <span class=mi>1</span><span class=p>,</span>                 <span class=c1># the number of instances used for training</span>
    <span class=n>max_run</span>              <span class=o>=</span> <span class=mi>2</span><span class=o>*</span><span class=mi>24</span><span class=o>*</span><span class=mi>60</span><span class=o>*</span><span class=mi>60</span><span class=p>,</span>        <span class=c1># maximum runtime in seconds (days * hours * minutes * seconds)</span>
    <span class=n>base_job_name</span>        <span class=o>=</span> <span class=n>job_name</span><span class=p>,</span>          <span class=c1># the name of the training job</span>
    <span class=n>role</span>                 <span class=o>=</span> <span class=n>role</span><span class=p>,</span>              <span class=c1># Iam role used in training job to access AWS ressources, e.g. S3</span>
    <span class=n>volume_size</span>          <span class=o>=</span> <span class=mi>300</span><span class=p>,</span>               <span class=c1># the size of the EBS volume in GB</span>
    <span class=n>transformers_version</span> <span class=o>=</span> <span class=s1>&#39;4.36.0&#39;</span><span class=p>,</span>            <span class=c1># the transformers version used in the training job</span>
    <span class=n>pytorch_version</span>      <span class=o>=</span> <span class=s1>&#39;2.1.0&#39;</span><span class=p>,</span>             <span class=c1># the pytorch_version version used in the training job</span>
    <span class=n>py_version</span>           <span class=o>=</span> <span class=s1>&#39;py310&#39;</span><span class=p>,</span>           <span class=c1># the python version used in the training job</span>
    <span class=n>hyperparameters</span>      <span class=o>=</span>  <span class=n>hyperparameters</span><span class=p>,</span>  <span class=c1># the hyperparameters passed to the training job</span>
    <span class=n>disable_output_compression</span> <span class=o>=</span> <span class=kc>True</span><span class=p>,</span>        <span class=c1># not compress output to save training time and cost</span>
    <span class=n>distribution</span><span class=o>=</span><span class=p>{</span><span class=s2>&quot;torch_distributed&quot;</span><span class=p>:</span> <span class=p>{</span><span class=s2>&quot;enabled&quot;</span><span class=p>:</span> <span class=kc>True</span><span class=p>}},</span>
    <span class=n>environment</span>          <span class=o>=</span> <span class=p>{</span>
        <span class=s2>&quot;HUGGINGFACE_HUB_CACHE&quot;</span><span class=p>:</span> <span class=s2>&quot;/tmp/.cache&quot;</span><span class=p>,</span> <span class=c1># set env variable to cache models in /tmp</span>
        <span class=s2>&quot;HF_TOKEN&quot;</span><span class=p>:</span> <span class=n>HfFolder</span><span class=o>.</span><span class=n>get_token</span><span class=p>(),</span>       <span class=c1># Retrieve HuggingFace Token to be used for downloading base models from</span>
        <span class=s2>&quot;ACCELERATE_USE_FSDP&quot;</span><span class=p>:</span><span class=s2>&quot;1&quot;</span><span class=p>,</span> 
        <span class=s2>&quot;FSDP_CPU_RAM_EFFICIENT_LOADING&quot;</span><span class=p>:</span><span class=s2>&quot;1&quot;</span>
    <span class=p>},</span>
    <span class=c1>#enable_remote_debug=True</span>
<span class=p>)</span>

<span class=c1># define a data input dictonary with our uploaded s3 uris</span>
<span class=n>data</span> <span class=o>=</span> <span class=p>{</span><span class=s1>&#39;training&#39;</span><span class=p>:</span> <span class=sa>f</span><span class=s2>&quot;</span><span class=si>{</span><span class=n>training_input_path</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>}</span>
<span class=c1># starting the train job with our uploaded datasets as input</span>
<span class=n>huggingface_estimator</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span><span class=n>data</span><span class=p>,</span> <span class=n>wait</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</code></pre></div> <div class=highlight><pre><span></span><code><span class=n>en_pubmed_model_s3_path</span> <span class=o>=</span> <span class=n>huggingface_estimator</span><span class=o>.</span><span class=n>model_data</span><span class=p>[</span><span class=s2>&quot;S3DataSource&quot;</span><span class=p>][</span><span class=s2>&quot;S3Uri&quot;</span><span class=p>]</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;EN PubMed Fine Tuned Model S3 Location: </span><span class=si>{</span><span class=n>en_pubmed_model_s3_path</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</code></pre></div> <h3> Second Iteration of fine tuning </h3> <p>In this iteration of fine tuning we will take the English Language Fine Tuned model from above and fine tune with a Portuguese translated version of the dataset.</p> <p>First you will translate the dataset into Portuguese using Amazon Translate. You will format the dataset into OAI format and uploaded to the SageMaker Session Bucket for Fine Tuning.</p> <p>Please make sure the SageMaker Role has permission to access Amazon Translate.</p> <div class=highlight><pre><span></span><code><span class=kn>import</span> <span class=nn>boto3</span>
<span class=kn>import</span> <span class=nn>aiobotocore.session</span>

<span class=n>s3_session</span> <span class=o>=</span> <span class=n>aiobotocore</span><span class=o>.</span><span class=n>session</span><span class=o>.</span><span class=n>AioSession</span><span class=p>()</span>
<span class=n>storage_options</span> <span class=o>=</span> <span class=p>{</span><span class=s2>&quot;session&quot;</span><span class=p>:</span> <span class=n>s3_session</span><span class=p>}</span>

<span class=k>global</span> <span class=n>trn_client</span> 
<span class=n>trn_client</span> <span class=o>=</span> <span class=n>boto3</span><span class=o>.</span><span class=n>client</span><span class=p>(</span><span class=s1>&#39;translate&#39;</span><span class=p>)</span>

<span class=k>def</span> <span class=nf>translate2pt</span><span class=p>(</span><span class=n>txt</span><span class=p>):</span>
    <span class=n>response</span> <span class=o>=</span> <span class=n>trn_client</span><span class=o>.</span><span class=n>translate_text</span><span class=p>(</span>
        <span class=n>Text</span><span class=o>=</span><span class=n>txt</span><span class=p>,</span>
        <span class=n>SourceLanguageCode</span><span class=o>=</span><span class=s1>&#39;en&#39;</span><span class=p>,</span>
        <span class=n>TargetLanguageCode</span><span class=o>=</span><span class=s1>&#39;pt&#39;</span><span class=p>,</span>
    <span class=p>)</span>
    <span class=k>return</span> <span class=n>response</span><span class=p>[</span><span class=s2>&quot;TranslatedText&quot;</span><span class=p>]</span>

<span class=k>def</span> <span class=nf>add_pt_content_to_pubmed</span><span class=p>(</span><span class=n>row</span><span class=p>):</span>
    <span class=n>row</span><span class=p>[</span><span class=s1>&#39;question_pt&#39;</span><span class=p>]</span> <span class=o>=</span> <span class=n>translate2pt</span><span class=p>(</span><span class=n>row</span><span class=p>[</span><span class=s1>&#39;question&#39;</span><span class=p>])</span>
    <span class=n>row</span><span class=p>[</span><span class=s1>&#39;answer_pt&#39;</span><span class=p>]</span> <span class=o>=</span> <span class=n>translate2pt</span><span class=p>(</span><span class=n>row</span><span class=p>[</span><span class=s1>&#39;answer&#39;</span><span class=p>])</span>
    <span class=k>return</span> <span class=n>row</span>

<span class=kn>from</span> <span class=nn>datasets</span> <span class=kn>import</span> <span class=n>load_dataset</span>

<span class=c1># Load dataset from the hub</span>
<span class=n>dataset</span> <span class=o>=</span> <span class=n>load_dataset</span><span class=p>(</span><span class=s2>&quot;ngram/medchat-qa&quot;</span><span class=p>,</span> <span class=n>split</span><span class=o>=</span><span class=s2>&quot;train[:100%]&quot;</span><span class=p>)</span>
<span class=n>dataset</span> <span class=o>=</span> <span class=n>dataset</span><span class=o>.</span><span class=n>train_test_split</span><span class=p>(</span><span class=n>test_size</span><span class=o>=</span><span class=mf>0.3</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s1>&#39;Schema for dataset: </span><span class=si>{</span><span class=n>dataset</span><span class=si>}</span><span class=s1>&#39;</span><span class=p>)</span>
<span class=n>dataset_pt</span> <span class=o>=</span> <span class=n>dataset</span><span class=o>.</span><span class=n>map</span><span class=p>(</span><span class=n>add_pt_content_to_pubmed</span><span class=p>,</span> <span class=n>batched</span><span class=o>=</span><span class=kc>False</span><span class=p>)</span>

<span class=n>dataset_pt</span> <span class=o>=</span> <span class=n>dataset_pt</span><span class=o>.</span><span class=n>remove_columns</span><span class=p>([</span><span class=s2>&quot;question&quot;</span><span class=p>,</span> <span class=s2>&quot;answer&quot;</span><span class=p>])</span>
<span class=n>dataset_pt</span> <span class=o>=</span> <span class=n>dataset_pt</span><span class=o>.</span><span class=n>rename_column</span><span class=p>(</span><span class=s2>&quot;question_pt&quot;</span><span class=p>,</span> <span class=s2>&quot;question&quot;</span><span class=p>)</span>
<span class=n>dataset_pt</span> <span class=o>=</span> <span class=n>dataset_pt</span><span class=o>.</span><span class=n>rename_column</span><span class=p>(</span><span class=s2>&quot;answer_pt&quot;</span><span class=p>,</span> <span class=s2>&quot;answer&quot;</span><span class=p>)</span>

<span class=n>dataset_pt</span><span class=o>.</span><span class=n>save_to_disk</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;</span><span class=si>{</span><span class=n>training_input_base_path</span><span class=si>}</span><span class=s2>/pt/&quot;</span><span class=p>,</span> <span class=n>storage_options</span><span class=o>=</span><span class=n>storage_options</span><span class=p>)</span>
</code></pre></div> <div class=highlight><pre><span></span><code><span class=kn>from</span> <span class=nn>datasets</span> <span class=kn>import</span> <span class=n>load_dataset</span><span class=p>,</span> <span class=n>VerificationMode</span>
<span class=kn>from</span> <span class=nn>datasets</span> <span class=kn>import</span> <span class=n>load_from_disk</span>

<span class=kn>import</span> <span class=nn>aiobotocore.session</span>
<span class=n>s3_session</span> <span class=o>=</span> <span class=n>aiobotocore</span><span class=o>.</span><span class=n>session</span><span class=o>.</span><span class=n>AioSession</span><span class=p>()</span>
<span class=n>storage_options</span> <span class=o>=</span> <span class=p>{</span><span class=s2>&quot;session&quot;</span><span class=p>:</span> <span class=n>s3_session</span><span class=p>}</span>

<span class=c1># Convert dataset to OAI messages</span>
<span class=n>system_message</span> <span class=o>=</span> <span class=s2>&quot;&quot;&quot;Você é Llama, um especialista médico encarregado de fornecer as respostas mais precisas e sucintas a perguntas específicas com base em dados médicos detalhados. Concentre-se na precisão e na franqueza de suas respostas, garantindo que cada resposta seja factual, concisa e objetiva. Evite elaborações desnecessárias e priorize a precisão em vez de parecer confiante.&quot;&quot;&quot;</span>

<span class=k>def</span> <span class=nf>create_conversation</span><span class=p>(</span><span class=n>row</span><span class=p>):</span>
    <span class=n>row</span><span class=p>[</span><span class=s2>&quot;messages&quot;</span><span class=p>]</span> <span class=o>=</span> <span class=p>[{</span>
        <span class=s2>&quot;role&quot;</span><span class=p>:</span> <span class=s2>&quot;system&quot;</span><span class=p>,</span>
        <span class=s2>&quot;content&quot;</span><span class=p>:</span> <span class=n>system_message</span>
    <span class=p>},{</span>
        <span class=s2>&quot;role&quot;</span><span class=p>:</span> <span class=s2>&quot;user&quot;</span><span class=p>,</span>
        <span class=s2>&quot;content&quot;</span><span class=p>:</span> <span class=n>row</span><span class=p>[</span><span class=s2>&quot;question&quot;</span><span class=p>]</span>
    <span class=p>},{</span>
        <span class=s2>&quot;role&quot;</span><span class=p>:</span> <span class=s2>&quot;assistant&quot;</span><span class=p>,</span>
        <span class=s2>&quot;content&quot;</span><span class=p>:</span> <span class=n>row</span><span class=p>[</span><span class=s2>&quot;answer&quot;</span><span class=p>]</span>
    <span class=p>}]</span>
    <span class=k>return</span> <span class=n>row</span>


<span class=c1># Load dataset from the hub</span>
<span class=n>dataset</span> <span class=o>=</span> <span class=n>load_from_disk</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;s3://</span><span class=si>{</span><span class=n>sagemaker_session_bucket</span><span class=si>}</span><span class=s2>/datasets/ngram/medchat-qa/pt/&quot;</span><span class=p>,</span> <span class=n>storage_options</span><span class=o>=</span><span class=n>storage_options</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s1>&#39;Number of Rows: </span><span class=si>{</span><span class=n>dataset</span><span class=o>.</span><span class=n>num_rows</span><span class=si>}</span><span class=s1>&#39;</span><span class=p>)</span>

<span class=c1># dataset = dataset.train_test_split(test_size=0.3)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s1>&#39;Schema for dataset: </span><span class=si>{</span><span class=n>dataset</span><span class=si>}</span><span class=s1>&#39;</span><span class=p>)</span>

<span class=c1># Add system message to each conversation</span>
<span class=n>columns_to_remove</span> <span class=o>=</span> <span class=nb>list</span><span class=p>(</span><span class=n>dataset</span><span class=p>[</span><span class=s2>&quot;train&quot;</span><span class=p>]</span><span class=o>.</span><span class=n>features</span><span class=p>)</span>
<span class=n>dataset</span> <span class=o>=</span> <span class=n>dataset</span><span class=o>.</span><span class=n>map</span><span class=p>(</span><span class=n>create_conversation</span><span class=p>,</span> <span class=n>remove_columns</span><span class=o>=</span><span class=n>columns_to_remove</span><span class=p>,</span> <span class=n>batched</span><span class=o>=</span><span class=kc>False</span><span class=p>)</span>

<span class=n>dataset</span><span class=p>[</span><span class=s2>&quot;train&quot;</span><span class=p>]</span> <span class=o>=</span> <span class=n>dataset</span><span class=p>[</span><span class=s2>&quot;train&quot;</span><span class=p>]</span><span class=o>.</span><span class=n>filter</span><span class=p>(</span><span class=k>lambda</span> <span class=n>x</span><span class=p>:</span> <span class=nb>len</span><span class=p>(</span><span class=n>x</span><span class=p>[</span><span class=s2>&quot;messages&quot;</span><span class=p>][</span><span class=mi>1</span><span class=p>:])</span> <span class=o>%</span> <span class=mi>2</span> <span class=o>==</span> <span class=mi>0</span><span class=p>)</span>
<span class=n>dataset</span><span class=p>[</span><span class=s2>&quot;test&quot;</span><span class=p>]</span> <span class=o>=</span> <span class=n>dataset</span><span class=p>[</span><span class=s2>&quot;test&quot;</span><span class=p>]</span><span class=o>.</span><span class=n>filter</span><span class=p>(</span><span class=k>lambda</span> <span class=n>x</span><span class=p>:</span> <span class=nb>len</span><span class=p>(</span><span class=n>x</span><span class=p>[</span><span class=s2>&quot;messages&quot;</span><span class=p>][</span><span class=mi>1</span><span class=p>:])</span> <span class=o>%</span> <span class=mi>2</span> <span class=o>==</span> <span class=mi>0</span><span class=p>)</span>

<span class=c1># save datasets to s3</span>
<span class=n>dataset</span><span class=p>[</span><span class=s2>&quot;train&quot;</span><span class=p>]</span><span class=o>.</span><span class=n>to_json</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;</span><span class=si>{</span><span class=n>training_input_path</span><span class=si>}</span><span class=s2>/train_dataset.json&quot;</span><span class=p>,</span> <span class=n>orient</span><span class=o>=</span><span class=s2>&quot;records&quot;</span><span class=p>,</span> <span class=n>force_ascii</span><span class=o>=</span><span class=kc>False</span><span class=p>)</span>
<span class=n>dataset</span><span class=p>[</span><span class=s2>&quot;test&quot;</span><span class=p>]</span><span class=o>.</span><span class=n>to_json</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;</span><span class=si>{</span><span class=n>training_input_path</span><span class=si>}</span><span class=s2>/test_dataset.json&quot;</span><span class=p>,</span> <span class=n>orient</span><span class=o>=</span><span class=s2>&quot;records&quot;</span><span class=p>,</span> <span class=n>force_ascii</span><span class=o>=</span><span class=kc>False</span><span class=p>)</span>

<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Training data uploaded to:&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;</span><span class=si>{</span><span class=n>training_input_path</span><span class=si>}</span><span class=s2>/train_dataset.json&quot;</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;https://s3.console.aws.amazon.com/s3/buckets/</span><span class=si>{</span><span class=n>sess</span><span class=o>.</span><span class=n>default_bucket</span><span class=p>()</span><span class=si>}</span><span class=s2>/?region=</span><span class=si>{</span><span class=n>sess</span><span class=o>.</span><span class=n>boto_region_name</span><span class=si>}</span><span class=s2>&amp;prefix=</span><span class=si>{</span><span class=n>training_input_path</span><span class=o>.</span><span class=n>split</span><span class=p>(</span><span class=s1>&#39;/&#39;</span><span class=p>,</span><span class=w> </span><span class=mi>3</span><span class=p>)[</span><span class=o>-</span><span class=mi>1</span><span class=p>]</span><span class=si>}</span><span class=s2>/&quot;</span><span class=p>)</span>
</code></pre></div> <p>Hyperparameters for the Fine Tuning job.</p> <p>Below you will notice that the location of the downloaded English model is provided as input to model_id_path variable instead of the HuggingFace model id as in the English dataset fine tuning. The training script will load the model from the Training job local disk which is automatically downloaded from S3 bucket by SageMaker.</p> <div class=highlight><pre><span></span><code><span class=n>pt_hyperparameters</span> <span class=o>=</span> <span class=p>{</span>
  <span class=c1>### SCRIPT PARAMETERS ###</span>
  <span class=s1>&#39;dataset_path&#39;</span><span class=p>:</span> <span class=s1>&#39;/opt/ml/input/data/training/&#39;</span><span class=p>,</span>    <span class=c1># path where sagemaker will save training dataset</span>
  <span class=s1>&#39;model_id_path&#39;</span><span class=p>:</span> <span class=s1>&#39;/opt/ml/input/data/model/&#39;</span><span class=p>,</span>      <span class=c1># path where the safetensor model file is downloaded to</span>
  <span class=s1>&#39;max_seq_len&#39;</span><span class=p>:</span> <span class=mi>3072</span><span class=p>,</span>                               <span class=c1># max sequence length for model and packing of the dataset</span>
  <span class=s1>&#39;use_qlora&#39;</span><span class=p>:</span> <span class=kc>True</span><span class=p>,</span>                                 <span class=c1># use QLoRA model</span>
  <span class=c1>### TRAINING PARAMETERS ###</span>
  <span class=s1>&#39;num_train_epochs&#39;</span><span class=p>:</span> <span class=mi>1</span><span class=p>,</span>                             <span class=c1># number of training epochs</span>
  <span class=s1>&#39;per_device_train_batch_size&#39;</span><span class=p>:</span> <span class=mi>1</span><span class=p>,</span>                  <span class=c1># batch size per device during training</span>
  <span class=s1>&#39;per_device_eval_batch_size&#39;</span><span class=p>:</span> <span class=mi>1</span><span class=p>,</span>                   <span class=c1># batch size for evaluation    </span>
  <span class=s1>&#39;gradient_accumulation_steps&#39;</span><span class=p>:</span> <span class=mi>4</span><span class=p>,</span>                  <span class=c1># number of steps before performing a backward/update pass</span>
  <span class=s1>&#39;gradient_checkpointing&#39;</span><span class=p>:</span> <span class=kc>True</span><span class=p>,</span>                    <span class=c1># use gradient checkpointing to save memory</span>
  <span class=s1>&#39;optim&#39;</span><span class=p>:</span> <span class=s2>&quot;adamw_torch&quot;</span><span class=p>,</span>                            <span class=c1># use fused adamw optimizer</span>
  <span class=s1>&#39;logging_steps&#39;</span><span class=p>:</span> <span class=mi>10</span><span class=p>,</span>                               <span class=c1># log every 10 steps</span>
  <span class=s1>&#39;save_strategy&#39;</span><span class=p>:</span> <span class=s2>&quot;epoch&quot;</span><span class=p>,</span>                          <span class=c1># save checkpoint every epoch</span>
  <span class=s1>&#39;evaluation_strategy&#39;</span><span class=p>:</span> <span class=s2>&quot;epoch&quot;</span><span class=p>,</span>
  <span class=s1>&#39;learning_rate&#39;</span><span class=p>:</span> <span class=mf>0.0002</span><span class=p>,</span>                           <span class=c1># learning rate, based on QLoRA paper</span>
  <span class=s1>&#39;bf16&#39;</span><span class=p>:</span> <span class=n>use_bf16</span><span class=p>,</span>                                  <span class=c1># use bfloat16 precision</span>
  <span class=s1>&#39;tf32&#39;</span><span class=p>:</span> <span class=kc>True</span><span class=p>,</span>                                      <span class=c1># use tf32 precision</span>
  <span class=s1>&#39;max_grad_norm&#39;</span><span class=p>:</span> <span class=mf>0.3</span><span class=p>,</span>                              <span class=c1># max gradient norm based on QLoRA paper</span>
  <span class=s1>&#39;warmup_ratio&#39;</span><span class=p>:</span> <span class=mf>0.03</span><span class=p>,</span>                              <span class=c1># warmup ratio based on QLoRA paper</span>
  <span class=s1>&#39;lr_scheduler_type&#39;</span><span class=p>:</span> <span class=s2>&quot;constant&quot;</span><span class=p>,</span>                   <span class=c1># use constant learning rate scheduler</span>
  <span class=s1>&#39;report_to&#39;</span><span class=p>:</span> <span class=s2>&quot;tensorboard&quot;</span><span class=p>,</span>                        <span class=c1># report metrics to tensorboard</span>
  <span class=s1>&#39;output_dir&#39;</span><span class=p>:</span> <span class=s1>&#39;/tmp/tun&#39;</span><span class=p>,</span>                          <span class=c1># Temporary output directory for model checkpoints</span>
  <span class=s1>&#39;merge_adapters&#39;</span><span class=p>:</span> <span class=kc>True</span><span class=p>,</span>                            <span class=c1># merge LoRA adapters into model for easier deployment</span>
  <span class=s1>&#39;fsdp&#39;</span><span class=p>:</span> <span class=s1>&#39;&quot;full_shard auto_wrap offload&quot;&#39;</span><span class=p>,</span>
<span class=p>}</span>
</code></pre></div> <p>Below you will use the SageMaker Hugging Face model and estimator to Fine Tune the model using the Portguese Dataset. </p> <p>Kindly note that you will provide the S3 location of the English Language Fine Tuned model into the fit method. The S3 path is provided in the pt_data variable in the model attribute. SageMaker automatically downloads the files from the respective S3 bucket provided to the fit method of the estimator.</p> <div class=highlight><pre><span></span><code><span class=kn>from</span> <span class=nn>sagemaker.huggingface</span> <span class=kn>import</span> <span class=n>HuggingFace</span>
<span class=kn>from</span> <span class=nn>huggingface_hub</span> <span class=kn>import</span> <span class=n>HfFolder</span> 
<span class=kn>import</span> <span class=nn>time</span>

<span class=c1># define Training Job Name</span>
<span class=n>pt_job_name</span> <span class=o>=</span> <span class=sa>f</span><span class=s1>&#39;</span><span class=si>{</span><span class=n>model_id</span><span class=o>.</span><span class=n>replace</span><span class=p>(</span><span class=s2>&quot;/&quot;</span><span class=p>,</span><span class=w> </span><span class=s2>&quot;-&quot;</span><span class=p>)</span><span class=si>}</span><span class=s1>-</span><span class=si>{</span><span class=s2>&quot;bf16&quot;</span><span class=w> </span><span class=k>if</span><span class=w> </span><span class=n>use_bf16</span><span class=w> </span><span class=k>else</span><span class=w> </span><span class=s2>&quot;f32&quot;</span><span class=w> </span><span class=si>}</span><span class=s1>&#39;</span>

<span class=c1># create the Estimator</span>
<span class=n>pt_huggingface_estimator</span> <span class=o>=</span> <span class=n>HuggingFace</span><span class=p>(</span>
    <span class=n>entry_point</span>          <span class=o>=</span> <span class=s1>&#39;run_fsdp_qlora.py&#39;</span><span class=p>,</span>    <span class=c1># train script</span>
    <span class=n>source_dir</span>           <span class=o>=</span> <span class=s1>&#39;scripts/trl/&#39;</span><span class=p>,</span>      <span class=c1># directory which includes all the files needed for training</span>
    <span class=n>instance_type</span>        <span class=o>=</span> <span class=s1>&#39;ml.g5.24xlarge&#39;</span><span class=p>,</span>   <span class=c1># instances type used for the training job</span>
    <span class=n>instance_count</span>       <span class=o>=</span> <span class=mi>1</span><span class=p>,</span>                 <span class=c1># the number of instances used for training</span>
    <span class=n>max_run</span>              <span class=o>=</span> <span class=mi>2</span><span class=o>*</span><span class=mi>24</span><span class=o>*</span><span class=mi>60</span><span class=o>*</span><span class=mi>60</span><span class=p>,</span>        <span class=c1># maximum runtime in seconds (days * hours * minutes * seconds)</span>
    <span class=n>base_job_name</span>        <span class=o>=</span> <span class=n>pt_job_name</span><span class=p>,</span>          <span class=c1># the name of the training job</span>
    <span class=n>role</span>                 <span class=o>=</span> <span class=n>role</span><span class=p>,</span>              <span class=c1># Iam role used in training job to access AWS ressources, e.g. S3</span>
    <span class=n>volume_size</span>          <span class=o>=</span> <span class=mi>300</span><span class=p>,</span>               <span class=c1># the size of the EBS volume in GB</span>
    <span class=n>transformers_version</span> <span class=o>=</span> <span class=s1>&#39;4.36.0&#39;</span><span class=p>,</span>            <span class=c1># the transformers version used in the training job</span>
    <span class=n>pytorch_version</span>      <span class=o>=</span> <span class=s1>&#39;2.1.0&#39;</span><span class=p>,</span>             <span class=c1># the pytorch_version version used in the training job</span>
    <span class=n>py_version</span>           <span class=o>=</span> <span class=s1>&#39;py310&#39;</span><span class=p>,</span>           <span class=c1># the python version used in the training job</span>
    <span class=n>hyperparameters</span>      <span class=o>=</span>  <span class=n>pt_hyperparameters</span><span class=p>,</span>  <span class=c1># the hyperparameters passed to the training job</span>
    <span class=n>disable_output_compression</span> <span class=o>=</span> <span class=kc>True</span><span class=p>,</span>        <span class=c1># not compress output to save training time and cost</span>
    <span class=n>distribution</span><span class=o>=</span><span class=p>{</span><span class=s2>&quot;torch_distributed&quot;</span><span class=p>:</span> <span class=p>{</span><span class=s2>&quot;enabled&quot;</span><span class=p>:</span> <span class=kc>True</span><span class=p>}},</span>
    <span class=n>environment</span>          <span class=o>=</span> <span class=p>{</span>
        <span class=s2>&quot;HUGGINGFACE_HUB_CACHE&quot;</span><span class=p>:</span> <span class=s2>&quot;/tmp/.cache&quot;</span><span class=p>,</span> <span class=c1># set env variable to cache models in /tmp</span>
        <span class=s2>&quot;HF_TOKEN&quot;</span><span class=p>:</span> <span class=n>HfFolder</span><span class=o>.</span><span class=n>get_token</span><span class=p>(),</span>       <span class=c1># Retrieve HuggingFace Token to be used for downloading base models from</span>
        <span class=s2>&quot;ACCELERATE_USE_FSDP&quot;</span><span class=p>:</span><span class=s2>&quot;1&quot;</span><span class=p>,</span> 
        <span class=s2>&quot;FSDP_CPU_RAM_EFFICIENT_LOADING&quot;</span><span class=p>:</span><span class=s2>&quot;1&quot;</span>
    <span class=p>},</span>
    <span class=c1># enable_remote_debug=True</span>
<span class=p>)</span>

<span class=c1># define a data input dictonary with our uploaded s3 uris</span>
<span class=n>pt_data</span> <span class=o>=</span> <span class=p>{</span><span class=s1>&#39;training&#39;</span><span class=p>:</span> <span class=n>training_input_path</span><span class=p>,</span> 
        <span class=s1>&#39;model&#39;</span><span class=p>:</span> <span class=sa>f</span><span class=s1>&#39;</span><span class=si>{</span><span class=n>en_pubmed_model_s3_path</span><span class=si>}</span><span class=s1>&#39;</span><span class=p>}</span>

<span class=c1># starting the train job with our uploaded datasets as input</span>
<span class=n>pt_huggingface_estimator</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span><span class=n>pt_data</span><span class=p>,</span> <span class=n>wait</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</code></pre></div> <div class=highlight><pre><span></span><code><span class=n>pt_pubmed_model_s3_path</span> <span class=o>=</span> <span class=n>pt_huggingface_estimator</span><span class=o>.</span><span class=n>model_data</span><span class=p>[</span><span class=s2>&quot;S3DataSource&quot;</span><span class=p>][</span><span class=s2>&quot;S3Uri&quot;</span><span class=p>]</span>
<span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;PT PubMed Fine Tuned Model S3 Location: </span><span class=si>{</span><span class=n>pt_pubmed_model_s3_path</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</code></pre></div> <h3> Import the finetuned model into Bedrock: </h3> <p>Below works only after Bedrock Custom Model Import feature is Generally Available (GA)</p> <div class=highlight><pre><span></span><code><span class=kn>import</span> <span class=nn>boto3</span>
<span class=kn>import</span> <span class=nn>datetime</span>
<span class=nb>print</span><span class=p>(</span><span class=n>boto3</span><span class=o>.</span><span class=n>__version__</span><span class=p>)</span>
</code></pre></div> <div class=highlight><pre><span></span><code><span class=n>br_client</span> <span class=o>=</span> <span class=n>boto3</span><span class=o>.</span><span class=n>client</span><span class=p>(</span><span class=s1>&#39;bedrock&#39;</span><span class=p>,</span> <span class=n>region_name</span><span class=o>=</span><span class=s1>&#39;us-west-2&#39;</span><span class=p>)</span>
</code></pre></div> <div class=highlight><pre><span></span><code><span class=n>pt_model_nm</span> <span class=o>=</span> <span class=s2>&quot;Meta-Llama-3-8B-bf16-MedChatQA-PT&quot;</span>
<span class=n>pt_imp_jb_nm</span> <span class=o>=</span> <span class=sa>f</span><span class=s2>&quot;</span><span class=si>{</span><span class=n>pt_model_nm</span><span class=si>}</span><span class=s2>-</span><span class=si>{</span><span class=n>datetime</span><span class=o>.</span><span class=n>datetime</span><span class=o>.</span><span class=n>now</span><span class=p>()</span><span class=o>.</span><span class=n>strftime</span><span class=p>(</span><span class=s1>&#39;%Y%m</span><span class=si>%d</span><span class=s1>%M%H%S&#39;</span><span class=p>)</span><span class=si>}</span><span class=s2>&quot;</span>
<span class=n>role_arn</span> <span class=o>=</span> <span class=s2>&quot;&lt;&lt;bedrock_role_with_custom_model_import_policy&gt;&gt;&quot;</span>
<span class=n>pt_model_src</span> <span class=o>=</span> <span class=p>{</span><span class=s2>&quot;s3DataSource&quot;</span><span class=p>:</span> <span class=p>{</span><span class=s2>&quot;s3Uri&quot;</span><span class=p>:</span> <span class=sa>f</span><span class=s2>&quot;</span><span class=si>{</span><span class=n>pt_pubmed_model_s3_path</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>}}</span>

<span class=n>resp</span> <span class=o>=</span> <span class=n>br_client</span><span class=o>.</span><span class=n>create_model_import_job</span><span class=p>(</span><span class=n>jobName</span><span class=o>=</span><span class=n>pt_imp_jb_nm</span><span class=p>,</span>
                                  <span class=n>importedModelName</span><span class=o>=</span><span class=n>pt_model_nm</span><span class=p>,</span>
                                  <span class=n>roleArn</span><span class=o>=</span><span class=n>role_arn</span><span class=p>,</span>
                                  <span class=n>modelDataSource</span><span class=o>=</span><span class=n>pt_model_src</span><span class=p>)</span>
</code></pre></div> <div class=highlight><pre><span></span><code><span class=n>en_model_nm</span> <span class=o>=</span> <span class=s2>&quot;Meta-Llama-3-8B-bf16-MedChatQA-EN&quot;</span>
<span class=n>en_imp_jb_nm</span> <span class=o>=</span> <span class=sa>f</span><span class=s2>&quot;</span><span class=si>{</span><span class=n>en_model_nm</span><span class=si>}</span><span class=s2>-</span><span class=si>{</span><span class=n>datetime</span><span class=o>.</span><span class=n>datetime</span><span class=o>.</span><span class=n>now</span><span class=p>()</span><span class=o>.</span><span class=n>strftime</span><span class=p>(</span><span class=s1>&#39;%Y%m</span><span class=si>%d</span><span class=s1>%M%H%S&#39;</span><span class=p>)</span><span class=si>}</span><span class=s2>&quot;</span>
<span class=n>role_arn</span> <span class=o>=</span> <span class=s2>&quot;&lt;&lt;bedrock_role_with_custom_model_import_policy&gt;&gt;&quot;</span>
<span class=n>en_model_src</span> <span class=o>=</span> <span class=p>{</span><span class=s2>&quot;s3DataSource&quot;</span><span class=p>:</span> <span class=p>{</span><span class=s2>&quot;s3Uri&quot;</span><span class=p>:</span> <span class=sa>f</span><span class=s2>&quot;</span><span class=si>{</span><span class=n>en_pubmed_model_s3_path</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>}}</span>

<span class=n>resp</span> <span class=o>=</span> <span class=n>br_client</span><span class=o>.</span><span class=n>create_model_import_job</span><span class=p>(</span><span class=n>jobName</span><span class=o>=</span><span class=n>en_imp_jb_nm</span><span class=p>,</span>
                                  <span class=n>importedModelName</span><span class=o>=</span><span class=n>en_model_nm</span><span class=p>,</span>
                                  <span class=n>roleArn</span><span class=o>=</span><span class=n>role_arn</span><span class=p>,</span>
                                  <span class=n>modelDataSource</span><span class=o>=</span><span class=n>en_model_src</span><span class=p>)</span>
</code></pre></div> <h3> Invoke the imported model using Bedrock API's </h3> <div class=highlight><pre><span></span><code><span class=err>!</span><span class=n>pip</span> <span class=n>install</span> <span class=n>boto3</span> <span class=n>botocore</span> <span class=o>--</span><span class=n>upgrade</span> <span class=o>--</span><span class=n>quiet</span>
</code></pre></div> <div class=highlight><pre><span></span><code><span class=kn>import</span> <span class=nn>boto3</span>
<span class=kn>import</span> <span class=nn>json</span>
<span class=kn>from</span> <span class=nn>botocore.exceptions</span> <span class=kn>import</span> <span class=n>ClientError</span>
</code></pre></div> <div class=highlight><pre><span></span><code><span class=n>client</span> <span class=o>=</span> <span class=n>boto3</span><span class=o>.</span><span class=n>client</span><span class=p>(</span><span class=s2>&quot;bedrock-runtime&quot;</span><span class=p>,</span> <span class=n>region_name</span><span class=o>=</span><span class=s2>&quot;&lt;&lt;region-name&gt;&gt;&quot;</span><span class=p>)</span>

<span class=n>model_id</span> <span class=o>=</span> <span class=s2>&quot;&lt;&lt;bedrock-model-arn&gt;&gt;&quot;</span>
</code></pre></div> <div class=highlight><pre><span></span><code><span class=k>def</span> <span class=nf>call_invoke_model_and_print</span><span class=p>(</span><span class=n>native_request</span><span class=p>):</span>
    <span class=n>request</span> <span class=o>=</span> <span class=n>json</span><span class=o>.</span><span class=n>dumps</span><span class=p>(</span><span class=n>native_request</span><span class=p>)</span>

    <span class=k>try</span><span class=p>:</span>
        <span class=c1># Invoke the model with the request.</span>
        <span class=n>response</span> <span class=o>=</span> <span class=n>client</span><span class=o>.</span><span class=n>invoke_model</span><span class=p>(</span><span class=n>modelId</span><span class=o>=</span><span class=n>model_id</span><span class=p>,</span> <span class=n>body</span><span class=o>=</span><span class=n>request</span><span class=p>)</span>
        <span class=n>model_response</span> <span class=o>=</span> <span class=n>json</span><span class=o>.</span><span class=n>loads</span><span class=p>(</span><span class=n>response</span><span class=p>[</span><span class=s2>&quot;body&quot;</span><span class=p>]</span><span class=o>.</span><span class=n>read</span><span class=p>())</span>

        <span class=n>response_text</span> <span class=o>=</span> <span class=n>model_response</span><span class=p>[</span><span class=s2>&quot;outputs&quot;</span><span class=p>][</span><span class=mi>0</span><span class=p>][</span><span class=s2>&quot;text&quot;</span><span class=p>]</span>
        <span class=nb>print</span><span class=p>(</span><span class=n>response_text</span><span class=p>)</span>     
    <span class=k>except</span> <span class=p>(</span><span class=n>ClientError</span><span class=p>,</span> <span class=ne>Exception</span><span class=p>)</span> <span class=k>as</span> <span class=n>e</span><span class=p>:</span>
        <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;ERROR: Can&#39;t invoke &#39;</span><span class=si>{</span><span class=n>model_id</span><span class=si>}</span><span class=s2>&#39;. Reason: </span><span class=si>{</span><span class=n>e</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
        <span class=n>exit</span><span class=p>(</span><span class=mi>1</span><span class=p>)</span>
</code></pre></div> <div class=highlight><pre><span></span><code><span class=n>system_prompt</span> <span class=o>=</span> <span class=s2>&quot;&quot;&quot;[INST]You are a medical expert tasked with providing the most accurate and succinct answers to specific questions based on detailed medical data. Focus on precision and directness in your responses, ensuring that each answer is factual, concise, and to the point. Avoid unnecessary elaboration and prioritize accuracy over sounding confident. Here are some guidelines for your responses:</span>

<span class=s2>- Provide clear, direct answers without filler or extraneous details.</span>
<span class=s2>- Base your responses solely on the information available in the medical text provided.</span>
<span class=s2>- Ensure that your answers are straightforward and easy to understand, yet medically accurate.</span>
<span class=s2>- Avoid speculative or generalized statements that are not directly supported by the text.</span>

<span class=s2>Use these guidelines to formulate your answers to the questions presented [/INST]&quot;&quot;&quot;</span>

<span class=n>prompt</span> <span class=o>=</span> <span class=s2>&quot;&quot;&quot;What is the recommended treatment for metformin overdosage?&lt;|end_of_text|&gt;</span>

<span class=s2>A:</span>
<span class=s2>&quot;&quot;&quot;</span>
<span class=n>formatted_prompt</span> <span class=o>=</span> <span class=sa>f</span><span class=s2>&quot;</span><span class=si>{</span><span class=n>system_prompt</span><span class=si>}</span><span class=se>\n\n</span><span class=si>{</span><span class=n>prompt</span><span class=si>}</span><span class=s2>&quot;</span>

<span class=n>native_request</span> <span class=o>=</span> <span class=p>{</span>
    <span class=s2>&quot;prompt&quot;</span><span class=p>:</span> <span class=n>formatted_prompt</span><span class=p>,</span>
    <span class=s2>&quot;top_p&quot;</span><span class=p>:</span> <span class=mf>0.9</span><span class=p>,</span>
    <span class=s2>&quot;temperature&quot;</span><span class=p>:</span> <span class=mf>0.6</span><span class=p>,</span>    
<span class=p>}</span>

<span class=n>call_invoke_model_and_print</span><span class=p>(</span><span class=n>native_request</span><span class=p>)</span>
</code></pre></div> <div class=highlight><pre><span></span><code><span class=n>system_prompt</span> <span class=o>=</span> <span class=s2>&quot;&quot;&quot;[INST]You are a medical expert tasked with providing the most accurate and succinct answers to specific questions based on detailed medical data. Focus on precision and directness in your responses, ensuring that each answer is factual, concise, and to the point. Avoid unnecessary elaboration and prioritize accuracy over sounding confident. Here are some guidelines for your responses:</span>

<span class=s2>- Provide clear, direct answers without filler or extraneous details.</span>
<span class=s2>- Base your responses solely on the information available in the medical text provided.</span>
<span class=s2>- Ensure that your answers are straightforward and easy to understand, yet medically accurate.</span>
<span class=s2>- Avoid speculative or generalized statements that are not directly supported by the text.</span>

<span class=s2>Use these guidelines to formulate your answers to the questions presented [/INST]&quot;&quot;&quot;</span>

<span class=n>prompt</span> <span class=o>=</span> <span class=s2>&quot;&quot;&quot;What is the recommended treatment for metformin overdosage?&lt;|end_of_text|&gt;</span>

<span class=s2>A:</span>
<span class=s2>&quot;&quot;&quot;</span>
<span class=n>formatted_prompt</span> <span class=o>=</span> <span class=sa>f</span><span class=s2>&quot;</span><span class=si>{</span><span class=n>system_prompt</span><span class=si>}</span><span class=se>\n\n</span><span class=si>{</span><span class=n>prompt</span><span class=si>}</span><span class=s2>&quot;</span>

<span class=n>native_request</span> <span class=o>=</span> <span class=p>{</span>
    <span class=s2>&quot;prompt&quot;</span><span class=p>:</span> <span class=n>formatted_prompt</span><span class=p>,</span>
    <span class=s2>&quot;max_tokens&quot;</span><span class=p>:</span> <span class=mi>512</span><span class=p>,</span>
    <span class=s2>&quot;top_p&quot;</span><span class=p>:</span> <span class=mf>0.9</span><span class=p>,</span>
    <span class=s2>&quot;temperature&quot;</span><span class=p>:</span> <span class=mf>0.6</span><span class=p>,</span>
<span class=p>}</span>

<span class=c1># Convert the native request to JSON.</span>
<span class=n>request</span> <span class=o>=</span> <span class=n>json</span><span class=o>.</span><span class=n>dumps</span><span class=p>(</span><span class=n>native_request</span><span class=p>)</span>

<span class=k>try</span><span class=p>:</span>
    <span class=c1># Invoke the model with the request.</span>
    <span class=n>streaming_response</span> <span class=o>=</span> <span class=n>client</span><span class=o>.</span><span class=n>invoke_model_with_response_stream</span><span class=p>(</span>
        <span class=n>modelId</span><span class=o>=</span><span class=n>model_id</span><span class=p>,</span> <span class=n>body</span><span class=o>=</span><span class=n>request</span>
    <span class=p>)</span>

    <span class=c1># Extract and print the response text in real-time.</span>
    <span class=k>for</span> <span class=n>event</span> <span class=ow>in</span> <span class=n>streaming_response</span><span class=p>[</span><span class=s2>&quot;body&quot;</span><span class=p>]:</span>
        <span class=n>chunk</span> <span class=o>=</span> <span class=n>json</span><span class=o>.</span><span class=n>loads</span><span class=p>(</span><span class=n>event</span><span class=p>[</span><span class=s2>&quot;chunk&quot;</span><span class=p>][</span><span class=s2>&quot;bytes&quot;</span><span class=p>])</span>
        <span class=k>if</span> <span class=s2>&quot;outputs&quot;</span> <span class=ow>in</span> <span class=n>chunk</span><span class=p>:</span>
            <span class=nb>print</span><span class=p>(</span><span class=n>chunk</span><span class=p>[</span><span class=s2>&quot;outputs&quot;</span><span class=p>][</span><span class=mi>0</span><span class=p>]</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=s2>&quot;text&quot;</span><span class=p>),</span> <span class=n>end</span><span class=o>=</span><span class=s2>&quot;&quot;</span><span class=p>)</span>

<span class=k>except</span> <span class=p>(</span><span class=n>ClientError</span><span class=p>,</span> <span class=ne>Exception</span><span class=p>)</span> <span class=k>as</span> <span class=n>e</span><span class=p>:</span>
    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;ERROR: Can&#39;t invoke &#39;</span><span class=si>{</span><span class=n>model_id</span><span class=si>}</span><span class=s2>&#39;&#39;. Reason: </span><span class=si>{</span><span class=n>e</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
    <span class=n>exit</span><span class=p>(</span><span class=mi>1</span><span class=p>)</span>
</code></pre></div> <h3> Clean up the Bedrock Imported Models </h3> <div class=highlight><pre><span></span><code><span class=n>resp</span> <span class=o>=</span> <span class=n>br_client</span><span class=o>.</span><span class=n>delete_imported_model</span><span class=p>(</span><span class=n>modelIdentifier</span><span class=o>=</span><span class=n>model_id</span><span class=p>)</span>
</code></pre></div> <form class=md-feedback name=feedback hidden> <fieldset> <legend class=md-feedback__title> Was this page helpful? </legend> <div class=md-feedback__inner> <div class=md-feedback__list> <button class="md-feedback__icon md-icon" type=submit title="This page was helpful" data-md-value=1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M5 9v12H1V9zm4 12a2 2 0 0 1-2-2V9c0-.55.22-1.05.59-1.41L14.17 1l1.06 1.06c.27.27.44.64.44 1.05l-.03.32L14.69 8H21a2 2 0 0 1 2 2v2c0 .26-.05.5-.14.73l-3.02 7.05C19.54 20.5 18.83 21 18 21zm0-2h9.03L21 12v-2h-8.79l1.13-5.32L9 9.03z"/></svg> </button> <button class="md-feedback__icon md-icon" type=submit title="This page could be improved" data-md-value=0> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M19 15V3h4v12zM15 3a2 2 0 0 1 2 2v10c0 .55-.22 1.05-.59 1.41L9.83 23l-1.06-1.06c-.27-.27-.44-.64-.44-1.06l.03-.31.95-4.57H3a2 2 0 0 1-2-2v-2c0-.26.05-.5.14-.73l3.02-7.05C4.46 3.5 5.17 3 6 3zm0 2H5.97L3 12v2h8.78l-1.13 5.32L15 14.97z"/></svg> </button> </div> <div class=md-feedback__note> <div data-md-value=1 hidden> Thanks for your feedback! </div> <div data-md-value=0 hidden> Thanks for your feedback! Help us improve this page by <a href="https://github.com/aws-samples/amazon-bedrock-samples/issues/new?title=[Online Feedback]: Short-Summary-of-Issue&body=Page URL: /custom-models/import_models/llama-3/llama3-ngrammedqa-fine-tuning/" target=_blank rel=noopener>creating an issue</a>. </div> </div> </div> </fieldset> </form> </article> </div> <script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script> </div> </main> <footer class=md-footer> <div class="md-footer-meta md-typeset"> <div class="md-footer-meta__inner md-grid"> <div class=md-copyright> <div class=md-copyright__highlight> Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved. </div> </div> <div class=md-social> <a href=https://github.com/aws-samples/amazon-bedrock-samples/tree/main target=_blank rel=noopener title=github.com class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 496 512"><!-- Font Awesome Free 6.7.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8M97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg> </a> </div> </div> </div> </footer> </div> <div class=md-dialog data-md-component=dialog> <div class="md-dialog__inner md-typeset"></div> </div> <script id=__config type=application/json>{"base": "../../../..", "features": ["tags", "toc.integrate", "content.code.copy", "content.code.select", "content.code.annotate", "navigation.footer", "search.highlight", "search.suggest"], "search": "../../../../assets/javascripts/workers/search.6ce7567c.min.js", "tags": {"Compatibility": "compat"}, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script> <script src=../../../../assets/javascripts/bundle.88dd0f4e.min.js></script> <script src=../../../../javascript/feedback.js></script> </body> </html>