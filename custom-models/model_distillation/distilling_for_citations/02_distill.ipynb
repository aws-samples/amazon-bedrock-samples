{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cbf2edd1",
   "metadata": {},
   "source": [
    "# Amazon Bedrock Model Distillation for Citations - Advanced Implementation Guide\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "After completing this notebook, you will be able to:\n",
    "1. Implement advanced model distillation techniques using Amazon Bedrock's APIs\n",
    "2. Configure and optimize teacher-student model architectures for citation tasks\n",
    "3. Monitor and evaluate distillation performance metrics\n",
    "4. Deploy and manage production-grade distilled models\n",
    "5. Implement best practices for model efficiency and cost optimization\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Model distillation is an advanced knowledge transfer technique that enables the creation of efficient, production-ready models by distilling knowledge from larger foundation models into smaller, specialized ones. This notebook demonstrates enterprise-grade implementation of model distillation in Amazon Bedrock, focusing on citation generation use cases.\n",
    "\n",
    "### Technical Overview\n",
    "\n",
    "The distillation process involves several sophisticated components:\n",
    "\n",
    "1. Knowledge Transfer Architecture\n",
    "   - Teacher Model (Nova Premier): Provides high-fidelity outputs and knowledge representation\n",
    "   - Student Model (Nova Lite): Optimized for efficient inference while maintaining citation accuracy\n",
    "   - Distillation Layer: Manages the knowledge transfer and optimization process\n",
    "\n",
    "2. Training Pipeline\n",
    "   - Input Processing: JSONL format with specialized citation schema\n",
    "   - Teacher Inference: Generates high-quality responses with citation metadata\n",
    "   - Student Training: Optimizes for both performance and efficiency\n",
    "   - Validation: Ensures citation accuracy and response quality\n",
    "\n",
    "3. Production Deployment\n",
    "   - Provisioned Throughput Management\n",
    "   - Performance Monitoring\n",
    "   - Cost Optimization\n",
    "   - High Availability Configuration\n",
    "\n",
    "This implementation guide focuses on advanced techniques and production considerations for building robust, scalable citation systems using Amazon Bedrock's distillation capabilities.\n",
    "\n",
    "## Production Considerations\n",
    "\n",
    "When implementing model distillation in production:\n",
    "\n",
    "1. Performance Optimization\n",
    "   - Monitor and tune distillation hyperparameters\n",
    "   - Implement robust validation pipelines\n",
    "   - Optimize for both accuracy and latency\n",
    "\n",
    "2. Resource Management\n",
    "   - Scale provisioned throughput based on demand\n",
    "   - Implement cost monitoring and optimization\n",
    "   - Configure auto-scaling policies\n",
    "\n",
    "3. Quality Assurance\n",
    "   - Validate citation accuracy and relevance\n",
    "   - Monitor model drift and performance degradation\n",
    "   - Implement automated testing pipelines\n",
    "\n",
    "### Setup and Prerequisites\n",
    "\n",
    "Before proceeding, ensure you have:\n",
    "\n",
    "- An active AWS account with appropriate permissions\n",
    "- Amazon Bedrock access enabled in your preferred region\n",
    "- An S3 bucket for storing training data and output\n",
    "- Training data in JSONL format\n",
    "- Sufficient service quota to use Provisioned Throughput in Bedrock\n",
    "- An IAM role with the following permissions:\n",
    "\n",
    "IAM Policy:\n",
    "```json\n",
    "{\n",
    "    \"Version\": \"2012-10-17\",\n",
    "    \"Statement\": [\n",
    "        {\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Action\": [\n",
    "                \"s3:GetObject\",\n",
    "                \"s3:PutObject\",\n",
    "                \"s3:ListBucket\"\n",
    "            ],\n",
    "            \"Resource\": [\n",
    "                \"arn:aws:s3:::YOUR_DISTILLATION_OUTPUT_BUCKET\",\n",
    "                \"arn:aws:s3:::YOUR_DISTILLATION_OUTPUT_BUCKET/*\",\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Action\": [\n",
    "                \"bedrock:CreateModelCustomizationJob\",\n",
    "                \"bedrock:GetModelCustomizationJob\",\n",
    "                \"bedrock:ListModelCustomizationJobs\",\n",
    "                \"bedrock:StopModelCustomizationJob\"\n",
    "            ],\n",
    "            \"Resource\": \"arn:aws:bedrock:YOUR_REGION:YOUR_ACCOUNT_ID:model-customization-job/*\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "```\n",
    "\n",
    "Trust Relationship:\n",
    "```json\n",
    "{\n",
    "    \"Version\": \"2012-10-17\",\n",
    "    \"Statement\": [\n",
    "        {\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Principal\": {\n",
    "                \"Service\": [\n",
    "                    \"bedrock.amazonaws.com\"\n",
    "                ]\n",
    "            },\n",
    "            \"Action\": \"sts:AssumeRole\",\n",
    "            \"Condition\": {\n",
    "                \"StringEquals\": {\n",
    "                    \"aws:SourceAccount\": \"YOUR_ACCOUNT_ID\"\n",
    "                },\n",
    "                \"ArnLike\": {\n",
    "                    \"aws:SourceArn\": \"arn:aws:bedrock:YOUR_REGION:YOUR_ACCOUNT_ID:model-customization-job/*\"\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "```\n",
    "\n",
    "#### Dataset:\n",
    "For this implementation, we'll use the `Uber10K dataset`, which provides a diverse set of citation examples for model training.\n",
    "\n",
    "First, let's set up our environment and import required libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9296e2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# upgrade boto3 \n",
    "%pip install --upgrade pip --quiet\n",
    "%pip install boto3 --upgrade --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063248b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# restart kernel\n",
    "from IPython.core.display import HTML\n",
    "HTML(\"<script>Jupyter.notebook.kernel.restart()</script>\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b031e3",
   "metadata": {},
   "source": [
    "# Model Selection and Configuration\n",
    "\n",
    "Choosing the right teacher and student models is crucial for successful distillation. Consider these key factors:\n",
    "\n",
    "1. Performance targets\n",
    "   - Citation accuracy and relevance metrics\n",
    "   - Response quality and coherence\n",
    "   - Context understanding and utilization\n",
    "\n",
    "2. Latency requirements\n",
    "   - Maximum acceptable inference time\n",
    "   - Throughput needs (requests per second)\n",
    "   - Response time consistency requirements\n",
    "\n",
    "3. Total Cost of Ownership (TCO)\n",
    "   - Model hosting costs\n",
    "   - Inference costs per request\n",
    "   - Training and maintenance costs\n",
    "\n",
    "In this implementation, we're using:\n",
    "- Teacher: Amazon Nova Premier (high accuracy, larger model)\n",
    "  - Optimized for high-quality citation generation\n",
    "  - Strong context understanding capabilities\n",
    "  - Robust metadata handling\n",
    "\n",
    "- Student: Amazon Nova Lite (faster inference, smaller footprint)\n",
    "  - Tuned for efficient citation processing\n",
    "  - Optimized for production deployment\n",
    "  - Balanced performance-cost ratio\n",
    "\n",
    "For production deployments, conduct thorough benchmarking across multiple model combinations. See the [Amazon Bedrock Model Selection Guide](https://docs.aws.amazon.com/bedrock/latest/userguide/model-selection.html) for detailed guidance.\n",
    "\n",
    "**Note**: Ensure you're operating in a [supporting region](https://docs.aws.amazon.com/bedrock/latest/userguide/regions.html) for your chosen models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc786809",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import sys\n",
    "import os\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "sys.path.append(parent_dir)\n",
    "\n",
    "import boto3\n",
    "from datetime import datetime\n",
    "from botocore.exceptions import ClientError\n",
    "from utils import create_s3_bucket, upload_training_data_to_s3, delete_s3_bucket_and_contents, \\\n",
    "create_model_distillation_role_and_permissions, delete_role_and_attached_policies, delete_distillation_buckets\n",
    "\n",
    "# Create Bedrock client\n",
    "bedrock_client = boto3.client(service_name=\"bedrock\",region_name='us-east-1')\n",
    "\n",
    "# Create runtime client for inference\n",
    "bedrock_runtime = boto3.client(service_name='bedrock-runtime',region_name='us-east-1')\n",
    "\n",
    "# Region and accountID\n",
    "session = boto3.session.Session(region_name='us-east-1')\n",
    "region =  'us-east-1' # session.region_name\n",
    "sts_client = session.client(service_name='sts',region_name='us-east-1')\n",
    "account_id = sts_client.get_caller_identity()['Account']\n",
    "\n",
    "# define bucket you want to create and upload the dataset to:\n",
    "BUCKET_NAME= '<BUCKET_NAME>' # Replace by your bucket name\n",
    "DATA_PREFIX = 'citations_distillation' # Replace by your defined prefix\n",
    "\n",
    "# configure teacher nd student model\n",
    "teacher_model = \"us.amazon.nova-premier-v1:0\"\n",
    "student_model = \"amazon.nova-lite-v1:0:300k\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "874e9a9c",
   "metadata": {},
   "source": [
    "# Prepare Dataset for Model Distillation\n",
    "\n",
    "The quality of your training data is crucial for successful model distillation. Let's examine the required format and best practices for data preparation.\n",
    "\n",
    "### Model Distillation Input Schema\n",
    "\n",
    "Training data must follow the Bedrock conversation schema in JSONL format. Each line represents a complete training example:\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"schemaVersion\": \"bedrock-conversation-2024\",\n",
    "    \"system\": [\n",
    "        {\n",
    "            \"text\": <Your-System-Prompt>\n",
    "        }\n",
    "    ],\n",
    "    \"messages\": [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"text\": <Your-Prompt-And-OR-Context>\n",
    "                }\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"text\": <Your-Ground-Truth-Response>\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "```\n",
    "\n",
    "### Data Quality Requirements\n",
    "\n",
    "1. Schema Compliance\n",
    "   - Valid JSON format per line\n",
    "   - Required schemaVersion field\n",
    "   - Complete message structure\n",
    "\n",
    "2. Content Quality\n",
    "   - Diverse citation examples\n",
    "   - Accurate ground truth responses\n",
    "   - Proper citation metadata\n",
    "\n",
    "3. Technical Validation\n",
    "   - UTF-8 encoding\n",
    "   - No malformed JSON\n",
    "   - Consistent formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10bea0b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate unique names for the job and model\n",
    "distillation_dataset = 'distillation_data.jsonl'\n",
    "current_dt = datetime.now().strftime('%Y-%m-%d-%H-%M-%S')\n",
    "job_name = f\"distill-citations-{current_dt}\"\n",
    "model_name = f\"distilled-citations-{current_dt}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce95f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Configure models and IAM role\n",
    "role_name, role_arn = create_model_distillation_role_and_permissions(bucket_name=BUCKET_NAME, account_id=account_id)\n",
    "\n",
    "# creating training data bucket\n",
    "create_s3_bucket(bucket_name=BUCKET_NAME)\n",
    "\n",
    "# Specify S3 locations\n",
    "training_data_s3_uri = upload_training_data_to_s3(BUCKET_NAME, distillation_dataset, prefix=DATA_PREFIX)\n",
    "output_path = f\"s3://{BUCKET_NAME}/{DATA_PREFIX}/outputs/\"\n",
    "\n",
    "# Set maximum response length\n",
    "max_response_length = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd8eebe",
   "metadata": {},
   "source": [
    "# Starting the Distillation Job\n",
    "\n",
    "With our environment configured and data prepared, we'll initiate the distillation process. This section covers:\n",
    "\n",
    "1. Job Configuration\n",
    "   - Model selection and parameters\n",
    "   - Resource allocation\n",
    "   - Output settings\n",
    "\n",
    "2. Performance Optimization\n",
    "   - Response length tuning\n",
    "   - Batch size configuration\n",
    "   - Resource utilization\n",
    "\n",
    "3. Monitoring Setup\n",
    "   - Metrics configuration\n",
    "   - Logging settings\n",
    "   - Alert thresholds\n",
    "\n",
    "We'll use the `create_model_customization_job` API with production-optimized settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ea0394",
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to add wait to let the role be persisted here\n",
    "response = bedrock_client.create_model_customization_job(\n",
    "    jobName=job_name,\n",
    "    customModelName=model_name,\n",
    "    roleArn=role_arn,\n",
    "    baseModelIdentifier=student_model,\n",
    "    customizationType=\"DISTILLATION\",\n",
    "    trainingDataConfig={\n",
    "        \"s3Uri\": training_data_s3_uri\n",
    "    },\n",
    "    outputDataConfig={\n",
    "        \"s3Uri\": output_path\n",
    "    },\n",
    "    customizationConfig={\n",
    "        \"distillationConfig\": {\n",
    "            \"teacherModelConfig\": {\n",
    "                \"teacherModelIdentifier\": teacher_model,\n",
    "                \"maxResponseLengthForInference\": max_response_length \n",
    "            }\n",
    "        }\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63b6d0c8",
   "metadata": {},
   "source": [
    "# Monitoring the Distillation Job\n",
    "\n",
    "Effective monitoring is crucial for production-grade model distillation. The process involves several phases:\n",
    "\n",
    "1. Data Processing Phase\n",
    "   - Input validation and preprocessing\n",
    "   - Schema compliance checking\n",
    "   - Data quality metrics\n",
    "\n",
    "2. Teacher Model Phase\n",
    "   - Response generation monitoring\n",
    "   - Quality metrics tracking\n",
    "   - Error handling and recovery\n",
    "\n",
    "3. Student Training Phase\n",
    "   - Loss metrics monitoring\n",
    "   - Performance optimization\n",
    "   - Resource utilization tracking\n",
    "\n",
    "### Key Metrics to Monitor\n",
    "\n",
    "1. Quality Metrics\n",
    "   - Citation accuracy\n",
    "   - Response relevance\n",
    "   - Context utilization\n",
    "\n",
    "2. Performance Metrics\n",
    "   - Training loss\n",
    "   - Validation scores\n",
    "   - Inference latency\n",
    "\n",
    "3. Resource Metrics\n",
    "   - GPU utilization\n",
    "   - Memory usage\n",
    "   - Network throughput\n",
    "\n",
    "Monitor the job status using `get_model_customization_job` and track detailed metrics in CloudWatch. See [Model Customization Monitoring](https://docs.aws.amazon.com/bedrock/latest/userguide/monitoring-customization.html) for comprehensive monitoring guidance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "811dd77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Record the distillation job arn\n",
    "job_arn = response['jobArn']\n",
    "print(\"job arn\", job_arn)\n",
    "\n",
    "# print job status\n",
    "job_status = bedrock_client.get_model_customization_job(jobIdentifier=job_arn)[\"status\"]\n",
    "print(job_status)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0da8a8e",
   "metadata": {},
   "source": [
    "# Deploying the Distilled Model\n",
    "\n",
    "Production deployment requires careful consideration of several factors:\n",
    "\n",
    "1. Infrastructure Configuration\n",
    "   - Provisioned Throughput (PT) sizing\n",
    "   - High availability setup\n",
    "   - Auto-scaling policies\n",
    "\n",
    "2. Performance Optimization\n",
    "   - Response caching strategies\n",
    "   - Load balancing configuration\n",
    "   - Request routing optimization\n",
    "\n",
    "3. Monitoring and Management\n",
    "   - CloudWatch metrics integration\n",
    "   - Alert configuration\n",
    "   - Performance dashboards\n",
    "\n",
    "4. Cost Management\n",
    "   - Resource utilization tracking\n",
    "   - Cost allocation monitoring\n",
    "   - Budget alerts\n",
    "\n",
    "For detailed deployment guidance, see [Provisioned Throughput](https://docs.aws.amazon.com/bedrock/latest/userguide/provisioned-throughput.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a050d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deploy the distilled model\n",
    "custom_model_id = bedrock_client.get_model_customization_job(jobIdentifier=job_arn)['outputModelArn']\n",
    "distilled_model_name = model_name\n",
    "\n",
    "provisioned_model_id = bedrock_client.create_provisioned_model_throughput(\n",
    "    modelUnits=1,\n",
    "    provisionedModelName=distilled_model_name,\n",
    "    # commitmentDuration # ommitted for no-commit\n",
    "    modelId=custom_model_id \n",
    ")['provisionedModelArn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ad1681",
   "metadata": {},
   "outputs": [],
   "source": [
    "provisioned_model_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca969f2e",
   "metadata": {},
   "source": [
    "Store the provisioned model endpoint ARN for subsequent inference operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6038780a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%store provisioned_model_id\n",
    "%store custom_model_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d7d80f5",
   "metadata": {},
   "source": [
    "## Configure Production Inference Endpoint\n",
    "\n",
    "The Provisioned Throughput endpoint provides dedicated capacity for consistent performance in production environments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c705bac",
   "metadata": {},
   "source": [
    "# Resource Management\n",
    "\n",
    "Proper cleanup of resources is essential for cost management. Use the following code to remove created resources when they're no longer needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0879a0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # delete bucket and dataset\n",
    "# delete_distillation_buckets(bucket_name)\n",
    "\n",
    "# delete role and its policy:\n",
    "# delete_role_and_attached_policies(role_name=role_name)\n",
    "\n",
    "# delete provisioned throughput:\n",
    "# response = bedrock_client.delete_provisioned_model_throughput(provisionedModelId=provisioned_model_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb8a025",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "This notebook has demonstrated advanced implementation techniques for model distillation in Amazon Bedrock, with a focus on citation generation use cases. \n",
    "\n",
    "## Next Steps\n",
    "\n",
    "In the next notebook ([03_batch_inference.ipynb](03_batch_inference.ipynb)), we'll explore:\n",
    "1. Implementing batch inference with the distilled model\n",
    "2. Evaluating citation accuracy and performance metrics\n",
    "3. Optimizing throughput and latency\n",
    "4. Monitoring production workloads\n",
    "\n",
    "For additional resources:\n",
    "- [Amazon Bedrock Model Distillation Documentation](https://docs.aws.amazon.com/bedrock/latest/userguide/model-distillation.html)\n",
    "- [Best Practices for Production Deployments](https://docs.aws.amazon.com/bedrock/latest/userguide/best-practices.html)\n",
    "- [Advanced Monitoring and Optimization](https://docs.aws.amazon.com/bedrock/latest/userguide/monitoring-customization.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef1bf4b",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "distilling_for_citations-ex_cldZ-",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
