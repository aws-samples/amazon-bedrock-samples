{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c44cd1bc",
   "metadata": {},
   "source": [
    "# Reinforcement Fine-Tuning Amazon Nova 2.0 Lite with FinQA\n",
    "\n",
    "This notebook walks through training an Amazon Nova model using Reinforcement Fine-Tuning (RFT) on the [FinQA](https://huggingface.co/datasets/ibm-research/finqa) FinQA dataset.\n",
    "\n",
    "## What's RFT?\n",
    "\n",
    "Traditional fine-tuning shows a model examples and says \"produce outputs like this.\" RFT takes a different approach: it lets the model generate its own responses, then uses a reward signal to reinforce good outputs and discourage bad ones. Think of it like training with a coach who gives feedback rather than just copying from a textbook.\n",
    "\n",
    "For math problems, this works particularly well because we can automatically verify if an answer is correct—no human labeling needed.\n",
    "\n",
    "## What's FinQA?\n",
    "\n",
    "[FinQA](https://github.com/czyssrs/FinQA) is a dataset of 8,281 question-answer pairs derived from 2,789 earnings reports of S&P 500 companies. Each example contains:\n",
    "\n",
    "- **Textual context**: Paragraphs from financial reports describing business performance\n",
    "- **Structured data**: Tables with financial metrics (revenue, expenses, ratios, etc.)\n",
    "- **Multi-step reasoning questions**: Questions requiring numerical calculations across both text and tables\n",
    "\n",
    "Unlike simple QA datasets, FinQA requires models to:\n",
    "1. Locate relevant numbers across text and tables\n",
    "2. Determine the correct mathematical operations (addition, subtraction, division, percentage change)\n",
    "3. Execute multi-step calculations to arrive at the final answer\n",
    "\n",
    "This makes it an ideal benchmark for testing financial reasoning capabilities—and a great candidate for RFT, since answers can be automatically verified.\n",
    "\n",
    "\n",
    "\n",
    "> *Example problem:*\n",
    "\n",
    "> **Context:** The following table shows the breakdown of net revenues by segment.\n",
    ">\n",
    "> | $ in millions | 2018 | 2017 | 2016 |\n",
    "> |---------------|------|------|------|\n",
    "> | Investment Banking | 7862 | 7371 | 6273 |\n",
    "> | Institutional Client Services | 13482 | 11802 | 14342 |\n",
    ">\n",
    "> *What is the percentage change in investment banking revenue from 2017 to 2018?*\n",
    ">\n",
    "> **Answer:** 6.66%\n",
    "\n",
    "## What we'll build\n",
    "\n",
    "1. Prepare FinQA data in the format Bedrock RFT expects\n",
    "2. Deploy a Lambda function that scores model responses (correct answer = reward)\n",
    "3. Kick off an RFT training job on Amazon Bedrock\n",
    "4. Monitor the job until completion\n",
    "\n",
    "By the end, you'll have a Nova model that's better at step-by-step math reasoning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f47d4ebb",
   "metadata": {},
   "source": [
    "## Prerequisites: SageMaker Role Permissions\n",
    "\n",
    "**NOTE:** If you are running this notebook using an AWS Profile with Admin you can skip this cell...\n",
    "\n",
    "....otherwise this Jupyter notebook requires your SageMaker execution role to have these IAM permissions:\n",
    "\n",
    "| Service | Actions | Resources | Why |\n",
    "|---------|---------|-----------|-----|\n",
    "| **S3** | `PutObject`, `GetObject`, `ListBucket`, `DeleteObject` | `arn:aws:s3:::YOUR-BUCKET/*` and `arn:aws:s3:::YOUR-BUCKET` | Upload/download training data |\n",
    "| **IAM** | `CreateRole`, `GetRole`, `AttachRolePolicy`, `PutRolePolicy`, **`PassRole`** | `arn:aws:iam::ACCOUNT:role/FINQA-Lambda-Role`, `arn:aws:iam::ACCOUNT:role/BedrockRFTRole` | Create Lambda & Bedrock roles |\n",
    "| **Lambda** | `CreateFunction`, `GetFunction`, `UpdateFunctionCode`, `InvokeFunction` | `arn:aws:lambda:REGION:ACCOUNT:function:finqa-reward-function` | Deploy reward function |\n",
    "| **Bedrock** | `CreateModelCustomizationJob`, `GetModelCustomizationJob` | `*` | Start/monitor training |\n",
    "| **STS** | `GetCallerIdentity` | `*` | Get account info |\n",
    "\n",
    "### To Add These Permissions:\n",
    "\n",
    "1. Go to [IAM Console](https://console.aws.amazon.com/iam) (with Admin access) → Roles → Your SageMaker role\n",
    "2. **Add permissions** → **Create inline policy** → **JSON** tab\n",
    "\n",
    "**Critical**: Ensure `iam:PassRole` is included - this allows Bedrock to assume the training role.\n",
    "\n",
    "If you get `AccessDenied` errors while running the notebook, you're missing one of these permissions.\n",
    "\n",
    "**Once you've updated your permissions, ensure you restart your notebook kernel to ensure the changes are propagated**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7a030f8",
   "metadata": {},
   "source": [
    "---\n",
    "## 0. Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ebc3cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -qU boto3 botocore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09b29dab",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Configuration & Data Prep\n",
    "\n",
    "First, set your AWS region, S3 bucket, and profile. Then we'll pull FinQA from GitHub, format it for Bedrock RFT, and upload to S3.\n",
    "\n",
    "The key formatting requirement: each training example needs a `prompt` and metadata containing the `ground_truth` answer that our reward function will check against."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e345ded2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"../..\")\n",
    "\n",
    "import boto3\n",
    "import json\n",
    "import time\n",
    "import os\n",
    "import random\n",
    "import urllib.request\n",
    "\n",
    "from helpers import (\n",
    "    create_lambda_deployment_package,\n",
    "    cleanup_lambda_deployment_package\n",
    ")\n",
    "\n",
    "# ============== UPDATE THESE VALUES ==============\n",
    "AWS_REGION = \"us-east-1\"\n",
    "S3_BUCKET = \"your-bucket-name\"\n",
    "AWS_PROFILE = None  # Set to your profile name, or None for default credentials\n",
    "# =================================================\n",
    "\n",
    "# Create session\n",
    "session = boto3.Session(profile_name=AWS_PROFILE, region_name=AWS_REGION) if AWS_PROFILE else boto3.Session(region_name=AWS_REGION)\n",
    "AWS_ACCOUNT_ID = session.client('sts').get_caller_identity()['Account']\n",
    "\n",
    "# Dataset configuration\n",
    "DATASET_NAME = \"finqa\"\n",
    "FINQA_BASE_URL = \"https://raw.githubusercontent.com/czyssrs/FinQA/main/dataset\"\n",
    "TRAIN_SAMPLES = 6251  # Number of samples from train.json (entire dataset)\n",
    "VAL_SAMPLES = 883     # Number of samples from dev.json\n",
    "TEST_SAMPLES = 1147    # Number of samples from test.json\n",
    "LOCAL_DATA_DIR = \"../../tmp-data\"\n",
    "\n",
    "assert S3_BUCKET != \"your-bucket-name\", \"Please update S3_BUCKET with your own bucket name\"\n",
    "\n",
    "# S3 paths\n",
    "S3_TRAINING_DATA = f\"s3://{S3_BUCKET}/rft-data/datasets/{DATASET_NAME}/train.jsonl\"\n",
    "S3_VALIDATION_DATA = f\"s3://{S3_BUCKET}/rft-data/datasets/{DATASET_NAME}/val.jsonl\"\n",
    "S3_OUTPUT_PATH = f\"s3://{S3_BUCKET}/rft-output/\"\n",
    "\n",
    "# Resource names\n",
    "LAMBDA_FUNCTION_NAME = f\"{DATASET_NAME}-reward-function\"\n",
    "LAMBDA_ROLE_NAME = f\"{DATASET_NAME.upper()}-Lambda-Role\"\n",
    "BEDROCK_ROLE_NAME = \"BedrockRFTRole\"\n",
    "REWARD_FUNCTION_FILE = f\"../../reward-functions/{DATASET_NAME}_rew_func.py\"\n",
    "REWARD_FUNCTION_MODULE = f\"{DATASET_NAME}_rew_func\"\n",
    "\n",
    "# Model configuration\n",
    "BASE_MODEL_ID = f\"arn:aws:bedrock:{AWS_REGION}::foundation-model/amazon.nova-2-lite-v1:0:256k\"\n",
    "CUSTOM_MODEL_NAME = f\"{DATASET_NAME}-nova-lite-rft-{int(time.time())}\"\n",
    "JOB_NAME = f\"{DATASET_NAME}-rft-job-{int(time.time())}\"\n",
    "\n",
    "# Initialize AWS clients\n",
    "s3_client = session.client('s3')\n",
    "bedrock_client = session.client('bedrock')\n",
    "lambda_client = session.client('lambda')\n",
    "iam_client = session.client('iam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa5f4f8-b8b7-45b0-b2d3-469d29f093ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Preprocess FinQA ---\n",
    "def preprocess_finqa(base_url, output_dir, train_samples=256, val_samples=32, test_samples=32):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    def download_json(filename):\n",
    "        url = f\"{base_url}/{filename}\"\n",
    "        print(f\"Downloading {url}...\")\n",
    "        with urllib.request.urlopen(url) as response:\n",
    "            return json.loads(response.read().decode())\n",
    "\n",
    "    def format_table(table):\n",
    "        if not table:\n",
    "            return \"\"\n",
    "        return \"\\n\".join(\" | \".join(str(cell) for cell in row) for row in table)\n",
    "\n",
    "    def format_row(item, idx, split):\n",
    "        qa = item.get(\"qa\", {})\n",
    "        question = qa.get(\"question\", \"\")\n",
    "        answer = str(qa.get(\"exe_ans\", qa.get(\"answer\", \"\")))\n",
    "\n",
    "        pre_text = \" \".join(item.get(\"pre_text\", []))\n",
    "        post_text = \" \".join(item.get(\"post_text\", []))\n",
    "        table_str = format_table(item.get(\"table\", []))\n",
    "\n",
    "        context_parts = []\n",
    "        if pre_text:\n",
    "            context_parts.append(f\"Context:\\n{pre_text}\")\n",
    "        if table_str:\n",
    "            context_parts.append(f\"\\nTable:\\n{table_str}\")\n",
    "        if post_text:\n",
    "            context_parts.append(f\"\\n{post_text}\")\n",
    "        context = \"\\n\".join(context_parts)\n",
    "\n",
    "        user_content = f\"\"\"{context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Solve this step by step. Show your reasoning, then provide your final answer in the format: ANSWER: <your answer>\"\"\"\n",
    "\n",
    "        return {\n",
    "            \"messages\": [\n",
    "                {\"role\": \"system\", \"content\": \"You are a financial analyst who answers questions about financial data and tables. Provide step-by-step reasoning and calculations.\"},\n",
    "                {\"role\": \"user\", \"content\": user_content}\n",
    "            ],\n",
    "            \"reference_answer\": {\"answer\": answer},\n",
    "            \"task_id\": f\"finqa_{split}_{idx}\",\n",
    "            \"domain\": \"finance\",\n",
    "            \"data_source\": \"finqa\",\n",
    "            \"original_question\": question,\n",
    "            \"original_program\": qa.get(\"program\", \"\")\n",
    "        }\n",
    "\n",
    "    def write_split(data, num_samples, filename, split_name):\n",
    "        random.seed(42)\n",
    "        samples = random.sample(data, min(num_samples, len(data)))\n",
    "        with open(f\"{output_dir}/{filename}\", \"w\") as f:\n",
    "            for i, item in enumerate(samples):\n",
    "                f.write(json.dumps(format_row(item, i, split_name)) + \"\\n\")\n",
    "        print(f\"✓ Created {output_dir}/{filename} ({len(samples)} samples)\")\n",
    "        return len(samples)\n",
    "\n",
    "    train_data = download_json(\"train.json\")\n",
    "    dev_data = download_json(\"dev.json\")\n",
    "    test_data = download_json(\"test.json\")\n",
    "\n",
    "    train_count = write_split(train_data, train_samples, \"train.jsonl\", \"train\")\n",
    "    val_count = write_split(dev_data, val_samples, \"val.jsonl\", \"val\")\n",
    "    test_count = write_split(test_data, test_samples, \"test.jsonl\", \"test\")\n",
    "\n",
    "    return train_count, val_count, test_count\n",
    "\n",
    "print(\"Preprocessing FinQA dataset...\")\n",
    "train_size, val_size, test_size = preprocess_finqa(FINQA_BASE_URL, LOCAL_DATA_DIR, TRAIN_SAMPLES, VAL_SAMPLES, TEST_SAMPLES)\n",
    "\n",
    "print(\"\\nUploading to S3...\")\n",
    "for local_file, s3_key in [\n",
    "    (\"train.jsonl\", f\"rft-data/datasets/{DATASET_NAME}/train.jsonl\"),\n",
    "    (\"val.jsonl\", f\"rft-data/datasets/{DATASET_NAME}/val.jsonl\"),\n",
    "    (\"test.jsonl\", f\"rft-data/datasets/{DATASET_NAME}/test.jsonl\")\n",
    "]:\n",
    "    s3_client.upload_file(f\"{LOCAL_DATA_DIR}/{local_file}\", S3_BUCKET, s3_key)\n",
    "    print(f\"✓ Uploaded {local_file}\")\n",
    "\n",
    "print(f\"\\n✓ Ready | {train_size} train / {val_size} val / {test_size} test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234274f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up temporary local data\n",
    "import shutil\n",
    "\n",
    "print(\"\\nCleaning up temporary files...\")\n",
    "if os.path.exists(LOCAL_DATA_DIR):\n",
    "    shutil.rmtree(LOCAL_DATA_DIR)\n",
    "    print(f\"✓ Removed {LOCAL_DATA_DIR}\")\n",
    "else:\n",
    "    print(f\"✓ No temporary files to clean\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af8412e9",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Deploy the Reward Function\n",
    "\n",
    "The reward function is the \"coach\" in our RFT setup. During training, Bedrock generates candidate responses and sends them to this Lambda. The Lambda extracts the model's answer, compares it to the ground truth, and returns a score (1.0 for correct, 0.0 for wrong).\n",
    "\n",
    "We also create the IAM roles that Bedrock and Lambda need to do their jobs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49641cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Lambda execution role\n",
    "print(\"Creating Lambda execution role...\")\n",
    "\n",
    "lambda_trust_policy = {\n",
    "    \"Version\": \"2012-10-17\",\n",
    "    \"Statement\": [{\"Effect\": \"Allow\", \"Principal\": {\"Service\": \"lambda.amazonaws.com\"}, \"Action\": \"sts:AssumeRole\"}]\n",
    "}\n",
    "\n",
    "try:\n",
    "    response = iam_client.create_role(\n",
    "        RoleName=LAMBDA_ROLE_NAME,\n",
    "        AssumeRolePolicyDocument=json.dumps(lambda_trust_policy),\n",
    "        Description=f\"Execution role for {DATASET_NAME} reward function\"\n",
    "    )\n",
    "    lambda_role_arn = response['Role']['Arn']\n",
    "    iam_client.attach_role_policy(RoleName=LAMBDA_ROLE_NAME, PolicyArn='arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole')\n",
    "    print(f\"✓ Created role: {LAMBDA_ROLE_NAME}\")\n",
    "    print(\"Waiting 10s for role propagation...\")\n",
    "    time.sleep(10)\n",
    "except iam_client.exceptions.EntityAlreadyExistsException:\n",
    "    lambda_role_arn = iam_client.get_role(RoleName=LAMBDA_ROLE_NAME)['Role']['Arn']\n",
    "    print(f\"✓ Using existing role: {LAMBDA_ROLE_NAME}\")\n",
    "\n",
    "# Package and deploy Lambda\n",
    "lambda_zip_content = create_lambda_deployment_package(\n",
    "    source_file=REWARD_FUNCTION_FILE,\n",
    "    zip_filename=\"lambda_deployment.zip\",\n",
    "    archive_name=f\"{REWARD_FUNCTION_MODULE}.py\"\n",
    ")\n",
    "\n",
    "print(f\"\\nDeploying Lambda: {LAMBDA_FUNCTION_NAME}...\")\n",
    "try:\n",
    "    lambda_client.get_function(FunctionName=LAMBDA_FUNCTION_NAME)\n",
    "    lambda_client.update_function_code(FunctionName=LAMBDA_FUNCTION_NAME, ZipFile=lambda_zip_content)\n",
    "    waiter = lambda_client.get_waiter('function_updated_v2')\n",
    "    waiter.wait(FunctionName=LAMBDA_FUNCTION_NAME)\n",
    "    print(\"✓ Updated existing function\")\n",
    "except lambda_client.exceptions.ResourceNotFoundException:\n",
    "    lambda_client.create_function(\n",
    "        FunctionName=LAMBDA_FUNCTION_NAME,\n",
    "        Runtime='python3.11',\n",
    "        Role=lambda_role_arn,\n",
    "        Handler=f\"{REWARD_FUNCTION_MODULE}.lambda_handler\",\n",
    "        Code={'ZipFile': lambda_zip_content},\n",
    "        Timeout=300,\n",
    "        MemorySize=512\n",
    "    )\n",
    "    print(\"✓ Created new function\")\n",
    "\n",
    "waiter = lambda_client.get_waiter('function_active_v2')\n",
    "waiter.wait(FunctionName=LAMBDA_FUNCTION_NAME)\n",
    "lambda_arn = lambda_client.get_function(FunctionName=LAMBDA_FUNCTION_NAME)['Configuration']['FunctionArn']\n",
    "print(f\"✓ Lambda ready: {lambda_arn}\")\n",
    "\n",
    "# Create Bedrock role\n",
    "print(f\"\\nCreating Bedrock role: {BEDROCK_ROLE_NAME}...\")\n",
    "\n",
    "bedrock_trust_policy = {\n",
    "    \"Version\": \"2012-10-17\",\n",
    "    \"Statement\": [{\"Effect\": \"Allow\", \"Principal\": {\"Service\": \"bedrock.amazonaws.com\"}, \"Action\": \"sts:AssumeRole\"}]\n",
    "}\n",
    "\n",
    "bedrock_permissions = {\n",
    "    \"Version\": \"2012-10-17\",\n",
    "    \"Statement\": [\n",
    "        {\"Effect\": \"Allow\", \"Action\": [\"s3:GetObject\", \"s3:ListBucket\"], \"Resource\": [f\"arn:aws:s3:::{S3_BUCKET}/*\", f\"arn:aws:s3:::{S3_BUCKET}\"]},\n",
    "        {\"Effect\": \"Allow\", \"Action\": \"s3:PutObject\", \"Resource\": f\"arn:aws:s3:::{S3_BUCKET}/rft-output/*\"},\n",
    "        {\"Effect\": \"Allow\", \"Action\": \"lambda:InvokeFunction\", \"Resource\": lambda_arn}\n",
    "    ]\n",
    "}\n",
    "\n",
    "try:\n",
    "    response = iam_client.create_role(\n",
    "        RoleName=BEDROCK_ROLE_NAME,\n",
    "        AssumeRolePolicyDocument=json.dumps(bedrock_trust_policy),\n",
    "        Description=\"Execution role for Bedrock RFT\"\n",
    "    )\n",
    "    bedrock_role_arn = response['Role']['Arn']\n",
    "    print(f\"✓ Created role: {BEDROCK_ROLE_NAME}\")\n",
    "except iam_client.exceptions.EntityAlreadyExistsException:\n",
    "    bedrock_role_arn = iam_client.get_role(RoleName=BEDROCK_ROLE_NAME)['Role']['Arn']\n",
    "    print(f\"✓ Using existing role: {BEDROCK_ROLE_NAME}\")\n",
    "\n",
    "iam_client.put_role_policy(RoleName=BEDROCK_ROLE_NAME, PolicyName='BedrockRFTPermissions', PolicyDocument=json.dumps(bedrock_permissions))\n",
    "print(f\"✓ Bedrock role ready: {bedrock_role_arn}\")\n",
    "\n",
    "cleanup_lambda_deployment_package()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad74e1e9",
   "metadata": {},
   "source": [
    "#### ---\n",
    "## 3. Test the Reward Function\n",
    "\n",
    "Before kicking off a multi-hour training job, let's make sure our reward function actually works. We'll send it a sample response and verify it returns the expected score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc221436",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Testing reward function...\")\n",
    "\n",
    "test_payload = [{\n",
    "    \"id\": \"test_001\",\n",
    "    \"messages\": [\n",
    "        {\"role\": \"user\", \"content\": \"What is the percentage increase from 100 to 125?\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"Let me calculate this step by step.\\n\\nPercentage increase = (New - Old) / Old × 100\\n= (125 - 100) / 100 × 100\\n= 25%\\n\\nANSWER: 25\"}\n",
    "    ],\n",
    "    \"reference_answer\": {\"answer\": \"25\"}\n",
    "}]\n",
    "\n",
    "response = lambda_client.invoke(\n",
    "    FunctionName=LAMBDA_FUNCTION_NAME,\n",
    "    InvocationType='RequestResponse',\n",
    "    Payload=json.dumps(test_payload)\n",
    ")\n",
    "\n",
    "result = json.loads(response['Payload'].read())\n",
    "print(json.dumps(result, indent=2))\n",
    "\n",
    "if 'errorMessage' in result:\n",
    "    print(f\"\\n✗ Error: {result['errorMessage']}\")\n",
    "elif isinstance(result, list) and result[0].get('aggregate_reward_score') == 1.0:\n",
    "    print(\"\\n✓ Reward function working correctly!\")\n",
    "else:\n",
    "    print(\"\\n⚠ Unexpected result - check the output above\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "501c879d",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Start the RFT Training Job\n",
    "\n",
    "Now for the main event. We'll create a model customization job that:\n",
    "- Takes our base Nova model\n",
    "- Trains it on FinQA using reinforcement learning\n",
    "- Uses our Lambda to score responses\n",
    "\n",
    "Training typically takes several hours depending on dataset size and hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff81fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Creating RFT training job...\")\n",
    "print(f\"  Job: {JOB_NAME}\")\n",
    "print(f\"  Model: {CUSTOM_MODEL_NAME}\")\n",
    "print(f\"  Base: {BASE_MODEL_ID}\")\n",
    "\n",
    "response = bedrock_client.create_model_customization_job(\n",
    "    jobName=JOB_NAME,\n",
    "    customModelName=CUSTOM_MODEL_NAME,\n",
    "    roleArn=bedrock_role_arn,\n",
    "    baseModelIdentifier=BASE_MODEL_ID,\n",
    "    customizationType='REINFORCEMENT_FINE_TUNING',\n",
    "    trainingDataConfig={'s3Uri': S3_TRAINING_DATA},\n",
    "    validationDataConfig={'validators': [{'s3Uri': S3_VALIDATION_DATA}]},\n",
    "    outputDataConfig={'s3Uri': S3_OUTPUT_PATH},\n",
    "    customizationConfig={\n",
    "        'rftConfig': {\n",
    "            'graderConfig': {'lambdaGrader': {'lambdaArn': lambda_arn}},\n",
    "            'hyperParameters': {\n",
    "                'batchSize': 32,\n",
    "                'epochCount': 1,\n",
    "                'evalInterval': 5,\n",
    "                'inferenceMaxTokens': 1000,\n",
    "                'learningRate': 0.00005,\n",
    "                'maxPromptLength': 4000,\n",
    "                'reasoningEffort': 'high',\n",
    "                'trainingSamplePerPrompt': 4\n",
    "            }\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "print(f\"\\n✓ Job created: {response['jobArn']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ffc6489",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Monitor Training Progress\n",
    "\n",
    "Run this cell periodically to check on your training job. Status will progress through: `InProgress` → `Completed` (or `Failed`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64057f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = bedrock_client.get_model_customization_job(jobIdentifier=JOB_NAME)\n",
    "print(f\"Job: {JOB_NAME}\")\n",
    "print(f\"Status: {response['status']}\")\n",
    "\n",
    "if response['status'] == 'Completed' and 'outputModelArn' in response:\n",
    "    print(f\"\\n✓ Training complete!\")\n",
    "    print(f\"  Model ARN: {response['outputModelArn']}\")\n",
    "elif response['status'] == 'Failed':\n",
    "    print(f\"\\n✗ Training failed: {response.get('failureMessage', 'Unknown error')}\")\n",
    "elif response['status'] == 'InProgress':\n",
    "    print(\"\\n⏳ Still training... run this cell again to check progress\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02747589",
   "metadata": {},
   "source": [
    "\n",
    "## Conclusion\n",
    "\n",
    "Congratulations, you've successfully launched a Reinforcement Fine-Tuning job for Amazon Nova on the FinQA dataset.\n",
    "\n",
    "### What You've Built\n",
    "\n",
    "- **Preprocessed FinQA dataset** into Bedrock RFT format  \n",
    "- **Deployed a Lambda reward function** that scores model responses  \n",
    "- **Created IAM roles** for Lambda and Bedrock execution  \n",
    "- **Started an RFT training job** with customized hyperparameters  \n",
    "\n",
    "### Next Steps\n",
    "\n",
    "Once your training job completes (check status in cell above):\n",
    "\n",
    "1. **Test your fine-tuned model** via the Bedrock API using the model ARN\n",
    "2. **Evaluate performance** on the held-out test set (`test.jsonl`)\n",
    "3. **Compare results** against the base Nova model\n",
    "4. **Experiment with hyperparameters** (learning rate, batch size, epochs) for better performance\n",
    "\n",
    "\n",
    "### Learn More\n",
    "\n",
    "- [Amazon Bedrock RFT Documentation](https://docs.aws.amazon.com/bedrock/latest/userguide/reinforcement-fine-tuning.html)\n",
    "- [Amazon Nova 2 Lite](https://docs.aws.amazon.com/ai/responsible-ai/nova-2-lite/overview.html)\n",
    "- [FinQA Dataset on GitHub](https://github.com/czyssrs/FinQA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56cb35fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rft-env",
   "language": "python",
   "name": "rft-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
