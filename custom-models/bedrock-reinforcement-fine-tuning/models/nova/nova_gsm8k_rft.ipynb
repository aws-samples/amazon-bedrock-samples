{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro-cell",
   "metadata": {},
   "source": [
    "# Reinforcement Fine-Tuning Amazon Nova 2.0 Lite with GSM8K\n",
    "\n",
    "This notebook walks through training an Amazon Nova model using Reinforcement Fine-Tuning (RFT) on the [GSM8K](https://huggingface.co/datasets/openai/gsm8k) math dataset.\n",
    "\n",
    "## What's RFT?\n",
    "\n",
    "Traditional fine-tuning shows a model examples and says \"produce outputs like this.\" RFT takes a different approach: it lets the model generate its own responses, then uses a reward signal to reinforce good outputs and discourage bad ones. Think of it like training with a coach who gives feedback rather than just copying from a textbook.\n",
    "\n",
    "For math problems, this works particularly well because we can automatically verify if an answer is correct—no human labeling needed.\n",
    "\n",
    "## What's GSM8K?\n",
    "\n",
    "GSM8K (Grade School Math 8K) is a dataset of ~8,000 grade-school math word problems. Each problem requires multi-step reasoning to solve. It's become a standard benchmark for testing whether language models can actually \"think\" through problems rather than just pattern-match.\n",
    "\n",
    "Example problem:\n",
    "> *Janet's ducks lay 16 eggs per day. She eats three for breakfast and bakes muffins with four. She sells the rest at $2 each. How much does she make daily?*\n",
    "\n",
    "## What we'll build\n",
    "\n",
    "1. Prepare GSM8K data in the format Bedrock RFT expects\n",
    "2. Deploy a Lambda function that scores model responses (correct answer = reward)\n",
    "3. Kick off an RFT training job on Amazon Bedrock\n",
    "4. Monitor the job until completion\n",
    "\n",
    "By the end, you'll have a Nova model that's better at step-by-step math reasoning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb03cb0-ed72-4677-9e45-d2a59733391e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Prerequisites: SageMaker Role Permissions\n",
    "\n",
    "**NOTE:** If you are running this notebook using an AWS Profile with Admin you can skip this cell...\n",
    "\n",
    "....otherwise this Jupyter notebook requires your SageMaker execution role to have these IAM permissions:\n",
    "\n",
    "| Service | Actions | Resources | Why |\n",
    "|---------|---------|-----------|-----|\n",
    "| **S3** | `PutObject`, `GetObject`, `ListBucket`, `DeleteObject` | `arn:aws:s3:::YOUR-BUCKET/*` and `arn:aws:s3:::YOUR-BUCKET` | Upload/download training data |\n",
    "| **IAM** | `CreateRole`, `GetRole`, `AttachRolePolicy`, `PutRolePolicy`, **`PassRole`** | `arn:aws:iam::ACCOUNT:role/GSMBK-Lambda-Role`, `arn:aws:iam::ACCOUNT:role/BedrockRFTRole` | Create Lambda & Bedrock roles |\n",
    "| **Lambda** | `CreateFunction`, `GetFunction`, `UpdateFunctionCode`, `InvokeFunction` | `arn:aws:lambda:REGION:ACCOUNT:function:gsm8k-reward-function` | Deploy reward function |\n",
    "| **Bedrock** | `CreateModelCustomizationJob`, `GetModelCustomizationJob` | `*` | Start/monitor training |\n",
    "| **STS** | `GetCallerIdentity` | `*` | Get account info |\n",
    "\n",
    "### To Add These Permissions:\n",
    "\n",
    "1. Go to [IAM Console](https://console.aws.amazon.com/iam) (with Admin access) → Roles → Your SageMaker role\n",
    "2. **Add permissions** → **Create inline policy** → **JSON** tab\n",
    "\n",
    "**Critical**: Ensure `iam:PassRole` is included - this allows Bedrock to assume the training role.\n",
    "\n",
    "If you get `AccessDenied` errors while running the notebook, you're missing one of these permissions.\n",
    "\n",
    "**Once you've updated your permissions, ensure you restart your notebook kernel to ensure the changes are propagated**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-0",
   "metadata": {},
   "source": [
    "---\n",
    "## 0. Install Dependencies\n",
    "\n",
    "We need `datasets` to pull GSM8K from HuggingFace, and up-to-date AWS SDK packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "install-deps",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -qU datasets boto3 botocore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-1",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Configuration & Data Prep\n",
    "\n",
    "First, set your AWS region, S3 bucket, and profile. Then we'll pull GSM8K from HuggingFace, format it for Bedrock RFT, and upload to S3.\n",
    "\n",
    "The key formatting requirement: each training example needs a `prompt` (the math question) and metadata containing the `ground_truth` answer that our reward function will check against."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "config-and-data",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"../..\")\n",
    "\n",
    "import boto3\n",
    "import json\n",
    "import time\n",
    "import os\n",
    "import re\n",
    "from datasets import load_dataset\n",
    "\n",
    "from helpers import (\n",
    "    create_lambda_deployment_package,\n",
    "    cleanup_lambda_deployment_package\n",
    ")\n",
    "\n",
    "# ============== UPDATE THESE VALUES ==============\n",
    "AWS_REGION = \"us-east-1\"\n",
    "S3_BUCKET = \"your-bucket-name\"\n",
    "AWS_PROFILE = None  # Set to your profile name, or None for default credentials\n",
    "# =================================================\n",
    "\n",
    "# Create session\n",
    "session = boto3.Session(profile_name=AWS_PROFILE, region_name=AWS_REGION) if AWS_PROFILE else boto3.Session(region_name=AWS_REGION)\n",
    "AWS_ACCOUNT_ID = session.client('sts').get_caller_identity()['Account']\n",
    "\n",
    "# Dataset configuration\n",
    "DATASET_NAME = \"gsm8k\"\n",
    "HF_DATASET = \"openai/gsm8k\"\n",
    "TOTAL_SAMPLES = 320\n",
    "LOCAL_DATA_DIR = \"../../tmp-data\"\n",
    "\n",
    "assert S3_BUCKET != \"your-bucket-name\", \"Please update S3_BUCKET with your own bucket name\"\n",
    "\n",
    "# S3 paths\n",
    "S3_TRAINING_DATA = f\"s3://{S3_BUCKET}/rft-data/datasets/{DATASET_NAME}/train.jsonl\"\n",
    "S3_VALIDATION_DATA = f\"s3://{S3_BUCKET}/rft-data/datasets/{DATASET_NAME}/val.jsonl\"\n",
    "S3_OUTPUT_PATH = f\"s3://{S3_BUCKET}/rft-output/\"\n",
    "\n",
    "# Resource names\n",
    "LAMBDA_FUNCTION_NAME = f\"{DATASET_NAME}-reward-function\"\n",
    "LAMBDA_ROLE_NAME = f\"{DATASET_NAME.upper()}-Lambda-Role\"\n",
    "BEDROCK_ROLE_NAME = \"BedrockRFTRole\"\n",
    "REWARD_FUNCTION_FILE = f\"../../reward-functions/{DATASET_NAME}_rew_func.py\"\n",
    "REWARD_FUNCTION_MODULE = f\"{DATASET_NAME}_rew_func\"\n",
    "\n",
    "# Model configuration\n",
    "BASE_MODEL_ID = f\"arn:aws:bedrock:{AWS_REGION}::foundation-model/amazon.nova-2-lite-v1:0:256k\"\n",
    "CUSTOM_MODEL_NAME = f\"{DATASET_NAME}-nova-lite-rft\"\n",
    "JOB_NAME = f\"{DATASET_NAME}-rft-job-{int(time.time())}\"\n",
    "\n",
    "# Initialize AWS clients\n",
    "s3_client = session.client('s3')\n",
    "bedrock_client = session.client('bedrock')\n",
    "lambda_client = session.client('lambda')\n",
    "iam_client = session.client('iam')\n",
    "\n",
    "# --- Preprocess GSM8K ---\n",
    "def preprocess_gsm8k(hf_path, total_samples, output_dir, train_ratio=0.8, val_ratio=0.1):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    ds = load_dataset(hf_path, \"main\")\n",
    "\n",
    "    train_size = int(total_samples * train_ratio)\n",
    "    val_size = int(total_samples * val_ratio)\n",
    "    test_size = total_samples - train_size - val_size\n",
    "\n",
    "    def extract_answer(answer_text):\n",
    "        match = re.search(r'####\\s*(-?\\d+(?:,\\d+)*)', answer_text)\n",
    "        return match.group(1).replace(',', '') if match else \"\"\n",
    "\n",
    "    def format_row(row, idx, split):\n",
    "        final_answer = extract_answer(row['answer'])\n",
    "\n",
    "        # Extract reasoning steps from the answer\n",
    "        steps = []\n",
    "        if '####' in row['answer']:\n",
    "            reasoning_part = row['answer'].split('####')[0].strip()\n",
    "            steps = [s.strip() for s in reasoning_part.split('\\n') if s.strip()]\n",
    "\n",
    "        return {\n",
    "            \"messages\": [\n",
    "                {\"role\": \"system\", \"content\": \"You are a helpful math tutor who solves word problems step by step.\"},\n",
    "                {\"role\": \"user\", \"content\": f\"{row['question']} Let's think step by step and output the final answer after \\\"####\\\".\"}\n",
    "            ],\n",
    "            \"reference_answer\": {\n",
    "                \"final_answer\": final_answer,\n",
    "                \"steps\": steps if steps else None\n",
    "            },\n",
    "            \"task_id\": f\"gsm8k_{split}_{idx}\",\n",
    "            \"domain\": \"math\",\n",
    "            \"difficulty_level\": \"grade_school\",\n",
    "            \"data_source\": hf_path,\n",
    "            \"original_question\": row['question'],\n",
    "            \"original_answer\": row['answer']\n",
    "        }\n",
    "\n",
    "    def write_split(data, start_idx, size, filename, split_name):\n",
    "        with open(f\"{output_dir}/{filename}\", \"w\") as f:\n",
    "            for i, row in enumerate(data.select(range(start_idx, start_idx + size))):\n",
    "                f.write(json.dumps(format_row(row, i, split_name)) + \"\\n\")\n",
    "        print(f\"✓ Created {output_dir}/{filename} ({size} samples)\")\n",
    "\n",
    "    hf_train = ds[\"train\"].shuffle(seed=42)\n",
    "    write_split(hf_train, 0, train_size, \"train.jsonl\", \"train\")\n",
    "    write_split(hf_train, train_size, val_size, \"val.jsonl\", \"val\")\n",
    "    write_split(hf_train, train_size + val_size, test_size, \"test.jsonl\", \"test\")\n",
    "\n",
    "    return train_size, val_size, test_size\n",
    "\n",
    "print(\"Preprocessing GSM8K dataset...\")\n",
    "train_size, val_size, test_size = preprocess_gsm8k(HF_DATASET, TOTAL_SAMPLES, LOCAL_DATA_DIR)\n",
    "\n",
    "print(\"\\nUploading to S3...\")\n",
    "for local_file, s3_key in [\n",
    "    (\"train.jsonl\", f\"rft-data/datasets/{DATASET_NAME}/train.jsonl\"),\n",
    "    (\"val.jsonl\", f\"rft-data/datasets/{DATASET_NAME}/val.jsonl\"),\n",
    "    (\"test.jsonl\", f\"rft-data/datasets/{DATASET_NAME}/test.jsonl\")\n",
    "]:\n",
    "    s3_client.upload_file(f\"{LOCAL_DATA_DIR}/{local_file}\", S3_BUCKET, s3_key)\n",
    "    print(f\"✓ Uploaded {local_file}\")\n",
    "\n",
    "print(f\"\\n✓ Ready | {train_size} train / {val_size} val / {test_size} test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c658dc-cbc5-410a-8162-03019e887ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up temporary local data\n",
    "import shutil\n",
    "\n",
    "print(\"\\nCleaning up temporary files...\")\n",
    "if os.path.exists(LOCAL_DATA_DIR):\n",
    "    shutil.rmtree(LOCAL_DATA_DIR)\n",
    "    print(f\"✓ Removed {LOCAL_DATA_DIR}\")\n",
    "else:\n",
    "    print(f\"✓ No temporary files to clean\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-2",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Deploy the Reward Function\n",
    "\n",
    "The reward function is the \"coach\" in our RFT setup. During training, Bedrock generates candidate responses and sends them to this Lambda. The Lambda extracts the model's answer, compares it to the ground truth, and returns a score (1.0 for correct, 0.0 for wrong).\n",
    "\n",
    "We also create the IAM roles that Bedrock and Lambda need to do their jobs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deploy-lambda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Lambda execution role\n",
    "print(\"Creating Lambda execution role...\")\n",
    "\n",
    "lambda_trust_policy = {\n",
    "    \"Version\": \"2012-10-17\",\n",
    "    \"Statement\": [{\"Effect\": \"Allow\", \"Principal\": {\"Service\": \"lambda.amazonaws.com\"}, \"Action\": \"sts:AssumeRole\"}]\n",
    "}\n",
    "\n",
    "try:\n",
    "    response = iam_client.create_role(\n",
    "        RoleName=LAMBDA_ROLE_NAME,\n",
    "        AssumeRolePolicyDocument=json.dumps(lambda_trust_policy),\n",
    "        Description=f\"Execution role for {DATASET_NAME} reward function\"\n",
    "    )\n",
    "    lambda_role_arn = response['Role']['Arn']\n",
    "    iam_client.attach_role_policy(RoleName=LAMBDA_ROLE_NAME, PolicyArn='arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole')\n",
    "    print(f\"✓ Created role: {LAMBDA_ROLE_NAME}\")\n",
    "    print(\"Waiting 10s for role propagation...\")\n",
    "    time.sleep(10)\n",
    "except iam_client.exceptions.EntityAlreadyExistsException:\n",
    "    lambda_role_arn = iam_client.get_role(RoleName=LAMBDA_ROLE_NAME)['Role']['Arn']\n",
    "    print(f\"✓ Using existing role: {LAMBDA_ROLE_NAME}\")\n",
    "\n",
    "# Package and deploy Lambda\n",
    "lambda_zip_content = create_lambda_deployment_package(\n",
    "    source_file=REWARD_FUNCTION_FILE,\n",
    "    zip_filename=\"lambda_deployment.zip\",\n",
    "    archive_name=f\"{REWARD_FUNCTION_MODULE}.py\"\n",
    ")\n",
    "\n",
    "print(f\"\\nDeploying Lambda: {LAMBDA_FUNCTION_NAME}...\")\n",
    "try:\n",
    "    lambda_client.get_function(FunctionName=LAMBDA_FUNCTION_NAME)\n",
    "    lambda_client.update_function_code(FunctionName=LAMBDA_FUNCTION_NAME, ZipFile=lambda_zip_content)\n",
    "    waiter = lambda_client.get_waiter('function_updated_v2')\n",
    "    waiter.wait(FunctionName=LAMBDA_FUNCTION_NAME)\n",
    "    print(\"✓ Updated existing function\")\n",
    "except lambda_client.exceptions.ResourceNotFoundException:\n",
    "    lambda_client.create_function(\n",
    "        FunctionName=LAMBDA_FUNCTION_NAME,\n",
    "        Runtime='python3.11',\n",
    "        Role=lambda_role_arn,\n",
    "        Handler=f\"{REWARD_FUNCTION_MODULE}.lambda_handler\",\n",
    "        Code={'ZipFile': lambda_zip_content},\n",
    "        Timeout=300,\n",
    "        MemorySize=512\n",
    "    )\n",
    "    print(\"✓ Created new function\")\n",
    "\n",
    "waiter = lambda_client.get_waiter('function_active_v2')\n",
    "waiter.wait(FunctionName=LAMBDA_FUNCTION_NAME)\n",
    "lambda_arn = lambda_client.get_function(FunctionName=LAMBDA_FUNCTION_NAME)['Configuration']['FunctionArn']\n",
    "print(f\"✓ Lambda ready: {lambda_arn}\")\n",
    "\n",
    "# Create Bedrock role\n",
    "print(f\"\\nCreating Bedrock role: {BEDROCK_ROLE_NAME}...\")\n",
    "\n",
    "bedrock_trust_policy = {\n",
    "    \"Version\": \"2012-10-17\",\n",
    "    \"Statement\": [{\"Effect\": \"Allow\", \"Principal\": {\"Service\": \"bedrock.amazonaws.com\"}, \"Action\": \"sts:AssumeRole\"}]\n",
    "}\n",
    "\n",
    "bedrock_permissions = {\n",
    "    \"Version\": \"2012-10-17\",\n",
    "    \"Statement\": [\n",
    "        {\"Effect\": \"Allow\", \"Action\": [\"s3:GetObject\", \"s3:ListBucket\"], \"Resource\": [f\"arn:aws:s3:::{S3_BUCKET}/*\", f\"arn:aws:s3:::{S3_BUCKET}\"]},\n",
    "        {\"Effect\": \"Allow\", \"Action\": \"s3:PutObject\", \"Resource\": f\"arn:aws:s3:::{S3_BUCKET}/rft-output/*\"},\n",
    "        {\"Effect\": \"Allow\", \"Action\": \"lambda:InvokeFunction\", \"Resource\": lambda_arn}\n",
    "    ]\n",
    "}\n",
    "\n",
    "try:\n",
    "    response = iam_client.create_role(\n",
    "        RoleName=BEDROCK_ROLE_NAME,\n",
    "        AssumeRolePolicyDocument=json.dumps(bedrock_trust_policy),\n",
    "        Description=\"Execution role for Bedrock RFT\"\n",
    "    )\n",
    "    bedrock_role_arn = response['Role']['Arn']\n",
    "    print(f\"✓ Created role: {BEDROCK_ROLE_NAME}\")\n",
    "except iam_client.exceptions.EntityAlreadyExistsException:\n",
    "    bedrock_role_arn = iam_client.get_role(RoleName=BEDROCK_ROLE_NAME)['Role']['Arn']\n",
    "    print(f\"✓ Using existing role: {BEDROCK_ROLE_NAME}\")\n",
    "\n",
    "iam_client.put_role_policy(RoleName=BEDROCK_ROLE_NAME, PolicyName='BedrockRFTPermissions', PolicyDocument=json.dumps(bedrock_permissions))\n",
    "print(f\"✓ Bedrock role ready: {bedrock_role_arn}\")\n",
    "\n",
    "cleanup_lambda_deployment_package()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-3",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Test the Reward Function\n",
    "\n",
    "Before kicking off a multi-hour training job, let's make sure our reward function actually works. We'll send it a sample response and verify it returns the expected score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "test-lambda",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Testing reward function...\")\n",
    "\n",
    "test_payload = [{\n",
    "    \"id\": \"test_001\",\n",
    "    \"messages\": [\n",
    "        {\"role\": \"user\", \"content\": \"What is 2 + 2?\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"Let me solve this step by step.\\n\\n2 + 2 = 4\\n\\n#### 4\"}\n",
    "    ],\n",
    "    \"metadata\": {\"reference_answer\": {\"final_answer\": \"4\"}}\n",
    "}]\n",
    "\n",
    "response = lambda_client.invoke(\n",
    "    FunctionName=LAMBDA_FUNCTION_NAME,\n",
    "    InvocationType='RequestResponse',\n",
    "    Payload=json.dumps(test_payload)\n",
    ")\n",
    "\n",
    "result = json.loads(response['Payload'].read())\n",
    "print(json.dumps(result, indent=2))\n",
    "\n",
    "if 'errorMessage' in result:\n",
    "    print(f\"\\n✗ Error: {result['errorMessage']}\")\n",
    "elif isinstance(result, list) and result[0].get('aggregate_reward_score') == 1.0:\n",
    "    print(\"\\n✓ Reward function working correctly!\")\n",
    "else:\n",
    "    print(\"\\n⚠ Unexpected result - check the output above\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-4",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Start the RFT Training Job\n",
    "\n",
    "Now for the main event. We'll create a model customization job that:\n",
    "- Takes our base Nova model\n",
    "- Trains it on GSM8K using reinforcement learning\n",
    "- Uses our Lambda to score responses\n",
    "\n",
    "Training typically takes several hours depending on dataset size and hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "create-job",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Creating RFT training job...\")\n",
    "print(f\"  Job: {JOB_NAME}\")\n",
    "print(f\"  Model: {CUSTOM_MODEL_NAME}\")\n",
    "print(f\"  Base: {BASE_MODEL_ID}\")\n",
    "\n",
    "response = bedrock_client.create_model_customization_job(\n",
    "    jobName=JOB_NAME,\n",
    "    customModelName=CUSTOM_MODEL_NAME,\n",
    "    roleArn=bedrock_role_arn,\n",
    "    baseModelIdentifier=BASE_MODEL_ID,\n",
    "    customizationType='REINFORCEMENT_FINE_TUNING',\n",
    "    trainingDataConfig={'s3Uri': S3_TRAINING_DATA},\n",
    "    validationDataConfig={'validators': [{'s3Uri': S3_VALIDATION_DATA}]},\n",
    "    outputDataConfig={'s3Uri': S3_OUTPUT_PATH},\n",
    "    customizationConfig={\n",
    "        'rftConfig': {\n",
    "            'graderConfig': {'lambdaGrader': {'lambdaArn': lambda_arn}},\n",
    "            'hyperParameters': {\n",
    "                'batchSize': 32,\n",
    "                'epochCount': 1,\n",
    "                'evalInterval': 50,\n",
    "                'inferenceMaxTokens': 8192,\n",
    "                'learningRate': 0.00005,\n",
    "                'maxPromptLength': 4096,\n",
    "                'reasoningEffort': 'high',\n",
    "                'trainingSamplePerPrompt': 4\n",
    "            }\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "print(f\"\\n✓ Job created: {response['jobArn']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-5",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Monitor Training Progress\n",
    "\n",
    "Run this cell periodically to check on your training job. Status will progress through: `InProgress` → `Completed` (or `Failed`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "monitor-job",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = bedrock_client.get_model_customization_job(jobIdentifier=JOB_NAME)\n",
    "print(f\"Job: {JOB_NAME}\")\n",
    "print(f\"Status: {response['status']}\")\n",
    "\n",
    "if response['status'] == 'Completed' and 'outputModelArn' in response:\n",
    "    print(f\"\\n✓ Training complete!\")\n",
    "    print(f\"  Model ARN: {response['outputModelArn']}\")\n",
    "elif response['status'] == 'Failed':\n",
    "    print(f\"\\n✗ Training failed: {response.get('failureMessage', 'Unknown error')}\")\n",
    "elif response['status'] == 'InProgress':\n",
    "    print(\"\\n⏳ Still training... run this cell again to check progress\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24bdc824-c8fe-4e51-977d-9911d8a3b586",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
