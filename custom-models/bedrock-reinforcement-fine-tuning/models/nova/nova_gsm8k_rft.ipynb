{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro-cell",
   "metadata": {},
   "source": [
    "# Reinforcement Fine-Tuning Amazon Nova 2.0 Lite with GSM8K\n",
    "\n",
    "This notebook walks through training an Amazon Nova model using Reinforcement Fine-Tuning (RFT) on the [GSM8K](https://huggingface.co/datasets/openai/gsm8k) math dataset.\n",
    "\n",
    "## What's RFT?\n",
    "\n",
    "Traditional fine-tuning shows a model examples and says \"produce outputs like this.\" RFT takes a different approach: it lets the model generate its own responses, then uses a reward signal to reinforce good outputs and discourage bad ones. Think of it like training with a coach who gives feedback rather than just copying from a textbook.\n",
    "\n",
    "For math problems, this works particularly well because we can automatically verify if an answer is correct—no human labeling needed.\n",
    "\n",
    "## What's GSM8K?\n",
    "\n",
    "GSM8K (Grade School Math 8K) is a dataset of ~8,000 grade-school math word problems. Each problem requires multi-step reasoning to solve. It's become a standard benchmark for testing whether language models can actually \"think\" through problems rather than just pattern-match.\n",
    "\n",
    "Example problem:\n",
    "> *Janet's ducks lay 16 eggs per day. She eats three for breakfast and bakes muffins with four. She sells the rest at $2 each. How much does she make daily?*\n",
    "\n",
    "## What we'll build\n",
    "\n",
    "1. Prepare GSM8K data in the format Bedrock RFT expects\n",
    "2. Deploy a Lambda function that scores model responses (correct answer = reward)\n",
    "3. Kick off an RFT training job on Amazon Bedrock\n",
    "4. Monitor the job until completion\n",
    "\n",
    "By the end, you'll have a Nova model that's better at step-by-step math reasoning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb03cb0-ed72-4677-9e45-d2a59733391e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Prerequisites: SageMaker Role Permissions\n",
    "\n",
    "**NOTE:** If you are running this notebook using an AWS Profile with Admin you can skip this cell...\n",
    "\n",
    "....otherwise this Jupyter notebook requires your SageMaker execution role to have these IAM permissions:\n",
    "\n",
    "| Service | Actions | Resources | Why |\n",
    "|---------|---------|-----------|-----|\n",
    "| **S3** | `PutObject`, `GetObject`, `ListBucket`, `DeleteObject` | `arn:aws:s3:::YOUR-BUCKET/*` and `arn:aws:s3:::YOUR-BUCKET` | Upload/download training data |\n",
    "| **IAM** | `CreateRole`, `GetRole`, `AttachRolePolicy`, `PutRolePolicy`, **`PassRole`** | `arn:aws:iam::ACCOUNT:role/GSMBK-Lambda-Role`, `arn:aws:iam::ACCOUNT:role/BedrockRFTRole` | Create Lambda & Bedrock roles |\n",
    "| **Lambda** | `CreateFunction`, `GetFunction`, `UpdateFunctionCode`, `InvokeFunction` | `arn:aws:lambda:REGION:ACCOUNT:function:gsm8k-reward-function` | Deploy reward function |\n",
    "| **Bedrock** | `CreateModelCustomizationJob`, `GetModelCustomizationJob` | `*` | Start/monitor training |\n",
    "| **STS** | `GetCallerIdentity` | `*` | Get account info |\n",
    "\n",
    "### To Add These Permissions:\n",
    "\n",
    "1. Go to [IAM Console](https://console.aws.amazon.com/iam) (with Admin access) → Roles → Your SageMaker role\n",
    "2. **Add permissions** → **Create inline policy** → **JSON** tab\n",
    "\n",
    "**Critical**: Ensure `iam:PassRole` is included - this allows Bedrock to assume the training role.\n",
    "\n",
    "If you get `AccessDenied` errors while running the notebook, you're missing one of these permissions.\n",
    "\n",
    "**Once you've updated your permissions, ensure you restart your notebook kernel to ensure the changes are propagated**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-0",
   "metadata": {},
   "source": [
    "---\n",
    "## 0. Install Dependencies\n",
    "\n",
    "We need `datasets` to pull GSM8K from HuggingFace, and up-to-date AWS SDK packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "install-deps",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -qU datasets boto3 botocore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-1",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Configuration & Data Prep\n",
    "\n",
    "First, set your AWS region, S3 bucket, and profile. Then we'll pull GSM8K from HuggingFace, format it for Bedrock RFT, and upload to S3.\n",
    "\n",
    "The key formatting requirement: each training example needs a `prompt` (the math question) and metadata containing the `ground_truth` answer that our reward function will check against."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a18e40f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"../..\")\n",
    "\n",
    "import boto3\n",
    "import json\n",
    "import time\n",
    "import os\n",
    "import re\n",
    "from datasets import load_dataset\n",
    "\n",
    "from helpers import (\n",
    "    create_lambda_deployment_package,\n",
    "    cleanup_lambda_deployment_package\n",
    ")\n",
    "\n",
    "# ============== UPDATE THESE VALUES ==============\n",
    "AWS_REGION = \"us-east-1\"\n",
    "S3_BUCKET = \"your-bucket-name\"\n",
    "AWS_PROFILE = None  # Set to your profile name, or None for default credentials\n",
    "# =================================================\n",
    "\n",
    "# Create session\n",
    "session = boto3.Session(profile_name=AWS_PROFILE, region_name=AWS_REGION) if AWS_PROFILE else boto3.Session(region_name=AWS_REGION)\n",
    "AWS_ACCOUNT_ID = session.client('sts').get_caller_identity()['Account']\n",
    "\n",
    "# Dataset configuration\n",
    "DATASET_NAME = \"gsm8k\"\n",
    "HF_DATASET = \"openai/gsm8k\"\n",
    "TOTAL_SAMPLES = None  # Set to None to use all available data, or an integer to limit\n",
    "LOCAL_DATA_DIR = \"../../tmp-data\"\n",
    "\n",
    "assert S3_BUCKET != \"your-bucket-name\", \"Please update S3_BUCKET with your own bucket name\"\n",
    "S3_OUTPUT_PATH = f\"s3://{S3_BUCKET}/rft-output/\"\n",
    "\n",
    "# Resource names\n",
    "LAMBDA_FUNCTION_NAME = f\"{DATASET_NAME}-reward-function\"\n",
    "LAMBDA_ROLE_NAME = f\"{DATASET_NAME.upper()}-Lambda-Role\"\n",
    "BEDROCK_ROLE_NAME = f\"BedrockRFT-{DATASET_NAME}-Role\"\n",
    "REWARD_FUNCTION_FILE = f\"../../reward-functions/{DATASET_NAME}_rew_func.py\"\n",
    "REWARD_FUNCTION_MODULE = f\"{DATASET_NAME}_rew_func\"\n",
    "\n",
    "# Model configuration\n",
    "BASE_MODEL_ID = f\"arn:aws:bedrock:{AWS_REGION}::foundation-model/amazon.nova-2-lite-v1:0:256k\"\n",
    "\n",
    "# Initialize AWS clients\n",
    "s3_client = session.client('s3')\n",
    "bedrock_client = session.client('bedrock')\n",
    "lambda_client = session.client('lambda')\n",
    "iam_client = session.client('iam')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "config-and-data",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_size(n):\n",
    "    \"\"\"Format sample count as human-readable string (e.g., 7k, 1.2k).\"\"\"\n",
    "    if n >= 1000:\n",
    "        return f\"{n/1000:.0f}k\" if n % 1000 == 0 else f\"{n/1000:.1f}k\"\n",
    "    return str(n)\n",
    "\n",
    "# --- Preprocess GSM8K ---\n",
    "def preprocess_gsm8k(hf_path, total_samples, output_dir, train_ratio=0.8, val_ratio=0.1):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    ds = load_dataset(hf_path, \"main\")\n",
    "\n",
    "    # Use all data if total_samples is None\n",
    "    available = len(ds[\"train\"])\n",
    "    total = min(total_samples, available) if total_samples else available\n",
    "\n",
    "    train_size = int(total * train_ratio)\n",
    "    val_size = int(total * val_ratio)\n",
    "    test_size = total - train_size - val_size\n",
    "\n",
    "    def extract_answer(answer_text):\n",
    "        match = re.search(r'####\\s*(-?\\d+(?:,\\d+)*)', answer_text)\n",
    "        return match.group(1).replace(',', '') if match else \"\"\n",
    "\n",
    "    def format_row(row, idx, split):\n",
    "        final_answer = extract_answer(row['answer'])\n",
    "\n",
    "        # Extract reasoning steps from the answer\n",
    "        steps = []\n",
    "        if '####' in row['answer']:\n",
    "            reasoning_part = row['answer'].split('####')[0].strip()\n",
    "            steps = [s.strip() for s in reasoning_part.split('\\n') if s.strip()]\n",
    "\n",
    "        return {\n",
    "            \"messages\": [\n",
    "                {\"role\": \"system\", \"content\": \"You are a helpful math tutor who solves word problems step by step.\"},\n",
    "                {\"role\": \"user\", \"content\": f\"{row['question']} Let's think step by step and output the final answer after \\\"####\\\".\"}\n",
    "            ],\n",
    "            \"reference_answer\": {\n",
    "                \"final_answer\": final_answer,\n",
    "                \"steps\": steps if steps else None\n",
    "            },\n",
    "            \"task_id\": f\"gsm8k_{split}_{idx}\",\n",
    "            \"domain\": \"math\",\n",
    "            \"difficulty_level\": \"grade_school\",\n",
    "            \"data_source\": hf_path,\n",
    "            \"original_question\": row['question'],\n",
    "            \"original_answer\": row['answer']\n",
    "        }\n",
    "\n",
    "    def write_split(data, start_idx, size, filename, split_name):\n",
    "        with open(f\"{output_dir}/{filename}\", \"w\") as f:\n",
    "            for i, row in enumerate(data.select(range(start_idx, start_idx + size))):\n",
    "                f.write(json.dumps(format_row(row, i, split_name)) + \"\\n\")\n",
    "        print(f\"✓ Created {output_dir}/{filename} ({size} samples)\")\n",
    "\n",
    "    hf_train = ds[\"train\"].shuffle(seed=42)\n",
    "    write_split(hf_train, 0, train_size, \"train.jsonl\", \"train\")\n",
    "    write_split(hf_train, train_size, val_size, \"val.jsonl\", \"val\")\n",
    "    write_split(hf_train, train_size + val_size, test_size, \"test.jsonl\", \"test\")\n",
    "\n",
    "    return train_size, val_size, test_size\n",
    "\n",
    "print(\"Preprocessing GSM8K dataset...\")\n",
    "train_size, val_size, test_size = preprocess_gsm8k(HF_DATASET, TOTAL_SAMPLES, LOCAL_DATA_DIR)\n",
    "\n",
    "# S3 paths with sample counts in filenames\n",
    "S3_TRAINING_DATA = f\"s3://{S3_BUCKET}/rft-data/datasets/{DATASET_NAME}/train-{format_size(train_size)}.jsonl\"\n",
    "S3_VALIDATION_DATA = f\"s3://{S3_BUCKET}/rft-data/datasets/{DATASET_NAME}/val-{format_size(val_size)}.jsonl\"\n",
    "S3_TEST_DATA = f\"s3://{S3_BUCKET}/rft-data/datasets/{DATASET_NAME}/test-{format_size(test_size)}.jsonl\"\n",
    "\n",
    "print(\"\\nUploading to S3...\")\n",
    "for local_file, s3_uri in [\n",
    "    (\"train.jsonl\", S3_TRAINING_DATA),\n",
    "    (\"val.jsonl\", S3_VALIDATION_DATA),\n",
    "    (\"test.jsonl\", S3_TEST_DATA)\n",
    "]:\n",
    "    s3_key = '/'.join(s3_uri.split('/')[3:])\n",
    "    s3_client.upload_file(f\"{LOCAL_DATA_DIR}/{local_file}\", S3_BUCKET, s3_key)\n",
    "    print(f\"✓ Uploaded {s3_uri.split('/')[-1]}\")\n",
    "\n",
    "print(f\"\\n✓ Ready | {train_size} train / {val_size} val / {test_size} test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c658dc-cbc5-410a-8162-03019e887ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up temporary local data\n",
    "import shutil\n",
    "\n",
    "print(\"\\nCleaning up temporary files...\")\n",
    "if os.path.exists(LOCAL_DATA_DIR):\n",
    "    shutil.rmtree(LOCAL_DATA_DIR)\n",
    "    print(f\"✓ Removed {LOCAL_DATA_DIR}\")\n",
    "else:\n",
    "    print(f\"✓ No temporary files to clean\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-2",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Deploy the Reward Function\n",
    "\n",
    "The reward function is the \"coach\" in our RFT setup. During training, Bedrock generates candidate responses and sends them to this Lambda. The Lambda extracts the model's answer, compares it to the ground truth, and returns a score (1.0 for correct, 0.0 for wrong).\n",
    "\n",
    "We also create the IAM roles that Bedrock and Lambda need to do their jobs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deploy-lambda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Lambda execution role\n",
    "print(\"Creating Lambda execution role...\")\n",
    "\n",
    "lambda_trust_policy = {\n",
    "    \"Version\": \"2012-10-17\",\n",
    "    \"Statement\": [{\"Effect\": \"Allow\", \"Principal\": {\"Service\": \"lambda.amazonaws.com\"}, \"Action\": \"sts:AssumeRole\"}]\n",
    "}\n",
    "\n",
    "try:\n",
    "    response = iam_client.create_role(\n",
    "        RoleName=LAMBDA_ROLE_NAME,\n",
    "        AssumeRolePolicyDocument=json.dumps(lambda_trust_policy),\n",
    "        Description=f\"Execution role for {DATASET_NAME} reward function\"\n",
    "    )\n",
    "    lambda_role_arn = response['Role']['Arn']\n",
    "    iam_client.attach_role_policy(RoleName=LAMBDA_ROLE_NAME, PolicyArn='arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole')\n",
    "    print(f\"✓ Created role: {LAMBDA_ROLE_NAME}\")\n",
    "    print(\"Waiting 10s for role propagation...\")\n",
    "    time.sleep(10)\n",
    "except iam_client.exceptions.EntityAlreadyExistsException:\n",
    "    lambda_role_arn = iam_client.get_role(RoleName=LAMBDA_ROLE_NAME)['Role']['Arn']\n",
    "    print(f\"✓ Using existing role: {LAMBDA_ROLE_NAME}\")\n",
    "\n",
    "# Package and deploy Lambda\n",
    "lambda_zip_content = create_lambda_deployment_package(\n",
    "    source_file=REWARD_FUNCTION_FILE,\n",
    "    zip_filename=\"lambda_deployment.zip\",\n",
    "    archive_name=f\"{REWARD_FUNCTION_MODULE}.py\"\n",
    ")\n",
    "\n",
    "print(f\"\\nDeploying Lambda: {LAMBDA_FUNCTION_NAME}...\")\n",
    "try:\n",
    "    lambda_client.get_function(FunctionName=LAMBDA_FUNCTION_NAME)\n",
    "    lambda_client.update_function_code(FunctionName=LAMBDA_FUNCTION_NAME, ZipFile=lambda_zip_content)\n",
    "    waiter = lambda_client.get_waiter('function_updated_v2')\n",
    "    waiter.wait(FunctionName=LAMBDA_FUNCTION_NAME)\n",
    "    print(\"✓ Updated existing function\")\n",
    "except lambda_client.exceptions.ResourceNotFoundException:\n",
    "    lambda_client.create_function(\n",
    "        FunctionName=LAMBDA_FUNCTION_NAME,\n",
    "        Runtime='python3.11',\n",
    "        Role=lambda_role_arn,\n",
    "        Handler=f\"{REWARD_FUNCTION_MODULE}.lambda_handler\",\n",
    "        Code={'ZipFile': lambda_zip_content},\n",
    "        Timeout=300,\n",
    "        MemorySize=512\n",
    "    )\n",
    "    print(\"✓ Created new function\")\n",
    "\n",
    "waiter = lambda_client.get_waiter('function_active_v2')\n",
    "waiter.wait(FunctionName=LAMBDA_FUNCTION_NAME)\n",
    "lambda_arn = lambda_client.get_function(FunctionName=LAMBDA_FUNCTION_NAME)['Configuration']['FunctionArn']\n",
    "print(f\"✓ Lambda ready: {lambda_arn}\")\n",
    "\n",
    "# Create Bedrock role\n",
    "print(f\"\\nCreating Bedrock role: {BEDROCK_ROLE_NAME}...\")\n",
    "\n",
    "bedrock_trust_policy = {\n",
    "    \"Version\": \"2012-10-17\",\n",
    "    \"Statement\": [{\"Effect\": \"Allow\", \"Principal\": {\"Service\": \"bedrock.amazonaws.com\"}, \"Action\": \"sts:AssumeRole\"}]\n",
    "}\n",
    "\n",
    "bedrock_permissions = {\n",
    "    \"Version\": \"2012-10-17\",\n",
    "    \"Statement\": [\n",
    "        {\"Effect\": \"Allow\", \"Action\": [\"s3:GetObject\", \"s3:ListBucket\"], \"Resource\": [f\"arn:aws:s3:::{S3_BUCKET}/*\", f\"arn:aws:s3:::{S3_BUCKET}\"]},\n",
    "        {\"Effect\": \"Allow\", \"Action\": \"s3:PutObject\", \"Resource\": f\"arn:aws:s3:::{S3_BUCKET}/rft-output/*\"},\n",
    "        {\"Effect\": \"Allow\", \"Action\": \"lambda:InvokeFunction\", \"Resource\": lambda_arn}\n",
    "    ]\n",
    "}\n",
    "\n",
    "try:\n",
    "    response = iam_client.create_role(\n",
    "        RoleName=BEDROCK_ROLE_NAME,\n",
    "        AssumeRolePolicyDocument=json.dumps(bedrock_trust_policy),\n",
    "        Description=\"Execution role for Bedrock RFT\"\n",
    "    )\n",
    "    bedrock_role_arn = response['Role']['Arn']\n",
    "    print(f\"✓ Created role: {BEDROCK_ROLE_NAME}\")\n",
    "except iam_client.exceptions.EntityAlreadyExistsException:\n",
    "    bedrock_role_arn = iam_client.get_role(RoleName=BEDROCK_ROLE_NAME)['Role']['Arn']\n",
    "    print(f\"✓ Using existing role: {BEDROCK_ROLE_NAME}\")\n",
    "\n",
    "iam_client.put_role_policy(RoleName=BEDROCK_ROLE_NAME, PolicyName='BedrockRFTPermissions', PolicyDocument=json.dumps(bedrock_permissions))\n",
    "print(f\"✓ Bedrock role ready: {bedrock_role_arn}\")\n",
    "\n",
    "cleanup_lambda_deployment_package()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-3",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Test the Reward Function\n",
    "\n",
    "Before kicking off a multi-hour training job, let's make sure our reward function actually works. We'll send it a sample response and verify it returns the expected score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "test-lambda",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Testing reward function...\")\n",
    "\n",
    "test_payload = [{\n",
    "    \"id\": \"test_001\",\n",
    "    \"messages\": [\n",
    "        {\"role\": \"user\", \"content\": \"What is 2 + 2?\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"Let me solve this step by step.\\n\\n2 + 2 = 4\\n\\n#### 4\"}\n",
    "    ],\n",
    "    \"metadata\": {\"reference_answer\": {\"final_answer\": \"4\"}}\n",
    "}]\n",
    "\n",
    "response = lambda_client.invoke(\n",
    "    FunctionName=LAMBDA_FUNCTION_NAME,\n",
    "    InvocationType='RequestResponse',\n",
    "    Payload=json.dumps(test_payload)\n",
    ")\n",
    "\n",
    "result = json.loads(response['Payload'].read())\n",
    "print(json.dumps(result, indent=2))\n",
    "\n",
    "if 'errorMessage' in result:\n",
    "    print(f\"\\n✗ Error: {result['errorMessage']}\")\n",
    "elif isinstance(result, list) and result[0].get('aggregate_reward_score') == 1.0:\n",
    "    print(\"\\n✓ Reward function working correctly!\")\n",
    "else:\n",
    "    print(\"\\n⚠ Unexpected result - check the output above\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "test-real-data-md",
   "metadata": {},
   "source": [
    "### Test with Real Training & Validation Data\n",
    "\n",
    "Let's verify the reward function works correctly with actual samples from our dataset by simulating correct model responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "test-real-data",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def load_samples_from_s3(s3_uri, n=5):\n",
    "    bucket = s3_uri.split('/')[2]\n",
    "    key = '/'.join(s3_uri.split('/')[3:])\n",
    "    obj = s3_client.get_object(Bucket=bucket, Key=key)\n",
    "    lines = obj['Body'].read().decode('utf-8').strip().split('\\n')\n",
    "    return [json.loads(line) for line in random.sample(lines, min(n, len(lines)))]\n",
    "\n",
    "def simulate_correct_response(sample):\n",
    "    \"\"\"Add an assistant message with the correct answer.\"\"\"\n",
    "    answer = sample['reference_answer']['final_answer']\n",
    "    sample_copy = sample.copy()\n",
    "    sample_copy['messages'] = sample['messages'] + [\n",
    "        {'role': 'assistant', 'content': f'Working through this step by step...\\n\\n#### {answer}'}\n",
    "    ]\n",
    "    return sample_copy\n",
    "\n",
    "print('Loading samples from S3...')\n",
    "train_samples = load_samples_from_s3(S3_TRAINING_DATA, n=5)\n",
    "val_samples = load_samples_from_s3(S3_VALIDATION_DATA, n=5)\n",
    "\n",
    "# Simulate correct responses\n",
    "test_payloads = [simulate_correct_response(s) for s in train_samples + val_samples]\n",
    "\n",
    "print(f'Testing {len(test_payloads)} samples (5 train + 5 val)...')\n",
    "response = lambda_client.invoke(\n",
    "    FunctionName=LAMBDA_FUNCTION_NAME,\n",
    "    InvocationType='RequestResponse',\n",
    "    Payload=json.dumps(test_payloads)\n",
    ")\n",
    "results = json.loads(response['Payload'].read())\n",
    "\n",
    "print('\\nResults:')\n",
    "for r in results:\n",
    "    score = r.get('aggregate_reward_score', 0)\n",
    "    status = '✓' if score == 1.0 else '✗'\n",
    "    print(f\"  {status} {r['id']}: {score}\")\n",
    "\n",
    "total_score = sum(r.get('aggregate_reward_score', 0) for r in results)\n",
    "print(f'\\nTotal: {total_score}/{len(results)} correct')\n",
    "\n",
    "if total_score == len(results):\n",
    "    print('✓ All samples scored correctly!')\n",
    "else:\n",
    "    print('⚠ Some samples failed - check reward function logic')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hyperparams-analysis-md",
   "metadata": {},
   "source": [
    "### Analyze Dataset for Hyperparameter Selection\n",
    "\n",
    "Before training, let's analyze our dataset to set appropriate values for `maxPromptLength` and `inferenceMaxTokens`.\n",
    "\n",
    "**Key hyperparameters to consider:**\n",
    "\n",
    "| Parameter | What it controls | Trade-off |\n",
    "|-----------|-----------------|-----------|\n",
    "| `maxPromptLength` | Max tokens for input prompts | Higher = more context, but more memory & slower training |\n",
    "| `inferenceMaxTokens` | Max tokens the model can generate per response | Higher = longer reasoning chains, but slower & more expensive |\n",
    "| `trainingSamplePerPrompt` | Number of response samples per prompt | More samples = better reward estimation, but slower |\n",
    "| `batchSize` | Samples per training batch | Larger = more stable gradients, but more memory |\n",
    "| `epochCount` | Full passes through the dataset | More epochs = more learning, but risk of overfitting |\n",
    "| `reasoningEffort` | How much \"thinking\" the model does | Higher = better quality, but slower inference |\n",
    "\n",
    "**For GSM8K specifically:**\n",
    "- Prompts are relatively short (math word problems)\n",
    "- Responses need room for step-by-step reasoning + final answer\n",
    "- We want `inferenceMaxTokens` large enough for multi-step solutions, but not wastefully large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hyperparams-analysis",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install tiktoken\n",
    "import tiktoken\n",
    "\n",
    "# Load tokenizer (cl100k_base is close to Nova's tokenizer)\n",
    "try:\n",
    "    enc = tiktoken.get_encoding('cl100k_base')\n",
    "except:\n",
    "    %pip install -q tiktoken\n",
    "    import tiktoken\n",
    "    enc = tiktoken.get_encoding('cl100k_base')\n",
    "\n",
    "def count_tokens(text):\n",
    "    return len(enc.encode(text))\n",
    "\n",
    "# Load all training samples\n",
    "print('Analyzing training data...')\n",
    "obj = s3_client.get_object(Bucket=S3_BUCKET, Key='/'.join(S3_TRAINING_DATA.split('/')[3:]))\n",
    "samples = [json.loads(line) for line in obj['Body'].read().decode('utf-8').strip().split('\\n')]\n",
    "\n",
    "# Calculate token counts\n",
    "prompt_tokens = []\n",
    "answer_tokens = []\n",
    "\n",
    "for s in samples:\n",
    "    # Prompt = system + user messages\n",
    "    prompt_text = ' '.join(m['content'] for m in s['messages'])\n",
    "    prompt_tokens.append(count_tokens(prompt_text))\n",
    "\n",
    "    # Reference answer (what we expect the model to produce)\n",
    "    answer_tokens.append(count_tokens(s['original_answer']))\n",
    "\n",
    "# Statistics\n",
    "import statistics\n",
    "\n",
    "print(f'\\nDataset Statistics ({len(samples)} samples)')\n",
    "print(f'\\nPrompt tokens (input):')\n",
    "print(f'  Min: {min(prompt_tokens)}, Max: {max(prompt_tokens)}, Mean: {statistics.mean(prompt_tokens):.0f}')\n",
    "print(f'  P95: {sorted(prompt_tokens)[int(len(prompt_tokens)*0.95)]}, P99: {sorted(prompt_tokens)[int(len(prompt_tokens)*0.99)]}')\n",
    "\n",
    "print(f'\\nAnswer tokens (expected output):')\n",
    "print(f'  Min: {min(answer_tokens)}, Max: {max(answer_tokens)}, Mean: {statistics.mean(answer_tokens):.0f}')\n",
    "print(f'  P95: {sorted(answer_tokens)[int(len(answer_tokens)*0.95)]}, P99: {sorted(answer_tokens)[int(len(answer_tokens)*0.99)]}')\n",
    "\n",
    "# Recommendations\n",
    "recommended_prompt_len = sorted(prompt_tokens)[int(len(prompt_tokens)*0.99)] * 2  # 2x P99 for safety\n",
    "recommended_max_tokens = sorted(answer_tokens)[int(len(answer_tokens)*0.99)] * 3  # 3x P99 for reasoning\n",
    "\n",
    "print(f'\\nRecommended hyperparameters:')\n",
    "print(f'  maxPromptLength: {recommended_prompt_len} (2x P99 prompt length)')\n",
    "print(f'  inferenceMaxTokens: {recommended_max_tokens} (3x P99 answer length, room for reasoning)')\n",
    "print(f'\\nNote: inferenceMaxTokens should be higher than reference answers since the model')\n",
    "print(f'      may generate longer reasoning chains during exploration.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-4",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Start the RFT Training Job\n",
    "\n",
    "Now for the main event. We'll create a model customization job that:\n",
    "- Takes our base Nova model\n",
    "- Trains it on GSM8K using reinforcement learning\n",
    "- Uses our Lambda to score responses\n",
    "\n",
    "Training typically takes several hours depending on dataset size and hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "create-job",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Creating RFT training job...\")\n",
    "\n",
    "# Generate unique model/job names with date and key hyperparams\n",
    "from datetime import datetime\n",
    "date_str = datetime.now().strftime('%Y%m%d')\n",
    "hp_suffix = f\"e{1}_bs{32}_lr{5e-5}\".replace('.', '').replace('-', '')  # e1_bs32_lr5e05\n",
    "CUSTOM_MODEL_NAME = f\"{DATASET_NAME}-nova-rft-{date_str}-{hp_suffix}\"\n",
    "JOB_NAME = f\"{DATASET_NAME}-rft-{date_str}-{int(time.time())}\"\n",
    "\n",
    "print(f\"  Job: {JOB_NAME}\")\n",
    "print(f\"  Model: {CUSTOM_MODEL_NAME}\")\n",
    "print(f\"  Base: {BASE_MODEL_ID}\")\n",
    "\n",
    "response = bedrock_client.create_model_customization_job(\n",
    "    jobName=JOB_NAME,\n",
    "    customModelName=CUSTOM_MODEL_NAME,\n",
    "    roleArn=bedrock_role_arn,\n",
    "    baseModelIdentifier=BASE_MODEL_ID,\n",
    "    customizationType='REINFORCEMENT_FINE_TUNING',\n",
    "    trainingDataConfig={'s3Uri': S3_TRAINING_DATA},\n",
    "    validationDataConfig={'validators': [{'s3Uri': S3_VALIDATION_DATA}]},\n",
    "    outputDataConfig={'s3Uri': S3_OUTPUT_PATH},\n",
    "    customizationConfig={\n",
    "        'rftConfig': {\n",
    "            'graderConfig': {'lambdaGrader': {'lambdaArn': lambda_arn}},\n",
    "            'hyperParameters': {\n",
    "                'batchSize': 32, # Balances stability with enough updates. If training seems unstable (reward oscillating wildly), try increasing to 64. If you want faster iteration during experimentation, you could try 16.\n",
    "                'epochCount': 1, # Start with 1, if validation rewards still increasing at the end of training, increase. Risk of overfitting otherwise as gsm8k isn't a large dataset.\n",
    "                'evalInterval': 10, # Defined across training steps (6k training samples / 32 batch size = ~188 steps per epoch)\n",
    "                'inferenceMaxTokens': 750,\n",
    "                'learningRate': 0.00005,\n",
    "                'maxPromptLength': 310,\n",
    "                'reasoningEffort': 'high',\n",
    "                'trainingSamplePerPrompt': 4 # With 6k training prompts, means that our model is seeing 24k responses per epoch.\n",
    "            }\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "print(f\"\\n✓ Job created: {response['jobArn']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-5",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Monitor Training Progress\n",
    "\n",
    "Run this cell periodically to check on your training job. Status will progress through: `InProgress` → `Completed` (or `Failed`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "monitor-job",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = bedrock_client.get_model_customization_job(jobIdentifier=JOB_NAME)\n",
    "print(f\"Job: {JOB_NAME}\")\n",
    "print(f\"Status: {response['status']}\")\n",
    "\n",
    "if response['status'] == 'Completed' and 'outputModelArn' in response:\n",
    "    print(f\"\\n✓ Training complete!\")\n",
    "    print(f\"  Model ARN: {response['outputModelArn']}\")\n",
    "elif response['status'] == 'Failed':\n",
    "    print(f\"\\n✗ Training failed: {response.get('failureMessage', 'Unknown error')}\")\n",
    "elif response['status'] == 'InProgress':\n",
    "    print(\"\\nStill training... run this cell again to check progress\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24bdc824-c8fe-4e51-977d-9911d8a3b586",
   "metadata": {},
   "source": [
    "\n",
    "## Conclusion\n",
    "\n",
    "Congratulations, you've successfully launched a Reinforcement Fine-Tuning job for Amazon Nova on the GSM8K math dataset.\n",
    "\n",
    "### What You've Built\n",
    "\n",
    "- **Preprocessed GSM8K dataset** into Bedrock RFT format  \n",
    "- **Deployed a Lambda reward function** that scores model responses  \n",
    "- **Created IAM roles** for Lambda and Bedrock execution  \n",
    "- **Started an RFT training job** with customized hyperparameters  \n",
    "\n",
    "### Next Steps\n",
    "\n",
    "Once your training job completes (check status in cell above):\n",
    "\n",
    "1. **Test your fine-tuned model** via the Bedrock API using the model ARN\n",
    "2. **Evaluate performance** on the held-out test set (`test.jsonl`)\n",
    "3. **Compare results** against the base Nova model\n",
    "4. **Experiment with hyperparameters** (learning rate, batch size, epochs) for better performance\n",
    "\n",
    "\n",
    "### Learn More\n",
    "\n",
    "- [Amazon Bedrock RFT Documentation](https://docs.aws.amazon.com/bedrock/latest/userguide/reinforcement-fine-tuning.html)\n",
    "- [Amazon Nova 2 Lite](https://docs.aws.amazon.com/ai/responsible-ai/nova-2-lite/overview.html)\n",
    "- [GSM8K Dataset on HuggingFace](https://huggingface.co/datasets/openai/gsm8k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "596f6545",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rft-env",
   "language": "python",
   "name": "rft-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
