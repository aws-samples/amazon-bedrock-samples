{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a899bfb2-fa00-482e-ab5a-f97daa18d876",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-20T23:22:21.289317Z",
     "iopub.status.busy": "2025-01-20T23:22:21.288559Z",
     "iopub.status.idle": "2025-01-20T23:22:21.296763Z",
     "shell.execute_reply": "2025-01-20T23:22:21.295537Z",
     "shell.execute_reply.started": "2025-01-20T23:22:21.289288Z"
    }
   },
   "source": [
    "# Extract and analyze a movie"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "259074a6-a277-4247-a8d1-faa44d0020bf",
   "metadata": {},
   "source": [
    "Industries such as Media & Entertainment, Advertising and Sports manage vast inventories of professionally produced videos, including TV shows, movies, news, sports events, documentaries, and more. To effectively extract insights from this type of video content, users require information such as video summaries, scene-level analysis, IAB classifications for ad targeting, and speaker identification.\n",
    "\n",
    "> [IAB categories](https://smartclip.tv/adtech-glossary/iab-categories/) are standard classifications for web content that are developed by the Interactive Advertising Bureau (IAB). These categories are used to sort advertisers into industries and segments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9cba547-3ef6-4194-a2e6-315e5abe7963",
   "metadata": {},
   "source": [
    "In this lab, we will use BDA Video to extract and analyze a sample open-source movie Meridian, walking through the process and exploring the generated outputs.\n",
    "![video moderation](../static/bda-video-scene.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a87659b5-90c4-40a4-9c03-931d70ab8955",
   "metadata": {},
   "source": [
    "## Prerequisits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf31c6e-182c-4998-83ce-f60ed4f53b38",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%pip install \"boto3>=1.35.76\" itables==2.2.4 PyPDF2==3.0.1 --upgrade -qq\n",
    "%pip install moviepy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "846d3478-84a7-4c29-a5e6-4a3f6c686d4b",
   "metadata": {},
   "source": [
    "For a self-hosted workshop, we recommend creating a new S3 bucket in the same region where you plan to run the workshop. You can name it `bda-workshop-YOUR_ACCOUNT_ID-YOUR_REGION`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dadc3186-7df3-4e5f-ae7d-2522ce275209",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_bucket = \"<Enter your bucket name here>\"\n",
    "data_prefix = \"bad-workshop/video\"\n",
    "output_prefix = \"bad-workshop/video/ouput\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b94080f3-7a23-4b04-898d-57be31c638a4",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "import uuid\n",
    "import utils\n",
    "\n",
    "bda_client = boto3.client('bedrock-data-automation')\n",
    "bda_runtime_client = boto3.client('bedrock-data-automation-runtime')\n",
    "s3_client = boto3.client('s3')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa554a34-ae81-4802-9ca5-b4a40e759f7e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-21T00:31:53.506949Z",
     "iopub.status.busy": "2025-01-21T00:31:53.506589Z",
     "iopub.status.idle": "2025-01-21T00:31:53.513035Z",
     "shell.execute_reply": "2025-01-21T00:31:53.511550Z",
     "shell.execute_reply.started": "2025-01-21T00:31:53.506925Z"
    }
   },
   "source": [
    "## Create a BDA project with a standard output configuration for videos\n",
    "To start a BDA job, you need a BDA project, which organizes both standard and custom output configurations. This project is reusable, allowing you to apply the same configuration to process multiple videos that share the same settings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "431eeea0-12c1-4cd7-8e40-f8c3d8b3f8be",
   "metadata": {},
   "source": [
    "In the code snippet below, we create a BDA project with standard output configurations for video modality. These configurations can be tailored to extract only the specific information you need. In this lab, we will enable the below video outputs:\n",
    "- Full video summary\n",
    "- Scene summaries\n",
    "- IAB categories on the scene level\n",
    "- Full audio transcript\n",
    "- Text in video with bounding-boxes\n",
    "\n",
    "For a complete API reference for creating a BDA project, refer to this [document](https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/bedrock-data-automation/client/create_data_automation_project.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2510f5-f4f2-4fdd-ac96-4d9edbeeba42",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = bda_client.create_data_automation_project(\n",
    "    projectName=f'bda-workshop-video-project-{str(uuid.uuid4())[0:4]}',\n",
    "    projectDescription='BDA workshop video sample project',\n",
    "    projectStage='DEVELOPMENT',\n",
    "    standardOutputConfiguration={\n",
    "        'video': {\n",
    "            'extraction': {\n",
    "                'category': {\n",
    "                    'state': 'ENABLED',\n",
    "                    'types': ['TEXT_DETECTION','TRANSCRIPT'],\n",
    "                },\n",
    "                'boundingBox': {\n",
    "                    'state': 'ENABLED',\n",
    "                }\n",
    "            },\n",
    "            'generativeField': {\n",
    "                'state': 'ENABLED',\n",
    "                'types': ['VIDEO_SUMMARY','SCENE_SUMMARY','IAB'],\n",
    "            }\n",
    "        }\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c1dfd78-a072-4375-b970-d2650909f0de",
   "metadata": {},
   "source": [
    "The create_data_automation_project API will return the project ARN, which we will use it to invoke the video analysis task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e824ab6c-5249-4364-927c-c5def65a32a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_project_arn = response.get(\"projectArn\")\n",
    "print(\"BDA video project ARN:\", video_project_arn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b81791-e597-457f-a375-265bc0711525",
   "metadata": {},
   "source": [
    "## Start an asynchronous BDA task to extract and analyze a movie\n",
    "In this section, we will use a open-source movie Meridian, and extract and analyze it using BDA, applying the configuration defined in the BDA project. We will then review the output to gain a deeper understanding of how BDA performs video extraction and analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6fd5d08-0be9-495e-bdc3-27e2b68c0e55",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-21T01:16:19.221297Z",
     "iopub.status.busy": "2025-01-21T01:16:19.220673Z",
     "iopub.status.idle": "2025-01-21T01:16:19.225680Z",
     "shell.execute_reply": "2025-01-21T01:16:19.224891Z",
     "shell.execute_reply.started": "2025-01-21T01:16:19.221270Z"
    }
   },
   "source": [
    "### Prepare the sample video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bad7889-a3a7-4c82-9766-eb5ecb94acf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_video_movie = './NetflixMeridian.mp4'\n",
    "!curl \"https://d1xvhy22zmw77y.cloudfront.net/tmp/NetflixMeridian.mp4\" --output NetflixMeridian.mp4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "462b8628-c692-4385-9725-48c4ea3b70cc",
   "metadata": {},
   "source": [
    "Let's display the video. [Meridian](https://en.wikipedia.org/wiki/Meridian_(film)) is a test movie from Netflix, we use it to showcase how BDA works with video extraction. As you can see, it is a classic-style movie composed of multiple scenes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd61670-4a65-471a-a75b-14525d923af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Video\n",
    "Video(sample_video_movie, width=800)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "591cf849-11ec-4c37-a3dc-e1bb5c51c92e",
   "metadata": {},
   "source": [
    "To analyze the video using BDA, we need to upload it to an S3 bucket that BDA can access. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9717c142-df4d-4d34-8a98-8f36a5671fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_key = f'{data_prefix}/{sample_video_movie.split(\"/\")[-1]}'\n",
    "s3_client.upload_file(sample_video_movie, data_bucket, s3_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c40b33c9-a23c-4dd3-8f66-22d169e598b7",
   "metadata": {},
   "source": [
    "### Start BDA task\n",
    "We will now invoke the BDA API to process the uploaded video. You need to provide the BDA project ARN that we created at the beginning of the lab and specify an S3 location where BDA will store the output results.\n",
    "\n",
    "For a complete API reference for invoke a BDA async task, refer to this [document](https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/bedrock-data-automation-runtime/client/invoke_data_automation_async.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "681293ae-0023-4eac-9970-af61ec934e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = bda_runtime_client.invoke_data_automation_async(\n",
    "    inputConfiguration={\n",
    "        's3Uri': f's3://{data_bucket}/{s3_key}'\n",
    "    },\n",
    "    outputConfiguration={\n",
    "        's3Uri': f's3://{data_bucket}/{output_prefix}'\n",
    "    },\n",
    "    dataAutomationConfiguration={\n",
    "        'dataAutomationArn': video_project_arn,\n",
    "        'stage': 'DEVELOPMENT'\n",
    "    },\n",
    "    notificationConfiguration={\n",
    "        'eventBridgeConfiguration': {\n",
    "            'eventBridgeEnabled': False\n",
    "        }\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c8b65a-1e4e-4dc1-b011-254e7d1cc941",
   "metadata": {},
   "source": [
    "The `invoke_data_automation_async` API is asynchronous. It returns an invocation task identifier, `invocationArn`. We can then use another API `get_data_automation_status` to monitor the task's status until it completes.\n",
    "\n",
    "> In production workloads, an event-driven pattern is recommended. Allow BDA to trigger the next step once the task is complete. This can be achieved by configuring the notificationConfiguration in the invoke task, which will send a notification to a subscribed AWS service, such as a Lambda function. Alternatively, you can set up an S3 trigger on the bucket where BDA will drop the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61061730-ded4-4852-bbf4-d18ab1168c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "invocation_arn = response.get(\"invocationArn\")\n",
    "print(\"BDA task started:\", invocation_arn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d13518bf-15eb-4e83-bc4b-955b66974457",
   "metadata": {},
   "source": [
    "In this lab, we will use the loop below to monitor the task by calling the `get_data_automation_status` API every 5 seconds until the task is complete.\n",
    "\n",
    "This video will take ~5-10 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb9c48c-9347-43ba-8148-1ea9c29479fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from IPython.display import clear_output\n",
    "from datetime import datetime\n",
    "\n",
    "status, status_response = None, None\n",
    "while status not in [\"Success\",\"ServiceError\",\"ClientError\"]:\n",
    "    status_response = bda_runtime_client.get_data_automation_status(\n",
    "        invocationArn=invocation_arn\n",
    "    )\n",
    "    status = status_response.get(\"status\")\n",
    "    clear_output(wait=True)\n",
    "    print(f\"{datetime.now().strftime('%H:%M:%S')} : BDA video task: {status}\")\n",
    "    time.sleep(5)\n",
    "\n",
    "output_config = status_response.get(\"outputConfiguration\",{}).get(\"s3Uri\")\n",
    "print(\"Ouput configureation file:\", output_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c617c2-3a71-43dd-b996-d7b9a4d86f08",
   "metadata": {},
   "source": [
    "## Access the BDA analysis result\n",
    "The `get_data_automation_status` API returns an S3 URI containing the result configuration, which provides the S3 location where BDA outputs the extraction results. We will then parse this file to retrieve the result path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e1adb7-1620-491f-adb1-b616451d62be",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "config_data = utils.read_json_on_s3(output_config,s3_client)\n",
    "print(json.dumps(config_data, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08dc0557-b53d-4dc4-ae1c-05de559093e7",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "As shown above, the BDA output configuration file contains metadata about the BDA result, including the job ID, status, modality, and the S3 location of the actual result JSON. We will now download this result file to verify the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc93edb4-e459-4c00-aeb6-31577240aabe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import JSON\n",
    "\n",
    "result_uri = config_data[\"output_metadata\"][0][\"segment_metadata\"][0][\"standard_output_path\"]\n",
    "result_data = utils.read_json_on_s3(result_uri,s3_client)\n",
    "\n",
    "JSON(result_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc2b413-3f1c-4225-8f60-01c00a256110",
   "metadata": {},
   "source": [
    "## Review the result\n",
    "The BDA video analysis result contains a detailed breakdown of information, organized by video and scene level.\n",
    "> A video scene is a sequence of shots that form a coherent unit of action or narrative within the video."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6e9aaec-d8a1-4b0d-9cb1-fdfcd85cb694",
   "metadata": {},
   "source": [
    "### Full video summary\n",
    "\n",
    "Let's take a look at the video level summary - it distills the key themes, events, and information presented throughout the video into a concise summary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b293b8fe-0db9-455a-9dfa-dd06a9063d0d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(result_data[\"video\"][\"summary\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8abfee39-d157-4b55-bc6b-6011b82579d5",
   "metadata": {},
   "source": [
    "### Full video transcription\n",
    "At the video level, we also receive the full transcript based on the video's audio, with speakers identified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "543bee0b-c95c-4082-9109-0bbf1fe69b96",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(result_data[\"video\"][\"transcript\"][\"representation\"][\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af915615-73b4-47c7-9ac4-c35637d028af",
   "metadata": {},
   "source": [
    "### Scene definition, summaries, and IAB categories \n",
    "BDA also generates a scene-level summary, as specified in the project configuration. Additionally, we get more metadata, including the start and end times of each scene, as well as the [IAB](https://en.wikipedia.org/wiki/Interactive_Advertising_Bureau) categories classified based on the scene content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e9fc8b5-fda1-47c9-99a6-d9cf9e5dcd24",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for scene in result_data[\"scenes\"]:\n",
    "    iabs = []\n",
    "    if scene.get(\"iab_categories\"):\n",
    "        for iab in scene[\"iab_categories\"]:\n",
    "            iabs.append(iab[\"category\"])\n",
    "        \n",
    "    print(f'[{scene[\"start_timecode_smpte\"]} - {scene[\"end_timecode_smpte\"]}] {\", \".join(iabs)}')\n",
    "    print(scene[\"summary\"])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a47d7a98-648d-4277-9ec7-8717b55211c4",
   "metadata": {},
   "source": [
    "### Granular audio transcripts\n",
    "Granular transcripts are also available at the scene level. Under each scene, you can find a list named `audio_segments` with associated timestamps. This can support additional downstream analysis that requires detailed transcript information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d2337c1-2a0b-40a9-81b7-1f3dfe1270bc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for scene in result_data[\"scenes\"]:\n",
    "    for trans in scene[\"audio_segments\"]:\n",
    "        print(f'[{trans[\"start_timestamp_millis\"]/1000} - {trans[\"end_timestamp_millis\"]/1000}] {trans[\"text\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de933514-e57b-45c7-9a7a-af12a528604b",
   "metadata": {},
   "source": [
    "### Frame level text extraction with bounding-boxes and confidence scores\n",
    "Text extraction, along with bounding boxes and confidence scores, is available at the frame level. In the output JSON structure, frames are organized under each scene with captured timestamp. If text is detected at a given frame, you can find text_words and text_lines included at the frame level.\n",
    "\n",
    "Let's plot the frames for a given scene with detected text, including their bounding boxes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207ed953-7356-4d09-a1ec-a941908446c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot all frames with boundingbox in the given scene\n",
    "scene_index = 1 \n",
    "\n",
    "width = result_data[\"metadata\"][\"frame_width\"]\n",
    "height = result_data[\"metadata\"][\"frame_height\"]\n",
    "\n",
    "from moviepy.video.io.VideoFileClip import VideoFileClip\n",
    "from PIL import Image, ImageDraw\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "with VideoFileClip(sample_video_movie) as video_clip:\n",
    "    for scene in result_data[\"scenes\"]:\n",
    "        if scene[\"scene_index\"] == scene_index:\n",
    "            for frame in scene[\"frames\"]:\n",
    "                bboxes = []\n",
    "                if frame.get(\"text_lines\"):\n",
    "                    for tl in frame[\"text_lines\"]:\n",
    "                        for l in tl[\"locations\"]:\n",
    "                            bbox = l[\"bounding_box\"]\n",
    "                            if bbox:\n",
    "                                bboxes.append((\n",
    "                                                width*bbox[\"left\"], \n",
    "                                                height*bbox[\"top\"], \n",
    "                                                width * (bbox[\"width\"]+bbox[\"left\"]), \n",
    "                                                height * (bbox[\"height\"] + bbox[\"top\"])\n",
    "                                            ))\n",
    "                if bboxes:\n",
    "                    timestamp = frame[\"timestamp_millis\"]/1000\n",
    "                    frame = video_clip.get_frame(timestamp)  \n",
    "                    frame_image = Image.fromarray(frame)\n",
    "                    draw = ImageDraw.Draw(frame_image)\n",
    "                    for box in bboxes:\n",
    "                        draw.rectangle(box, outline=\"red\", width=2)\n",
    "\n",
    "                    plt.figure(figsize=(10, 6))\n",
    "                    plt.imshow(frame_image)\n",
    "                    plt.title(f\"Frame at {timestamp} seconds with Bounding Boxes\")\n",
    "                    plt.axis(\"off\")\n",
    "                    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7ebc676-e867-4155-b136-556943b7a4b8",
   "metadata": {},
   "source": [
    "## Summary\n",
    "BDA video returns highly detailed metadata managed by the configuration. In this lab, we have enabled standard outputs required for media video analysis, using a movie as an example. You can explore the output JSON to discover more details. This lab does not cover moderation detection and analysis; for that, you can refer to the next lab, which uses a social media-style video as an example to better understand the moderation analysis offered by BDA video."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f626c2f-2994-4d5e-86f8-1084c319e9ea",
   "metadata": {},
   "source": [
    "## Clean up\n",
    "\n",
    "Delete the BDA project, blueprint, image, and result from S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31814f0d-5ae7-40d0-8344-4b50050e2358",
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete BDA project\n",
    "response = bda_client.delete_data_automation_project(\n",
    "    projectArn=video_project_arn\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e03d9f2c-74a7-4427-9632-836a9be25018",
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete uploaded image from S3\n",
    "s3_client.delete_object(Bucket=data_bucket, Key=s3_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4953074-9a5c-461b-893b-c5cbf4872b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete results from S3\n",
    "utils.delete_s3_folder(data_bucket, output_config.replace(\"job_metadata.json\",\"\") ,s3_client)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
