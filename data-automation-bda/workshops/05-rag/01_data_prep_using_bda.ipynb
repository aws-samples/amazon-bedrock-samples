{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28739f83-678f-4e76-bb40-af12caf8fac2",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Amazon Bedrock Knowledge Bases - Audio and Video Data Preparation using Amazon Bedrock Data Automation\n",
    "\n",
    "# Introduction\n",
    "\n",
    "This module demonstrates how to build a Multimodal Retrieval-Augmented Generation (RAG) application using Amazon Bedrock Data Automation (BDA) and Bedrock Knowledge Bases (KB). The application is designed to analyze and generate insights from multi-modalal data, including video and audio data. By incorporating contextual information from your own data sources with BDA, you can create highly accurate and secure intelligent search Generative AI applications.\n",
    "\n",
    "In this notebook, it shows the first step of building this intelligent search application: how to efficiently process video and audio data by using BDA to generate contextual outputs for KB embedding.\n",
    "\n",
    "With the latest integration between BDA and Amazon Bedrock Knowledge Bases, you can specify BDA as parser of your data source for Bedrock Knowledge Bases.\n",
    "\n",
    "## Key Features\n",
    "\n",
    "- Amazon Bedrock Data Automation (BDA): A managed service that automatically extracts content from multimodal data. BDA streamlines the generation of valuable insights from unstructured multimodal content such as documents, images, audio, and videos through a unified multi-modal inference API.\n",
    "  \n",
    "- Bedrock KB to build a RAG solution with BDA: Amazon Bedrock KB extract multi-modal content using BDA, generating semantic embeddings using the selected embedding model, and storing them in the chosen vector store. This enables users to retrieve and generate answers to questions derived not only from text but also from image, video and audio data. Additionally, retrieved results include source attribution for visual data, enhancing transparency and building trust in the generated outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca16843e-0586-4c58-991f-ca6898e192e2",
   "metadata": {
    "editable": true,
    "jp-MarkdownHeadingCollapsed": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Prerequisites\n",
    "Please make sure to enable `Anthropic Claude 3 Sonnet` , `Amazon Nova Micro` and  `Titan Text Embeddings V2` model access in Amazon Bedrock Console\n",
    "\n",
    "You need to have suitable IAM role permission to run this notebook. For IAM role, choose either an existing IAM role in your account or create a new role. The role must the necessary permissions to invoke the BDA, Bedrock KB, create IAM roles, SageMaker and S3 APIs.\n",
    "\n",
    "Note: The AdministratorAccess IAM policy can be used, if allowed by security policies at your organization.\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Note:</b> Please run the notebook cell one at a time instead of using \"Run All Cells\" option.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a1ac402-0ae3-4041-9cb6-8b2c253c58d3",
   "metadata": {},
   "source": [
    "# Setup notebook and boto3 clients\n",
    "\n",
    "In this step, we will import some necessary libraries that will be used throughout this notebook. To use Amazon Bedrock Data Automation (BDA) with boto3, you'll need to ensure you have the latest version of the AWS SDK for Python (boto3) installed. Version Boto3 1.35.96 of later is required.\n",
    "\n",
    "Note: At time of Public Preview launch, BDA is available in us-west-2 only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f75bfcb2-1f39-4288-a6b7-d3604cff85bc",
   "metadata": {
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%pip install -r ./requirements.txt --no-deps --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ecada3-f537-4099-b0a8-2c8204ee1dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# restart kernel\n",
    "from IPython.core.display import HTML\n",
    "HTML(\"<script>Jupyter.notebook.kernel.restart()</script>\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b30dd502-5210-4567-99ce-d2300c5f43a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d66d474-3dfd-49ea-b132-8122b3675530",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Note:</b> In this workshop, a new S3 bucket following the naming convention \"kb-bda-multimodal-datasource-{account_id}\" will be used, and the input and output will be saved under a folder called \"bda\" in the default bucket.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02bb5216-a0d3-4a6d-a57f-ec95c98aa2a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "from botocore.exceptions import ClientError\n",
    "import os\n",
    "import json, uuid\n",
    "from datetime import datetime\n",
    "import time\n",
    "from time import sleep\n",
    "import pprint\n",
    "import random\n",
    "from retrying import retry\n",
    "\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import tempfile\n",
    "import io\n",
    "import base64\n",
    "from IPython.display import JSON, IFrame, Audio, display, clear_output\n",
    "import IPython.display as display\n",
    "import sagemaker\n",
    "import logging\n",
    "from utils.knowledge_base import BedrockKnowledgeBase\n",
    "\n",
    "#create client\n",
    "suffix = random.randrange(200, 900)\n",
    "\n",
    "sts_client = boto3.client('sts')\n",
    "account_id = sts_client.get_caller_identity()[\"Account\"]\n",
    "\n",
    "session = sagemaker.Session()\n",
    "bucket_name = session.default_bucket()\n",
    "\n",
    "region_name = \"us-west-2\"\n",
    "region = region_name\n",
    "\n",
    "s3_client = boto3.client('s3', region_name=region_name)\n",
    "\n",
    "bda_client = boto3.client('bedrock-data-automation', region_name=region_name)\n",
    "bda_runtime_client = boto3.client('bedrock-data-automation-runtime', region_name=region_name)\n",
    "\n",
    "bedrock_agent_client = boto3.client('bedrock-agent')\n",
    "bedrock_agent_runtime_client = boto3.client('bedrock-agent-runtime') \n",
    "\n",
    "logging.basicConfig(format='[%(asctime)s] p%(process)s {%(filename)s:%(lineno)d} %(levelname)s - %(message)s', level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "region, account_id\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35005ea3-d6c1-49dc-9d79-ffab966a0f30",
   "metadata": {},
   "source": [
    "Download sample files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc84ab98-3174-40c5-939b-bef79e921eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('examples', exist_ok=True)\n",
    "!curl 'https://ws-assets-prod-iad-r-pdx-f3b3f9f1a7d6a3d0.s3.us-west-2.amazonaws.com/335119c4-e170-43ad-b55c-76fa6bc33719/bda-idp.png' --output './examples/bda-idp.png'\n",
    "!curl 'https://ws-assets-prod-iad-r-pdx-f3b3f9f1a7d6a3d0.s3.us-west-2.amazonaws.com/335119c4-e170-43ad-b55c-76fa6bc33719/bda.m4v' --output './examples/bda.m4v'\n",
    "!curl 'https://ws-assets-prod-iad-r-pdx-f3b3f9f1a7d6a3d0.s3.us-west-2.amazonaws.com/335119c4-e170-43ad-b55c-76fa6bc33719/bedrock-ug.pdf' --output './examples/bedrock-ug.pdf'\n",
    "!curl 'https://ws-assets-prod-iad-r-pdx-f3b3f9f1a7d6a3d0.s3.us-west-2.amazonaws.com/335119c4-e170-43ad-b55c-76fa6bc33719/podcastdemo.mp3' --output './examples/podcastdemo.mp3'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c1c8b3-1176-4d45-a48d-0295908206a4",
   "metadata": {},
   "source": [
    "## Create a BDA project\n",
    "To start a BDA job, you need a BDA project, which organizes both standard and custom output configurations. This project is reusable, allowing you to apply the same configuration to process multiple video/audio files that share the same settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b85496-ab88-4a99-892a-c2f764800c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_name= f'bda-workshop-kb-project-{str(uuid.uuid4())[0:4]}'\n",
    "\n",
    "# delete project if it already exists\n",
    "projects_existing = [project for project in bda_client.list_data_automation_projects()[\"projects\"] if project[\"projectName\"] == project_name]\n",
    "if len(projects_existing) >0:\n",
    "    print(f\"Deleting existing project: {projects_existing[0]}\")\n",
    "    bda_client.delete_data_automation_project(projectArn=projects_existing[0][\"projectArn\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c64b4833-ce48-431d-9da0-d162b05957f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = bda_client.create_data_automation_project(\n",
    "    projectName=project_name,\n",
    "    projectDescription='BDA workshop sample project',\n",
    "    projectStage='DEVELOPMENT',\n",
    "    standardOutputConfiguration={\n",
    "        \"video\": {\n",
    "            \"extraction\": {\n",
    "                \"category\": {\n",
    "                    \"state\": \"ENABLED\",\n",
    "                    \"types\": [\"CONTENT_MODERATION\", \"TEXT_DETECTION\", \"TRANSCRIPT\"]\n",
    "                },\n",
    "                \"boundingBox\": {\"state\": \"ENABLED\"}\n",
    "            },\n",
    "            \"generativeField\": {\n",
    "                \"state\": \"ENABLED\",\n",
    "                \"types\": [\"VIDEO_SUMMARY\", \"SCENE_SUMMARY\", \"IAB\"]\n",
    "            }\n",
    "        },\n",
    "        \"audio\": {\n",
    "            \"extraction\": {\n",
    "                \"category\": {\n",
    "                    \"state\": \"ENABLED\", \n",
    "                    \"types\": [\"AUDIO_CONTENT_MODERATION\", \"CHAPTER_CONTENT_MODERATION\", \"TRANSCRIPT\"]\n",
    "                }\n",
    "            },\n",
    "            \"generativeField\": {\n",
    "                \"state\": \"ENABLED\",\n",
    "                \"types\": [\"AUDIO_SUMMARY\", \"CHAPTER_SUMMARY\", \"IAB\"]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aad4b09-b0f4-4e77-a375-6477efd87179",
   "metadata": {},
   "outputs": [],
   "source": [
    "kb_project_arn = response.get(\"projectArn\")\n",
    "print(\"BDA kb project ARN:\", kb_project_arn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265795d4-9b13-46b9-b636-78b5ac8165b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload an audio file\n",
    "from IPython.display import Audio,Video, display\n",
    "\n",
    "file_name_audio = 'examples/podcastdemo.mp3'\n",
    "object_name_audio = f'bda/input/{file_name_audio}'\n",
    "\n",
    "s3_client.upload_file(file_name_audio, bucket_name, object_name_audio)\n",
    "\n",
    "file_name_video = 'examples/bda.m4v'\n",
    "object_name_video = f'bda/input/{file_name_video}'\n",
    "\n",
    "s3_client.upload_file(file_name_video, bucket_name, object_name_video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad12ac4f-ee81-45cc-a261-dbe15e6058d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and play an MP3 file\n",
    "display(Audio(file_name_audio, autoplay=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ffeef40-d916-4c99-bf47-3f891f7f6142",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and play an MP4 file\n",
    "\n",
    "from IPython.display import HTML\n",
    "from base64 import b64encode\n",
    "from utils.knowledge_base_operators import play\n",
    "\n",
    "play(file_name_video)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd51747b-9e30-4a3d-b792-6eeccc57c60d",
   "metadata": {},
   "source": [
    "### Start BDA tasks\n",
    "We will now invoke the BDA API to process the uploaded audio file. You need to provide the BDA project ARN that we created at the beginning of the lab and specify an S3 location where BDA will store the output results.\n",
    "\n",
    "For a complete API reference for invoke a BDA async task, refer to this [document](https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/bedrock-data-automation-runtime/client/invoke_data_automation_async.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8041bf5-48c8-48c2-bcf6-53146715eedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start BDA task audio\n",
    "\n",
    "input_name = object_name_audio\n",
    "output_name = f'bda/output/' \n",
    "\n",
    "response_aud = bda_runtime_client.invoke_data_automation_async(\n",
    "    inputConfiguration={'s3Uri':  f\"s3://{bucket_name}/{input_name}\"},\n",
    "    outputConfiguration={'s3Uri': f\"s3://{bucket_name}/{output_name}\"},\n",
    "    dataAutomationProfileArn= f'arn:aws:bedrock:us-west-2:{account_id}:data-automation-profile/us.data-automation-v1',\n",
    "    dataAutomationConfiguration={\n",
    "        'dataAutomationProjectArn': kb_project_arn,\n",
    "        'stage': 'DEVELOPMENT'\n",
    "    })\n",
    "response_aud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e34652-6b38-462b-874d-90dd5518a861",
   "metadata": {},
   "outputs": [],
   "source": [
    "invocation_audio_arn = response_aud.get(\"invocationArn\")\n",
    "print(\"BDA audio task started:\", invocation_audio_arn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7917b7d-7c18-4f5b-88a3-397d89e860da",
   "metadata": {},
   "source": [
    "\n",
    "##### We will repeat the process for the uploaded video file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021e6a0d-6b93-40c2-b8e0-ea682a65959c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start BDA task video\n",
    "input_name = object_name_video\n",
    "output_name = f'bda/output/' \n",
    "\n",
    "response_vid = bda_runtime_client.invoke_data_automation_async(\n",
    "    inputConfiguration={'s3Uri':  f\"s3://{bucket_name}/{object_name_video}\"},\n",
    "    outputConfiguration={'s3Uri': f\"s3://{bucket_name}/{output_name}\"},\n",
    "    dataAutomationProfileArn= f'arn:aws:bedrock:us-west-2:{account_id}:data-automation-profile/us.data-automation-v1',\n",
    "    dataAutomationConfiguration={\n",
    "        'dataAutomationProjectArn': kb_project_arn,\n",
    "        'stage': 'DEVELOPMENT'\n",
    "    })\n",
    "response_vid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf31a93f-8b91-46f8-9bba-5b3b1d07b5ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "invocation_video_arn = response_vid.get(\"invocationArn\")\n",
    "print(\"BDA video task started:\", invocation_video_arn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b91ec47d-7043-4ba2-8c22-c8509a40c76e",
   "metadata": {},
   "source": [
    "### We can monitor the progress status of BDA task execution, by running the code cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a778f7-8c43-4418-8b4a-f5ec2e76971c",
   "metadata": {},
   "outputs": [],
   "source": [
    "statusAudio,statusVideo, status_aud_response, status_vid_response = None, None, None, None\n",
    "\n",
    "while statusAudio not in [\"Success\",\"ServiceError\",\"ClientError\"] or statusVideo not in [\"Success\",\"ServiceError\",\"ClientError\"]:\n",
    "    \n",
    "    status_aud_response = bda_runtime_client.get_data_automation_status(\n",
    "        invocationArn=invocation_audio_arn\n",
    "    )\n",
    "    statusAudio = status_aud_response.get(\"status\")\n",
    "        \n",
    "    status_vid_response = bda_runtime_client.get_data_automation_status(\n",
    "        invocationArn=invocation_video_arn\n",
    "    )\n",
    "    statusVideo = status_vid_response.get(\"status\")\n",
    "    \n",
    "    clear_output(wait=True)\n",
    "    print(f\"{datetime.now().strftime('%H:%M:%S')} : \"\\\n",
    "          f\"BDA kb video task: {statusVideo} \"\\\n",
    "          f\"BDA kb audio task: {statusAudio}\")\n",
    "    time.sleep(5)\n",
    "\n",
    "\n",
    "output_aud_config = status_aud_response.get(\"outputConfiguration\",{}).get(\"s3Uri\")\n",
    "print(\"Ouput configuration file:\", output_aud_config)\n",
    "\n",
    "output_vid_config = status_vid_response.get(\"outputConfiguration\",{}).get(\"s3Uri\")\n",
    "print(\"Ouput configuration file:\", output_vid_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b61a1172-6264-4817-a050-deb73b5e3164",
   "metadata": {},
   "source": [
    "# Examine the BDA output for the processed audio file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af95cdc6-9033-4348-a030-1f3a283273ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_aud_loc = status_aud_response['outputConfiguration']['s3Uri'].split(\"/job_metadata.json\", 1)[0].split(bucket_name+\"/\")[1]\n",
    "out_aud_loc += \"/0/standard_output/0/result.json\"\n",
    "print(out_aud_loc)\n",
    "s3_client.download_file(bucket_name, out_aud_loc, 'result_aud.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0290d27-768a-4da8-973b-33f9eb29e86d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_aud = json.load(open('result_aud.json'))\n",
    "print(data_aud[\"audio\"][\"summary\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a26401-30f8-4112-a1d2-c21a0af8e119",
   "metadata": {},
   "source": [
    "# Examine the BDA output for the processed video file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b593584-88db-4cca-89b0-820ebe43a19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_vid_loc = status_vid_response['outputConfiguration']['s3Uri'].split(\"/job_metadata.json\", 1)[0].split(bucket_name+\"/\")[1]\n",
    "out_vid_loc += \"/0/standard_output/0/result.json\"\n",
    "print(out_vid_loc)\n",
    "s3_client.download_file(bucket_name, out_vid_loc, 'result_vid.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c59e8657-7ca2-46f1-99b6-d634383f600c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_vid = json.load(open('result_vid.json'))\n",
    "print(data_vid[\"video\"][\"summary\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9517a0eb-008c-4087-b5c7-7efe41886b3c",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Congrats! By following this notebook, you finished the BDA processing of video and audio files, and you are ready to build a robust Multimodal RAG application tailored to your specific needs in the next notebook: 02_audio_video_rag_kb."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
