{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a899bfb2-fa00-482e-ab5a-f97daa18d876",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-20T23:22:21.289317Z",
     "iopub.status.busy": "2025-01-20T23:22:21.288559Z",
     "iopub.status.idle": "2025-01-20T23:22:21.296763Z",
     "shell.execute_reply": "2025-01-20T23:22:21.295537Z",
     "shell.execute_reply.started": "2025-01-20T23:22:21.289288Z"
    }
   },
   "source": [
    "# Analyze an advertisement image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9cba547-3ef6-4194-a2e6-315e5abe7963",
   "metadata": {},
   "source": [
    "In this lab, we will use BDA to extract and analyze a sample advertisement image, utilizing both standard output settings and a customized blueprint for deeper insights. We will walk through the process and explore the generated outputs.\n",
    "\n",
    "![video moderation](../static/bda-image-travel.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a87659b5-90c4-40a4-9c03-931d70ab8955",
   "metadata": {},
   "source": [
    "## Prerequisits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf31c6e-182c-4998-83ce-f60ed4f53b38",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%pip install \"boto3>=1.37.4\" --upgrade -qq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b94080f3-7a23-4b04-898d-57be31c638a4",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "import uuid\n",
    "import utils\n",
    "import sagemaker\n",
    "\n",
    "bda_client = boto3.client('bedrock-data-automation')\n",
    "bda_runtime_client = boto3.client('bedrock-data-automation-runtime')\n",
    "s3_client = boto3.client('s3')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "846d3478-84a7-4c29-a5e6-4a3f6c686d4b",
   "metadata": {},
   "source": [
    "For a self-hosted workshop, we recommend creating a new S3 bucket in the same region where you plan to run the workshop. You can name it `bda-workshop-YOUR_ACCOUNT_ID-YOUR_REGION`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dadc3186-7df3-4e5f-ae7d-2522ce275209",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_bucket = sagemaker.Session().default_bucket() # Enter your bucket name here\n",
    "data_prefix = \"bda-workshop/image\"\n",
    "output_prefix = \"bda-workshop/image/ouput\"\n",
    "\n",
    "print('Workshop S3 bucket:', data_bucket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ed08eb-05f8-4106-94de-08b5c38e4132",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get current AWS account Id and region\n",
    "sts = boto3.client('sts')\n",
    "account_id = sts.get_caller_identity()['Account']\n",
    "region = boto3.Session().region_name\n",
    "\n",
    "print(f'Current AWS account Id: {account_id}, region name: {region}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa554a34-ae81-4802-9ca5-b4a40e759f7e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-21T00:31:53.506949Z",
     "iopub.status.busy": "2025-01-21T00:31:53.506589Z",
     "iopub.status.idle": "2025-01-21T00:31:53.513035Z",
     "shell.execute_reply": "2025-01-21T00:31:53.511550Z",
     "shell.execute_reply.started": "2025-01-21T00:31:53.506925Z"
    }
   },
   "source": [
    "## Create a BDA project with both standard and custom output configurations for image\n",
    "To start a BDA job, you need a BDA project, which organizes both standard and custom output configurations. This project is reusable, allowing you to apply the same configuration to process multiple images that share the same settings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "431eeea0-12c1-4cd7-8e40-f8c3d8b3f8be",
   "metadata": {},
   "source": [
    "In the code snippet below, we create a BDA project with standard and custom output configurations for image modality. These configurations can be tailored to extract only the specific information you need. In this lab, we will enable the below standard image outputs:\n",
    "- Text detection with bounding-box\n",
    "- Brand and logos with bounding-box\n",
    "- IAB categories on the scene level\n",
    "- Image summary\n",
    "\n",
    "We will also set up a custom output configuration by defining a blueprint to extract and infer customized properties.\n",
    "\n",
    "For a complete API reference for creating a BDA project, refer to this [document](https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/bedrock-data-automation/client/create_data_automation_project.html). For creating a BDA blue print, refer to this [document](https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/bedrock-data-automation/client/create_blueprint.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2510f5-f4f2-4fdd-ac96-4d9edbeeba42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_project(blue_print_arn):\n",
    "    response = bda_client.create_data_automation_project(\n",
    "        projectName=f'bda-workshop-image-project-{str(uuid.uuid4())[0:4]}',\n",
    "        projectDescription='BDA workshop image sample project',\n",
    "        projectStage='DEVELOPMENT',\n",
    "        standardOutputConfiguration={\n",
    "            'image': {\n",
    "                'extraction': {\n",
    "                    'category': {\n",
    "                        'state': 'ENABLED',\n",
    "                        'types': [\n",
    "                            'TEXT_DETECTION','LOGOS'\n",
    "                        ]\n",
    "                    },\n",
    "                    'boundingBox': {\n",
    "                        'state': 'ENABLED'\n",
    "                    }\n",
    "                },\n",
    "                'generativeField': {\n",
    "                    'state': 'ENABLED',\n",
    "                    'types': [\n",
    "                        'IMAGE_SUMMARY','IAB'\n",
    "                    ]\n",
    "                }\n",
    "            },\n",
    "        },\n",
    "        customOutputConfiguration={\n",
    "            'blueprints': [\n",
    "                {\n",
    "                    'blueprintArn': blue_print_arn,\n",
    "                    'blueprintStage': 'DEVELOPMENT'\n",
    "                },\n",
    "            ]\n",
    "        },\n",
    "    )\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b49dcad1-71ac-4726-ae82-015c181d8545",
   "metadata": {},
   "source": [
    "We will create a blueprint and pass it to the BDA project with the following customized output definitions:\n",
    "- Number of products in the image\n",
    "- Scene location\n",
    "- Product type\n",
    "\n",
    "For more information on creating a BDA image blueprint, refer to this [document](https://docs.aws.amazon.com/bedrock/latest/userguide/bda-idp-images.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc37c122-cf6f-4efb-96fd-e4d60a71dff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "blueprint = {\n",
    "  \"documentClass\": \"Ad scene analysis\",\n",
    "  \"description\": \"This blueprint is designed to extract key information from an image depicting an Ad scene.\",\n",
    "  \"properties\": {\n",
    "    \"product_count\": {\n",
    "      \"type\": \"number\",\n",
    "      \"inferenceType\": \"extractive\",\n",
    "      \"description\": \"Count the number of product visible in the image.\"\n",
    "    },\n",
    "    \"scene_location\": {\n",
    "      \"type\": \"string\",\n",
    "      \"inferenceType\": \"extractive\",\n",
    "      \"description\": \"Describe the setting or location of the scene, such as the type of field or surrounding buildings.\"\n",
    "    },\n",
    "    \"product_type\": {\n",
    "      \"type\": \"string\",\n",
    "      \"inferenceType\": \"extractive\",\n",
    "      \"description\": \"What is the primary product or service being advertised, e.g., Clothing, Electronics, Food & Beverage, etc.?\"\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\n",
    "bp_response = bda_client.create_blueprint(\n",
    "    blueprintName='bda-image-custom-bp',\n",
    "    type='IMAGE',\n",
    "    blueprintStage='DEVELOPMENT',\n",
    "    schema=json.dumps(blueprint),\n",
    ")\n",
    "blueprint_arn = bp_response.get(\"blueprint\",{}).get(\"blueprintArn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f15b1d-83b7-414b-b552-6d2dd9cb0ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = create_project(blueprint_arn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c1dfd78-a072-4375-b970-d2650909f0de",
   "metadata": {},
   "source": [
    "The create_data_automation_project API will return the project ARN, which we will use it to invoke the BDA job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e824ab6c-5249-4364-927c-c5def65a32a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_project_arn = response.get(\"projectArn\")\n",
    "print(\"BDA image project ARN:\", image_project_arn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b81791-e597-457f-a375-265bc0711525",
   "metadata": {},
   "source": [
    "## Start an asynchronous BDA task to extract and analyze an image\n",
    "In this section, we will use a sample advertising product image to extract and analyze data using BDA, applying the configuration defined in the BDA project. We will then review the output to better understand how BDA performs image extraction and analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6fd5d08-0be9-495e-bdc3-27e2b68c0e55",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-21T01:16:19.221297Z",
     "iopub.status.busy": "2025-01-21T01:16:19.220673Z",
     "iopub.status.idle": "2025-01-21T01:16:19.225680Z",
     "shell.execute_reply": "2025-01-21T01:16:19.224891Z",
     "shell.execute_reply.started": "2025-01-21T01:16:19.221270Z"
    }
   },
   "source": [
    "### Prepare the sample image\n",
    "Download the sample image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bad7889-a3a7-4c82-9766-eb5ecb94acf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download sample image\n",
    "sample_image = 'travel.png'\n",
    "source_url = f'https://ws-assets-prod-iad-r-pdx-f3b3f9f1a7d6a3d0.s3.us-west-2.amazonaws.com/335119c4-e170-43ad-b55c-76fa6bc33719/travel.png'\n",
    "\n",
    "!curl {source_url} --output {sample_image}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "462b8628-c692-4385-9725-48c4ea3b70cc",
   "metadata": {},
   "source": [
    "Let's display the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd61670-4a65-471a-a75b-14525d923af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(sample_image, width=800)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "591cf849-11ec-4c37-a3dc-e1bb5c51c92e",
   "metadata": {},
   "source": [
    "To analyze the image using BDA, we need to upload it to an S3 bucket that BDA can access. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9717c142-df4d-4d34-8a98-8f36a5671fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_key = f'{data_prefix}/{sample_image.split(\"/\")[-1]}'\n",
    "s3_client.upload_file(sample_image, data_bucket, s3_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c40b33c9-a23c-4dd3-8f66-22d169e598b7",
   "metadata": {},
   "source": [
    "### Start BDA task\n",
    "We will now invoke the BDA API to process the uploaded image. You need to provide the BDA project ARN that we created at the beginning of the lab and specify an S3 location where BDA will store the output results.\n",
    "\n",
    "For a complete API reference for invoke a BDA async task, refer to this [document](https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/bedrock-data-automation-runtime/client/invoke_data_automation_async.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "681293ae-0023-4eac-9970-af61ec934e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = bda_runtime_client.invoke_data_automation_async(\n",
    "    inputConfiguration={\n",
    "        's3Uri': f's3://{data_bucket}/{s3_key}'\n",
    "    },\n",
    "    outputConfiguration={\n",
    "        's3Uri': f's3://{data_bucket}/{output_prefix}'\n",
    "    },\n",
    "    dataAutomationConfiguration={\n",
    "        'dataAutomationProjectArn': image_project_arn,\n",
    "        'stage': 'DEVELOPMENT'\n",
    "    },\n",
    "    notificationConfiguration={\n",
    "        'eventBridgeConfiguration': {\n",
    "            'eventBridgeEnabled': False\n",
    "        }\n",
    "    },\n",
    "    dataAutomationProfileArn=f'arn:aws:bedrock:{region}:{account_id}:data-automation-profile/us.data-automation-v1'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c8b65a-1e4e-4dc1-b011-254e7d1cc941",
   "metadata": {},
   "source": [
    "The `invoke_data_automation_async` API is asynchronous. It returns an invocation task identifier, `invocationArn`. We can then use another API `get_data_automation_status` to monitor the task's status until it completes.\n",
    "\n",
    "> In production workloads, an event-driven pattern is recommended. Allow BDA to trigger the next step once the task is complete. This can be achieved by configuring the notificationConfiguration in the invoke task, which will send a notification to a subscribed AWS service, such as a Lambda function. Alternatively, you can set up an S3 trigger on the bucket where BDA will drop the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61061730-ded4-4852-bbf4-d18ab1168c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "invocation_arn = response.get(\"invocationArn\")\n",
    "print(\"BDA task started:\", invocation_arn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d13518bf-15eb-4e83-bc4b-955b66974457",
   "metadata": {},
   "source": [
    "In this lab, we will use the loop below to monitor the task by calling the `get_data_automation_status` API every 5 seconds until the task is complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb9c48c-9347-43ba-8148-1ea9c29479fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from IPython.display import clear_output\n",
    "from datetime import datetime\n",
    "\n",
    "status, status_response = None, None\n",
    "while status not in [\"Success\",\"ServiceError\",\"ClientError\"]:\n",
    "    status_response = bda_runtime_client.get_data_automation_status(\n",
    "        invocationArn=invocation_arn\n",
    "    )\n",
    "    status = status_response.get(\"status\")\n",
    "    clear_output(wait=True)\n",
    "    print(f\"{datetime.now().strftime('%H:%M:%S')} : BDA image task: {status}\")\n",
    "    time.sleep(5)\n",
    "\n",
    "output_config = status_response.get(\"outputConfiguration\",{}).get(\"s3Uri\")\n",
    "print(\"Ouput configureation file:\", output_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c617c2-3a71-43dd-b996-d7b9a4d86f08",
   "metadata": {},
   "source": [
    "## Access the BDA analysis result\n",
    "The `get_data_automation_status` API returns an S3 URI containing the result configuration, which provides the S3 location where BDA outputs the extraction results. We will then parse this file to retrieve the result path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e1adb7-1620-491f-adb1-b616451d62be",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "config_data = utils.read_json_on_s3(output_config,s3_client)\n",
    "print(json.dumps(config_data, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08dc0557-b53d-4dc4-ae1c-05de559093e7",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "As shown above, the BDA output configuration file contains metadata about the BDA result, including the job ID, status, modality, and the S3 location of the standard and custom output locations: `standard_output_path`, `custom_output_path`. We will now download these result files to verify the output.\n",
    "\n",
    "The standard output result file contains extraction and inference results based on the configuration defined in the BDA image project's standard output configuration section. Under the image field, you will find details such as the summary, IAB categories, and more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc93edb4-e459-4c00-aeb6-31577240aabe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import JSON\n",
    "\n",
    "result_uri = config_data[\"output_metadata\"][0][\"segment_metadata\"][0][\"standard_output_path\"]\n",
    "result_data = utils.read_json_on_s3(result_uri,s3_client)\n",
    "\n",
    "JSON(result_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c1903fd-8878-41ea-9074-da982cf9e8a3",
   "metadata": {},
   "source": [
    "The custom output result file contains extracted and inferred results based on the blueprint definition.\n",
    "- The `matched_blueprint` field indicates which blueprint BDA used to process the image.\n",
    "- Under the `inference_result` field, you will find the customized properties and results based on the blueprint definition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5be91a0-048b-498e-8bfc-bbacd3c26c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_output_uri = config_data[\"output_metadata\"][0][\"segment_metadata\"][0][\"custom_output_path\"]\n",
    "custom_output_data = utils.read_json_on_s3(custom_output_uri,s3_client)\n",
    "\n",
    "JSON(custom_output_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb484f3-6eba-43c9-b569-e07ff5739cb3",
   "metadata": {},
   "source": [
    "## Review the result - standard output\n",
    "The standard output contains information such as the image summary, IAB categories, and extracted text with bounding boxes.\n",
    "\n",
    "### Image summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e3428a3-3b14-46bd-a277-70050f29dc01",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result_data[\"image\"][\"summary\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86784205-ca84-406e-a0d0-27823e375657",
   "metadata": {},
   "source": [
    "### IAB categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c9428b4-bfe6-4353-85ee-d72dff97adc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for iab in result_data[\"image\"][\"iab_categories\"]:\n",
    "    print(iab[\"category\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e7e0f4d-c41a-46f1-9a74-c8517185cde3",
   "metadata": {},
   "source": [
    "### Text in image with bounding boxes\n",
    "Now, let's examine the text extracted from the image. We have enabled bounding boxes in the BDA projectâ€™s standard output configuration. Below is the code to plot the bounding boxes along with the extracted text from the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30fdd8c2-0501-4653-8873-991cea6bb541",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "width = result_data[\"metadata\"][\"image_width_pixels\"]\n",
    "height = result_data[\"metadata\"][\"image_height_pixels\"]\n",
    "\n",
    "image = Image.open(sample_image)\n",
    "draw = ImageDraw.Draw(image)\n",
    "\n",
    "for txt in result_data[\"image\"][\"text_lines\"]:\n",
    "    for l in txt[\"locations\"]:\n",
    "        bbox = l[\"bounding_box\"]\n",
    "        box = (\n",
    "                width*bbox[\"left\"], \n",
    "                height*bbox[\"top\"], \n",
    "                width * (bbox[\"width\"]+bbox[\"left\"]), \n",
    "                height * (bbox[\"height\"] + bbox[\"top\"])\n",
    "            )\n",
    "        draw.rectangle(box, outline=\"blue\", width=2)\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.imshow(image)\n",
    "        plt.title(f'Detected text: {txt[\"text\"]}')\n",
    "        plt.axis(\"off\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e00c7238-95e0-4f9b-9827-dc9accd9687a",
   "metadata": {},
   "source": [
    "### Brand and logos in image with bounding boxes\n",
    "Brand and logo information, including bounding boxes and confidence scores, can be found in the standard output under the image.logos field. The code snippet below uses the Pillow library to plot the detected logos from the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b7b9e4e-0425-4af6-88fe-6598573cad93",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "width = result_data[\"metadata\"][\"image_width_pixels\"]\n",
    "height = result_data[\"metadata\"][\"image_height_pixels\"]\n",
    "\n",
    "image = Image.open(sample_image)\n",
    "draw = ImageDraw.Draw(image)\n",
    "\n",
    "if \"logos\" in result_data[\"image\"]:\n",
    "    for logo in result_data[\"image\"][\"logos\"]:\n",
    "        for l in logo[\"locations\"]:\n",
    "            bbox = l[\"bounding_box\"]\n",
    "            box = (\n",
    "                    width*bbox[\"left\"], \n",
    "                    height*bbox[\"top\"], \n",
    "                    width * (bbox[\"width\"]+bbox[\"left\"]), \n",
    "                    height * (bbox[\"height\"] + bbox[\"top\"])\n",
    "                )\n",
    "            draw.rectangle(box, outline=\"blue\", width=2)\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            plt.imshow(image)\n",
    "            plt.title(f'Detected logos: {logo[\"name\"]}')\n",
    "            plt.axis(\"off\")\n",
    "            plt.show()\n",
    "else:\n",
    "    print(\"No logo detected\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44afe474-1595-4435-a81a-d07bc1f38ed0",
   "metadata": {},
   "source": [
    "## Clean up\n",
    "Delete the BDA project, blueprint, image, and result from S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d901c2f-a911-4d50-b572-1f021db99b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete BDA project\n",
    "response = bda_client.delete_data_automation_project(\n",
    "    projectArn=image_project_arn\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a5d28d-ef4e-4c45-93e0-edae44252927",
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete blueprint\n",
    "response = bda_client.delete_blueprint(\n",
    "    blueprintArn=blueprint_arn,\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "659437e6-a8ba-467e-bef1-e596fdad1abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete uploaded image from S3\n",
    "s3_client.delete_object(Bucket=data_bucket, Key=s3_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1124ef30-5a91-496e-b74f-693fee6eee07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete results from S3\n",
    "utils.delete_s3_folder(data_bucket, output_config.replace(\"job_metadata.json\",\"\") ,s3_client)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
