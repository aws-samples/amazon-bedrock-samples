{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "<h2> How to work with Amazon Bedrock Knowledge Bases</h2>\n",
    "\n",
    "*Note: This notebook has been adapted from the [Chat with your document using Knowledge Bases for Amazon Bedrock - RetrieveAndGenerate API](https://github.com/aws-samples/amazon-bedrock-samples/blob/main/knowledge-bases/features-examples/00-zero-setup-chat-with-your-document/chat_with_document_kb.ipynb)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Overview </h2>\n",
    "\n",
    "This notebook demonstrates using Amazon Bedrock Knowledge Bases. It takes a use case of `chat with your document` capability, where you can securely ask questions on a single document, without the overhead of setting up a vector database or ingesting data, making it effortless for businesses to use their enterprise data. You only need to provide a relevant data file as input and choose your FM to get started.\n",
    "\n",
    "For details around use cases and benefits, please refer to this [blogpost](#https://aws.amazon.com/blogs/machine-learning/knowledge-bases-in-amazon-bedrock-now-simplifies-asking-questions-on-a-single-document/).\n",
    "\n",
    "<h2> Context </h2>\n",
    "\n",
    "[Amazon Bedrock Knowledge Bases](https://docs.aws.amazon.com/bedrock/latest/userguide/knowledge-base.html) allows you to integrate proprietary information into your generative-AI applications. Using the Retrieval Augment Generation (RAG) technique, a knowledge base searches your data to find the most useful information and then uses it to answer natural language questions. Once set up, you can take advantage of a knowledge base in the following ways:\n",
    "\n",
    "- Configure your RAG application to use the [RetrieveAndGenerate](https://docs.aws.amazon.com/bedrock/latest/APIReference/API_agent-runtime_RetrieveAndGenerate.html\n",
    ") API to query your knowledge base and generate responses from the information it retrieves. You can also call the [Retrieve API](https://docs.aws.amazon.com/bedrock/latest/APIReference/API_agent-runtime_Retrieve.html) to query your knowledge base with information retrieved directly from the knowledge base.\n",
    "- Associate your knowledge base with an agent (for more information, see [Amazon Bedrock Agents](https://docs.aws.amazon.com/bedrock/latest/userguide/agents.html)) to add RAG capability to the agent by helping it reason through the steps it can take to help end users.\n",
    "- A knowledge base can be used not only to answer user queries, and analyze documents, but also to augment prompts provided to foundation models by providing context to the prompt. When answering user queries, the knowledge base retains conversation context. The knowledge base also grounds answers in citations so that users can find further information by looking up the exact text that a response is based on and also check that the response makes sense and is factually correct."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Architecture </h3>\n",
    "\n",
    "![How Knowledge Bases for Amazon Bedrock Works](assets/how-to-knowledgebase.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Prerequisites </h2>\n",
    "\n",
    "- Amazon Bedrock basic setup has been completed, see `Prerequisites` section under [Amazon Bedrock APIs - Getting Started](01_invoke_api.ipynb)\n",
    "- Amazon Bedrock access to below given Foundation Model used in this notebook in `us-east-1` (N. Virginia) region.\n",
    "\n",
    "| Provider Name | Foundation Model Name | Model Id |\n",
    "| ------- | ------------- | ------------- |\n",
    "| Anthropic | Claude 3 Sonnet  | anthropic.claude-3-sonnet-20240229-v1:0 |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Setup </h2>\n",
    "\n",
    "⚠️ This notebook should work well with the Data Science 3.0 kernel (Python 3.10 runtime) in SageMaker Studio ⚠️"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --upgrade pip\n",
    "%pip install --upgrade boto3\n",
    "%pip install --upgrade botocore\n",
    "%pip install pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# restart kernel\n",
    "from IPython.core.display import HTML\n",
    "HTML(\"<script>Jupyter.notebook.kernel.restart()</script>\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Before we begin, lets check the boto3 version, make sure its equal to or greater than `1.34.94`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "boto3.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Initialize client for Amazon Bedrock for accessing the `RetrieveAndGenerate` API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import pprint\n",
    "from botocore.client import Config\n",
    "\n",
    "pp = pprint.PrettyPrinter(indent=2)\n",
    "region = \"us-east-1\"\n",
    "bedrock_config = Config(connect_timeout=120, read_timeout=120, retries={'max_attempts': 0})\n",
    "\n",
    "bedrock_agent_client = boto3.client(\"bedrock-agent-runtime\",\n",
    "                              region_name=region,\n",
    "                              config=bedrock_config,\n",
    "                                    )\n",
    "model_id = \"anthropic.claude-3-sonnet-20240229-v1:0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "For data, you can either upload the document you want to chat with or point to the Amazon Simple Storage Service (Amazon S3) bucket location that contains your file. We provide you with both options in the notebook. However in both cases, the supported file formats are PDF, MD (Markdown), TXT, DOCX, HTML, CSV, XLS, and XLSX. Make that the file size does not exceed 10 MB and contains no more than 20K tokens. A token is considered to be a unit of text, such as a word, sub-word, number, or symbol, that is processed as a single entity. Due to the preset ingestion token limit, it is recommended to use a file under 10MB. However, a text-heavy file, that is much smaller than 10MB, can potentially breach the token limit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Notebook/Code with comments</h2>\n",
    "\n",
    "<h3> Option 1 - Upload the document (default) </h3>\n",
    "\n",
    "In our example, we will use a pdf file of Amazon Shareholder Letter for Year 2022."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load pdf\n",
    "from pypdf import PdfReader\n",
    "# creating a pdf reader object\n",
    "file_name = \"assets/2022-Shareholder-Letter.pdf\" #path of the file on your local machine.\n",
    "reader = PdfReader(file_name)\n",
    "# printing number of pages in pdf file\n",
    "print(len(reader.pages))\n",
    "text = \"\"\n",
    "page_count = 1\n",
    "for page in reader.pages:\n",
    "    text+= f\"\\npage_{str(page_count)}\\n {page.extract_text()}\"\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "<h3> Option 2 - Point to S3 location of your file (Optional) </h3>\n",
    "\n",
    "Make sure to replace the `bucket_name` and `prefix_file_name` to the location of your file, and you have required permissions to access the S3 file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_name = \"<replace with your bucket name>\"\n",
    "prefix_file_name = \"<replace with the file name in your bucket>\" #include prefixes if any alongwith the file name.\n",
    "document_s3_uri = f's3://{bucket_name}/{prefix_file_name}'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "<h3> RetreiveAndGenerate API for chatting with your document </h3>\n",
    "\n",
    "The code in the below cell, defines a Python function called `retrieveAndGenerate` that takes two optional arguments: `input` (the input text) and `sourceType` (the type of source to use, defaulting to \"S3\"). It also sets a default value for the `model_id` parameter.\n",
    "\n",
    "The function constructs an Amazon Resource Name (ARN) for the specified model using the `model_id` and the `REGION` variable.\n",
    "\n",
    "If the `sourceType` is \"S3\", the function calls the `retrieve_and_generate` method of the `bedrock_agent_client` object, passing in the input text and a configuration for retrieving and generating from external sources. The configuration specifies that the source is an S3 location, and it provides the S3 URI of the document.\n",
    "\n",
    "If the `sourceType` is not \"S3\", the function calls the same `retrieve_and_generate` method, but with a different configuration. In this case, the source is specified as byte content, which includes a file name, content type (application/pdf), and the actual text data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieveAndGenerate(input, sourceType=\"S3\", model_id = \"anthropic.claude-3-sonnet-20240229-v1:0\"):\n",
    "    model_arn = f'arn:aws:bedrock:{region}::foundation-model/{model_id}'\n",
    "    if sourceType==\"S3\":\n",
    "        return bedrock_agent_client.retrieve_and_generate(\n",
    "            input={\n",
    "                'text': input\n",
    "            },\n",
    "            retrieveAndGenerateConfiguration={\n",
    "                'type': 'EXTERNAL_SOURCES',\n",
    "                'externalSourcesConfiguration': {\n",
    "                    'modelArn': model_arn,\n",
    "                    \"sources\": [\n",
    "                        {\n",
    "                            \"sourceType\": sourceType,\n",
    "                            \"s3Location\": {\n",
    "                                \"uri\": document_s3_uri\n",
    "                            }\n",
    "                        }\n",
    "                    ]\n",
    "                }\n",
    "            }\n",
    "        )\n",
    "    else:\n",
    "        return bedrock_agent_client.retrieve_and_generate(\n",
    "            input={\n",
    "                'text': input\n",
    "            },\n",
    "            retrieveAndGenerateConfiguration={\n",
    "                'type': 'EXTERNAL_SOURCES',\n",
    "                'externalSourcesConfiguration': {\n",
    "                    'modelArn': model_arn,\n",
    "                    \"sources\": [\n",
    "                        {\n",
    "                            \"sourceType\": sourceType,\n",
    "                            \"byteContent\": {\n",
    "                                \"identifier\": file_name,\n",
    "                                \"contentType\": \"application/pdf\",\n",
    "                                \"data\": text,\n",
    "                                }\n",
    "                        }\n",
    "                    ]\n",
    "                }\n",
    "            }\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "If you want to chat with the document by uploading the file use `sourceType` as `BYTE_CONTENT` and for pointing it to s3 bucket, use `sourceType` as `S3`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "query = \"Summarize the document\"\n",
    "response = retrieveAndGenerate(input=query, sourceType=\"BYTE_CONTENT\")\n",
    "generated_text = response['output']['text']\n",
    "pp.pprint(generated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "<h3> Citations or source attributions </h3>\n",
    "\n",
    "Lets retrieve the source attribution or citations for the above response.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "citations = response[\"citations\"]\n",
    "contexts = []\n",
    "for citation in citations:\n",
    "    retrievedReferences = citation[\"retrievedReferences\"]\n",
    "    for reference in retrievedReferences:\n",
    "         contexts.append(reference[\"content\"][\"text\"])\n",
    "\n",
    "pp.pprint(contexts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Next steps </h2>\n",
    "\n",
    "Now that we have seen how to use Amazon Bedrock Knowledge Bases, you can learn\n",
    "\n",
    "- How to use [Amazon Bedrock Agents](04_agents_api.ipynb)\n",
    "- How to use [Amazon Bedrock Guardrails](02_guardrails_api.ipynb)\n",
    "- To further explore the capabilities of Amazon Bedrock Knowledge Bases, refer [RAG and Knowledge Bases](../../rag/knowledge-bases/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Clean up</h2>\n",
    "\n",
    "This notebook does not require any cleanup or additional deletion of resources."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
