# RAG using structured and unstructed data

This notebook demonstrates how to leverage `multiple data sources`, including structured data from a database and unstructured data (like PDFs, text files, etc.), to answer questions using the Retrieval Augmented Generation (RAG) approach. Specifically, it sets up a `MultiRetrievalQAChain` that can answer queries by retrieving information from an Amazon Bedrock knowledge base (unstructured data) and a database (structured data using Text-to-SQL as a retriever), and then generating responses using the Claude 3.0 Sonnet language model.

## Prerequisites

1. A knowledge base created in Amazon Bedrock using unstructured data.
2. Data available for querying via SQL in Amazon Athena.

If you don't have these prerequisites, follow these steps:

1. Create a knowledge base and ingest documents by following [this notebook](https://github.com/aws-samples/amazon-bedrock-samples/blob/main/knowledge-bases/features-examples/01-rag-concepts/01_create_ingest_documents_test_kb_multi_ds.ipynb). Note down the knowledge base ID.
2. For synthetic text data to create your knowledge base, refer to [this link](https://github.com/aws-samples/amazon-bedrock-samples/tree/main/knowledge-bases/features-examples/synthetic_dataset).
3. To get access to tabular data, you can run `0-create-dummy-structured-data.ipynb` and `1_create_sql_dataset_optional.ipynb` notebook to setup an Amazon Atehna database. 


#### Prerequisites
**Note:** This notebook assumes that you have
1. created a knowledge base for Amazon Bedrock using unstructred data
2. have data available for querying via SQL in Amazon Athena.

If you haven't met the prerequisite, please follow these steps:

1. Create a knowledge base and ingest your documents by following this [01_create_ingest_documents_test_kb_multi_ds.ipynb](https://github.com/aws-samples/amazon-bedrock-samples/blob/main/knowledge-bases/features-examples/01-rag-concepts/01_create_ingest_documents_test_kb_multi_ds.ipynb).
2. Note down the knowledge base ID, as you'll need it later in this notebook.
3. If you need to use synthetic data for testing, refer to this [link](https://github.com/aws-samples/amazon-bedrock-samples/tree/main/knowledge-bases/features-examples/synthetic_dataset) to get synthetic text data that you can use to create your knowledge base for Amazon bedrock.
4. To create synthetic structured data, you can run [0-create-dummy-structured-data.ipynb](https://github.com/aws-samples/amazon-bedrock-samples/tree/main/knowledge-bases/use-case-examples/rag-using-structured-unstructured-data/0-create-dummy-structured-data.ipynb) notebook and then use [1_create_sql_dataset_optional.ipynb](https://github.com/aws-samples/amazon-bedrock-samples/tree/main/knowledge-bases/use-case-examples/rag-using-structured-unstructured-data/1_create_sql_dataset_optional.ipynb) notebook to create a database and table in Amazon Athena.

**Note**: The `custom_database_retriever.py` file currently uses table schema for a retail order website generated by using [0-create-dummy-structured-data.ipynb](https://github.com/aws-samples/amazon-bedrock-samples/tree/main/knowledge-bases/use-case-examples/rag-using-structured-unstructured-data/0-create-dummy-structured-data.ipynb) notebook. If you choose to use a different dataset, please update the schema for tables and table information inside `custom_database_retriever.py` file.

## Implementation

In the notebook, `MultiRetrievalQAChain` uses two retrievers: one for the knowledge base and another for the database. It also includes a default conversation chain that manages the dialogue between the user and the system, utilizing the LLM, a custom prompt, and a memory buffer to track context.

The central component is the `MultiRetrievalQAChain` itself, which combines the knowledge base retriever, database retriever, and default conversation chain. Based on the user's query, this chain determines the appropriate retriever, retrieves relevant information from the corresponding data source, and then employs the LLM to generate a contextual response informed by the conversation history.

This system can handle a diverse range of queries, from general questions to complex analytical database queries, providing natural language responses by synthesizing information from multiple sources.

## Setting up the Custom Retriever for Text-to-SQL

The code for the custom module can be found in `CustomDatabaseRetriever.py`. This module defines a retriever class called `AmazonAthenaRetriever` that retrieves relevant data from an Amazon Athena database using SQL queries generated by Amazon Bedrock.

The retriever interacts with the Athena database through the AWS boto3 SDK, allowing running SQL queries on data stored in Amazon S3. It generates SQL queries based on natural language input, executes the queries on Athena, and returns the results as a list of documents formatted for a LangChain RetrievalQA chain.

## Important Note
1. The notebook uses a custom module built specifically for Amazon Athena, but you can customize it for other databases like Amazon Redshift and Amazon RDS using their respective data APIs.
2. In the notebook we are using the MultiRetrievalQAChain with only two retrievers but this chain can use more than two retrievers if needed.