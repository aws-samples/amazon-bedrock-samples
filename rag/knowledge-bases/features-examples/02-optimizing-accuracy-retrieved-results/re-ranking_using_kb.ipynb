{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15c08f81",
   "metadata": {},
   "source": [
    "# Re-ranking\n",
    "\n",
    "Amazon Bedrock provides access to reranker models that you can use when querying to improve the relevance of the retrieved results.  reranker model calculates the relevance of chunks to a query and reorders the results based on the scores that it calculates. By using a reranker model, you can return responses that are better suited to answering the query. \n",
    "\n",
    "Reranker models are trained to identify relevance signals based on a query and then use those signals to rank documents. Because of this, the models can provide more relevant, more accurate results.\n",
    "\n",
    "If you're using `Amazon Bedrock Knowledge Bases` for building your Retrieval Augmented Generation (RAG) application, use a reranker model while calling the `Retrieve` or `RetrieveAndGenerate operation`. The results from reranking override the default ranking that Amazon Bedrock Knowledge Bases determines.\n",
    "\n",
    "This notebook demonstrates the use of **reranking model** with Amazon Bedrock Knowledge Bases, through the Rerank API which will help to further improve the accuracy and relevance of RAG applications. With a reranker model, you can retrieve fewer, but more relevant, results. By feeding these results to the foundation model that you use to generate a response, you can also decrease cost and latency.\n",
    "\n",
    "Let's explore how to implement and utilize reranking models with Amazon Bedrock Knowledge Bases for an example use case."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece99ba7",
   "metadata": {},
   "source": [
    "## 1. Setup\n",
    "Before running the rest of this notebook, you'll need to run the cells below to (ensure necessary libraries are installed and) connect to Bedrock.\n",
    "\n",
    "Please ignore any pip dependency error (if you see any while installing libraries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc89fe3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --force-reinstall -q -r utils/requirements.txt --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57056c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --upgrade boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165e5495",
   "metadata": {},
   "outputs": [],
   "source": [
    "# restart kernel\n",
    "from IPython.core.display import HTML\n",
    "HTML(\"<script>Jupyter.notebook.kernel.restart()</script>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c1c0eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "print(boto3.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7173b4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84241929",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import boto3\n",
    "import logging\n",
    "import pprint\n",
    "import json\n",
    "\n",
    "# Set the path to import module\n",
    "from pathlib import Path\n",
    "current_path = Path().resolve()\n",
    "current_path = current_path.parent\n",
    "if str(current_path) not in sys.path:\n",
    "    sys.path.append(str(current_path))\n",
    "# Print sys.path to verify\n",
    "# print(sys.path)\n",
    "\n",
    "from utils.knowledge_base import BedrockKnowledgeBase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda1c18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clients\n",
    "s3_client = boto3.client('s3')\n",
    "sts_client = boto3.client('sts')\n",
    "session = boto3.session.Session(region_name = 'us-west-2')\n",
    "region =  session.region_name\n",
    "account_id = sts_client.get_caller_identity()[\"Account\"]\n",
    "bedrock_agent_client = boto3.client('bedrock-agent')\n",
    "bedrock_agent_runtime_client = boto3.client('bedrock-agent-runtime') \n",
    "logging.basicConfig(format='[%(asctime)s] p%(process)s {%(filename)s:%(lineno)d} %(levelname)s - %(message)s', level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "region, account_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d74b5be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Get the current timestamp\n",
    "current_time = time.time()\n",
    "\n",
    "# Format the timestamp as a string\n",
    "timestamp_str = time.strftime(\"%Y%m%d%H%M%S\", time.localtime(current_time))[-7:]\n",
    "# Create the suffix using the timestamp\n",
    "suffix = f\"{timestamp_str}\"\n",
    "knowledge_base_name = 'reranking-kb'\n",
    "knowledge_base_description = \"Knowledge Base for re-ranking.\"\n",
    "bucket_name = f'{knowledge_base_name}-{suffix}'\n",
    "foundation_model = \"anthropic.claude-3-sonnet-20240229-v1:0\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5142d7f",
   "metadata": {},
   "source": [
    "## 2 - Create knowledge bases with fixed chunking strategy\n",
    "Let's start by creating a [Knowledge Base for Amazon Bedrock](https://aws.amazon.com/bedrock/knowledge-bases/) to store video games data in csv format. Knowledge Bases allow you to integrate with different vector databases including [Amazon OpenSearch Serverless](https://aws.amazon.com/opensearch-service/features/serverless/), [Amazon Aurora](https://aws.amazon.com/rds/aurora/), [Pinecone](http://app.pinecone.io/bedrock-integration), [Redis Enterprise]() and [MongoDB Atlas](). For this example, we will integrate the knowledge base with Amazon OpenSearch Serverless. To do so, we will use the helper class `BedrockKnowledgeBase` which will create the knowledge base and all of its pre-requisites:\n",
    "1. IAM roles and policies\n",
    "2. S3 bucket\n",
    "3. Amazon OpenSearch Serverless encryption, network and data access policies\n",
    "4. Amazon OpenSearch Serverless collection\n",
    "5. Amazon OpenSearch Serverless vector index\n",
    "6. Knowledge base\n",
    "7. Knowledge base data source"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8283567d",
   "metadata": {},
   "source": [
    "We will create a knowledge base using fixed chunking strategy. \n",
    "\n",
    "You can chhose different chunking strategies by changing the below parameter values: \n",
    "```\n",
    "\"chunkingStrategy\": \"FIXED_SIZE | NONE | HIERARCHICAL | SEMANTIC\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "258fbb58",
   "metadata": {},
   "outputs": [],
   "source": [
    "knowledge_base_metadata = BedrockKnowledgeBase(\n",
    "    kb_name=f'{knowledge_base_name}-{suffix}',\n",
    "    kb_description=knowledge_base_description,\n",
    "    data_bucket_name=bucket_name, \n",
    "    chunking_strategy = \"FIXED_SIZE\", \n",
    "    suffix = suffix\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c79183c7",
   "metadata": {},
   "source": [
    "### 2.1 Download Amazon 2019, 2020, 2021, 2022, & 2023 annual reports and upload it to Amazon S3\n",
    "\n",
    "Now that we have created the knowledge base, let's populate it with the `sec-10-k reports` dataset to KB. This data is being downloaded from [here](https://ir.aboutamazon.com/annual-reports-proxies-and-shareholder-letters/default.aspx). This data is about Amazon's annual reports, proxies and shareholder letters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c758da68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def create_directory(directory_name):    \n",
    "    if not os.path.exists(directory_name):\n",
    "        os.makedirs(directory_name)\n",
    "        print(f\"Directory '{directory_name}' created successfully.\")\n",
    "    else:\n",
    "        print(f\"Directory '{directory_name}' already exists.\")\n",
    "\n",
    "# Call the function to create the directory\n",
    "create_directory(\"sec-10-k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2bf67c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def download_file(url, filename):\n",
    "    # Send a GET request to the URL\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    # Check if the request was successful\n",
    "    if response.status_code == 200:\n",
    "        # Open the file in write-binary mode\n",
    "        with open(filename, 'wb') as file:\n",
    "            # Write the content of the response to the file\n",
    "            file.write(response.content)\n",
    "        print(f\"File downloaded successfully: {filename}\")\n",
    "    else:\n",
    "        print(f\"Failed to download file. Status code: {response.status_code}\")\n",
    "\n",
    "# URL of the files to download\n",
    "urls = [\"https://s2.q4cdn.com/299287126/files/doc_financials/2024/ar/Amazon-com-Inc-2023-Annual-Report.pdf\",\n",
    "        \"https://s2.q4cdn.com/299287126/files/doc_financials/2023/ar/Amazon-2022-Annual-Report.pdf\",\n",
    "        \"https://s2.q4cdn.com/299287126/files/doc_financials/2022/ar/Amazon-2021-Annual-Report.pdf\",\n",
    "        \"https://s2.q4cdn.com/299287126/files/doc_financials/2021/ar/Amazon-2020-Annual-Report.pdf\",\n",
    "        \"https://s2.q4cdn.com/299287126/files/doc_financials/2020/ar/2019-Annual-Report.pdf\"]\n",
    "\n",
    "\n",
    "for url in urls:\n",
    "    # Name for the downloaded file\n",
    "    filename = url.split('/')[-1]\n",
    "\n",
    "    # Path to save the downloaded file\n",
    "    filepath = f\"./sec-10-k/{filename}\"\n",
    "\n",
    "    # Call the function to download the file\n",
    "    download_file(url, filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b83f68",
   "metadata": {},
   "source": [
    "Let's upload the annual reports data available in the `sec-10-k` folder to s3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e12fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_directory(path, bucket_name):\n",
    "        for root,dirs,files in os.walk(path):\n",
    "            for file in files:\n",
    "                if not file.startswith('.DS_Store'):\n",
    "                    file_to_upload = os.path.join(root,file)\n",
    "                    print(f\"uploading file {file_to_upload} to {bucket_name}\")\n",
    "                    s3_client.upload_file(file_to_upload,bucket_name,file)\n",
    "\n",
    "# upload metadata file to S3\n",
    "upload_directory(\"sec-10-k\", bucket_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b70a4b4b",
   "metadata": {},
   "source": [
    "Now start the ingestion job. Since, we are using the same documents as used for fixed chunking, we are skipping the step to upload documents to s3 bucket. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "241a6ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensure that the kb is available\n",
    "time.sleep(30)\n",
    "# sync knowledge base\n",
    "knowledge_base_metadata.start_ingestion_job()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad55ab6",
   "metadata": {},
   "source": [
    "Finally we save the Knowledge Base Id to test the solution at a later stage. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "677c97ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "kb_id = knowledge_base_metadata.get_knowledge_base_id()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc80032",
   "metadata": {},
   "source": [
    "## 3. Evaluate the relevance of query responses with and without Re-ranking (using Ragas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cea8edf",
   "metadata": {},
   "source": [
    "Define models for generation, evaluation and re-ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bfa5a6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms.bedrock import Bedrock\n",
    "from langchain_aws import ChatBedrock\n",
    "from langchain_aws import BedrockEmbeddings\n",
    "\n",
    "bedrock_client = boto3.client('bedrock-runtime')\n",
    "\n",
    "TEXT_GENERATION_MODEL_ID = \"anthropic.claude-3-haiku-20240307-v1:0\"\n",
    "EVALUATION_MODEL_ID = \"anthropic.claude-3-sonnet-20240229-v1:0\"\n",
    "EMBEDDING_MODEL_ID = \"amazon.titan-embed-text-v2:0\"\n",
    "\n",
    "# Reranker model: there are two reranker models available at launch\n",
    "AMAZON_RERANKER_MODEL_ID = \"amazon.rerank-v1:0\"\n",
    "COHERE_RERANKER_MODEL_ID = \"cohere.rerank-v3-5:0\"\n",
    "\n",
    "\n",
    "llm_for_evaluation = ChatBedrock(model_id=\"anthropic.claude-3-sonnet-20240229-v1:0\", client=bedrock_client)\n",
    "bedrock_embeddings = BedrockEmbeddings(model_id=\"amazon.titan-embed-text-v2:0\", client=bedrock_client)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c336de9",
   "metadata": {},
   "source": [
    "#### 3.1 Update Knowledge Bases execution role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aeac148b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before using autogenerated filters - update the knowledge base execution IAM role with right permissions\n",
    "\n",
    "iam = boto3.resource('iam')\n",
    "client = boto3.client('iam')\n",
    "\n",
    "def get_attached_policies(role_name):\n",
    "    response = client.list_attached_role_policies(RoleName=role_name)\n",
    "    attached_policies = response['AttachedPolicies']\n",
    "    return attached_policies\n",
    "\n",
    "# get the knowledge base IAM role name\n",
    "get_kb_response = bedrock_agent_client.get_knowledge_base(knowledgeBaseId = kb_id)\n",
    "role_arn = get_kb_response['knowledgeBase']['roleArn']\n",
    "role_name = role_arn.split('/')[-1]\n",
    "\n",
    "# get attached policies\n",
    "attached_policies = get_attached_policies(role_name)\n",
    "attached_policies\n",
    "\n",
    "def update_kb_execution_role(attached_policies, region_name):\n",
    "    \n",
    "    for policy in attached_policies:\n",
    "\n",
    "        print(policy['PolicyArn'])\n",
    "        policy_name = policy['PolicyName']\n",
    "        policy_arn = policy['PolicyArn']\n",
    "\n",
    "        if 'FoundationModel' in policy_arn:\n",
    "            print('Updating FoundationModel policy: ',policy_arn)\n",
    "            policy = iam.Policy(policy_arn)\n",
    "            version = policy.default_version\n",
    "            policyJson = version.document\n",
    "            policyJson['Statement'][0]['Resource'].append(f'arn:aws:bedrock:{region}::foundation-model/{TEXT_GENERATION_MODEL_ID}')\n",
    "            policyJson['Statement'][0]['Resource'].append(f'arn:aws:bedrock:{region}::foundation-model/{EVALUATION_MODEL_ID}')  \n",
    "            policyJson['Statement'][0]['Resource'].append(f'arn:aws:bedrock:{region}::foundation-model/{AMAZON_RERANKER_MODEL_ID}') \n",
    "            policyJson['Statement'][0]['Resource'].append(f'arn:aws:bedrock:{region}::foundation-model/{COHERE_RERANKER_MODEL_ID}') \n",
    "        \n",
    "            client.detach_role_policy(RoleName=role_name,\n",
    "                PolicyArn=policy_arn)\n",
    "            \n",
    "            response = client.delete_policy(\n",
    "                PolicyArn=policy_arn\n",
    "            )\n",
    "            print(response)\n",
    "           \n",
    "            response = client.create_policy(\n",
    "            PolicyName= policy_name,\n",
    "            PolicyDocument=json.dumps(policyJson)\n",
    "            )\n",
    "            print(response)\n",
    "        \n",
    "        client.attach_role_policy(\n",
    "            RoleName=role_name,\n",
    "            PolicyArn=policy_arn\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3521cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "update_kb_execution_role(attached_policies, region)\n",
    "# time.sleep(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "529118c5",
   "metadata": {},
   "source": [
    "#### 3.2 Customize retrieve and generate configuraion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "df68891d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_and_generate(query, reranker_model=None, kb_id=None, TEXT_GENERATION_MODEL_ID=None, metadata_filters=None):\n",
    "    \n",
    "    # Prepare retrieval configuration\n",
    "    retrieval_config = {\n",
    "        \"vectorSearchConfiguration\": {\n",
    "            \"numberOfResults\": 30 if reranker_model else 3\n",
    "        }\n",
    "    }\n",
    "\n",
    "    if reranker_model:\n",
    "        retrieval_config[\"vectorSearchConfiguration\"][\"rerankingConfiguration\"] = {\n",
    "            \"type\": \"BEDROCK_RERANKING_MODEL\",\n",
    "            \"bedrockRerankingConfiguration\": {\n",
    "                \"modelConfiguration\": {\n",
    "                    \"modelArn\": f'arn:aws:bedrock:{region}::foundation-model/{reranker_model}',\n",
    "                },\n",
    "                \"numberOfRerankedResults\": 3\n",
    "            }\n",
    "        }\n",
    "\n",
    "        if metadata_filters:\n",
    "            retrieval_config[\"vectorSearchConfiguration\"][\"rerankingConfiguration\"][\"bedrockRerankingConfiguration\"][\"metadataConfiguration\"] = {\n",
    "                                                                \"selectionMode\" : \"SELECTIVE\",\n",
    "                                                                \"selectiveModeConfiguration\" : {\n",
    "                                                                    \"fieldsToInclude\": [{\n",
    "                                                                        \"fieldName\": \"year\",\n",
    "                                                                    }]\n",
    "                                                                }\n",
    "                                                            }\n",
    "                    \n",
    "\n",
    "    # Call the retrieve and generate API\n",
    "    start = time.time()\n",
    "    response = bedrock_agent_runtime_client.retrieve_and_generate(\n",
    "        input={'text': query},\n",
    "        retrieveAndGenerateConfiguration={\n",
    "            'type': 'KNOWLEDGE_BASE',\n",
    "            'knowledgeBaseConfiguration': {\n",
    "                'knowledgeBaseId': kb_id,\n",
    "                'modelArn': f'arn:aws:bedrock:{region}::foundation-model/{TEXT_GENERATION_MODEL_ID}',\n",
    "                'retrievalConfiguration': retrieval_config,\n",
    "            },\n",
    "        }\n",
    "    )\n",
    "    time_spent = time.time() - start\n",
    "\n",
    "    print(f\"[Response] : {response['output']['text']}\\n\")\n",
    "    print(f\"[Invocation time] : {time_spent}\\n\")\n",
    "\n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc724b4",
   "metadata": {},
   "source": [
    "#### 3.3 Prepare dataset for evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b086554a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "from ragas import evaluate\n",
    "from ragas.metrics import (\n",
    "    context_relevancy,\n",
    "    context_recall,\n",
    "    context_precision,\n",
    "    context_entity_recall,\n",
    "    answer_correctness,\n",
    ")\n",
    "\n",
    "#specify the metrics here\n",
    "metrics = [\n",
    "    context_relevancy,\n",
    "    context_recall,\n",
    "    context_precision,\n",
    "    context_entity_recall,\n",
    "    answer_correctness,\n",
    "]\n",
    "\n",
    "questions = [\n",
    "    \"How many jobs did Amazon create in 2020, and what was its total global workforce after this expansion?\",\n",
    "    \"How does the 2023 net sales mix reflect Amazon's global priorities and strategic investments across segments?\",\n",
    "    \"How did foreign exchange rate fluctuations impact Amazon's net sales and the corresponding segment's performance in 2023?\",\n",
    "    \"What is the cumulative growth contribution of AWS and Advertising segments to Amazon's 2022 consolidated revenue?\",\n",
    "    \"How did Amazon's investments in technology infrastructure and fulfillment operations affect its cash flows and operating expenses in 2022?\",\n",
    "    \"What types of securities does Amazon invest its excess cash in 2019 and how are these investments classified in the balance sheet?\"\n",
    "]\n",
    "ground_truths = [\n",
    "    \"Amazon added 500,000 jobs in 2020, bringing its total workforce to approximately 1.3 million employees worldwide.\",\n",
    "    \"Amazon's 2023 net sales mix highlights its global priorities, with North America contributing 61%, International 23%, and AWS 16% of total sales. Year-over-year growth in each segment—12% for North America, 11% for International, and 13% for AWS—was driven by increased unit sales, advertising services, and subscription offerings. These trends reflect Amazon's balanced approach to expanding its core markets, strengthening its international presence, and investing in AWS's innovative cloud services to sustain long-term growth.\",\n",
    "    \"In 2023, foreign exchange rate fluctuations had a mixed impact on Amazon's financial performance. While these changes reduced consolidated net sales by $71 million, they positively influenced the International segment, increasing its net sales by $88 million. This highlights the nuanced effects of currency fluctuations, where gains in specific regions, such as the International segment, helped offset broader challenges at the consolidated level.\",\n",
    "    \"In 2022, AWS achieved a 29% year-over-year revenue growth, increasing from $62.2 billion in 2021 to $80.1 billion. Similarly, the Advertising segment experienced a 25% year-over-year growth, reaching $31 billion in revenue for the year. Together, these segments contributed significantly to Amazon's total consolidated revenue of $434 billion. AWS accounted for 19.59%, while Advertising contributed 7.14%, resulting in a cumulative contribution of approximately 26.73%.\",\n",
    "    \"In 2022, Amazon's substantial investments in technology infrastructure and fulfillment operations significantly impacted its cash flows and operating expenses. The company allocated $58.3 billion in cash capital expenditures to support AWS growth and expand its fulfillment network, resulting in a 31% increase in technology and content expenses due to higher payroll costs for technical teams and infrastructure spending on servers, networking equipment, and data centers. Fulfillment costs rose by 12%, driven by increased product sales volume, inventory levels, and wage rate incentives. These investments led to a decline in free cash flow to $(11,569) million, compared to $(9,069) million in 2021. Despite the higher costs, these expenditures were crucial for scaling operations, enhancing the customer experience, and sustaining long-term growth, particularly in AWS and global fulfillment capacity, highlighting Amazon's commitment to maintaining its competitive edge in a rapidly evolving market.\",\n",
    "    \"Amazon typically invests its excess cash in AAA-rated money market funds and investment-grade short- to intermediate-term fixed income securities, which are classified as either Cash and cash equivalents or Marketable securities on its consolidated balance sheets. In 2019, Amazon's marketable securities portfolio included a variety of assets such as money market funds, equity securities, foreign government and agency securities, U.S. government and agency securities, corporate debt securities, asset-backed securities, and other fixed income securities. These marketable securities were categorized as either Level 1 or Level 2 securities on the balance sheet.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4ff26dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_eval_dataset(questions, ground_truths, kb_id=None, TEXT_GENERATION_MODEL_ID=None, reranker_model=None, metadata_filters = None):\n",
    "    answers = []\n",
    "    contexts = []\n",
    "    \n",
    "    for query in questions:\n",
    "        response = retrieve_and_generate(\n",
    "            query,\n",
    "            reranker_model=reranker_model,\n",
    "            kb_id=kb_id,\n",
    "            TEXT_GENERATION_MODEL_ID=TEXT_GENERATION_MODEL_ID,\n",
    "            metadata_filters=metadata_filters\n",
    "        )\n",
    "        \n",
    "        answers.append(response[\"output\"][\"text\"])\n",
    "        \n",
    "        context_group = []\n",
    "        for citation in response[\"citations\"]:\n",
    "            context_group.extend([\n",
    "                ref[\"content\"][\"text\"]\n",
    "                for ref in citation[\"retrievedReferences\"]\n",
    "                if \"content\" in ref and \"text\" in ref[\"content\"]\n",
    "            ])\n",
    "        contexts.append(context_group)\n",
    "        time.sleep(15)\n",
    "\n",
    "    # Create dictionary\n",
    "    data = {\n",
    "        \"question\": questions,\n",
    "        \"answer\": answers,\n",
    "        \"contexts\": contexts,\n",
    "        \"ground_truth\": ground_truths\n",
    "    }\n",
    "\n",
    "    # Convert dict to dataset\n",
    "    dataset = Dataset.from_dict(data)\n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c51b09a",
   "metadata": {},
   "source": [
    "#### 3.4 Evaluate dataset - without re-ranker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84dc3d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "without_reranker_dataset = prepare_eval_dataset(questions, ground_truths, kb_id, TEXT_GENERATION_MODEL_ID, reranker_model=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9250cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "without_reranker_result = evaluate(\n",
    "    dataset=without_reranker_dataset,\n",
    "    metrics=metrics,\n",
    "    llm=llm_for_evaluation,\n",
    "    embeddings=bedrock_embeddings,\n",
    ")\n",
    "\n",
    "without_reranker_result_df = without_reranker_result.to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61243e2d",
   "metadata": {},
   "source": [
    "#### 3.5 Evaluate dataset - with re-ranker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92591600",
   "metadata": {},
   "outputs": [],
   "source": [
    "with_reranker_dataset = prepare_eval_dataset(questions, ground_truths, kb_id, TEXT_GENERATION_MODEL_ID, reranker_model=AMAZON_RERANKER_MODEL_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e78450",
   "metadata": {},
   "outputs": [],
   "source": [
    "with_reranker_result = evaluate(\n",
    "dataset=with_reranker_dataset,\n",
    "metrics=metrics,\n",
    "llm=llm_for_evaluation,\n",
    "embeddings=bedrock_embeddings,\n",
    ")\n",
    "\n",
    "with_reranker_result_df = with_reranker_result.to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f2f965",
   "metadata": {},
   "source": [
    "#### 3.4 Evaluate dataset - with re-ranker + metadata configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c85464",
   "metadata": {},
   "source": [
    "##### 3.4.1 Prepare metadata for ingestion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "17fe7e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "def generate_matadata(data_dir):\n",
    "    \n",
    "    # Loop through all PDF files in the directory\n",
    "    for filename in os.listdir(data_dir):\n",
    "        if not filename.startswith('.DS_Store'):\n",
    "            # Define the metadata dictionary\n",
    "            metadata ={}\n",
    "            \n",
    "            filename= f'{data_dir}/{filename}'\n",
    "            print(filename)\n",
    "            \n",
    "            # Create metadata\n",
    "            metadata[\"company\"] = \"Amazon\"\n",
    "            metadata[\"ticker\"] = \"AMZN\"\n",
    "            metadata[\"year\"] = re.search(r'\\d+', filename.split('/')[-1]).group(0)\n",
    "\n",
    "            # Create a JSON object\n",
    "            json_data = {\"metadataAttributes\": metadata}\n",
    "\n",
    "            # print(json_data)\n",
    "\n",
    "            # Write the JSON object to a file\n",
    "            with open(f\"{filename.replace('.pdf', '.pdf.metadata.json')}\", \"w\") as f:\n",
    "                json.dump(json_data, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a16a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = './sec-10-k'\n",
    "generate_matadata(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca6d8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload metadata file to S3\n",
    "upload_directory(\"sec-10-k\", bucket_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c503656e",
   "metadata": {},
   "source": [
    "##### 3.4.2 Ingest metadata into Knowledge Bases\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "576f6fe6",
   "metadata": {},
   "source": [
    "Now start the ingestion job. Since, we are using the same documents as used for fixed chunking, we are skipping the step to upload documents to s3 bucket. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdfb5938",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensure that the kb is available\n",
    "time.sleep(30)\n",
    "# sync knowledge base\n",
    "knowledge_base_metadata.start_ingestion_job()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12589fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with_reranker_metadata_filters_dataset = prepare_eval_dataset(questions, ground_truths, kb_id, TEXT_GENERATION_MODEL_ID, reranker_model=AMAZON_RERANKER_MODEL_ID, metadata_filters=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21463f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with_reranker_metadata_filters_result = evaluate(\n",
    "dataset=with_reranker_metadata_filters_dataset,\n",
    "metrics=metrics,\n",
    "llm=llm_for_evaluation,\n",
    "embeddings=bedrock_embeddings,\n",
    ")\n",
    "\n",
    "with_reranker_metadata_filters_result_df = with_reranker_result.to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c44ec665",
   "metadata": {},
   "source": [
    "#### 3.5 Prepare Comparison data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f5ca9fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create the side-by-side DataFrame\n",
    "comparison_df = pd.DataFrame({\n",
    "    'question': without_reranker_result_df['question'],\n",
    "    'without_reranker_answer': without_reranker_result_df['answer'],\n",
    "    'with_reranker_answer': with_reranker_result_df['answer'],\n",
    "    'with_reranker_metadata_answer': with_reranker_metadata_filters_result_df['answer'],\n",
    "    \n",
    "    'without_reranker_answer_correctness': without_reranker_result_df['answer_correctness'],\n",
    "    'with_reranker_answer_correctness': with_reranker_result_df['answer_correctness'],\n",
    "    'with_reranker_metadata_correctness': with_reranker_metadata_filters_result_df['answer_correctness'],\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30363097",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_colwidth = 1000\n",
    "comparison_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e83ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate average correctness\n",
    "without_reranker_avg_correctness = without_reranker_result_df['answer_correctness'].mean()\n",
    "with_reranker_avg_correctness = with_reranker_result_df['answer_correctness'].mean()\n",
    "with_reranker_metadata_avg_correctness = with_reranker_metadata_filters_result_df['answer_correctness'].mean()\n",
    "\n",
    "print(f\"\\nAverage Correctness without Reranker: {without_reranker_avg_correctness:.4f}\")\n",
    "print(f\"Average Correctness with Reranker: {with_reranker_avg_correctness:.4f}\")\n",
    "print(f\"Average Correctness with Reranker and metadata filter: {with_reranker_metadata_avg_correctness:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5577ab01-5239-4a19-9042-a263e8a3de6b",
   "metadata": {},
   "source": [
    "### 2.7 Clean up\n",
    "Please make sure to uncomment and run below cells to delete the resources created in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f8a07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete local directory\n",
    "import shutil\n",
    "\n",
    "dir_path = \"sec-10-k\" # Replace with the actual path\n",
    "\n",
    "try:\n",
    "    shutil.rmtree(dir_path)\n",
    "    print(f\"Directory '{dir_path}' and its contents have been deleted successfully.\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Directory '{dir_path}' not found.\")\n",
    "except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab05eb1-76c9-47b7-8d28-16ee720966d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Empty and delete S3 Bucket\n",
    "\n",
    "objects = s3_client.list_objects(Bucket=bucket_name)  \n",
    "if 'Contents' in objects:\n",
    "    for obj in objects['Contents']:\n",
    "        s3_client.delete_object(Bucket=bucket_name, Key=obj['Key']) \n",
    "s3_client.delete_bucket(Bucket=bucket_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0cab3a2-e121-4d65-9254-4d318cf428f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"===============================Knowledge base==============================\")\n",
    "knowledge_base_metadata.delete_kb(delete_s3_bucket=True, delete_iam_roles_and_policies=True)"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
