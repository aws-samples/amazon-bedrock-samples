{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0990bbd-0159-48f2-bba6-3b28dca6c4f6",
   "metadata": {},
   "source": [
    "# Combining Guardrails Contextual Grounding and Knowledge Bases\n",
    "This notebook demonstrates how to combine Guardrails for Amazon Bedrock contextual grounding filter with the Knowledge Bases for Amazon Bedrock. By doing so, we can ensure that the model's responses are factually grounded and aligned with the information stored in the Knowledge Base.\n",
    "\n",
    "In the notebook we will be using the [D&D Systems Reference Document (SRD)](https://www.dndbeyond.com/resources/1781-systems-reference-document-srd)(CC-BY-4.0) to store it into the Knowledge Base.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4847b39-cc13-4ade-9354-37d9f0dd44f7",
   "metadata": {},
   "source": [
    "What we are going to create in this notebook:\n",
    "1. **Import libraries:** We will load the needed libraries to make the notebook work correctly. \n",
    "2. **Create Knowledge Base:** We are going to store the D&D Systems Reference Document in a managed knowledge base in Amazon Bedrock. \n",
    "3. **Configure Guardrail:** We are going to configure our guardrail with the contextual grounding filter thresholds.\n",
    "4. **Test the contextual grounding:** We are going to retrieve context from the KB and pass it to a LLM with a query and evaluate hallucinations. \n",
    "5. **Delete resources:** To save in costs, we are going to delete all the resources created. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed816ff-4a40-4c7f-9487-317eb06ad7ed",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Note:</b> Please make sure to enable `Anthropic Claude 3 Sonnet`and `Titan Embedding Text V2`  model access in Amazon Bedrock Console, as the notebook will use these models.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b365cc77-4b27-4a20-9b0f-2ba0075a0a6a",
   "metadata": {},
   "source": [
    "## 1. Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd96469-b93e-4344-aba3-4e4937d92067",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --force-reinstall -q -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f59ae64-03a5-4d4a-87bd-4c35514d90b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import uuid\n",
    "import boto3\n",
    "import json\n",
    "import requests\n",
    "from knowledge_base import BedrockKnowledgeBase\n",
    "from utils import print_results,print_results_with_guardrail\n",
    "session = boto3.session.Session()\n",
    "region = session.region_name\n",
    "unique_id = str(uuid.uuid4())[:4]\n",
    "s3_client = boto3.client(\"s3\",region_name=region)\n",
    "bedrock = boto3.client(\"bedrock\",region_name=region)\n",
    "bedrock_runtime = boto3.client(\"bedrock-runtime\",region_name=region)\n",
    "bedrock_agent_client = boto3.client(\"bedrock-agent\",region_name=region)\n",
    "bedrock_agent_runtime_client = boto3.client(\"bedrock-agent-runtime\",region_name=region)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69a0aca1-2e0f-4a6a-974c-6d0cde052748",
   "metadata": {},
   "source": [
    "## 2. Create Knowledge Base for Amazon Bedrock"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f3c375-58da-4a9a-a675-5225d46650fb",
   "metadata": {},
   "source": [
    "### 2.1 Download the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e59fa25-a6c0-4f54-ab9d-bae4fc4c46fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://media.wizards.com/2023/downloads/dnd/SRD_CC_v5.1.pdf\"\n",
    "file_name = \"kb_documents/SRD_CC_v5.1.pdf\"\n",
    "os.makedirs(\"kb_documents\", exist_ok=True)\n",
    "response = requests.get(url)\n",
    "with open(file_name, \"wb\") as file:\n",
    "    file.write(response.content)\n",
    "print(f\"File '{file_name}' has been downloaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3222db64-9526-4a71-bc4c-81886d7b2cc5",
   "metadata": {},
   "source": [
    "### 2.1 Creating Knowledge Base for Amazon Bedrock\n",
    "\n",
    "We will now going to create a Knowledge Base for Amazon Bedrock and its requirements including:\n",
    "- [Amazon OpenSearch Serverless](https://aws.amazon.com/opensearch-service/features/serverless/) for the vector database\n",
    "- [AWS IAM](https://aws.amazon.com/iam/) roles and permissions\n",
    "- [Amazon S3](https://aws.amazon.com/s3/) bucket to store the knowledge base documents\n",
    "\n",
    "To create the knowledge base and its dependencies, we will use the `BedrockKnowledgeBase` support class, available in this folder. It allows you to create a new knowledge base, ingest documents to the knowledge base data source and delete the resources after you are done working with this lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed3e9f6-1a27-402e-aaae-b23885b091e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "knowledge_base_name = \"{}-cgdemo\".format(unique_id)\n",
    "knowledge_base_description = \"Knowledge Base containing d&d Guide\"\n",
    "bucket_name = \"{}-cgdemo-bucket\".format(unique_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f303ac-963e-457e-bebd-9c588527d3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "knowledge_base = BedrockKnowledgeBase(\n",
    "    kb_name=knowledge_base_name,\n",
    "    kb_description=knowledge_base_description,\n",
    "    data_bucket_name=bucket_name,\n",
    "    chunking_strategy = \"FIXED_SIZE\", \n",
    "    suffix = f'{unique_id}-f'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fa2e9c8-ea4b-4730-b19d-6d291e6d5c40",
   "metadata": {},
   "source": [
    "We now upload the knowledge base documents to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "585e3bd1-5835-4bf4-af67-021ed3acaead",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_directory(path, bucket_name):\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for file in files:\n",
    "            if file.endswith(\".pdf\"):\n",
    "                file_to_upload = os.path.join(root, file)\n",
    "                print(f\"uploading file {file_to_upload} to {bucket_name}\")\n",
    "                s3_client.upload_file(file_to_upload, bucket_name, file)\n",
    "\n",
    "upload_directory(\"kb_documents\", bucket_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5972a33-dcbb-4320-961e-e0ed6120eac5",
   "metadata": {},
   "source": [
    "And ingest the documents to the knowledge base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b8b265-1f39-4293-b7d0-049207acdd34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensure that the kb is available\n",
    "time.sleep(30)\n",
    "# sync knowledge base\n",
    "knowledge_base.start_ingestion_job()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c25c31d-14c7-40aa-9736-5d2e17f91177",
   "metadata": {},
   "outputs": [],
   "source": [
    "kb_id = knowledge_base.get_knowledge_base_id()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb0acbb-3c38-4ae6-af8f-5fccde836cc6",
   "metadata": {},
   "source": [
    "### 2.2 Testing Knowledge Base\n",
    "Let's now test that the created knowledge base works as expected. To do so, we first retrieve the knowledge base id. \n",
    "\n",
    "Next we can use the [`RetrieveAndGenerate`](https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/bedrock-agent-runtime/client/retrieve_and_generate.html) \n",
    "API from boto3 to retrieve the context for the question from the knowledge base and generate the final response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e97f13-6490-4121-9fc6-c890137bc278",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id=\"anthropic.claude-3-sonnet-20240229-v1:0\"\n",
    "response = bedrock_agent_runtime_client.retrieve_and_generate(\n",
    "    input={\n",
    "        \"text\": \"What should I know about elves?\"\n",
    "    },\n",
    "    retrieveAndGenerateConfiguration={\n",
    "        \"type\": \"KNOWLEDGE_BASE\",\n",
    "        \"knowledgeBaseConfiguration\": {\n",
    "            'knowledgeBaseId': kb_id,\n",
    "            \"modelArn\": model_id,\n",
    "            \"retrievalConfiguration\": {\n",
    "                \"vectorSearchConfiguration\": {\n",
    "                    \"numberOfResults\":5\n",
    "                } \n",
    "            }\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "print(response['output']['text'],end='\\n'*2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67569ad0-8e72-4a54-9d8e-0bf7b85937fb",
   "metadata": {},
   "source": [
    "## 3. Configure Guardrail for Amazon Bedrock"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78fcfffe-117d-43a2-b907-aa09219e33d9",
   "metadata": {},
   "source": [
    "Now we have the Knowledge Base created, configured and synced with our documents, let's go and create our Guardrail for Amazon Bedrock. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f4d1113-63c1-407c-82a3-f633db256e4f",
   "metadata": {},
   "source": [
    "There are two filtering parameters for the contextual grounding check:\n",
    "\n",
    "- **Grounding** â€“ This can be enabled by providing a grounding threshold that represents the minimum confidence score for a model response to be grounded. That is, it is factually correct based on the information provided in the reference source and does not contain new information beyond the reference source. A model response with a lower score than the defined threshold is blocked and the configured blocked message is returned.\n",
    "\n",
    "- **Relevance** â€“ This parameter works based on a relevance threshold that represents the minimum confidence score for a model response to be relevant to the userâ€™s query. Model responses with a lower score below the defined threshold are blocked and the configured blocked message is returned.\n",
    "\n",
    "A higher threshold for the grounding and relevance scores will result in more responses being blocked. Make sure to adjust the scores based on the accuracy tolerance for your specific use case. For example, a customer-facing application in the finance domain may need a high threshold due to lower tolerance for inaccurate content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04dffb9f-09d3-4e4a-a8b4-0145acf0c873",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = bedrock.create_guardrail(\n",
    "    name=\"contextual-grounding-guardrail-{}\".format(unique_id),\n",
    "    description=\"D&D Guardrail\",\n",
    "    contextualGroundingPolicyConfig={\n",
    "        'filtersConfig': [\n",
    "            {\n",
    "                'type': 'GROUNDING',\n",
    "                'threshold': 0.5\n",
    "            },\n",
    "            {\n",
    "                'type': 'RELEVANCE',\n",
    "                'threshold': 0.8\n",
    "            },\n",
    "        ]\n",
    "    },\n",
    "    blockedInputMessaging=\"Sorry, I can not respond to this.\",\n",
    "    blockedOutputsMessaging=\"Sorry, I can not respond to this.\",\n",
    ")\n",
    "guardrailId = response[\"guardrailId\"]\n",
    "print(\"The guardrail id is\",response[\"guardrailId\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47c53e38-4289-45f0-ba3d-16abf26b544d",
   "metadata": {},
   "source": [
    "## 4. Test the contextual grounding capability\n",
    "Now we have set up the Knowledge Base and Guardrail let's test them together.\n",
    "\n",
    "In this section we will first retrieve the KB results and then pass it on to the Converse API which has the Guardrail integrated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c003c734-8ce1-406f-8840-db553ac53f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def invoke_kb(kb_query):\n",
    "    kb_response = bedrock_agent_runtime_client.retrieve(\n",
    "        knowledgeBaseId=kb_id,\n",
    "        retrievalConfiguration={\n",
    "            'vectorSearchConfiguration': {\n",
    "                'numberOfResults': 2,\n",
    "            }\n",
    "        },\n",
    "        retrievalQuery={\n",
    "            'text': kb_query\n",
    "        }\n",
    "    )\n",
    "    model_id=\"anthropic.claude-3-sonnet-20240229-v1:0\"\n",
    " \n",
    "    inference_config = {\"temperature\": 0.1}\n",
    "\n",
    "    # The message for the model and the content that you want the guardrail to assess.\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"text\": str(kb_response)},\n",
    "                {\"text\": kb_query}\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "    response = bedrock_runtime.converse(modelId=model_id,messages=messages, inferenceConfig=inference_config)\n",
    "    print(\"\"\"\n",
    "    ================================\n",
    "    Invoke KB without Guardrails\n",
    "    ================================\n",
    "    \"\"\")\n",
    "    print_results(kb_response, response)\n",
    "\n",
    "\n",
    "def invoke_kb_with_guardrail(kb_query):\n",
    "    kb_response = bedrock_agent_runtime_client.retrieve(\n",
    "        knowledgeBaseId=kb_id,\n",
    "        retrievalConfiguration={\n",
    "            'vectorSearchConfiguration': {\n",
    "                'numberOfResults': 2,\n",
    "            }\n",
    "        },\n",
    "        retrievalQuery={\n",
    "            'text': kb_query\n",
    "        }\n",
    "    )\n",
    "    model_id=\"anthropic.claude-3-sonnet-20240229-v1:0\"\n",
    "    inference_config = {\"temperature\": 0.1}\n",
    "    guardrail_config = {\n",
    "        \"guardrailIdentifier\": guardrailId,\n",
    "        \"guardrailVersion\": \"DRAFT\",\n",
    "        \"trace\": \"enabled\"\n",
    "    }\n",
    "\n",
    "    # The message for the model and the content that you want the guardrail to assess.\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"guardContent\": {\n",
    "                        \"text\": {\n",
    "                            \"text\": str(kb_response),\n",
    "                            \"qualifiers\": [\"grounding_source\"],\n",
    "                        }\n",
    "                    }\n",
    "                },\n",
    "                {\n",
    "                    \"guardContent\": {\n",
    "                        \"text\": {\n",
    "                            \"text\": kb_query,\n",
    "                            \"qualifiers\": [\"query\"],\n",
    "                        }\n",
    "                    }\n",
    "                },\n",
    "            ],\n",
    "        }\n",
    "    ]\n",
    "    response = bedrock_runtime.converse(modelId=model_id,messages=messages,guardrailConfig=guardrail_config, inferenceConfig=inference_config,)\n",
    "    print(\"\"\"\n",
    "    ================================\n",
    "    Invoke KB with Guardrails\n",
    "    ================================\n",
    "    \"\"\")\n",
    "    print_results_with_guardrail(kb_response, response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50970d62-d6a1-4029-b1df-f3d4654ea3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "kb_query = \"What are High Elves?\"\n",
    "invoke_kb(kb_query)\n",
    "invoke_kb_with_guardrail(kb_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d50a33-2669-4052-9c62-4272560fec00",
   "metadata": {},
   "outputs": [],
   "source": [
    "kb_query = \"Where should the elves go if they arrive in Paris?\"\n",
    "invoke_kb(kb_query)\n",
    "invoke_kb_with_guardrail(kb_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e85431-d209-4fc6-84da-1a190d73001c",
   "metadata": {},
   "source": [
    "## 5. Delete resources\n",
    "Let's delete all the resources to avoid unnecessary costs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7aba642-7f9c-4369-9320-f00c53947fb5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Delete the Knowledge Base\n",
    "knowledge_base.delete_kb(delete_s3_bucket=True, delete_iam_roles_and_policies=True)\n",
    "## Delete the Guardrail\n",
    "bedrock.delete_guardrail(guardrailIdentifier = guardrailId)"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-west-2:236514542706:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
