{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom JSON Processing with Transformation Functions in Amazon Bedrock Knowledge Bases\n",
    "\n",
    "In modern RAG applications, the ability to effectively process and transform data before it reaches your Foundation Models is crucial for optimal performance. While standard JSON processing works for many use cases, complex enterprise applications often require more nuanced control over how their data is structured and presented. \n",
    "\n",
    "Just as query reformulation helps break down complex queries for better retrieval, transformation functions allow you to reshape and refine your JSON data to better serve your specific use case. This capability is particularly valuable when working with varied data sources or when you need to standardize information across different formats. By customizing how your JSON data is processed, you can enhance the quality of responses from your RAG applications while maintaining efficiency and scalability.\n",
    "\n",
    "This example will explore how to leverage transformation functions in Amazon Bedrock Knowledge Bases to optimize your JSON processing pipeline and achieve more precise and relevant results from your GenAI applications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset\n",
    "\n",
    "This example is processing JSON files from FootballData dataset, for UEFA European Championship 2016.\n",
    "\n",
    "We're not going to use entire dataset, we just filtered a couple of teams, to be part of our example.\n",
    "\n",
    "Dataset can be found on [this](https://github.com/jokecamp/FootballData/tree/master/UEFA_European_Championship/Euro%202016/players_json) under MIT license."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import the needed libraries\n",
    "\n",
    "First step is to install the pre-requisites packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --upgrade pip --quiet\n",
    "%pip install -r ../requirements.txt --no-deps --quiet\n",
    "%pip install -r ../requirements.txt --upgrade --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to restart kernel\n",
    "\n",
    "#import IPython\n",
    "\n",
    "#IPython.Application.instance().kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import boto3\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "sys.path.insert(0, \".\")\n",
    "sys.path.insert(1, \"..\")\n",
    "\n",
    "\n",
    "from utils.knowledge_base import BedrockKnowledgeBase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following are clients and variables that will be used across this example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clients\n",
    "s3_client = boto3.client('s3')\n",
    "sts_client = boto3.client('sts')\n",
    "session = boto3.session.Session()\n",
    "region =  session.region_name\n",
    "account_id = sts_client.get_caller_identity()[\"Account\"]\n",
    "bedrock_client = boto3.client('bedrock') \n",
    "bedrock_agent_client = boto3.client('bedrock-agent')\n",
    "bedrock_agent_runtime_client = boto3.client('bedrock-agent-runtime')\n",
    "iam_client = boto3.client('iam')\n",
    "\n",
    "\n",
    "region, account_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Get the current timestamp\n",
    "current_time = time.time()\n",
    "\n",
    "# Format the timestamp as a string\n",
    "timestamp_str = time.strftime(\"%Y%m%d%H%M%S\", time.localtime(current_time))[-7:]\n",
    "# Create the suffix using the timestamp\n",
    "suffix = f\"{timestamp_str}\"\n",
    "\n",
    "knowledge_base_name_custom = 'custom-chunking-kb'\n",
    "knowledge_base_description = \"Knowledge Base containing complex Json\"\n",
    "bucket_name = f'{knowledge_base_name_custom}-{suffix}'\n",
    "intermediate_bucket_name = f'{knowledge_base_name_custom}-intermediate-{suffix}'\n",
    "lambda_function_name = f'{knowledge_base_name_custom}-lambda-{suffix}'\n",
    "foundation_model = \"anthropic.claude-3-sonnet-20240229-v1:0\"\n",
    "\n",
    "# Define data sources\n",
    "data_source=[{\"type\": \"S3\", \"bucket_name\": bucket_name}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 - Create Lambda Function\n",
    "\n",
    "Following customized Lambda function will work as a transformation function to process JSON elements from input datasets and split it before ingest on Vector Database.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile lambda_function.py\n",
    "import json\n",
    "import logging\n",
    "import boto3\n",
    "\n",
    "\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "\n",
    "def read_s3_file(s3_client, bucket, key):\n",
    "    response = s3_client.get_object(Bucket=bucket, Key=key)\n",
    "    return json.loads(response['Body'].read().decode('utf-8'))\n",
    "\n",
    "def write_to_s3(s3_client, bucket, key, content):\n",
    "    s3_client.put_object(Bucket=bucket, Key=key, Body=json.dumps(content))\n",
    "\n",
    "\n",
    "def lambda_handler(event, context):\n",
    "    logger.info('input={}'.format(json.dumps(event)))\n",
    "    s3 = boto3.client('s3')\n",
    "\n",
    "    # Extract relevant information from the input event\n",
    "    input_files = event.get('inputFiles')\n",
    "    input_bucket = event.get('bucketName')\n",
    "\n",
    "    if not all([input_files, input_bucket]):\n",
    "        raise ValueError(\"Missing required input parameters\")\n",
    "\n",
    "    output_files = []\n",
    "\n",
    "    for input_file in input_files:\n",
    "        logger.info('input file ={}'.format(input_file))\n",
    "        content_batches = input_file.get('contentBatches', [])\n",
    "        original_file_location = input_file.get('originalFileLocation', {})\n",
    "\n",
    "        processed_batches = []\n",
    "\n",
    "        for batch in content_batches:\n",
    "            input_key = batch.get('key')\n",
    "            #print(input_key)\n",
    "            if not input_key:\n",
    "                    raise ValueError(\"Missing key in content batch\")\n",
    "\n",
    "            file_content = read_s3_file(s3, input_bucket, input_key)\n",
    "\n",
    "            # Process content\n",
    "            file_key = \"sheets\"\n",
    "            json_content = json.loads(file_content['fileContents'][0]['contentBody'])\n",
    "            sec_key = \"\"\n",
    "            \n",
    "            if 'Players' in json_content[file_key]:\n",
    "                sec_key = 'Players'\n",
    "            elif 'Teams' in json_content[file_key]:\n",
    "                sec_key = 'Teams'\n",
    "            else:\n",
    "                raise Exception(\"Key Not Found on File\")\n",
    "\n",
    "            for i in json_content[file_key][sec_key]:\n",
    "                filename_key = input_key.split('/')[-1].replace('-players_1.JSON','')\n",
    "                i.update({'filename': filename_key})\n",
    "                print(i)\n",
    "                id_key = 'name' if 'name' in i else 'Team'\n",
    "                #output_key = \"output/{}_{}.json\".format(file_key, i['id'])\n",
    "                output_key = \"output/{}_{}.json\".format(filename_key, i[id_key])\n",
    "                print(output_key)\n",
    "                processed_content = {'fileContents': []}\n",
    "                processed_content['fileContents'].append({\n",
    "                        'contentType': 'json', \n",
    "                        'contentBody': json.dumps(i)\n",
    "                })\n",
    "                \n",
    "                # Write processed content back to S3\n",
    "                write_to_s3(s3, input_bucket, output_key, processed_content)\n",
    "\n",
    "                # Add processed batch information\n",
    "                processed_batches.append({\n",
    "                    'key': output_key\n",
    "                })\n",
    "        \n",
    "        output_file = {\n",
    "            'originalFileLocation': original_file_location,\n",
    "            'contentBatches': processed_batches\n",
    "        }\n",
    "\n",
    "        output_files.append(output_file)\n",
    "\n",
    "    result = {'outputFiles': output_files}\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 - Create Knowledge Base with custom chunking strategy\n",
    "\n",
    "Let's start by creating a Amazon Bedrock Knowledge Base to store couple of datasets (on [dataset/](../dataset/) folder):\n",
    "\n",
    "- `team-player.json`: data from specific team, where team will be an specific Country soccer team, for example: `italy-players.json` has information about Italy team during Euro 2016.\n",
    "\n",
    "**As mentioned, in [Dataset](#Dataset) section, this is an open dataset under MIT license.**\n",
    "\n",
    "Knowledge Bases allow you to integrate with different vector databases including Amazon OpenSearch Serverless, Amazon Aurora, Pinecone, Redis Enterprise and MongoDB Atlas. For this example, we will integrate the knowledge base with Amazon OpenSearch Serverless. To do so, we will use the helper class BedrockKnowledgeBase which will create the knowledge base and all of its pre-requisites:\n",
    "\n",
    "1. IAM roles and policies\n",
    "1. S3 bucket\n",
    "1. Amazon OpenSearch Serverless encryption, network and data access policies\n",
    "1. Amazon OpenSearch Serverless collection\n",
    "1. Amazon OpenSearch Serverless vector index\n",
    "1. Knowledge base\n",
    "1. Knowledge base data source\n",
    "1. Create a knowledge base using CUSTOM chunking strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "knowledge_base_custom = BedrockKnowledgeBase(\n",
    "    kb_name=f'{knowledge_base_name_custom}-{suffix}',\n",
    "    kb_description=knowledge_base_description,\n",
    "    data_sources=data_source,\n",
    "    lambda_function_name=lambda_function_name,\n",
    "    intermediate_bucket_name=intermediate_bucket_name, \n",
    "    chunking_strategy = \"CUSTOM\",\n",
    "    suffix = f'{suffix}-c',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 - Upload datasets to S3 and start ingestion Job\n",
    "\n",
    "After Knowledge Base creation, let's upload both datasets into a S3 Bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "file_list = glob.glob('../dataset/*.json') \n",
    "file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in file_list:\n",
    "    s3_client.upload_file(f, bucket_name, f.split('/')[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's start the ingestion job to process those files.\n",
    "\n",
    "If you want to check processing logs, you can find lambda function attached to your Knowledge Base and go to monitoring tab, to find Cloud Watch Logs link and see the logs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensure that the kb is available\n",
    "time.sleep(30)\n",
    "# sync knowledge base\n",
    "knowledge_base_custom.start_ingestion_job()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5 - Test Knowledge Base\n",
    "\n",
    "Now the Knowlegde Base is available we can test it out using the [retrieve](https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/bedrock-agent-runtime/client/retrieve.html) and [retrieve_and_generate](https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/bedrock-agent-runtime/client/retrieve_and_generate.html) functions.\n",
    "\n",
    "First, let's retrieve Knowledge Base ID and store it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kb_id_custom = knowledge_base_custom.get_knowledge_base_id()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1 Testing Knowledge Base with Retrieve and Generate API\n",
    "\n",
    "Now, let's start with a simple question, asking about a place called Elephanta Caves and languages they speak over there.\n",
    "\n",
    "The answer is in the `\"id\":1037` on the `destinations.json` file, which means Mumbai is the expected answer with Marathi, Hindi, and English being the languages spoken there.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Who is main Spain's goalkeeper?\" \n",
    "# Expected: Casillas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = bedrock_agent_runtime_client.retrieve_and_generate(\n",
    "    input={\n",
    "        \"text\": query\n",
    "    },\n",
    "    retrieveAndGenerateConfiguration={        \n",
    "        \"type\": \"KNOWLEDGE_BASE\",\n",
    "        \"knowledgeBaseConfiguration\": {\n",
    "            'knowledgeBaseId': kb_id_custom,\n",
    "            \"modelArn\": \"arn:aws:bedrock:{}::foundation-model/{}\".format(region, foundation_model),\n",
    "            \"retrievalConfiguration\": {\n",
    "                \"vectorSearchConfiguration\": {\n",
    "                    \"numberOfResults\": 10\n",
    "                } \n",
    "            }\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "print(response['output']['text'],end='\\n'*2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's ask another question, about places where they speak Japanese and also visualize both APIs, to see data returned from knowledge base and model thinking with those answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Who was the midfielder player that has more goals for Spain?\" \n",
    "# Expected: David Silva"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = bedrock_agent_runtime_client.retrieve_and_generate(\n",
    "    input={\n",
    "        \"text\": query\n",
    "    },\n",
    "    retrieveAndGenerateConfiguration={\n",
    "        \"type\": \"KNOWLEDGE_BASE\",\n",
    "        \"knowledgeBaseConfiguration\": {\n",
    "            'knowledgeBaseId': kb_id_custom,\n",
    "            \"modelArn\": \"arn:aws:bedrock:{}::foundation-model/{}\".format(region, foundation_model),\n",
    "            \"retrievalConfiguration\": {\n",
    "                \"vectorSearchConfiguration\": {\n",
    "                    \"numberOfResults\": 20\n",
    "                } \n",
    "            }\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "print(response['output']['text'],end='\\n'*2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, with the retrieve and generate API, we get the final response directly. Now let's observe the citations for the RetrieveAndGenerate API.\n",
    "\n",
    "Since, our primary focus on this notebook is to observe the retrieved chunks and citations returned by the model while generating the response. When we provide the relevant context to the foundation model alongwith the query, it will most likely generate the high quality response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def citations_rag_print(response_ret):\n",
    "#structure 'retrievalResults': list of contents. Each list has content, location, score, metadata\n",
    "    for num,chunk in enumerate(response_ret,1):\n",
    "        print(f'Chunk {num}: ',chunk['content']['text'],end='\\n'*2)\n",
    "        print(f'Chunk {num} Location: ',chunk['location'],end='\\n'*2)\n",
    "        print(f'Chunk {num} Metadata: ',chunk['metadata'],end='\\n'*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_custom = response['citations'][0]['retrievedReferences']\n",
    "print(\"# of citations or chunks used to generate the response: \", len(response_custom))\n",
    "citations_rag_print(response_custom)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2 Testing Knowledge Base with Retrieve API\n",
    "\n",
    "If you need an extra layer of control, you can retrieve the chunks that best match your query using the retrieve API. In this setup, we can configure the desired number of results and control the final answer with your own application logic. The API then provides you with the matching content, its S3 location, the similarity score and the chunk metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def response_print(response_ret):\n",
    "#structure 'retrievalResults': list of contents. Each list has content, location, score, metadata\n",
    "    for num,chunk in enumerate(response_ret['retrievalResults'],1):\n",
    "        print(f'Chunk {num}: ',chunk['content']['text'],end='\\n'*2)\n",
    "        print(f'Chunk {num} Location: ',chunk['location'],end='\\n'*2)\n",
    "        print(f'Chunk {num} Score: ',chunk['score'],end='\\n'*2)\n",
    "        print(f'Chunk {num} Metadata: ',chunk['metadata'],end='\\n'*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "response_custom_ret = bedrock_agent_runtime_client.retrieve(\n",
    "    knowledgeBaseId=kb_id_custom, \n",
    "    nextToken='string',\n",
    "    retrievalConfiguration={\n",
    "        \"vectorSearchConfiguration\": {\n",
    "            \"numberOfResults\":10,\n",
    "        } \n",
    "    },\n",
    "    retrievalQuery={\n",
    "        'text': query\n",
    "    }\n",
    ")\n",
    "print(\"# of citations or chunks used to generate the response: \", len(response_custom_ret['retrievalResults']))\n",
    "response_print(response_custom_ret)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can notice, with CUSTOM chunking, we get 5 retrieved results as requested in the API using semantic similarity, which is the default for the Retrieve API.\n",
    "\n",
    "Those references are stored separately in the Vector Database, following the JSON structure, but all of them are part of the same file. This makes our model return better responses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6 - Create Knowledge Base without custom chunking\n",
    "\n",
    "On this optional step, you are going to create another Knowledge base, using fixed chunking strategy.\n",
    "\n",
    "This will be baseline Knowledge base to compare against previous created with custom Json chunking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the current timestamp\n",
    "current_time = time.time()\n",
    "\n",
    "# Format the timestamp as a string\n",
    "timestamp_str = time.strftime(\"%Y%m%d%H%M%S\", time.localtime(current_time))[-7:]\n",
    "# Create the suffix using the timestamp\n",
    "suffix = f\"{timestamp_str}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "knowledge_base_name_regular = 'fixed-chunk'\n",
    "\n",
    "knowledge_base_regular = BedrockKnowledgeBase(\n",
    "    kb_name=f'{knowledge_base_name_regular}-{suffix}',\n",
    "    #kb_description=knowledge_base_description,\n",
    "    data_sources=data_source,\n",
    "    suffix = f'{suffix}-c',\n",
    "    #chunking_strategy = \"FIXED\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sync knowledge base\n",
    "knowledge_base_regular.start_ingestion_job()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kb_id_fixed = knowledge_base_regular.get_knowledge_base_id()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quick test to check that KB with fixed size is working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Who was the midfielder player that has more goals for Spain?\" \n",
    "# Expected: David Silva"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = bedrock_agent_runtime_client.retrieve_and_generate(\n",
    "    input={\n",
    "        \"text\": query\n",
    "    },\n",
    "    retrieveAndGenerateConfiguration={\n",
    "        \"type\": \"KNOWLEDGE_BASE\",\n",
    "        \"knowledgeBaseConfiguration\": {\n",
    "            'knowledgeBaseId': kb_id_fixed,\n",
    "            \"modelArn\": \"arn:aws:bedrock:{}::foundation-model/{}\".format(region, foundation_model),\n",
    "            \"retrievalConfiguration\": {\n",
    "                \"vectorSearchConfiguration\": {\n",
    "                    \"numberOfResults\": 20\n",
    "                } \n",
    "            }\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "print(response['output']['text'],end='\\n'*2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  7 Evaluating RAG Performance\n",
    "\n",
    "Now, we're going to use Bedrock Model Evaluation feature (for RAG) to evaluate how accurate our KB is, and compare it with a fixed size KB.\n",
    "\n",
    "We have ground truth [examples](ground_truth.jsonl) with sample answers based into our dataset. It contains 15 examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create bucket to store eval dataset and evaluation outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_bucket_name = f'eval-rag-bucket-{suffix}'\n",
    "eval_role_name = f'Amazon-Bedrock-Eval-Role-{suffix}'\n",
    "\n",
    "kb_retrieve_policy_name = f'Bedrock-Eval-Policy-Retrieve-{suffix}'\n",
    "kb_invoke_model_policy_name = f'Bedrock-Eval-Policy-Invoke-{suffix}'\n",
    "kb_bucket_policy_name = f'Bedrock-Eval-Policy-S3-{suffix}'\n",
    "\n",
    "\n",
    "eval_bucket_name, eval_role_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_bucket = s3_client.create_bucket(Bucket=eval_bucket_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.1 Create Policy and Role\n",
    "\n",
    "On this step, we're going to create required permissions to run RAG Evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kb_retrieve_policy = {\n",
    "    \"Version\": \"2012-10-17\",\n",
    "    \"Statement\": [\n",
    "        {\n",
    "            \"Sid\": \"AllowKBCombinedCallOnKnowledgeBaseInstance\",\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Action\": [\n",
    "                \"bedrock:Retrieve\",\n",
    "                \"bedrock:RetrieveAndGenerate\"\n",
    "            ],\n",
    "            \"Resource\": \n",
    "            [f\"arn:aws:bedrock:{region}:459440633540:knowledge-base/{kb_id_custom}\",\n",
    "             f\"arn:aws:bedrock:{region}:459440633540:knowledge-base/{kb_id_fixed}\"]\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "kb_invoke_model_policy = {\n",
    "        \"Version\": \"2012-10-17\",\n",
    "        \"Statement\": [\n",
    "            {\n",
    "                \"Sid\": \"AllowAccessToBedrockResources\",\n",
    "                \"Effect\": \"Allow\",\n",
    "                \"Action\": [\n",
    "                    \"bedrock:InvokeModel\",\n",
    "                    \"bedrock:InvokeModelWithResponseStream\",\n",
    "                    \"bedrock:CreateModelInvocationJob\",\n",
    "                    \"bedrock:StopModelInvocationJob\",\n",
    "                    \"bedrock:GetProvisionedModelThroughput\",\n",
    "                    \"bedrock:GetInferenceProfile\",\n",
    "                    \"bedrock:ListInferenceProfiles\",\n",
    "                    \"bedrock:GetImportedModel\",\n",
    "                    \"bedrock:GetPromptRouter\",\n",
    "                    \"sagemaker:InvokeEndpoint\"\n",
    "                ],\n",
    "                \"Resource\": [\n",
    "                    \"arn:aws:bedrock:*::foundation-model/*\",\n",
    "                    f\"arn:aws:bedrock:*:{account_id}:inference-profile/*\",\n",
    "                    f\"arn:aws:bedrock:*:{account_id}:provisioned-model/*\",\n",
    "                    f\"arn:aws:bedrock:*:{account_id}:imported-model/*\",\n",
    "                    f\"arn:aws:bedrock:*:{account_id}:application-inference-profile/*\",\n",
    "                    f\"arn:aws:bedrock:*:{account_id}:default-prompt-router/*\",\n",
    "                    f\"arn:aws:sagemaker:*:{account_id}:endpoint/*\",\n",
    "                    f\"arn:aws:bedrock:*:{account_id}:marketplace/model-endpoint/all-access\"\n",
    "                ]\n",
    "            }\n",
    "        ]\n",
    "}\n",
    "\n",
    "kb_bucket_policy = {\n",
    "    \"Version\": \"2012-10-17\",\n",
    "    \"Statement\": [\n",
    "        {\n",
    "            \"Sid\": \"FetchInputBuckets\",\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Action\": [\n",
    "                \"s3:GetObject\",\n",
    "                \"s3:ListBucket\"\n",
    "            ],\n",
    "            \"Resource\": [\n",
    "                f\"arn:aws:s3:::{eval_bucket_name}\",\n",
    "                f\"arn:aws:s3:::{eval_bucket_name}/*\"\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"Sid\": \"FetchAndUpdateOutputBucket\",\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Action\": [\n",
    "                \"s3:GetObject\",\n",
    "                \"s3:ListBucket\",\n",
    "                \"s3:PutObject\",\n",
    "                \"s3:GetBucketLocation\",\n",
    "                \"s3:AbortMultipartUpload\",\n",
    "                \"s3:ListBucketMultipartUploads\"\n",
    "            ],\n",
    "            \"Resource\": [\n",
    "                f\"arn:aws:s3:::{eval_bucket_name}\",\n",
    "                f\"arn:aws:s3:::{eval_bucket_name}/*\"\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "assume_role_policy_document = {\n",
    "    \"Version\": \"2012-10-17\",\n",
    "    \"Statement\": [\n",
    "        {\n",
    "            \"Sid\": \"AllowBedrockToAssumeRole\",\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Principal\": {\n",
    "                \"Service\": \"bedrock.amazonaws.com\"\n",
    "            },\n",
    "            \"Action\": \"sts:AssumeRole\",\n",
    "            \"Condition\": {\n",
    "                \"StringEquals\": {\n",
    "                    \"aws:SourceAccount\": f\"{account_id}\"\n",
    "                },\n",
    "                \"ArnEquals\": {\n",
    "                    \"aws:SourceArn\": f\"arn:aws:bedrock:{region}:{account_id}:evaluation-job/*\"\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "kb_retrieve_policy_json = json.dumps(kb_retrieve_policy)\n",
    "kb_invoke_model_policy_json = json.dumps(kb_invoke_model_policy)\n",
    "kb_bucket_policy_json = json.dumps(kb_bucket_policy)\n",
    "\n",
    "assume_role_policy_document_json = json.dumps(assume_role_policy_document)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Evaluation Role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kb_eval_iam_role = iam_client.create_role(\n",
    "    RoleName=eval_role_name,\n",
    "    AssumeRolePolicyDocument=assume_role_policy_document_json\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kb_eval_iam_role['Role']['RoleName']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create policies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kb_eval_retrieve_response = iam_client.create_policy(\n",
    "    PolicyName=kb_retrieve_policy_name,\n",
    "    PolicyDocument= kb_retrieve_policy_json\n",
    ")\n",
    "\n",
    "iam_client.attach_role_policy(\n",
    "            RoleName=kb_eval_iam_role['Role']['RoleName'],\n",
    "            PolicyArn=kb_eval_retrieve_response['Policy']['Arn']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kb_invoke_model_policy_response = iam_client.create_policy(\n",
    "    PolicyName=kb_invoke_model_policy_name,\n",
    "    PolicyDocument= kb_invoke_model_policy_json\n",
    ")\n",
    "\n",
    "iam_client.attach_role_policy(\n",
    "            RoleName=kb_eval_iam_role['Role']['RoleName'],\n",
    "            PolicyArn=kb_invoke_model_policy_response['Policy']['Arn']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kb_bucket_policy_response = iam_client.create_policy(\n",
    "    PolicyName=kb_bucket_policy_name,\n",
    "    PolicyDocument= kb_bucket_policy_json\n",
    ")\n",
    "\n",
    "iam_client.attach_role_policy(\n",
    "            RoleName=kb_eval_iam_role['Role']['RoleName'],\n",
    "            PolicyArn=kb_bucket_policy_response['Policy']['Arn']\n",
    ")    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.2 Create Evaluation Jobs\n",
    "\n",
    "We're going to create two evaluation jobs, first one for Custom RAG, with JSON chunking and second one for fixed size chunking, not considering custom function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_file_name = 'ground_truth.jsonl'\n",
    "s3_client.upload_file(eval_file_name, eval_bucket_name, f'evaluation/{eval_file_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_name_chuck = f\"kb-evaluation-json-{datetime.now().strftime('%Y-%m-%d-%H-%M-%S')}\"\n",
    "job_name_fixed = f\"kb-evaluation-fixed-{datetime.now().strftime('%Y-%m-%d-%H-%M-%S')}\"\n",
    "input_uri = f's3://{eval_bucket_name}/evaluation/{eval_file_name}'\n",
    "output_uri = f's3://{eval_bucket_name}/output/'\n",
    "#eval_model = 'anthropic.claude-3-5-sonnet-20240620-v1:0'\n",
    "eval_model = 'anthropic.claude-3-haiku-20240307-v1:0'\n",
    "generator_model = 'us.anthropic.claude-3-5-haiku-20241022-v1:0'\n",
    "\n",
    "# Configure retrieval settings\n",
    "num_results = 20\n",
    "#search_type = \"HYBRID\"\n",
    "search_type = \"SEMANTIC\"\n",
    "\n",
    "input_uri, output_uri"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This job will evaluate two metrics:\n",
    "\n",
    "**Builtin.Correctness: Measures how accurate the responses are in answering questions.**\n",
    "\n",
    "Why is this important? This metric is crucial to surfacing the issue of the responses not using accurate information to answer the questions. A lower score indicates that there's an issue.\n",
    "\n",
    "How does scoring of 0-1 work? 1 indicates fully correct answers, 0 indicates incorrect answers. The higher the score the more correct the answers.\n",
    "\n",
    "\n",
    "**Builtin.Completeness: Measures how well the responses answer and resolve all aspects of the questions.**\n",
    "\n",
    "Why is this important? This metric is crucial to surfacing the issue of the responses not addressing all of the requirements of the questions. A lower score indicates that there's an issue.\n",
    "\n",
    "How does scoring of 0-1 work? 1 indicates fully complete answers, 0 indicates entirely incomplete answers. The higher the score the more complete the answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_rag(job_name, kb_id, num_results, search_type):\n",
    "    resp = bedrock_client.create_evaluation_job(\n",
    "        jobName=job_name,\n",
    "        jobDescription=\"Evaluate retrieval performance\",\n",
    "        roleArn=kb_eval_iam_role['Role']['Arn'],\n",
    "        applicationType=\"RagEvaluation\",\n",
    "        inferenceConfig={\n",
    "            \"ragConfigs\": [{\n",
    "            \"knowledgeBaseConfig\": {\n",
    "                \"retrieveAndGenerateConfig\": {\n",
    "                    \"type\": \"KNOWLEDGE_BASE\",\n",
    "                    \"knowledgeBaseConfiguration\": {\n",
    "                        \"knowledgeBaseId\": kb_id,\n",
    "                        \"modelArn\": generator_model,\n",
    "                        \"retrievalConfiguration\": {\n",
    "                            \"vectorSearchConfiguration\": {\n",
    "                                \"numberOfResults\": num_results,\n",
    "                                \"overrideSearchType\": search_type\n",
    "                                }\n",
    "                            }\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "            }]\n",
    "        },\n",
    "        outputDataConfig={\n",
    "            \"s3Uri\": output_uri\n",
    "        },\n",
    "        evaluationConfig={\n",
    "            \"automated\": {\n",
    "                \"datasetMetricConfigs\": [{\n",
    "                    \"taskType\": \"Generation\",\n",
    "                    \"dataset\": {\n",
    "                        \"name\": \"RagDataset\",\n",
    "                        \"datasetLocation\": {\n",
    "                            \"s3Uri\": input_uri\n",
    "                        }\n",
    "                    },\n",
    "                    \"metricNames\": [\n",
    "                        \"Builtin.Correctness\",\n",
    "                        \"Builtin.Completeness\"\n",
    "                    ]\n",
    "                }],\n",
    "                \"evaluatorModelConfig\": {\n",
    "                    \"bedrockEvaluatorModels\": [{\n",
    "                        \"modelIdentifier\": eval_model\n",
    "                    }]\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    )\n",
    "    return resp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_eval_job(job_arn):\n",
    "\n",
    "    # Get job ARN based on job type\n",
    "    evaluation_job_arn = job_arn\n",
    "\n",
    "    # Check job status\n",
    "    response = bedrock_client.get_evaluation_job(\n",
    "        jobIdentifier=evaluation_job_arn \n",
    "    )\n",
    "    print(f\"Job Status: {response['status']}\")\n",
    "\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_rag_eval = evaluate_rag(job_name_chuck, kb_id_custom, num_results, search_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_job_resp = check_eval_job(custom_rag_eval['jobArn'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_rag_eval = evaluate_rag(job_name_fixed, kb_id_fixed, num_results, search_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_job_resp = check_eval_job(fixed_rag_eval['jobArn'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.3 Read evaluation files and compare results\n",
    "\n",
    "This step will download generate output files into local folder to compare results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir_resp = f\"output/{custom_job_resp['jobName']}/{custom_job_resp['jobArn'].split('/')[-1]}/inference_configs/0/datasets/RagDataset/\"\n",
    "#out_dir_resp\n",
    "s3_files_resp = s3_client.list_objects_v2(Bucket=eval_bucket_name, Prefix=out_dir_resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_files_resp = s3_client.download_file(eval_bucket_name, s3_files_resp['Contents'][0]['Key'], 'custom_kb.jsonl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir_resp = f\"output/{fixed_job_resp['jobName']}/{fixed_job_resp['jobArn'].split('/')[-1]}/inference_configs/0/datasets/RagDataset/\"\n",
    "\n",
    "#out_dir_resp\n",
    "s3_files_resp = s3_client.list_objects_v2(Bucket=eval_bucket_name, Prefix=out_dir_resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_files_resp = s3_client.download_file(eval_bucket_name, s3_files_resp['Contents'][0]['Key'], 'fixed_kb.jsonl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's process downloaded files and compare both metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom KB with Json chunking\n",
    "import pandas as pd\n",
    "\n",
    "custom_kb_df = pd.read_json('custom_kb.jsonl', lines=True)\n",
    "json_objects = []\n",
    "\n",
    "for index, row in custom_kb_df.iterrows():\n",
    "    row_dict = row.to_dict()\n",
    "    json_objects.append(row_dict)\n",
    "\n",
    "\n",
    "ans_correctness_custom = []\n",
    "ans_completeness_custom = []\n",
    "\n",
    "for obj in json_objects:\n",
    "    for i in obj['conversationTurns'][0]['results']:\n",
    "        if i['metricName'] == \"Builtin.Correctness\":\n",
    "            rresult = 0 if i[\"result\"] is None else i[\"result\"]\n",
    "            ans_correctness_custom.append(rresult)\n",
    "        elif i['metricName'] == \"Builtin.Completeness\":\n",
    "            rresult = 0 if i[\"result\"] is None else i[\"result\"]\n",
    "            ans_completeness_custom.append(rresult)\n",
    "        else:\n",
    "            raise Exception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regular KB with Fixed chunking\n",
    "import pandas as pd\n",
    "\n",
    "fixed_kb_df = pd.read_json('fixed_kb.jsonl', lines=True)\n",
    "json_objects = []\n",
    "\n",
    "for index, row in fixed_kb_df.iterrows():\n",
    "    row_dict = row.to_dict()\n",
    "    json_objects.append(row_dict)\n",
    "\n",
    "\n",
    "ans_correctness_fixed = []\n",
    "ans_completeness_fixed = []\n",
    "\n",
    "for obj in json_objects:\n",
    "    for i in obj['conversationTurns'][0]['results']:\n",
    "        if i['metricName'] == \"Builtin.Correctness\":\n",
    "            rresult = 0 if i[\"result\"] is None else i[\"result\"]\n",
    "            ans_correctness_fixed.append(rresult)\n",
    "        elif i['metricName'] == \"Builtin.Completeness\":\n",
    "            rresult = 0 if i[\"result\"] is None else i[\"result\"]\n",
    "            ans_completeness_fixed.append(rresult)\n",
    "        else:\n",
    "            raise Exception"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's run next cell and compare results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_correctness_final = round((sum(ans_correctness_custom)/len(ans_correctness_custom)) * 100, 2)\n",
    "custom_completeness_final = round((sum(ans_completeness_custom)/len(ans_completeness_custom)) * 100, 2)\n",
    "fixed_correctness_final = round((sum(ans_correctness_fixed)/len(ans_correctness_fixed)) * 100, 2)\n",
    "fixed_completeness_final = round((sum(ans_completeness_fixed)/len(ans_completeness_fixed)) * 100, 2)\n",
    "\n",
    "print(f\"Fixed Chunking Strategy - Correctness:{fixed_correctness_final}, Json Custom Chunking - Correctness:{custom_correctness_final}\")\n",
    "print(f\"Fixed Chunking Strategy - Completeness:{fixed_completeness_final}, Json Custom Chunking - Completeness:{custom_completeness_final}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.4 Conclusions\n",
    "\n",
    "To see detailed information about model comparison, you can go to Amazon Bedrock console, and then open Evaluations tab. On Evaluations tab, click on RAG tab.\n",
    "\n",
    "You will be able to see evaluation jobs that had been executed. Select your two jobs and click on \"Compare\" button:\n",
    "\n",
    "![Evaluations](../images/eval-models.png)\n",
    "\n",
    "You will able to see comparison metrics as folowing:\n",
    "\n",
    "![Evaluations](../images/model-eval-1.png)\n",
    "\n",
    "![Evaluations](../images/model-eval-2.png)\n",
    "\n",
    "As you can see, on following report (generated on AWS Console) JSON custom chunking has shown 7.1% of improvement in Correctness (0.75 against 0.70) and 15.6% in Completeness (0.93 against 0.8), using 15 data samples for this evaluation job."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7 - Clean Up\n",
    "\n",
    "To clean up resources, execute following method from helper class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "knowledge_base_custom.delete_kb(delete_s3_bucket=True, delete_lambda_function=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "knowledge_base_regular.delete_kb(delete_s3_bucket=True, delete_lambda_function=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_bucket_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kb_eval_iam_role['Role']['RoleName']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iam_client.detach_role_policy(RoleName=kb_eval_iam_role['Role']['RoleName'],\n",
    "                              PolicyArn=kb_invoke_model_policy_response['Policy']['Arn'])\n",
    "\n",
    "iam_client.detach_role_policy(RoleName=kb_eval_iam_role['Role']['RoleName'],\n",
    "                              PolicyArn=kb_bucket_policy_response['Policy']['Arn'])\n",
    "\n",
    "iam_client.detach_role_policy(RoleName=kb_eval_iam_role['Role']['RoleName'],\n",
    "                              PolicyArn=kb_eval_retrieve_response['Policy']['Arn'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iam_client.delete_role(RoleName=kb_eval_iam_role['Role']['RoleName'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iam_client.delete_policy(PolicyArn=kb_eval_retrieve_response['Policy']['Arn'])\n",
    "iam_client.delete_policy(PolicyArn=kb_invoke_model_policy_response['Policy']['Arn'])\n",
    "iam_client.delete_policy(PolicyArn=kb_bucket_policy_response['Policy']['Arn'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.1 Delete Bucket (Optional)\n",
    "\n",
    "This action will delete Evaluation reports generated (it will stop to work on AWS Console also)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.resource('s3')\n",
    "\n",
    "bucket = s3.Bucket(eval_bucket_name)\n",
    "if bucket in s3.buckets.all():\n",
    "    print(f\"Found bucket {eval_bucket_name}\")\n",
    "    # Delete all objects including versions (if versioning enabled)\n",
    "    bucket.object_versions.delete()\n",
    "    bucket.objects.all().delete()\n",
    "    print(f\"Deleted all objects in bucket {eval_bucket_name}\")\n",
    "    \n",
    "    # Delete the bucket\n",
    "    bucket.delete()\n",
    "    print(f\"Deleted bucket {eval_bucket_name}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
