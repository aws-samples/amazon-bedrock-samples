{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e3f8924-01d4-4702-b548-aa33dda5d11d",
   "metadata": {},
   "source": [
    "# Graph RAG using Amazon Bedrock Knowledge Bases\n",
    "In this module, you'll learn how to improve Generative AI applications using Retrieval-Augmented Generation (RAG) combined with Amazon Bedrock Knowledge Bases, enabling more accurate, contextual, and explainable responses combined with graph data.\n",
    "\n",
    "The following steps will guide you through the process of using Amazon Bedrock Knowledge Bases with GraphRAG to enhance Generative AI applications.\n",
    "This module contains:\n",
    "1. [Overview](#Overview)\n",
    "2. [Pre-requisites](#Pre-requisites)\n",
    "3. [Setup](#Setup)\n",
    "4. [Create KB with Amazon Neptune as vector](#Create-KB-with-Amazon-Neptune-vector)\n",
    "5. [Test the Knowledge Graph](#Test-the-Knowledge-Graph)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75464c27-0c7a-4fe8-b6f0-ddce7c96209b",
   "metadata": {},
   "source": [
    "## Overview\n",
    "Amazon Bedrock Knowledge Bases offers a fully managed GraphRAG feature with Amazon Neptune. This functionality uses Retrieval Augmented Generation (RAG) techniques combined with graphs to enhance generative AI applications so that end users can get more accurate and comprehensive responses.\n",
    "\n",
    "GraphRAG automatically identifies and uses relationships between related entities and structural elements (such as section titles) across documents that are ingested into Amazon Bedrock Knowledge Bases. This means that generative AI applications can deliver more relevant responses in cases where connecting data and reasoning across multiple document chunks is needed.\n",
    "\n",
    "Amazon Bedrock Knowledge Bases automatically manages the creation and maintenance of the graphs from Amazon Neptune, so you can provide relevant responses to your end users, without relying on expertise in graph techniques.\n",
    "\n",
    "Amazon Bedrock Knowledge Bases with GraphRAG offers the following benefits:\n",
    "\n",
    "- More relevant responses by using contextual information from related entities and document sections.\n",
    "\n",
    "- Better summarization by incorporating key content from your data sources while filtering out unnecessary information.\n",
    "\n",
    "- More explainable responses by understanding the relationships between different entities in the dataset and providing citations.\n",
    "\n",
    "**Note**: GraphRAG is available in AWS Regions where both Amazon Bedrock Knowledge Bases and Amazon Neptune Analytics are both available.\n",
    "\n",
    "- For this module, we will use the Anthropic Claude 3 Haiku model as our FM to work with the max no. of results and prompt customization features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d09998e7-6062-4edb-9348-bbe54026a101",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Pre-requisites\n",
    "Before being able to answer the questions, the documents must be processed and stored in a knowledge base. For this notebook, we use a `synthetic dataset for 10K financial reports` to create the Amazon Bedrock Knowledge Bases. \n",
    "\n",
    "1. Upload your documents (data source) to Amazon S3 bucket."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a68ef2-f670-451f-9399-343570489b95",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1608ffd-60f5-459b-ba2e-174209ff7537",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%pip install --upgrade pip --quiet\n",
    "%pip install -r ../requirements.txt --no-deps --quiet\n",
    "%pip install -r ../requirements.txt --upgrade --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e624a8b-3700-4896-845f-642588e8dd7b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# restart kernel\n",
    "from IPython.core.display import HTML\n",
    "HTML(\"<script>Jupyter.notebook.kernel.restart()</script>\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3cb27dd-a2de-4e38-aa7b-c315953b9921",
   "metadata": {},
   "source": [
    "### Initialize boto3 client\n",
    "Through out the notebook, we are going to utilise RetrieveAndGenerate to test knowledge base features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "563d853e-2966-47bb-9183-aab31d64e8b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import boto3\n",
    "import pprint\n",
    "import sys\n",
    "from botocore.exceptions import ClientError\n",
    "from botocore.client import Config\n",
    "import time\n",
    "import os\n",
    "import logging\n",
    "\n",
    "# Set the path to import module\n",
    "from pathlib import Path\n",
    "current_path = Path().resolve()\n",
    "current_path = current_path.parent\n",
    "if str(current_path) not in sys.path:\n",
    "    sys.path.append(str(current_path))\n",
    "    \n",
    "from utils.knowledge_base import BedrockKnowledgeBase\n",
    "\n",
    "# Create boto3 session\n",
    "sts_client = boto3.client('sts')\n",
    "boto3_session = boto3.session.Session()\n",
    "region_name = boto3_session.region_name\n",
    "account_id = sts_client.get_caller_identity()['Account']\n",
    "\n",
    "# Create s3 client\n",
    "s3_client = boto3.client('s3')\n",
    "\n",
    "# Create bedrock agent client\n",
    "bedrock_config = Config(connect_timeout=120, read_timeout=120, retries={'max_attempts': 0}, region_name=region_name)\n",
    "bedrock_agent_client = boto3_session.client(\"bedrock-agent-runtime\",\n",
    "                              config=bedrock_config)\n",
    "\n",
    "# Define FM to be used for generations \n",
    "model_id = \"anthropic.claude-3-haiku-20240307-v1:0\" # we will be using Anthropic Claude 3 Haiku throughout the notebook\n",
    "model_arn = f'arn:aws:bedrock:{region_name}::foundation-model/{model_id}'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2004717-61c2-44de-b56d-c146b71f11f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Get the current timestamp\n",
    "current_time = time.time()\n",
    "\n",
    "# Format the timestamp as a string\n",
    "timestamp_str = time.strftime(\"%Y%m%d%H%M%S\", time.localtime(current_time))[-7:]\n",
    "# Create the suffix using the timestamp\n",
    "suffix = f\"{timestamp_str}\"\n",
    "\n",
    "knowledge_base_name = f\"bedrock-sample-knowledge-base-{suffix}\"\n",
    "knowledge_base_description = \"Graph RAG knowledge base.\"\n",
    "\n",
    "bucket_name = f'{knowledge_base_name}-{account_id}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed17bf3-a80f-43c2-877c-366920791792",
   "metadata": {},
   "source": [
    "## Create KB with Amazon Neptune as vector\n",
    "To build GraphRAG, you must choose Amazon Neptune Analytics as your vector store.\n",
    "The knowledge base automatically generates and stores document embeddings in Amazon Neptune, along with a graph representation of entities and their relationships derived from the document corpus.\n",
    "\n",
    "When your GraphRAG-based application is running, you can continue using the Knowledge Bases API operations to provide end users with more comprehensive, relevant, and explainable responses.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96da3b94-6dac-40cb-a596-80843461c04f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sources = [{\"type\": \"S3\", \"bucket_name\": bucket_name}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31aa139f-00fe-4955-9927-4996f7761937",
   "metadata": {},
   "outputs": [],
   "source": [
    "knowledge_base = BedrockKnowledgeBase(\n",
    "    kb_name=f'{knowledge_base_name}',\n",
    "    kb_description=knowledge_base_description,\n",
    "    data_sources=data_sources,\n",
    "    chunking_strategy = \"GRAPH\", \n",
    "    suffix = f'{suffix}-f',\n",
    "    vector_store=\"NEPTUNE_ANALYTICS\" # can be OPENSEARCH_SERVERLESS or NEPTUNE_ANALYTICS\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb35e0f-befb-4016-a778-f3a43ab41e42",
   "metadata": {},
   "source": [
    "## Download data to ingest into our knowledge base.\n",
    "We'll use the following data:\n",
    "\n",
    "sythetic data stored in a local directory as first data source\n",
    "### Upload data to S3 Bucket data source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d74971-1877-407e-b309-cc3e1a1a3246",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "s3_client = boto3.client('s3')\n",
    "\n",
    "def upload_directory(path, bucket_name):\n",
    "        for root,dirs,files in os.walk(path):\n",
    "            for file in files:\n",
    "                file_to_upload = os.path.join(root,file)\n",
    "                print(f\"uploading file {file_to_upload} to {bucket_name}\")\n",
    "                s3_client.upload_file(file_to_upload,bucket_name,file)\n",
    "\n",
    "upload_directory(\"../synthetic_dataset\", bucket_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c599ac39-0b0e-4892-848d-42ab63c895ad",
   "metadata": {},
   "source": [
    "## Start ingestion job\n",
    "Once the KB and data source(s) created, we can start the ingestion job for each data source. During the ingestion job, KB will fetch the documents in the data source, pre-process it to extract text, chunk it based on the chunking size provided, create embeddings of each chunk and then write it to the vector database, in this case Neptune Analytics.\n",
    "\n",
    "NOTE: Currently, you can only kick-off one ingestion job at one time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22422739-cf95-470f-a656-be25b8ee2959",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensure that the kb is available\n",
    "time.sleep(60)\n",
    "# sync knowledge base\n",
    "knowledge_base.start_ingestion_job()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308014fd-f6e8-4fd7-ae30-6b86c4374416",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep the kb_id for invocation later in the invoke request\n",
    "kb_id = knowledge_base.get_knowledge_base_id()\n",
    "%store kb_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d40848-f11e-4853-bfdc-c8f14a1e5994",
   "metadata": {},
   "source": [
    "## 2.2 Test the Knowledge Graph created using Amazon Bedrock Knowledge Bases\n",
    "You can use the same `retreive` or `retrieve_and_generate` API based on your use case to query the `Neptune Analytics` graph created using Amazon Bedrock Knowledge Bases.\n",
    "\n",
    "### Testing Knowledge Base with Retrieve and Generate API\n",
    "We will first test it with `retrieve_and_generate` API which will now query the `Neptune Analytics` graph created using Amazon Bedrock Knowledge Bases to fetch the search results, augment it with the prompt and then use the provided foundation model to generate the response. \n",
    "\n",
    "`query = Provide a summary of consolidated statements of cash flows of Octank Financial for the fiscal years ended December 31, 2019.`\n",
    "\n",
    "The right response for this query as per ground truth QA pair is:\n",
    "\n",
    "```\n",
    "According to the consolidated statements of cash flows, in the fiscal year ended December 31, 2019, Octank Financial had:\n",
    "- Net cash provided by operating activities of $710 million\n",
    "- Net cash used in investing activities of $240 million\n",
    "- Net cash provided by financing activities of $350 million\n",
    "- An overall net increase in cash and cash equivalents of $120 million\n",
    "```\n",
    "\n",
    "**NOTE**: Based on the model selected for generating responses, actual response may differ, however, will be semantically similar. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5878231-6993-4590-af39-f0102872f390",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Provide a summary of consolidated statements of cash flows of Octank Financial for the fiscal years ended December 31, 2019?\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46fce99e-27bd-49d5-bd35-530be199c5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# foundation_model = \"amazon.nova-micro-v1:0\"\n",
    "\n",
    "response = bedrock_agent_client.retrieve_and_generate(\n",
    "    input={\n",
    "        \"text\": query\n",
    "    },\n",
    "    retrieveAndGenerateConfiguration={\n",
    "        \"type\": \"KNOWLEDGE_BASE\",\n",
    "        \"knowledgeBaseConfiguration\": {\n",
    "            'knowledgeBaseId': kb_id,\n",
    "            \"modelArn\": model_arn,\n",
    "            \"retrievalConfiguration\": {\n",
    "                \"vectorSearchConfiguration\": {\n",
    "                    \"numberOfResults\":5\n",
    "                } \n",
    "            }\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "print(response['output']['text'],end='\\n'*2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "064ef04f-1d21-488a-b58b-8977f32e51af",
   "metadata": {},
   "source": [
    "As you can see, with the retrieve and generate API we get the final response directly and we don't see the different sources used to generate this response. Let's now retrieve the source information from the knowledge base with the retrieve API."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "187a19ea-f0ae-4961-adf7-51971841da99",
   "metadata": {},
   "source": [
    "### Testing Knowledge Base with Retrieve API\n",
    "If you need an extra layer of control, you can retrieve the chunks that best match your query using the retrieve API. Since, the vector store is `Neptune Analytics`, the retrieve API will query the graph to fetch the relevant chunks (search results). In this setup, we can configure the desired number of results and control the final answer with your own application logic. The API then provides you with the matching content, its S3 location, the similarity score and the chunk metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe94869c-5cde-4934-9369-e9abe7707bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_ret = bedrock_agent_client.retrieve(\n",
    "    knowledgeBaseId=kb_id, \n",
    "    nextToken='string',\n",
    "    retrievalConfiguration={\n",
    "        \"vectorSearchConfiguration\": {\n",
    "            \"numberOfResults\":5,\n",
    "        } \n",
    "    },\n",
    "    retrievalQuery={\n",
    "        \"text\": \"How many new positions were opened across Amazon's fulfillment and delivery network?\"\n",
    "    }\n",
    ")\n",
    "\n",
    "def response_print(retrieve_resp):\n",
    "#structure 'retrievalResults': list of contents. Each list has content, location, score, metadata\n",
    "    for num,chunk in enumerate(response_ret['retrievalResults'],1):\n",
    "        print(f'Chunk {num}: ',chunk['content']['text'],end='\\n'*2)\n",
    "        print(f'Chunk {num} Location: ',chunk['location'],end='\\n'*2)\n",
    "        print(f'Chunk {num} Score: ',chunk['score'],end='\\n'*2)\n",
    "        print(f'Chunk {num} Metadata: ',chunk['metadata'],end='\\n'*2)\n",
    "\n",
    "response_print(response_ret)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8978508d-4d96-42eb-9ea2-95c6153d5d39",
   "metadata": {},
   "source": [
    "## Clean up\n",
    "Please make sure to uncomment and run the below section to delete all the resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6dd9960-be10-45e4-b46d-a54e7a79c487",
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete role and policies\n",
    "print(\"===============================Deleting Knowledge Base and associated resources==============================\\n\")\n",
    "knowledge_base.delete_kb(delete_s3_bucket=True, delete_iam_roles_and_policies=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94385593",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Note:</b> Remember to delete KB, OSS index and related IAM roles and policies to avoid incurring any charges.\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "bedrock_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
