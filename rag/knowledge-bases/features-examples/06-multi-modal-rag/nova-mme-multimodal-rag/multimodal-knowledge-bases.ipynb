{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a004c9f5-5f9e-4faa-9137-d02699c75e06",
   "metadata": {},
   "source": [
    "# Amazon Bedrock Multimodal Knowledge Bases with S3 Vectors\n",
    "This notebook provides sample code for building multimodal RAG applications using Amazon Bedrock Knowledge Bases with Amazon Nova Multimodal Embeddings and S3 Vectors. This notebook demonstrates:\n",
    "\n",
    "1. Overview\n",
    "2. Pre-requisites\n",
    "3. Uploading Product Catalog (Images/Videos)\n",
    "4. Creating an S3 Vector Store and Index\n",
    "5. Creating a Multimodal Knowledge Base\n",
    "6. Creating and Syncing the Data Source\n",
    "7. Testing with Text Queries\n",
    "8. Testing with Image-based Visual Search\n",
    "9. Cleanup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c127230f-e6fd-4ffc-afac-018cf0441ca7",
   "metadata": {},
   "source": [
    "## Overview\n",
    "Amazon Bedrock Knowledge Bases now supports multimodal retrieval, enabling you to search and retrieve information across text, images, audio, and video within a fully managed service.\n",
    "\n",
    "### What's New?\n",
    "Previously, Bedrock Knowledge Bases supported text documents and images, but video and audio required custom preprocessing pipelines. With multimodal retrieval, you can now:\n",
    "\n",
    "- **Ingest multiple content types**: Process text, images, videos, and audio in a unified workflow\n",
    "- **Preserve visual context**: Content is encoded using multimodal embeddings that maintain visual and audio characteristics\n",
    "- **Enable cross-modal search**: Search using text to find videos, or upload an image to find visually similar content\n",
    "\n",
    "### Amazon Nova Multimodal Embeddings\n",
    "In this notebook, we'll use Amazon Nova Multimodal Embeddings‚Äîthe first unified embedding model that encodes text, documents, images, video, and audio into a single shared vector space. This enables powerful use cases like:\n",
    "\n",
    "- Visual product search in e-commerce\n",
    "- Finding similar scenes in video content\n",
    "- Matching products across different media types\n",
    "\n",
    "### Use Case: Visual Product Search\n",
    "We'll build a product catalog search system where customers can:\n",
    "- Search using text descriptions\n",
    "- Upload a photo to find similar products\n",
    "- Query using natural language about product features\n",
    "\n",
    "The system will retrieve visually similar items by comparing embedded representations across your product images and videos, stored efficiently in S3 Vectors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d98661-6a84-4536-99c3-bdf2b0f731f6",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "To complete this notebook you should have:\n",
    "\n",
    "1. An AWS account with appropriate permissions\n",
    "2. A role with access to: Amazon S3, AWS STS, Amazon Bedrock, and S3 Vectors\n",
    "3. Product images/videos in a local `product-catalog` folder\n",
    "\n",
    "### About the Dataset\n",
    "This notebook assumes you have product images (phone cases, accessories, etc.) in a local folder. The multimodal Knowledge Base will process these images and enable visual similarity search. You can also bring in your own dataset of multi-modal content."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f22e67e-2b90-4c7a-8611-28f13e99133f",
   "metadata": {},
   "source": [
    "### Setup\n",
    "\n",
    "Let's first install the required dependencies and initialize the boto3 clients we'll need throughout this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d29953-a0a3-4736-b774-0053115785c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install or update boto3 and pillow for image handling\n",
    "!pip install -qU boto3 pillow matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f09e250-bcaa-4515-b5fd-8475ac0bc4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import time\n",
    "import uuid\n",
    "import boto3\n",
    "import base64\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "from botocore.client import Config\n",
    "from botocore.exceptions import ClientError\n",
    "\n",
    "# Import utility functions\n",
    "from utils import (\n",
    "    generate_short_code, \n",
    "    create_bedrock_execution_role, \n",
    "    empty_and_delete_bucket, \n",
    "    create_s3_bucket\n",
    ")\n",
    "\n",
    "# Create boto3 session and get account information\n",
    "boto3_session = boto3.session.Session()\n",
    "region_name = boto3_session.region_name\n",
    "\n",
    "# Verify we're in a supported region for Nova Multimodal Embeddings\n",
    "if region_name != 'us-east-1':\n",
    "    print(f\"‚ö†Ô∏è Warning: Amazon Nova Multimodal Embeddings is currently only available in us-east-1.\")\n",
    "    print(f\"   Your current region is: {region_name}\")\n",
    "    print(f\"   Please switch to us-east-1 to use this feature.\")\n",
    "else:\n",
    "    print(f\"‚úÖ Region check passed: {region_name}\")\n",
    "\n",
    "# Initialize AWS clients\n",
    "iam_client = boto3.client('iam')\n",
    "s3_client = boto3.client('s3')\n",
    "sts_client = boto3.client('sts')\n",
    "account_id = sts_client.get_caller_identity()['Account']\n",
    "\n",
    "# Create s3vectors client for vector store operations\n",
    "s3vectors = boto3.client('s3vectors', region_name=region_name)\n",
    "\n",
    "# Create bedrock agent clients with extended timeouts for long-running operations\n",
    "bedrock_config = Config(\n",
    "    connect_timeout=120, \n",
    "    read_timeout=120, \n",
    "    retries={'max_attempts': 0}, \n",
    "    region_name=region_name\n",
    ")\n",
    "bedrock_agent_runtime_client = boto3_session.client(\"bedrock-agent-runtime\", config=bedrock_config)\n",
    "bedrock_agent_client = boto3.client('bedrock-agent', region_name=region_name)\n",
    "\n",
    "# Generate unique identifier for resource names to avoid conflicts\n",
    "unique_id = generate_short_code()\n",
    "\n",
    "# Define resource names with unique identifiers\n",
    "bucket_name = f\"product-catalog-{unique_id}\"\n",
    "multimodal_storage_bucket_name = f\"multimodal-product-catalog-{unique_id}\"\n",
    "vector_store_name = f\"multimodal-vector-store-{unique_id}\"\n",
    "vector_index_name = f\"multimodal-vector-index-{unique_id}\"\n",
    "kb_name = f\"kb-product-catalog-{unique_id}\"\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"Resource Configuration\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Unique Identifier:  {unique_id}\")\n",
    "print(f\"AWS Account ID:     {account_id}\")\n",
    "print(f\"AWS Region:         {region_name}\")\n",
    "print(f\"S3 Bucket:          {bucket_name}\")\n",
    "print(f\"S3 Multimodal Data: {multimodal_storage_bucket_name}\")\n",
    "print(f\"Vector Store:       {vector_store_name}\")\n",
    "print(f\"Vector Index:       {vector_index_name}\")\n",
    "print(f\"Knowledge Base:     {kb_name}\")\n",
    "print(f\"{'='*60}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2a38afe-34fe-46b1-a154-ba5cc6e30d03",
   "metadata": {},
   "source": [
    "## Upload Product Catalog to S3\n",
    "\n",
    "First, we'll create an S3 bucket and upload our product catalog. The catalog should contain images and/or videos of products (e.g., phone cases, accessories).\n",
    "\n",
    "Make sure you have your product images/videos in a local folder named `product-catalog` in the same directory as this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e62e60-0085-4b93-984c-9ca2fe9ea814",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the local folder containing your product catalog\n",
    "catalog_folder = \"product-catalog\"\n",
    "\n",
    "# Verify the folder exists\n",
    "if not os.path.exists(catalog_folder):\n",
    "    print(f\"‚ùå Error: Folder '{catalog_folder}' not found.\")\n",
    "    print(f\"   Please create a folder named '{catalog_folder}' and add your product images/videos.\")\n",
    "    print(f\"   Expected location: {os.path.abspath(catalog_folder)}\")\n",
    "else:\n",
    "    # Count files\n",
    "    files = [f for f in os.listdir(catalog_folder) \n",
    "             if os.path.isfile(os.path.join(catalog_folder, f)) and not f.startswith('.')]\n",
    "    \n",
    "    print(f\"‚úÖ Found {len(files)} files in {catalog_folder}\")\n",
    "    \n",
    "    # Show file types\n",
    "    extensions = {}\n",
    "    for f in files:\n",
    "        ext = os.path.splitext(f)[1].lower()\n",
    "        extensions[ext] = extensions.get(ext, 0) + 1\n",
    "    \n",
    "    print(f\"   File types: {dict(extensions)}\")\n",
    "    print(f\"   Sample files: {files[:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7507a45-9a4e-4135-8907-6c1ac65f1850",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create S3 bucket for product catalog\n",
    "create_s3_bucket(bucket_name, region=region_name)\n",
    "# Create S3 bucket for multimodal storage Location\n",
    "create_s3_bucket(multimodal_storage_bucket_name, region=region_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6037a89-698c-4efa-b0fb-284555ddb333",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_folder_to_s3(folder_path, bucket_name, prefix=''):\n",
    "    \"\"\"\n",
    "    Upload all files from a folder to an S3 bucket\n",
    "    \n",
    "    Args:\n",
    "        folder_path: Path to the folder containing files to upload\n",
    "        bucket_name: Name of the S3 bucket\n",
    "        prefix: Prefix to add to the object names in S3 (optional)\n",
    "    \"\"\"\n",
    "    upload_count = 0\n",
    "    total_files = 0\n",
    "    \n",
    "    # Count total files first (excluding hidden files)\n",
    "    for _, _, files in os.walk(folder_path):\n",
    "        total_files += len([f for f in files if not f.startswith('.')])\n",
    "    \n",
    "    if total_files == 0:\n",
    "        print(f\"‚ö†Ô∏è No files found in {folder_path}\")\n",
    "        return\n",
    "    \n",
    "    print(f\"\\nUploading {total_files} files to S3 bucket '{bucket_name}'...\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    # Upload files\n",
    "    for root, dirs, files in os.walk(folder_path):\n",
    "        for file in files:\n",
    "            # Skip hidden files and system files\n",
    "            if file.startswith('.'):\n",
    "                continue\n",
    "                \n",
    "            local_path = os.path.join(root, file)\n",
    "            relative_path = os.path.relpath(local_path, folder_path)\n",
    "            s3_path = os.path.join(prefix, relative_path).replace(\"\\\\\", \"/\")\n",
    "            \n",
    "            try:\n",
    "                s3_client.upload_file(local_path, bucket_name, s3_path)\n",
    "                upload_count += 1\n",
    "                \n",
    "                # Show progress periodically\n",
    "                if upload_count % 10 == 0 or upload_count == total_files:\n",
    "                    print(f\"Progress: {upload_count}/{total_files} files uploaded\")\n",
    "                    \n",
    "            except ClientError as e:\n",
    "                print(f\"‚ùå Error uploading {local_path}: {e}\")\n",
    "    \n",
    "    print(\"-\" * 60)\n",
    "    print(f\"‚úÖ Successfully uploaded {upload_count} files to S3 bucket '{bucket_name}'\\n\")\n",
    "\n",
    "# Upload the product catalog\n",
    "upload_folder_to_s3(catalog_folder, bucket_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b6793e-e05d-495c-ba7b-d0f2b2462aca",
   "metadata": {},
   "source": [
    "## Create S3 Vector Store and Index\n",
    "\n",
    "Now we'll create an S3 Vector Store to hold our multimodal embeddings. S3 Vector Store provides cost-effective and durable storage optimized for large-scale vector datasets with sub-second query performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837332f0-58e6-40f9-a67f-8cbf9d19c91a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the dimensionality of our embedding vectors\n",
    "# Amazon Nova Multimodal Embeddings uses 3072 dimensions by default\n",
    "vector_dimension = 3072\n",
    "\n",
    "print(f\"Vector dimension: {vector_dimension}\")\n",
    "print(f\"This matches Amazon Nova Multimodal Embeddings default output dimension\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "759a6565-5aa0-4d3b-bbab-1145053c7f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vector_bucket(vector_bucket_name):\n",
    "    \"\"\"Create an S3 Vector bucket and return its ARN\"\"\"\n",
    "    try:\n",
    "        print(f\"Creating S3 Vector Store: {vector_bucket_name}\")\n",
    "        \n",
    "        # Create the vector bucket\n",
    "        s3vectors.create_vector_bucket(vectorBucketName=vector_bucket_name)\n",
    "        print(f\"‚úÖ Vector bucket '{vector_bucket_name}' created successfully\")\n",
    "        \n",
    "        # Get the vector bucket details\n",
    "        response = s3vectors.get_vector_bucket(vectorBucketName=vector_bucket_name)\n",
    "        bucket_info = response.get(\"vectorBucket\", {})\n",
    "        vector_store_arn = bucket_info.get(\"vectorBucketArn\")\n",
    "        \n",
    "        if not vector_store_arn:\n",
    "            raise ValueError(\"Vector bucket ARN not found in response\")\n",
    "            \n",
    "        print(f\"Vector bucket ARN: {vector_store_arn}\")\n",
    "        return vector_store_arn\n",
    "        \n",
    "    except ClientError as e:\n",
    "        error_code = e.response.get('Error', {}).get('Code', 'Unknown')\n",
    "        error_message = e.response.get('Error', {}).get('Message', 'Unknown error')\n",
    "        print(f\"‚ùå Error creating vector bucket: {error_code} - {error_message}\")\n",
    "        raise\n",
    "\n",
    "# Create the vector bucket\n",
    "vector_store_arn = create_vector_bucket(vector_store_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3736f9a-1496-4569-bec1-2153eeab3e27",
   "metadata": {},
   "source": [
    "### Creating a Vector Index\n",
    "\n",
    "Now that we have created the vector store, we need to create a vector index. The vector index is where:\n",
    "\n",
    "1. Vector embeddings are stored and organized\n",
    "2. Similarity searches are performed\n",
    "3. Metadata about our documents is maintained\n",
    "\n",
    "We'll specify parameters like dimension (3072 for Nova Multimodal), distance metric (cosine similarity), and data type (float32)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e82d03-ff30-405d-ab18-299e37c316c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_and_get_index_arn(s3vectors_client, vector_store_name, vector_index_name, vector_dimension):\n",
    "    \"\"\"\n",
    "    Create a vector index in the specified vector store and return its ARN\n",
    "    \n",
    "    Args:\n",
    "        s3vectors_client: Boto3 client for S3 Vectors\n",
    "        vector_store_name: Name of the vector store\n",
    "        vector_index_name: Name for the new index\n",
    "        vector_dimension: Dimension of the vectors (3072 for Nova Multimodal)\n",
    "        \n",
    "    Returns:\n",
    "        str: ARN of the created index\n",
    "    \"\"\"\n",
    "    # Define index configuration\n",
    "    index_config = {\n",
    "        \"vectorBucketName\": vector_store_name,\n",
    "        \"indexName\": vector_index_name,\n",
    "        \"dimension\": vector_dimension,\n",
    "        \"distanceMetric\": \"cosine\",  # Using cosine similarity as our metric\n",
    "        \"dataType\": \"float32\",       # Standard for most embedding models\n",
    "        \"metadataConfiguration\": {\n",
    "            \"nonFilterableMetadataKeys\": [\"AMAZON_BEDROCK_TEXT\"]  # Text content won't be used for filtering\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        print(f\"\\nCreating vector index with configuration:\")\n",
    "        print(f\"  - Dimension: {vector_dimension}\")\n",
    "        print(f\"  - Distance Metric: cosine\")\n",
    "        print(f\"  - Data Type: float32\")\n",
    "        \n",
    "        # Create the index\n",
    "        s3vectors_client.create_index(**index_config)\n",
    "        print(f\"‚úÖ Vector index '{vector_index_name}' created successfully\")\n",
    "\n",
    "        # Get the index ARN\n",
    "        response = s3vectors_client.list_indexes(vectorBucketName=vector_store_name)\n",
    "        index_arn = response.get(\"indexes\", [{}])[0].get(\"indexArn\")\n",
    "        \n",
    "        if not index_arn:\n",
    "            raise ValueError(\"Index ARN not found in response\")\n",
    "            \n",
    "        print(f\"Vector index ARN: {index_arn}\")\n",
    "        return index_arn\n",
    "\n",
    "    except ClientError as e:\n",
    "        error_code = e.response.get('Error', {}).get('Code', 'Unknown')\n",
    "        error_message = e.response.get('Error', {}).get('Message', 'Unknown error')\n",
    "        print(f\"‚ùå Failed to create or retrieve index: {error_code} - {error_message}\")\n",
    "        raise\n",
    "\n",
    "# Create the vector index\n",
    "vector_index_arn = create_and_get_index_arn(\n",
    "    s3vectors,\n",
    "    vector_store_name,\n",
    "    vector_index_name,\n",
    "    vector_dimension\n",
    ")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"‚úÖ Vector index successfully created\")\n",
    "print(f\"{'='*60}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b1e82f6-b95c-48a9-ac15-3fd9ab9a7078",
   "metadata": {},
   "source": [
    "## Create a Multimodal Knowledge Base\n",
    "\n",
    "Now we'll create a Knowledge Base configured for multimodal retrieval using Amazon Nova Multimodal Embeddings and S3 Vectors as the vector store. First, we need to set up the appropriate IAM permissions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9956969e-33f1-493e-8086-1a6e5e0f2188",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create IAM role for Bedrock Knowledge Base\n",
    "print(f\"\\nCreating IAM execution role for Knowledge Base...\\n\")\n",
    "\n",
    "create_role = create_bedrock_execution_role(\n",
    "    unique_id, \n",
    "    region_name, \n",
    "    bucket_name,\n",
    "    multimodal_storage_bucket_name, \n",
    "    vector_store_name,\n",
    "    vector_index_name,\n",
    "    account_id\n",
    ")\n",
    "\n",
    "roleArn = create_role[\"Role\"][\"Arn\"]\n",
    "roleName = create_role[\"Role\"][\"RoleName\"]\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"IAM Role Details\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Role Name: {roleName}\")\n",
    "print(f\"Role ARN:  {roleArn}\")\n",
    "print(f\"{'='*60}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aeb0d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bedrock_agent_runtime_client = boto3_session.client(\"bedrock-agent-runtime\")\n",
    "bedrock_agent_client = boto3.client('bedrock-agent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef848f0-e4d5-4aa4-a72b-068679715644",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wait for IAM role propagation\n",
    "print(\"\\nWaiting for IAM role propagation (30 seconds)...\")\n",
    "print(\"This ensures the role and policies are fully available before creating the Knowledge Base.\")\n",
    "time.sleep(30)\n",
    "print(\"‚úÖ Role propagation complete\\n\")\n",
    "\n",
    "# Create the multimodal Knowledge Base with Nova embeddings and S3 Vectors\n",
    "print(f\"Creating Knowledge Base: {kb_name}\")\n",
    "print(f\"  - Embedding Model: Amazon Nova Multimodal Embeddings v1\")\n",
    "print(f\"  - Vector Dimensions: 3072\")\n",
    "print(f\"  - Vector Store: S3 Vectors\")\n",
    "\n",
    "create_kb_response = bedrock_agent_client.create_knowledge_base(\n",
    "    name=kb_name,\n",
    "    description='Multimodal Product Catalog Knowledge Base with Amazon Nova Embeddings and S3 Vectors',\n",
    "    roleArn=roleArn,\n",
    "    knowledgeBaseConfiguration={\n",
    "        'type': 'VECTOR',\n",
    "        'vectorKnowledgeBaseConfiguration': {\n",
    "            # Use Amazon Nova Multimodal Embeddings\n",
    "            'embeddingModelArn': f'arn:aws:bedrock:{region_name}::foundation-model/amazon.nova-2-multimodal-embeddings-v1:0',\n",
    "            'embeddingModelConfiguration': {\n",
    "                'bedrockEmbeddingModelConfiguration': {\n",
    "                    'audio': [{'segmentationConfiguration': {'fixedLengthDuration': 5}}],\n",
    "                    'dimensions': 3072,  # Nova Multimodal default dimension\n",
    "                    'embeddingDataType': 'FLOAT32',\n",
    "                    'video': [{'segmentationConfiguration': {'fixedLengthDuration': 5}}]\n",
    "                }\n",
    "            },\n",
    "            # Storage location for extracted images from multimodal documents\n",
    "            'supplementalDataStorageConfiguration': {\n",
    "                'storageLocations': [\n",
    "                    {\n",
    "                        'type': 'S3',\n",
    "                        's3Location': {\n",
    "                            'uri': f's3://{multimodal_storage_bucket_name}'  # Update with your bucket\n",
    "                        }\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        },\n",
    "    },\n",
    "    storageConfiguration={\n",
    "        'type': 'S3_VECTORS',\n",
    "        's3VectorsConfiguration': {\n",
    "            'indexArn': f'arn:aws:s3vectors:{region_name}:{account_id}:bucket/{vector_store_name}/index/{vector_index_name}',\n",
    "        },\n",
    "    }\n",
    ")\n",
    "\n",
    "knowledge_base_id = create_kb_response[\"knowledgeBase\"][\"knowledgeBaseId\"]\n",
    "print(f\"\\n‚úÖ Knowledge Base created with ID: {knowledge_base_id}\")\n",
    "\n",
    "print(f\"\\nWaiting for Knowledge Base to become active...\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# Poll for KB creation status\n",
    "status = \"CREATING\"\n",
    "start_time = time.time()\n",
    "\n",
    "while status == \"CREATING\":\n",
    "    response = bedrock_agent_client.get_knowledge_base(\n",
    "        knowledgeBaseId=knowledge_base_id\n",
    "    )\n",
    "    \n",
    "    status = response['knowledgeBase']['status']\n",
    "    elapsed_time = int(time.time() - start_time)\n",
    "    \n",
    "    print(f\"Status: {status} | Elapsed time: {elapsed_time}s\")\n",
    "    \n",
    "    if status == \"CREATING\":\n",
    "        print(\"Checking again in 30 seconds...\")\n",
    "        time.sleep(30)\n",
    "    else:\n",
    "        break\n",
    "\n",
    "print(\"-\" * 60)\n",
    "print(f\"\\n‚úÖ Knowledge Base creation completed with status: {status}\")\n",
    "print(f\"   Total time: {elapsed_time} seconds\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0656085-5b49-41c0-884b-2578d26d723a",
   "metadata": {},
   "source": [
    "## Create and Sync the Data Source\n",
    "\n",
    "Now we'll create a data source pointing to our S3 bucket with product images/videos, and configure it to use the Amazon Bedrock default parser which will handle multimodal content natively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80218a72-0a96-40cf-b9bc-7a61e08713dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the multimodal data source\n",
    "print(f\"Creating data source for S3 bucket: {bucket_name}\")\n",
    "\n",
    "data_source_response = bedrock_agent_client.create_data_source(\n",
    "    knowledgeBaseId=knowledge_base_id,\n",
    "    name='product-catalog-ds',\n",
    "    description='Product catalog with images and videos',\n",
    "    dataDeletionPolicy='DELETE',\n",
    "    dataSourceConfiguration={\n",
    "        'type': 'S3',\n",
    "        's3Configuration': {\n",
    "            'bucketArn': f'arn:aws:s3:::{bucket_name}',\n",
    "        },\n",
    "    },\n",
    "    vectorIngestionConfiguration={\n",
    "        'chunkingConfiguration': {\n",
    "            'chunkingStrategy': 'NONE',\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "datasource_id = data_source_response[\"dataSource\"][\"dataSourceId\"]\n",
    "print(f\"‚úÖ Data source created with ID: {datasource_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52274ec7-7448-42a7-893a-a8deaf0b4c5d",
   "metadata": {},
   "source": [
    "## Sync the Data Source\n",
    "\n",
    "Now we'll start the ingestion job to process our product catalog. This will:\n",
    "1. Read images and videos from S3\n",
    "2. Generate multimodal embeddings using Amazon Nova\n",
    "3. Store embeddings in the S3 Vector Store\n",
    "\n",
    "This process may take several minutes depending on the size and number of files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6586835f-89b2-48d8-bd57-7023ac1d9584",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start the ingestion job\n",
    "print(f\"\\nStarting ingestion job for Knowledge Base: {knowledge_base_id}\")\n",
    "print(f\"Data Source: {datasource_id}\\n\")\n",
    "\n",
    "response_ingestion = bedrock_agent_client.start_ingestion_job(\n",
    "    dataSourceId=datasource_id,\n",
    "    description='Initial product catalog sync',\n",
    "    knowledgeBaseId=knowledge_base_id\n",
    ")\n",
    "\n",
    "ingestion_job_id = response_ingestion['ingestionJob']['ingestionJobId']\n",
    "print(f\"‚úÖ Ingestion job started with ID: {ingestion_job_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436d5355-ef87-4026-9320-9a62709d946f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monitor the ingestion job progress\n",
    "status = \"STARTING\"\n",
    "start_time = time.time()\n",
    "\n",
    "print(\"\\nMonitoring ingestion job progress:\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "while status in [\"STARTING\", \"IN_PROGRESS\"]:\n",
    "    response = bedrock_agent_client.get_ingestion_job(\n",
    "        dataSourceId=datasource_id,\n",
    "        knowledgeBaseId=knowledge_base_id,\n",
    "        ingestionJobId=ingestion_job_id\n",
    "    )\n",
    "    \n",
    "    status = response['ingestionJob']['status']\n",
    "    elapsed_time = int(time.time() - start_time)\n",
    "    \n",
    "    stats = response['ingestionJob']['statistics']\n",
    "    \n",
    "    print(f\"\\nStatus: {status} | Elapsed: {elapsed_time}s\")\n",
    "    print(f\"  Documents scanned:  {stats['numberOfDocumentsScanned']}\")\n",
    "    print(f\"  Documents indexed:  {stats['numberOfNewDocumentsIndexed']}\")\n",
    "    print(f\"  Documents failed:   {stats['numberOfDocumentsFailed']}\")\n",
    "    \n",
    "    if status in [\"STARTING\", \"IN_PROGRESS\"]:\n",
    "        print(f\"\\n‚è≥ Checking again in 30 seconds...\")\n",
    "        time.sleep(30)\n",
    "    else:\n",
    "        break\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "\n",
    "if status == \"COMPLETE\":\n",
    "    print(f\"\\n‚úÖ Ingestion job completed successfully!\")\n",
    "else:\n",
    "    print(f\"\\n‚ö†Ô∏è Ingestion job ended with status: {status}\")\n",
    "    \n",
    "print(f\"\\nFinal Statistics:\")\n",
    "print(f\"  üìÑ Documents scanned:  {stats['numberOfDocumentsScanned']}\")\n",
    "print(f\"  ‚úÖ Documents indexed:  {stats['numberOfNewDocumentsIndexed']}\")\n",
    "print(f\"  ‚ùå Documents failed:   {stats['numberOfDocumentsFailed']}\")\n",
    "print(f\"  ‚è±Ô∏è  Total time:         {elapsed_time} seconds\")\n",
    "print(\"\\n\" + \"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdbedc12-0ca8-4a3c-8b29-fa55be912b25",
   "metadata": {},
   "source": [
    "## Test the Knowledge Base with Text Queries\n",
    "\n",
    "Now that our multimodal Knowledge Base is ready, let's test it with text-based queries. We'll use the Retrieve API to retrieve the most similar chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a9149d",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_query = \"A metallic phone cover\"\n",
    "\n",
    "response = bedrock_agent_runtime_client.retrieve(\n",
    "    knowledgeBaseId=knowledge_base_id,\n",
    "    retrievalQuery={\n",
    "        \"text\": input_query\n",
    "    },\n",
    "    retrievalConfiguration={\n",
    "        \"vectorSearchConfiguration\": {\n",
    "            \"numberOfResults\": 5\n",
    "        }\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccba1cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML, display, Image as IPImage\n",
    "import boto3\n",
    "import uuid\n",
    "s3_client = boto3.client('s3')\n",
    "\n",
    "def display_video_segment(s3_uri, start_time_ms, end_time_ms, score, width=400):\n",
    "    \"\"\"Display video segment with controls\"\"\"\n",
    "    bucket = s3_uri.replace('s3://', '').split('/')[0]\n",
    "    key = '/'.join(s3_uri.replace('s3://', '').split('/')[1:])\n",
    "    \n",
    "    presigned_url = s3_client.generate_presigned_url(\n",
    "        'get_object',\n",
    "        Params={'Bucket': bucket, 'Key': key},\n",
    "        ExpiresIn=3600\n",
    "    )\n",
    "    \n",
    "    start_sec = start_time_ms / 1000\n",
    "    end_sec = end_time_ms / 1000\n",
    "    video_id = f\"video_{uuid.uuid4().hex[:8]}\"\n",
    "    \n",
    "    html = f\"\"\"\n",
    "    <div style=\"margin: 20px 0; padding: 10px; border: 2px solid #2196F3; border-radius: 5px; max-width: {width + 20}px;\">\n",
    "        <div style=\"background: #2196F3; color: white; padding: 8px; margin: -10px -10px 10px -10px;\">\n",
    "            <strong>üìπ Video Segment: {start_sec:.1f}s - {end_sec:.1f}s | Score: {score:.3f}</strong>\n",
    "        </div>\n",
    "        \n",
    "        <video id=\"{video_id}\" width=\"{width}\" controls preload=\"metadata\" style=\"max-width: 100%;\">\n",
    "            <source src=\"{presigned_url}\" type=\"video/mp4\">\n",
    "        </video>\n",
    "        \n",
    "        <div style=\"margin-top: 10px; padding: 8px; background: #e3f2fd; border-radius: 3px; font-family: monospace; font-size: 12px;\">\n",
    "            <span id=\"{video_id}_status\">‚è≥ Loading...</span>\n",
    "        </div>\n",
    "    </div>\n",
    "    \n",
    "    <script>\n",
    "        (function() {{\n",
    "            var video = document.getElementById('{video_id}');\n",
    "            var status = document.getElementById('{video_id}_status');\n",
    "            var startTime = {start_sec};\n",
    "            var endTime = {end_sec};\n",
    "            var seeked = false;\n",
    "            \n",
    "            function seekToStart() {{\n",
    "                if (video.readyState >= 2 && !seeked) {{\n",
    "                    video.currentTime = startTime;\n",
    "                    seeked = true;\n",
    "                    status.innerHTML = '‚úÖ Ready at ' + startTime.toFixed(1) + 's';\n",
    "                }}\n",
    "            }}\n",
    "            \n",
    "            video.addEventListener('loadedmetadata', seekToStart);\n",
    "            video.addEventListener('loadeddata', seekToStart);\n",
    "            video.addEventListener('canplay', seekToStart);\n",
    "            setTimeout(seekToStart, 100);\n",
    "            setTimeout(seekToStart, 500);\n",
    "            \n",
    "            video.addEventListener('timeupdate', function() {{\n",
    "                if (video.currentTime >= endTime) {{\n",
    "                    video.pause();\n",
    "                    video.currentTime = startTime;\n",
    "                    status.innerHTML = '‚èπÔ∏è Segment ended';\n",
    "                }} else if (video.currentTime >= startTime) {{\n",
    "                    status.innerHTML = '‚ñ∂Ô∏è ' + video.currentTime.toFixed(1) + 's';\n",
    "                }}\n",
    "            }});\n",
    "        }})();\n",
    "    </script>\n",
    "    \"\"\"\n",
    "    \n",
    "    display(HTML(html))\n",
    "\n",
    "def display_image_result(image_b64, source_uri, score, width=400):\n",
    "    \"\"\"Display image result - FIXED VERSION\"\"\"\n",
    "    html = f\"\"\"\n",
    "    <div style=\"margin: 20px 0; padding: 10px; border: 2px solid #4CAF50; border-radius: 5px; max-width: {width + 20}px;\">\n",
    "        <div style=\"background: #4CAF50; color: white; padding: 8px; margin: -10px -10px 10px -10px;\">\n",
    "            <strong>üñºÔ∏è Image | Relevance Score: {score:.3f}</strong>\n",
    "        </div>\n",
    "        <div style=\"margin: 10px 0; text-align: center;\">\n",
    "            <img src=\"{image_b64}\" style=\"max-width: {width}px; width: 100%; height: auto; border-radius: 5px;\"/>\n",
    "        </div>\n",
    "        <div style=\"margin-top: 10px; padding: 8px; background: #f1f8e9; border-radius: 3px; font-family: monospace; font-size: 11px; word-break: break-all;\">\n",
    "            üìÅ Source: {source_uri}\n",
    "        </div>\n",
    "    </div>\n",
    "    \"\"\"\n",
    "    display(HTML(html))\n",
    "\n",
    "def display_all_retrieval_results(response, video_width=500, image_width=300):\n",
    "    \"\"\"Display all retrieval results with separate sizing for videos and images\"\"\"\n",
    "    \n",
    "    print(f\"üîç Found {len(response['retrievalResults'])} relevant results\\n\")\n",
    "    \n",
    "    for idx, result in enumerate(response['retrievalResults'], 1):\n",
    "        score = result['score']\n",
    "        \n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"Result #{idx}\")\n",
    "        print(f\"{'='*80}\\n\")\n",
    "        \n",
    "        if result['content']['type'] == 'VIDEO':\n",
    "            video_uri = result['content']['video']['s3Uri']\n",
    "            start_time = result['metadata']['x-amz-bedrock-kb-chunk-start-time-in-millis']\n",
    "            end_time = result['metadata']['x-amz-bedrock-kb-chunk-end-time-in-millis']\n",
    "            source_uri = result['location']['s3Location']['uri']\n",
    "            \n",
    "            print(f\"Type: VIDEO\")\n",
    "            print(f\"Source File: {source_uri}\")\n",
    "            print(f\"Time Range: {start_time/1000:.1f}s - {end_time/1000:.1f}s\")\n",
    "            print(f\"Score: {score:.3f}\\n\")\n",
    "            \n",
    "            display_video_segment(video_uri, start_time, end_time, score, video_width)\n",
    "            \n",
    "        elif result['content']['type'] == 'IMAGE':\n",
    "            image_b64 = result['content']['byteContent']\n",
    "            source_uri = result['location']['s3Location']['uri']\n",
    "            \n",
    "            print(f\"Type: IMAGE\")\n",
    "            print(f\"Source File: {source_uri}\")\n",
    "            print(f\"Score: {score:.3f}\\n\")\n",
    "            \n",
    "            display_image_result(image_b64, source_uri, score, image_width)\n",
    "\n",
    "# Use it with different sizes for videos vs images\n",
    "display_all_retrieval_results(response, video_width=600, image_width=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1af54940-a9e9-4baf-ae8f-9f081cca28f6",
   "metadata": {},
   "source": [
    "## Test with Image-based Visual Search\n",
    "\n",
    "Now for the powerful part‚Äîvisual search! Upload a reference image to find visually similar products in your catalog. This demonstrates the cross-modal capability of Amazon Nova Multimodal Embeddings.\n",
    "\n",
    "### Using the Retrieve API\n",
    "\n",
    "First, let's use the Retrieve API to see the raw retrieval results with similarity scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c0c14f9-882b-4f57-9190-b40a1ae3235a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import os\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "from botocore.exceptions import ClientError\n",
    "\n",
    "def image_to_base64(image_path):\n",
    "    \"\"\"\n",
    "    Convert an image file to base64 string\n",
    "    \"\"\"\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "def display_image_from_base64(base64_str, title=\"Image\"):\n",
    "    \"\"\"\n",
    "    Display image from base64 string\n",
    "    \"\"\"\n",
    "    if base64_str.startswith('data:image'):\n",
    "        base64_str = base64_str.split(',')[1]\n",
    "    \n",
    "    image_bytes = base64.b64decode(base64_str)\n",
    "    image = Image.open(BytesIO(image_bytes))\n",
    "    return image\n",
    "\n",
    "# Path to your reference image\n",
    "reference_image_path = \"test-image/phone.png\"  # Update this path\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"Image-based Visual Search Test\")\n",
    "print(f\"{'='*70}\\n\")\n",
    "\n",
    "if not os.path.exists(reference_image_path):\n",
    "    print(f\"‚ö†Ô∏è Reference image not found: {reference_image_path}\")\n",
    "    print(f\"\\nTo test visual search:\")\n",
    "    print(f\"1. Place a reference image in the same folder as this notebook\")\n",
    "    print(f\"2. Name it 'reference_image.png' (or update the path above)\")\n",
    "    print(f\"3. Run this cell again\")\n",
    "    print(f\"\\nExpected location: {os.path.abspath(reference_image_path)}\")\n",
    "    print(f\"\\nüí° Alternative: Download a product image from your S3 bucket first!\")\n",
    "    \n",
    "else:\n",
    "    # Display the reference image\n",
    "    print(\"üîç Reference Image:\")\n",
    "    reference_img = Image.open(reference_image_path)\n",
    "    \n",
    "    # Create figure for reference image\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(4, 4))\n",
    "    ax.imshow(reference_img)\n",
    "    ax.axis('off')\n",
    "    ax.set_title(\"Search Query Image\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"\\nImage size: {reference_img.size}\")\n",
    "    print(f\"Image mode: {reference_img.mode}\")\n",
    "    \n",
    "    # Convert image to base64\n",
    "    image_base64 = image_to_base64(reference_image_path)\n",
    "    \n",
    "    # Determine image format from file extension\n",
    "    image_format = reference_image_path.split('.')[-1].lower()\n",
    "    if image_format == 'jpg':\n",
    "        image_format = 'jpeg'\n",
    "    \n",
    "    print(f\"\\nSearching for visually similar products...\")\n",
    "    print(f\"Query image format: {image_format}\")\n",
    "    \n",
    "    # Query with image using Retrieve API\n",
    "    response = bedrock_agent_runtime_client.retrieve(\n",
    "        knowledgeBaseId=knowledge_base_id,  # Use the variable\n",
    "        retrievalQuery={\n",
    "            \"type\": \"IMAGE\",\n",
    "            \"image\": {\n",
    "                \"format\": image_format,\n",
    "                \"inlineContent\": base64.b64decode(image_base64)\n",
    "            }\n",
    "        },\n",
    "        retrievalConfiguration={\n",
    "            \"vectorSearchConfiguration\": {\n",
    "                \"numberOfResults\": 5,\n",
    "            } \n",
    "        }\n",
    "    )\n",
    "\n",
    "    display_all_retrieval_results(response, video_width=600, image_width=300)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a11966-48af-44bc-b9af-bc4be36b25ac",
   "metadata": {},
   "source": [
    "## Understanding the Results\n",
    "\n",
    "The multimodal Knowledge Base with S3 Vectors provides several powerful capabilities:\n",
    "\n",
    "### Search Methods\n",
    "\n",
    "1. **Text Queries**: Searches across product images and videos using semantic understanding of your text description\n",
    "   - Example: \"metallic phone cover\" finds products with metallic finishes\n",
    "   \n",
    "2. **Image Queries**: Finds visually similar products by comparing visual features\n",
    "   - Colors, patterns, shapes, textures\n",
    "   - No need for text descriptions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f8a3b4c-9e1f-4d2e-a1de-3b2e7c8f9d0e",
   "metadata": {},
   "source": [
    "## Next Steps and Use Cases\n",
    "\n",
    "This multimodal Knowledge Base architecture can be extended for various use cases:\n",
    "\n",
    "### E-commerce\n",
    "- **Visual product search**: Customers upload photos to find similar items\n",
    "- **Style matching**: Find products that match a particular aesthetic\n",
    "- **Cross-sell recommendations**: Suggest visually complementary products\n",
    "- **Reverse image search**: Find products seen in social media or other sites\n",
    "\n",
    "### Manufacturing\n",
    "- **Equipment manuals**: Search through technical documentation with diagrams\n",
    "- **Quality control**: Find similar defects in inspection images\n",
    "- **Training materials**: Locate specific procedures in video tutorials\n",
    "- **Parts identification**: Match components visually\n",
    "\n",
    "### Media and Entertainment\n",
    "- **Video libraries**: Find similar scenes across large video collections\n",
    "- **Content discovery**: Search using text descriptions or reference images\n",
    "- **Asset management**: Organize and retrieve visual content efficiently\n",
    "\n",
    "### Further Enhancements\n",
    "\n",
    "1. **Add metadata filtering**\n",
    "   - Price ranges, categories, availability\n",
    "   - Brand, color, size attributes\n",
    "   \n",
    "2. **Implement re-ranking**\n",
    "   - Use Cohere Rerank for improved relevance\n",
    "   - Combine with user preferences and behavior\n",
    "   \n",
    "3. **Combine with recommendations**\n",
    "   - Purchase history\n",
    "   - User preferences\n",
    "   - Trending products\n",
    "   \n",
    "4. **Add audio/video processing**\n",
    "   - Use Bedrock Data Automation (BDA) for speech transcription\n",
    "   - Extract audio features from product videos\n",
    "   - Combine visual and audio embeddings\n",
    "5. **Send the results to a multimodal model to generate responses**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a11966-48af-44bc-b9af-bc4be36b25ac",
   "metadata": {},
   "source": [
    "## Clean up\n",
    "\n",
    "To avoid ongoing charges, clean up all the resources we've created in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10823dcb-af1e-4cc8-a95a-70e79be2e2a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\n{'='*70}\")\n",
    "print(\"Starting cleanup process...\")\n",
    "print(f\"{'='*70}\\n\")\n",
    "\n",
    "# Step 1: Delete Knowledge Base\n",
    "print(f\"[1/4] Deleting Knowledge Base: {knowledge_base_id}\")\n",
    "try:\n",
    "    bedrock_agent_client.delete_knowledge_base(knowledgeBaseId=knowledge_base_id)\n",
    "    print(\"      ‚úÖ Knowledge Base deleted successfully\\n\")\n",
    "except Exception as e:\n",
    "    print(f\"      ‚ùå Error deleting Knowledge Base: {str(e)}\\n\")\n",
    "\n",
    "# Step 2: Delete S3 Vector Store policy\n",
    "print(f\"[2/4] Deleting S3 Vector Store: {vector_store_name}\")\n",
    "try:\n",
    "    s3vectors.delete_vector_bucket_policy(vectorBucketName=vector_store_name)\n",
    "    print(\"      ‚úÖ S3 Vector Store policy deleted successfully\\n\")\n",
    "except Exception as e:\n",
    "    print(f\"      ‚ùå Error deleting Vector Store policy: {str(e)}\\n\")\n",
    "\n",
    "# Step 3: Empty and delete S3 Bucket\n",
    "print(f\"[3/4] Emptying and deleting S3 Bucket: {bucket_name}\")\n",
    "try:\n",
    "    empty_and_delete_bucket(bucket_name)\n",
    "except Exception as e:\n",
    "    print(f\"      ‚ùå Error emptying and deleting S3 Bucket: {str(e)}\\n\")\n",
    "\n",
    "# Step 4: Delete IAM Role and policies\n",
    "print(f\"[4/4] Deleting IAM Role: {roleName}\")\n",
    "try:\n",
    "    # List and detach all attached policies\n",
    "    attached_policies = iam_client.list_attached_role_policies(RoleName=roleName).get('AttachedPolicies', [])\n",
    "    \n",
    "    for policy in attached_policies:\n",
    "        print(f\"      Detaching policy: {policy['PolicyName']}\")\n",
    "        iam_client.detach_role_policy(RoleName=roleName, PolicyArn=policy['PolicyArn'])\n",
    "        \n",
    "        # Delete the policy\n",
    "        try:\n",
    "            iam_client.delete_policy(PolicyArn=policy['PolicyArn'])\n",
    "            print(f\"      Deleted policy: {policy['PolicyName']}\")\n",
    "        except Exception as e:\n",
    "            print(f\"      Warning: Could not delete policy {policy['PolicyName']}: {e}\")\n",
    "    \n",
    "    # Delete the role\n",
    "    iam_client.delete_role(RoleName=roleName)\n",
    "    print(f\"      ‚úÖ IAM Role deleted successfully\\n\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"      ‚ùå Error deleting IAM Role: {str(e)}\\n\")\n",
    "\n",
    "print(f\"{'='*70}\")\n",
    "print(\"‚úÖ Cleanup completed successfully!\")\n",
    "print(f\"{'='*70}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
