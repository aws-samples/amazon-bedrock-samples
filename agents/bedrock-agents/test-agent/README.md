## Agents for Amazon Bedrock Latency and Output Tests

This code runs latency and output tests for agents built with [Agents for Amazon Bedrock](https://aws.amazon.com/bedrock/agents/).

To use this solution, you should provide a test data file in `JSON` format. The test data has the following format:

```json
{
    "conversationID": [
        "query1",
        "query2",
        ...
    ],
    "conversationID2": [
        {
            "file": "data/FAKECO.csv",
            "type": "CHAT",
            "query": "What is the data in this file?"
        },
        {
            "file": "data/FAKECO.csv",
            "type": "CODE_INTERPRETER",
            "query": "Describe the data in the file"
        }
    ],
    "conversationID3": [
        "Please generate a list of the 10 greatest books of all time. Return it as a CSV file. Always return the file, even if you have provided it before.",
        {
            "file": "data/FAKECO.csv",
            "type": "CODE_INTERPRETER",
            "query": "Given the attached price data file, please make me a chart with moving average in red and actual data in blue"
        },
        "generate two csv files for me. \none called SALES, with 3 columns: COMPANY_ID, COMPANY_NAME, and SALES_2024. \nthe other called DETAILS, with 3 columns: COMPANY_ID, COMPANY_STATE_CODE. \nfollow these rules:\n1) each file should contain 200 companies, and share the same company ID’s. \n2) use human readable english words in the names (not random strings of letters and digits), \n3) use ID’s of the form: C00001. \n4) Only use states that are generally considered to be near the east coast or near the west coast. \n5) Make the revenue from each eastern company range from 0 to $700,000, \n6) Make revenue from each western company range from $500,000 up to $2,000,000. \nWhen done, test to be sure you have followed each of the above rules, \nand produce a chart comparing sales per company in the two regions using box plots."
    ],
    "conversationID4": [
        {
            "promptSessionAttributes": {
                "today": "July 29th 2024"
            },
            "sessionAttributes": {
                "user_id": "1"
            },
            "query": "What day is tomorrow?"
        }
    ]
}
```
For each conversation, you should pass a list of queries. A query can be a string or an object. For the cases where a query is an object, you can pass the information used in the `sessionState` object of the [InvokeAgent](https://docs.aws.amazon.com/bedrock/latest/APIReference/API_agent-runtime_InvokeAgent.html) API.

### Usage
1. Update your test file. Two examples are provided: `test.json` and `test2.json`
   1. You can pass session and prompt attributes -- see example in `test2.json`
   1. You can pass files to `CHAT` or `CODE_INTERPRETER` -- see example in `test2.json`
   2. You can create multiple conversations. Conversations inside the same list share the same `sessionId`
1. Install pre-requisites
```commandline
pip install -r requirements.txt
```
1. Make sure you have your proper AWS setup (not required if running through AWS environment such as SageMaker Studio)
1. Run code with your agent
```commandline
python test_agent.py --test_file <YOUR_TEST_FILE_NAME> --agent_id <YOUR_AGENT_ID> --agent_alias_id <YOUR_AGENT_ALIAS_ID> --region <REGION_WHERE_AGENT_IS_DEPLOYED> 
```

### Output

The `test_agent.py` script will create an `output` folder where the trace events for each execution is stored in a Markdown format. If any files are generated by the agent, those are also stored in the same folder. For each conversation, a `latency_summary` file is generated.