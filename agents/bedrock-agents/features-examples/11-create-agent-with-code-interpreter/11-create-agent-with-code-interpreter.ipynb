{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "089569ae-9348-4442-8e2a-941a8e5c00ac",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<h2> Create Agent with Code Interpreter </h2>\n",
    "\n",
    "In this notebook we will create an Agent for Amazon Bedrock using the new capabilities for code interpreter to execute code. Code interpreter is a special pre-defined tool (action group) that provides the model with a sandbox environment in which it can execute code (currently Python), using a set of available pre-defined libraries.\n",
    "\n",
    "The example will first use code interpreter to help answer math questions. LLMs often struggle with accuracy on math, but are proficient in writing code, so the agent will write code to perform its math calculations, use code interpreter to execute it, and pass the results back to the user. We will also show how to pass files into the agent, either for chat processing or for analysis using code interpretation. Finally, the agent will use code interpreter to write code to create files of types that it normally could not, such as graphs.\n",
    "\n",
    "Examples:\n",
    "- Create agent with code interpretation\n",
    "- Invoke agent asking for some math questions\n",
    "- Invoke agent passing a file for chat\n",
    "- Invoke agent passing a file for code interpretation\n",
    "- Invoke agent to plot a graph\n",
    "- Invoke agent to create documents\n",
    "\n",
    "The following architecture will be built:\n",
    "\n",
    "![Code interpreter agent](images/architecture.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "073fb566-1bb1-46ec-bdb3-7012a2e74714",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<h2> Prerequisites </h2>\n",
    "\n",
    "Before starting, let's update the botocore and boto3 packages to ensure we have the latest version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c603ce06-61d8-4236-92e8-883e0d49cfea",
   "metadata": {
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "!python3 -m pip install --upgrade -q boto3\n",
    "!python3 -m pip install --upgrade -q botocore\n",
    "!python3 -m pip install --upgrade -q awscli"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f3bc3b-4db6-44bb-8d8e-3ea58e811111",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Let's now check the boto3 version to ensure the correct version has been installed. Your version should be greater than or equal to 1.34.139."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48daaac3-aeb2-439b-8648-f9a088b4f40c",
   "metadata": {
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import botocore\n",
    "import awscli\n",
    "print(boto3.__version__)\n",
    "print(botocore.__version__)\n",
    "print(awscli.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "498f033c-3cf4-4071-ac8e-6bb31920897a",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Next we want to import the support packages and set the logger object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5255655e-d83e-416a-a459-83590483d22b",
   "metadata": {
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "from io import BytesIO\n",
    "import uuid\n",
    "import pprint\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "593be615-dab2-4084-a518-ee905113bfc7",
   "metadata": {
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# setting logger\n",
    "logging.basicConfig(format='[%(asctime)s] p%(process)s {%(filename)s:%(lineno)d} %(levelname)s - %(message)s', level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52dad4b8-c2e0-44cf-99ee-5c2a7e1a600f",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Let's now create the boto3 clients for the required AWS services"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67883027-bbb5-42a6-955d-0aa019a8e4b3",
   "metadata": {
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# getting boto3 clients for required AWS services\n",
    "sts_client = boto3.client('sts')\n",
    "iam_client = boto3.client('iam')\n",
    "lambda_client = boto3.client('lambda')\n",
    "bedrock_agent_client = boto3.client('bedrock-agent')\n",
    "bedrock_agent_runtime_client = boto3.client('bedrock-agent-runtime')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71505c3b-c2a5-47dc-a427-77f21ab50f0d",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Next we can set some configuration variables for the agent and for the lambda function being created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6af5cd4-33b8-40c3-9d99-1790540eb60c",
   "metadata": {
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "session = boto3.session.Session()\n",
    "region = session.region_name\n",
    "account_id = sts_client.get_caller_identity()[\"Account\"]\n",
    "region, account_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dcb5332-c035-435a-91e5-838ec95d9a7d",
   "metadata": {
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# configuration variables\n",
    "suffix = f\"{region}-{account_id}\"\n",
    "agent_name = \"assistant-w-code-interpret\"\n",
    "agent_bedrock_allow_policy_name = f\"{agent_name}-ba-{suffix}\"\n",
    "agent_role_name = f'AmazonBedrockExecutionRoleForAgents_{agent_name}'\n",
    "agent_foundation_model = \"anthropic.claude-3-sonnet-20240229-v1:0\"\n",
    "agent_description = \"Assistant with code interpreter that can write and execute code to answer questions\"\n",
    "agent_instruction = \"\"\"\n",
    "You are an assistant that helps customers answer questions and create documents.\n",
    "You have access to code interpreter to execute Python code, so when tasks are best handled via Python code, \n",
    "write code as needed and pass it to code interpreter to execute, then return the result to the user.\n",
    "\"\"\"\n",
    "agent_alias_name = f\"{agent_name}-alias\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3da023d2",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<h2> Create synthetic stock price data </h2>\n",
    "\n",
    "We will use a CSV of stock price data for the non-existent company 'FAKECO'; we create it here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f76ee4",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "def make_synthetic_stock_data(filename):\n",
    "    # Define the start and end dates\n",
    "    start_date = datetime(2023, 6, 27)\n",
    "    end_date = datetime(2024, 6, 27)\n",
    "\n",
    "    # Create a date range\n",
    "    date_range = pd.date_range(start_date, end_date, freq='D')\n",
    "\n",
    "    # Initialize lists to store the data\n",
    "    symbol = []\n",
    "    dates = []\n",
    "    open_prices = []\n",
    "    high_prices = []\n",
    "    low_prices = []\n",
    "    close_prices = []\n",
    "    adj_close_prices = []\n",
    "    volumes = []\n",
    "\n",
    "    # Set the initial stock price\n",
    "    initial_price = 100.0\n",
    "\n",
    "    # Generate plausible stock prices\n",
    "    for date in date_range:\n",
    "        symbol.append('FAKECO')\n",
    "        dates.append(date)\n",
    "        open_price = np.round(initial_price + np.random.uniform(-1, 1), 2)\n",
    "        high_price = np.round(open_price + np.random.uniform(0, 5), 2)\n",
    "        low_price = np.round(open_price - np.random.uniform(0, 5), 2)\n",
    "        close_price = np.round(np.random.uniform(low_price, high_price), 2)\n",
    "        adj_close_price = close_price\n",
    "        volume = np.random.randint(1000, 10000000)\n",
    "\n",
    "        open_prices.append(open_price)\n",
    "        high_prices.append(high_price)\n",
    "        low_prices.append(low_price)\n",
    "        close_prices.append(close_price)\n",
    "        adj_close_prices.append(adj_close_price)\n",
    "        volumes.append(volume)\n",
    "\n",
    "        initial_price = close_price\n",
    "\n",
    "    # Create a DataFrame\n",
    "    data = {\n",
    "        'Symbol': symbol,\n",
    "        'Date': dates,\n",
    "        'Open': open_prices,\n",
    "        'High': high_prices,\n",
    "        'Low': low_prices,\n",
    "        'Close': close_prices,\n",
    "        'Adj Close': adj_close_prices,\n",
    "        'Volume': volumes\n",
    "    }\n",
    "\n",
    "    stock_data = pd.DataFrame(data)\n",
    "\n",
    "    # Save the dataframe\n",
    "    stock_data.to_csv(filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3c0f63",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Insure the output directory exists\n",
    "import os\n",
    "if not os.path.exists('output'):\n",
    "    os.makedirs('output')\n",
    "\n",
    "stock_file = os.path.join('output', 'FAKECO.csv')\n",
    "if not os.path.exists(stock_file):\n",
    "    make_synthetic_stock_data(stock_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87aa9665-7cab-4794-b496-fd84a8a7972b",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<h2> Create Agent </h2>\n",
    "\n",
    "We will now create the agent. To do so, we first need to create the agent policies that allow bedrock model invocation for a specific foundation model and the agent IAM role with the policy associated to it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ffd724-3d1b-4916-8513-466c5dd03fcc",
   "metadata": {
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Create IAM policies for agent\n",
    "bedrock_agent_bedrock_allow_policy_statement = {\n",
    "    \"Version\": \"2012-10-17\",\n",
    "    \"Statement\": [\n",
    "        {\n",
    "            \"Sid\": \"AmazonBedrockAgentBedrockFoundationModelPolicy\",\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Action\": \"bedrock:InvokeModel\",\n",
    "            \"Resource\": [\n",
    "                f\"arn:aws:bedrock:{region}::foundation-model/{agent_foundation_model}\"\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "bedrock_policy_json = json.dumps(bedrock_agent_bedrock_allow_policy_statement)\n",
    "\n",
    "agent_bedrock_policy = iam_client.create_policy(\n",
    "    PolicyName=agent_bedrock_allow_policy_name,\n",
    "    PolicyDocument=bedrock_policy_json\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f3cf61-e65b-4c61-8a66-76bd5946eb32",
   "metadata": {
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Create IAM Role for the agent and attach IAM policies\n",
    "assume_role_policy_document = assume_role_policy_document = {\n",
    "    \"Version\": \"2012-10-17\",\n",
    "    \"Statement\": [{\n",
    "          \"Effect\": \"Allow\",\n",
    "          \"Principal\": {\n",
    "            \"Service\": \"bedrock.amazonaws.com\"\n",
    "          },\n",
    "          \"Action\": \"sts:AssumeRole\"\n",
    "    }]\n",
    "}\n",
    "\n",
    "assume_role_policy_document_json = json.dumps(assume_role_policy_document)\n",
    "agent_role = iam_client.create_role(\n",
    "    RoleName=agent_role_name,\n",
    "    AssumeRolePolicyDocument=assume_role_policy_document_json\n",
    ")\n",
    "\n",
    "# Pause to make sure role is created\n",
    "time.sleep(10)\n",
    "    \n",
    "iam_client.attach_role_policy(\n",
    "    RoleName=agent_role_name,\n",
    "    PolicyArn=agent_bedrock_policy['Policy']['Arn']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6083fe88-05af-4455-9744-e9593fc784f3",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<h3> Creating the Bedrock agent </h3>\n",
    "\n",
    "Once the needed IAM role is created, we can use the Bedrock Agent client to create a new agent. To do so we use the `create_agent` function. It requires an agent name, underlying foundation model and instructions. You can also provide an agent description. Note that the agent created is not yet prepared. Later, we will prepare and use the agent.\n",
    "\n",
    "You cannot set the agent to use code interpreter at create time; because code interpreter is a special action group, that is done when creating the action group, below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6251ebaa-693d-4fee-b28c-2b0692d94ae5",
   "metadata": {
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "response = bedrock_agent_client.create_agent(\n",
    "    agentName=agent_name,\n",
    "    agentResourceRoleArn=agent_role['Role']['Arn'],\n",
    "    description=agent_description,\n",
    "    idleSessionTTLInSeconds=1800,\n",
    "    foundationModel=agent_foundation_model,\n",
    "    instruction=agent_instruction\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a44f69-64ae-45ce-8961-41cf4363f271",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Let's now store the agent id in a local variable to use it on subsequent steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0774ea09-6ccf-476d-b2bb-c8265b614f60",
   "metadata": {
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "agent_id = response['agent']['agentId']\n",
    "agent_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65efbf63-fbdb-4220-ab89-c7af740447ef",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<h3> Create Agent Action Group </h3>\n",
    "\n",
    "In Bedrock agents, action groups define tools for the agent to use. We will now create an agent action group to provide the agent with code interpreter, a runtime environment for evaluating code. Action groups can also define other tools, such as lambda functions, and can also define a channel for the model to solicit clarifying input from the user if needed (treating the user as a tool that the model can invoke). Our action group, however, just defines the code interpreter. This is done via a special access parameter, parentActionGroupSignature (see [boto3 documentation](https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/bedrock-agent/client/create_agent_action_group.html))\n",
    "\n",
    "To allow your agent to generate, run, and troubleshoot code when trying to complete a task, set `parentActionGroupSignature=AMAZON.CodeInterpreter`. You must leave the description, apiSchema, and actionGroupExecutor fields blank for this action group.\n",
    "\n",
    "Note that you can also define an action group with parentActionGroupSignature set to the special value `AMAZON.UserInput`. If this is set, then during orchestration, if your agent determines that it needs to invoke an API in an action group, but doesn’t have enough information to complete the API request, it will invoke this action group instead and return an Observation reprompting the user for more information. User input is appropriate if you know the interaction has a human in the loop. We do not do that here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d474b3e7-8501-48ed-82d1-f8a3792227a4",
   "metadata": {
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Pause to make sure agent is created\n",
    "time.sleep(30)\n",
    "# Now, we can configure and create an action group here:\n",
    "\n",
    "# Enable code interpretation for the agent\n",
    "agent_action_group_response = bedrock_agent_client.create_agent_action_group(\n",
    "    agentId=agent_id,       \n",
    "    agentVersion='DRAFT',\n",
    "    actionGroupName='code-interpreter',\n",
    "    parentActionGroupSignature='AMAZON.CodeInterpreter',\n",
    "    actionGroupState='ENABLED'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22feec4a-d3ec-48f6-9e33-e5a09f08701e",
   "metadata": {
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "agent_action_group_response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b3bab10-e5dc-4138-a9ff-76b2ff2ff9e6",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<h3> Preparing Agent </h3>\n",
    "\n",
    "Let's create a DRAFT version of the agent that can be used for internal testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7094e7f-915a-4396-8d98-c3bfee3ccf1e",
   "metadata": {
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "response = bedrock_agent_client.prepare_agent(\n",
    "    agentId=agent_id\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae1ff1a",
   "metadata": {
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Pause to make sure agent is prepared\n",
    "time.sleep(30)\n",
    "\n",
    "# Extract the agentAliasId from the response\n",
    "agent_alias_id = \"TSTALIASID\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "620847cb",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<h2> Invoking the agent </h2>\n",
    "\n",
    "We will now define a helper function to invoke the agent and parse its responses, then invoke it to see it use code invocation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd5cbde-5ca7-48f2-85b3-2ffe349229f9",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<h3> Define a helper function for agent invocation </h3>\n",
    "\n",
    "This helper function can invoke your agent and parse the stream of returned responses. \n",
    "\n",
    "*Note: This helper function differs from the one used in similar examples by also defining a show_code_use parameter, which will cause the helper to print a message if the agent invokes the code interpreter, and also has the event stream parsing separated into another helper function `process_response`. Later in the notebook we will replace `process_response` with a more elaborate version that can capture returned files and output more richly formatted data*\n",
    "\n",
    "The `invoke_agent_helper` function allows the user to send a `query` to the agent with a `session_id`. A session defines a turn of back and forward conversations that a user has with the agent. The agent can remember the full context inside of a session. Once the user ends a session, this context is removed.\n",
    "\n",
    "The user can then decide to enable trace or not using the `enable_trace` boolean variable and to pass a session state as a dictionary via the `session_state` variable.\n",
    "\n",
    "If a new `session_id` is provided, the agent will create a new conversation without previous context. If the same `session_id` is reused, the conversation context related to that session is known by the agent.\n",
    "\n",
    "If the `enable_trace` is set to `True`, each response from the agent is accompanied by a *trace* that details the step being orchestrated by the agent. It allows you to follow the agent's (reasoning via Chain of Thoughts prompting) that led to the final response at that point of the conversation.\n",
    "\n",
    "To handle the memory capabilities the `memory_id` parameter is used. Once a session is ended, it will summarize the content into a new session id as part of the `memory_id`.\n",
    "\n",
    "You can also pass a session context using the `session_state` parameter. The session state allows you to share the following information with the agent:\n",
    "- **`sessionAttributes`**: attributes that persist over a session between the user and the agent. All invokeAgent calls with the same session_id belong to the same sesison and will have the sessionAttributes shared with them as long as the session time limit has not being surpassed and the user has not ended the session. The sessionAttributes are available in the lambda function but are **not** added to the agent's prompt. As a result, you can only use session attributes if your lambda function can handle them. You can find more examples of using a session attribute [here](https://github.com/aws-samples/amazon-bedrock-samples/tree/main/agents-for-bedrock/features-examples/06-prompt-and-session-attributes). It is also a good pattern to implement fine-grained access control for certain APIs using the lambda function integration. You can find an example for it [here](https://github.com/aws-samples/amazon-bedrock-samples/tree/main/agents-for-bedrock/features-examples/09-fine-grained-access-permissions)\n",
    "- **`promptSessionAttributes`**: attributes that persist over a single invokeAgent call. Prompt attributes are added to the prompt and to the lambda function. You can also use the `$prompt_session_attributes$` placeholder when editing the orchestration base prompt.\n",
    "- **`invocationId`**: The id returned by the agent in the [ReturnControlPayload](https://docs.aws.amazon.com/bedrock/latest/APIReference/API_agent-runtime_ReturnControlPayload.html) object in the returnControl field of the InvokeAgent response. This field is required if passing the answer of a Return of Control invocation. You can find an example of how to use it [here](https://github.com/aws-samples/amazon-bedrock-samples/tree/main/agents-for-bedrock/features-examples/03-create-agent-with-return-of-control).\n",
    "- **`returnControlInvocationResults`**: the results obtained from invoking the action outside of agents for Amazon Bedrock.  This field is required if passing the answer of a Return of Control invocation. You can find an example of how to use it [here](https://github.com/aws-samples/amazon-bedrock-samples/tree/main/agents-for-bedrock/features-examples/03-create-agent-with-return-of-control).\n",
    "\n",
    "Finally, if `show_code_use` is passed as True, the helper will print a message when the code interpreter is invoked. It turns on tracing internally to do this.\n",
    "\n",
    "We will also use the test `agent_alias_id` set to `TSTALIASID`. This is a default value that you can use to test agents being developed. You can also [deploy your agent](https://docs.aws.amazon.com/bedrock/latest/userguide/agents-deploy.html) to create a new version of your agent and have a new agent alias id.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce1f5e94",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def invoke_agent_helper(\n",
    "    query, session_id, agent_id, alias_id, enable_trace=False, memory_id=None, session_state=None, end_session=False, show_code_use=False\n",
    "):\n",
    "    \n",
    "    if not session_state:\n",
    "        session_state = {}\n",
    "\n",
    "    # invoke the agent API\n",
    "    agent_response = bedrock_agent_runtime_client.invoke_agent(\n",
    "        inputText=query,\n",
    "        agentId=agent_id,\n",
    "        agentAliasId=alias_id,\n",
    "        sessionId=session_id,\n",
    "        enableTrace=(enable_trace | show_code_use), # Force tracing on if showing code use\n",
    "        endSession=end_session,\n",
    "        memoryId=memory_id,\n",
    "        sessionState=session_state\n",
    "    )\n",
    "    return process_response(agent_response, enable_trace=enable_trace, show_code_use=show_code_use)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc06a12",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def process_response(resp, enable_trace:bool=False, show_code_use:bool=False):\n",
    "    if enable_trace:\n",
    "        logger.info(pprint.pprint(resp))\n",
    "\n",
    "    event_stream = resp['completion']\n",
    "    try:\n",
    "        for event in event_stream:\n",
    "            if 'chunk' in event:\n",
    "                data = event['chunk']['bytes']\n",
    "                if enable_trace:\n",
    "                    logger.info(f\"Final answer ->\\n{data.decode('utf8')}\")\n",
    "                agent_answer = data.decode('utf8')\n",
    "                return agent_answer\n",
    "                # End event indicates that the request finished successfully\n",
    "            elif 'trace' in event:\n",
    "                if 'codeInterpreterInvocationInput' in json.dumps(event['trace']):\n",
    "                    if show_code_use:\n",
    "                        print(\"Invoked code interpreter\")\n",
    "                if enable_trace:\n",
    "                    logger.info(json.dumps(event['trace'], indent=2))\n",
    "            else:\n",
    "                raise Exception(\"unexpected event.\", event)\n",
    "    except Exception as e:\n",
    "        raise Exception(\"unexpected event.\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86f6763d-220d-49e2-b08e-9cf5a0494128",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<h2> Invoking code interpreter </h2>\n",
    "\n",
    "We ask the agent to generate a random string, which will require it to use the code interpreter. Using the `show_code_use` flag, we can see that the agent invokes code interpreter to evaluate the python code it generates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4525b20b-e977-43a7-84fe-5dee0202e0fa",
   "metadata": {
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## create a random id for session initiator id\n",
    "session_id:str = str(uuid.uuid1())\n",
    "memory_id:str = 'TST_MEM_ID'\n",
    "query = \"Please generate a 10 character long string of random characters\"\n",
    "invoke_agent_helper(query, session_id, agent_id, agent_alias_id, enable_trace=False, memory_id=memory_id, show_code_use=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c878200",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Similarly, the agent will write Python code and invoke code interpreter to solve math problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d787a666",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "query = \"What is 75 * sin(.75)?\"\n",
    "invoke_agent_helper(query, session_id, agent_id, agent_alias_id, enable_trace=False, memory_id=memory_id, \n",
    "                    show_code_use=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b266f2-18c8-4ebd-b6e0-8c06c2b593ed",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "By comparison, other operations where the model does not need to execute code do not invoke code interpreter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca7a33c3-44f5-45d7-a880-7f6d33783c68",
   "metadata": {
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "query = \"thank you!\"\n",
    "invoke_agent_helper(query, session_id, agent_id, agent_alias_id, enable_trace=False, memory_id=memory_id, show_code_use=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c4006f",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<h2> Sending files to the agent </h2>\n",
    "\n",
    "We can send files to the agent, either for use in normal chat, or for use with code interpreter. To send files, we attach them to the session state."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "877397f0",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<h3> Define helper functions </h3>\n",
    "\n",
    "We define helper functions to handle the various kinds of files, setting the media type properly, and to invoke the agent and process responses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbeee4e4",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The helper function below adds files to the session state. Files are passed via the session state. Each file is specified by a:\n",
    "* name\n",
    "* sourceType ('s3', or 'byte_content' for local files, \n",
    "* mediaType (currently supports: CSV, XLS, XLSX, YAML, JSON, DOC, DOCX, HTML, MD, TXT, and PDF)\n",
    "* data (from the file data)\n",
    "* useCase indicating how we intend the model use the file, which can be either `CHAT` or `CODE_INTERPRETER`.\n",
    "\n",
    "See the [session state documentation](https://docs.aws.amazon.com/bedrock/latest/userguide/agents-test-code-interpretation.html) for more detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae73da3",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Return a session state populated with the files from the supplied list of filenames\n",
    "def add_file_to_session_state(file_name, use_case='CODE_INTERPRETER', session_state=None):\n",
    "    if use_case != \"CHAT\" and use_case != \"CODE_INTERPRETER\":\n",
    "        raise ValueError(\"Use case must be either 'CHAT' or 'CODE_INTERPRETER'\")\n",
    "    if not session_state:\n",
    "        session_state = {\n",
    "            \"files\": []\n",
    "        }\n",
    "    type = file_name.split(\".\")[-1].upper()\n",
    "    name = file_name.split(\"/\")[-1]\n",
    "\n",
    "    if type == \"CSV\":\n",
    "        media_type = \"text/csv\" \n",
    "    elif type in [\"XLS\", \"XLSX\"]:\n",
    "        media_type = \"application/vnd.openxmlformats-officedocument.spreadsheetml.sheet\"\n",
    "    else:\n",
    "        media_type = \"text/plain\"\n",
    "\n",
    "    named_file = {\n",
    "        \"name\": name,\n",
    "        \"source\": {\n",
    "            \"sourceType\": \"BYTE_CONTENT\", \n",
    "            \"byteContent\": {\n",
    "                \"mediaType\": media_type,\n",
    "                \"data\": open(file_name, \"rb\").read()\n",
    "            }\n",
    "        },\n",
    "        \"useCase\": use_case\n",
    "    }\n",
    "    session_state['files'].append(named_file)\n",
    "\n",
    "    return session_state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "666c49cf",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<h3> Passing files for normal chat </h3>\n",
    "\n",
    "Here we pass in a local CSV file and ask the model to explain what the data is. Note that when adding the file to the session state, we specify use case 'CHAT' instead of 'CODE_INTERPRETER' and by setting show_code_use=True for our helper we see that the model does not use the code interpreter, it assesses the information using the LLM model's intelligence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "936efbf9",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "First, we examine the file ourselves. We see it is a list of historical prices for a stock."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dfb4314",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import base64 \n",
    "\n",
    "# base64 encode the csv file \n",
    "with open(stock_file, \"rb\") as file_name:\n",
    "    data = file_name.read()\n",
    "    encoded_file = data #base64.b64encode(data)\n",
    "\n",
    "    # Show the first 100 characters of the encoded file\n",
    "encoded_file[0:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47dbd0a0",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Next, we invoke the agent to examine the file and tell us about its data. The agent recognizes the data in the file (which contains synthetically generated stock price data for 'FAKECO'), telling us what kind of data it is and what date range it covers. Note that it does not need to invoke code interpretation to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e7f5ac0",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Invoke the agent and process the response stream\n",
    "query = \"What is the data in this file?\"\n",
    "\n",
    "sessionState=add_file_to_session_state(stock_file, 'CHAT')\n",
    "\n",
    "invoke_agent_helper(query, session_id, agent_id, agent_alias_id, enable_trace=False, session_state=sessionState, \n",
    "                    memory_id=memory_id, show_code_use=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11148c8d",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<h3> Passing files for use with code interpretation </h3>\n",
    "\n",
    "Now that we know the contents of the file are stock data, we can ask financial questions about it, which will require the model to invoke the code interpreter. Here we re-create the session data specifying the use case as 'CODE_INTERPRETER'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6764fb90",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Invoke the agent and process the response stream\n",
    "query = \"Given the attached price data file, what pct growth happened across the full time series for closing price? what was the price on the first and last days?\"\n",
    "\n",
    "sessionState=add_file_to_session_state(stock_file, 'CODE_INTERPRETER')\n",
    "\n",
    "invoke_agent_helper(query, session_id, agent_id, agent_alias_id, enable_trace=False, session_state=sessionState, \n",
    "                    memory_id=memory_id, show_code_use=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99205aed",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We see the model invoked the code interpreter, and analyzed the data in response to the questions asked."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "485af0b7",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<h2> Generating files with code interpreter </h2>\n",
    "\n",
    "Amazon Bedrock agents can also generate and return files to the user. They can generate files either by using the model's native intelligence to generate file types, such as .CSV files, or by the agent writing code using code interpreter to write code to generate binary files, such as data plots. Agents return files in the response stream."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab42583",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<h3> The Bedrock Agents response stream </h3>\n",
    "\n",
    "The response stream consists of events, formatted in JSON. It conveys rich data about the details of the agent's thought and actions as it works through the [ReAct pattern](https://aws.amazon.com/blogs/aws/preview-enable-foundation-models-to-complete-tasks-with-agents-for-amazon-bedrock/) (reasoning and action). Here are some important keys:\n",
    "* 'files' contain files generated by the agent's LLM model intrinsically\n",
    "* 'trace' events contain information about the agent's thought process and work steps. There are several kinds of trace events: \n",
    "    * 'modelInvocationInput' keys contain \n",
    "    * 'rationale' keys contain the agent's reasoning\n",
    "    * 'invocationInput' keys contain details of parameters to action group calls. \n",
    "        * 'codeInterpreterInvocationInput' keys within that contain code that the model generated and is passing to code interpretation.\n",
    "    * 'observation' keys contain important observations, including:\n",
    "        * 'codeInterpreterInvocationOutput' within that contains specific output from the code interpretation:\n",
    "            * 'executionOutput' contains the results of the code execution\n",
    "            * 'executionError' is populated with an error if an error is encountered while executing the code\n",
    "            * 'files' contain files generated by the code interpretation\n",
    "        * 'finalResponse' contains the agent's final response\n",
    "\n",
    "We will redefine our helper function to capture file results from the response stream. Then we will use it to save files generated by the agent, either through its own intelligence or by using code interpretation, and returned to the user."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7592e082",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<h3> Redefine the helper function </h3>\n",
    "\n",
    "We redefine the `process_response` helper function to be able to capture and display more of the rich detail from the response stream. Here we are importing IPython.display so that if run in a notebook with rich display output like Markdown, it can better display the agent interaction, such as embedding returned files for display. We must import additional libraries for notebook and image handling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c41e02d1",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9501898",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def process_response(resp, enable_trace:bool=True, show_code_use:bool=False):\n",
    "    if resp['ResponseMetadata']['HTTPStatusCode'] != 200:\n",
    "        print(f\"API Response was not 200: {resp}\")\n",
    "\n",
    "    event_stream = resp['completion']\n",
    "    for event in event_stream:\n",
    "        if 'files' in event.keys():\n",
    "            files_event = event['files']\n",
    "            display(Markdown(\"### Files\"))\n",
    "            files_list = files_event['files']\n",
    "            for this_file in files_list:\n",
    "                print(f\"{this_file['name']} ({this_file['type']})\")\n",
    "                file_bytes = this_file['bytes']\n",
    "\n",
    "                # save bytes to file, given the name of file and the bytes \n",
    "                file_name = os.path.join('output', this_file['name'])\n",
    "                with open(file_name, 'wb') as f:\n",
    "                    f.write(file_bytes)\n",
    "                if this_file['type'] == 'image/png' or this_file['type'] == 'image/jpeg':\n",
    "                    img = mpimg.imread(file_name)\n",
    "                    plt.imshow(img)\n",
    "                    plt.show()\n",
    "\n",
    "        if 'trace' in event.keys() and enable_trace:\n",
    "            trace_event = event.get('trace')['trace']['orchestrationTrace']\n",
    "\n",
    "            if 'modelInvocationInput' in trace_event.keys():\n",
    "                pass\n",
    "\n",
    "            if 'rationale' in trace_event.keys():\n",
    "                rationale = trace_event['rationale']['text']\n",
    "                display(Markdown(f\"### Rationale\\n{rationale}\"))\n",
    "\n",
    "            if 'invocationInput' in trace_event.keys() and show_code_use:\n",
    "                inv_input = trace_event['invocationInput']\n",
    "                if 'codeInterpreterInvocationInput' in inv_input:\n",
    "                    gen_code = inv_input['codeInterpreterInvocationInput']['code']\n",
    "                    code = f\"```python\\n{gen_code}\\n```\"\n",
    "                    display(Markdown(f\"### Generated code\\n{code}\"))\n",
    "\n",
    "            if 'observation' in trace_event.keys():\n",
    "                obs = trace_event['observation']\n",
    "                if 'codeInterpreterInvocationOutput' in obs:\n",
    "                    if 'executionOutput' in obs['codeInterpreterInvocationOutput'].keys() and show_code_use:\n",
    "                        raw_output = obs['codeInterpreterInvocationOutput']['executionOutput']\n",
    "                        output = f\"```\\n{raw_output}\\n```\"\n",
    "                        display(Markdown(f\"### Output from code execution\\n{output}\"))\n",
    "\n",
    "                    if 'executionError' in obs['codeInterpreterInvocationOutput'].keys():\n",
    "                        display(Markdown(f\"### Error from code execution\\n{obs['codeInterpreterInvocationOutput']['executionError']}\"))\n",
    "\n",
    "                    if 'files' in obs['codeInterpreterInvocationOutput'].keys():\n",
    "                        display(Markdown(\"### Files generated\\n\"))\n",
    "                        display(Markdown(f\"{obs['codeInterpreterInvocationOutput']['files']}\"))\n",
    "\n",
    "                if 'finalResponse' in obs:                    \n",
    "                    final_resp = obs['finalResponse']['text']\n",
    "                    display(Markdown(f\"### Final response\\n{final_resp}\"))\n",
    "                    return final_resp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2168611",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<h3> Generate a file using code generation </h3>\n",
    "\n",
    "We will ask the agent to generate a file, which it will return via the response stream."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca89d1c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "Please generate a list of the 10 greatest books of all time. Return it as a CSV file. Always return the file, even if you have provided it before.\n",
    "\"\"\"\n",
    "\n",
    "invoke_agent_helper(query, session_id, agent_id, agent_alias_id, enable_trace=False, session_state=sessionState,\n",
    "                    memory_id=memory_id, show_code_use=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae1469d",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<h3> Generate a chart using code interpretation </h3>\n",
    "\n",
    "We will send in the same stock price data file as before, but this time will ask for a chart. Our agent will need to write python code to create the chart. The markdown-enhanced response stream parser will render the chart into the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59643033",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Invoke the agent and process the response stream\n",
    "query = \"Given the attached price data file, please make me a chart with moving average in red and actual data in blue\"\n",
    "\n",
    "sessionState=add_file_to_session_state(stock_file, 'CODE_INTERPRETER')\n",
    "\n",
    "invoke_agent_helper(query, session_id, agent_id, agent_alias_id, enable_trace=True, session_state=sessionState,\n",
    "                    memory_id=memory_id, show_code_use=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d582bfb",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<h3> Generate synthetic data and analyze it </h3>\n",
    "\n",
    "For a final more complex example, we prompt the agent to create a synthetic data set, perform analysis, and render a visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bfb786d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Invoke the agent and process the response stream\n",
    "query = \"\"\"\n",
    "generate two csv files for me. \n",
    "one called SALES, with 3 columns: COMPANY_ID, COMPANY_NAME, and SALES_2024. \n",
    "the other called DETAILS, with 3 columns: COMPANY_ID, COMPANY_STATE_CODE. \n",
    "follow these rules:\n",
    "1) each file should contain 200 companies, and share the same company ID’s. \n",
    "2) use human readable english words in the names (not random strings of letters and digits), \n",
    "3) use ID’s of the form: C00001. \n",
    "4) Only use states that are generally considered to be near the east coast or near the west coast. \n",
    "5) Make the revenue from each eastern company range from 0 to $700,000, \n",
    "6) Make revenue from each western company range from $500,000 up to $2,000,000. \n",
    "When done, test to be sure you have followed each of the above rules, \n",
    "and produce a chart comparing sales per company in the two regions using box plots.\n",
    "\"\"\"\n",
    "\n",
    "invoke_agent_helper(query, session_id, agent_id, agent_alias_id, enable_trace=True, session_state=sessionState,\n",
    "                    memory_id=memory_id, show_code_use=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb098ccf-fbc2-4588-8556-dd0eb49b1146",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<h2> Clean up </h2>\n",
    "\n",
    "Optionally, you can clean up the resources created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c1a37d-f07a-4fbb-bb39-0a5b0ef8eca1",
   "metadata": {
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# This is not needed, you can delete agent successfully after deleting alias only\n",
    "# Additionaly, you need to disable it first\n",
    "action_group_id = agent_action_group_response['agentActionGroup']['actionGroupId']\n",
    "action_group_name = agent_action_group_response['agentActionGroup']['actionGroupName']\n",
    "\n",
    "response = bedrock_agent_client.update_agent_action_group(\n",
    "    agentId=agent_id,\n",
    "    agentVersion='DRAFT',\n",
    "    actionGroupId= action_group_id,\n",
    "    actionGroupName=action_group_name,\n",
    "    actionGroupState='DISABLED',\n",
    "    parentActionGroupSignature='AMAZON.CodeInterpreter'\n",
    ")\n",
    "\n",
    "action_group_deletion = bedrock_agent_client.delete_agent_action_group(\n",
    "    agentId=agent_id,\n",
    "    agentVersion='DRAFT',\n",
    "    actionGroupId= action_group_id\n",
    ")\n",
    "agent_deletion = bedrock_agent_client.delete_agent(\n",
    "    agentId=agent_id\n",
    ")\n",
    "\n",
    "# Delete IAM Roles and policies\n",
    "\n",
    "for policy in [agent_bedrock_allow_policy_name]:\n",
    "    iam_client.detach_role_policy(RoleName=agent_role_name, PolicyArn=f'arn:aws:iam::{account_id}:policy/{policy}')\n",
    "\n",
    "for policy in [agent_bedrock_policy]:\n",
    "    iam_client.delete_policy(\n",
    "        PolicyArn=policy['Policy']['Arn']\n",
    ")\n",
    "    \n",
    "iam_client.delete_role(\n",
    "    RoleName=agent_role_name\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25e995a3-7842-4bcc-93e9-759b6b3b6722",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<h2> Conclusion </h2>\n",
    "\n",
    "We have now experimented with using boto3 SDK to create and invoke an agent with code interpretation enabled. We also learned how send files to the agent and to retrieve files returned by the agent in its response stream. We used Markdown rendering to better display the elements that the agent transmits in its response stream, including its rationale, code that it writes to pursue the goal, and the results from code invocation.\n",
    "<br>\n",
    "\n",
    "<h2> Next Steps </h2>\n",
    "\n",
    "As a next step, you should experiment further with the the agent's to explore how it can to pursue more complex requests using code evaluation.\n",
    "<br>\n",
    "\n",
    "<h2> Thank You </h2>"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}