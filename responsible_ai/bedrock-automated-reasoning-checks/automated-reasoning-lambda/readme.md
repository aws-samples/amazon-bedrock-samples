# Amazon Bedrock Automated Reasoning Checks with Lambda

This sample demonstrates how to implement Amazon Bedrock Automated Reasoning checks capabilities within AWS Lambda functions. Automated Reasoning allows you to validate content against logical rules and policies, ensuring compliance with business requirements and preventing factual inaccuracies in AI-generated content.

## Features

- Load custom Bedrock service models in a Lambda function
- Create and manage guardrails with Automated Reasoning policies
- Apply guardrails to validate content against logical rules
- Process and interpret the validation results across four different result types
- Generate corrected responses using multiple foundation models
- Support for multiple model invocation methods (converse API with fallback to invoke_model)

## Prerequisites

- AWS Account with access to Amazon Bedrock service
- Access to Automated Reasoning capabilities in AWS Bedrock (private preview feature)
- Lambda execution role with appropriate permissions for Bedrock services
- Foundation model access for corrected response generation
- Basic understanding of Python and AWS Lambda functions

## Setup Instructions

1. **Create a Lambda Function**
   - Create a new Lambda function using Python 3.9 or later
   - Set appropriate memory (recommended: at least 256MB) and timeout (recommended: at least 30 seconds)

2. **Package the Lambda Function**
   - Create a directory structure with the following:
     ```
     lambda_package/
     ├── lambda_function.py
     └── models/
         ├── bedrock-2023-04-20.api.json
         └── bedrock-runtime-2023-09-30.api.json
     ```
   - Copy the provided code into `lambda_function.py`
   - Ensure you have the required model JSON files in the models directory
   - Upload the model files to Lambda

3. **Configure Environment Variables**
   - Set `DEFAULT_GUARDRAIL_NAME` to your preferred guardrail name
   - Set `AR_POLICY` to your Automated Reasoning policy ID

4. **Update IAM Permissions**
   - Ensure your Lambda execution role has permissions for:
     - `bedrock:CreateGuardrail`
     - `bedrock:ListGuardrails`
     - `bedrock:ApplyGuardrail`
     - `bedrock:InvokeModel`
     - `bedrock-runtime:InvokeModel`
     - `bedrock-runtime:Converse`

## Using the Sample

The Lambda function accepts a JSON event with the following structure:

```json
{
  "query": "I am a part-time employee, am I eligible for LoAP?",
  "response": "Yes, part time employees are allowed to use LoAP",
  "include_corrected_response": true,
  "model_type": "claude_3_5_haiku"
}
```

Parameters:
- `query`: The original question asked by the user
- `response`: The response to validate against Automated Reasoning policies
- `include_corrected_response`: (Optional, default: true) Whether to generate a corrected response when violations are found
- `model_type`: (Optional, default: "claude_3_5_haiku") The foundation model to use for generating corrected responses

Available model options:
- `nova_lite`: Amazon Bedrock Nova Lite
- `nova_micro`: Amazon Bedrock Nova Micro  
- `nova_pro`: Amazon Bedrock Nova Pro
- `claude_3_5_sonnet`: Anthropic Claude 3.5 Sonnet
- `claude_3_5_haiku`: Anthropic Claude 3.5 Haiku (default)

## Understanding the Output

The function returns a JSON response with:

```json
{
  "input": [
    {"text": {"text": "I am a part-time employee, am I eligible for LoAP?", "qualifiers": ["query"]}},
    {"text": {"text": "Yes, part time employees are allowed to use LoAP", "qualifiers": ["guard_content"]}}
  ],
  "automatedReasoning": {
    "findings": [
      {
        "result": "INVALID",
        "rules": [...],
        "suggestions": [...]
      }
    ]
  },
  "has_findings": true,
  "model_used": "anthropic.claude-3-5-haiku-20241022-v1:0",
  "corrected_response": "corrected or enhanced response text"
}
```

Key components:
- `input`: The content submitted for validation
- `automatedReasoning`: Detailed findings from policy evaluation
  - `result`: Can be "VALID", "INVALID", "SATISFIABLE", or "NOT_UNDERSTOOD"
  - `rules`: Rules that were validated or violated
  - `suggestions`: Suggested corrections or assumptions
- `has_findings`: Boolean flag indicating whether there are relevant findings
- `model_used`: The model ID used for generating the corrected response
- `corrected_response`: An improved response generated by the selected model (if requested and findings exist)

## Result Types

The Automated Reasoning system can produce four different result types:

1. **VALID**: For responses that align with policy rules
2. **INVALID**: For responses containing policy inaccuracies 
3. **SATISFIABLE**: The response is correct under certain assumptions that need clarification
4. **NOT_UNDERSTOOD**: For queries too complex for deterministic evaluation

## How It Works

1. The Lambda function loads custom Amazon Bedrock service models to access private preview features
2. It creates or retrieves an Automated Reasoning guardrail
3. The guardrail validates the response against logical policy rules
4. If findings exist, the function can generate a corrected response using the specified foundation model
5. It attempts to use the converse API first, with fallback to invoke_model if needed
6. The function returns detailed validation results and the corrected response

## Notes

- Automated Reasoning is currently a private preview feature in AWS Bedrock
- This sample requires custom service model files that may need to be updated as the service evolves
- The function has several configuration variables (DEFAULT_GUARDRAIL_NAME, AR_POLICY, REGION) that can be set as Lambda environment variables rather than hardcoded
- The function is configured for the US West (Oregon) region by default
- The corrected response generation is optional and can be disabled by setting `include_corrected_response` to false
- Different models may have varying capabilities for generating corrected responses
- The function includes comprehensive error handling for model invocation with multiple fallback mechanisms