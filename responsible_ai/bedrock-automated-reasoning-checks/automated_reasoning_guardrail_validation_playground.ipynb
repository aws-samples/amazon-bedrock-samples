{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automated Reasoning Guardrail Validation Playground\n",
    "\n",
    "This notebook demonstrates how to create a guardrail with an automated reasoning policy attachedd and validates the LLM response.\n",
    "It includes the following:\n",
    "\n",
    "1. Setting up the Bedrock client with custom API models\n",
    "2. Creating a guardrail with an automated reasoning policy attached\n",
    "3. Call ApplyGuardrails API to validate LLM response\n",
    "4. Print the formatted automated reasoning response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "First, let's import the necessary libraries and set up the Bedrock client with custom API models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import boto3\n",
    "import uuid\n",
    "import time\n",
    "import pandas as pd\n",
    "from IPython.display import display, HTML, JSON\n",
    "import ipywidgets as widgets\n",
    "from datetime import datetime\n",
    "from findings_utils import extract_reasoning_findings\n",
    "from policy_definition import get_policy_definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Bedrock client\n",
    "REGION_NAME=\"us-west-2\" # Fill in the AWS Region\n",
    "my_session = boto3.session.Session()\n",
    "runtime_client = my_session.client('bedrock-runtime', region_name=REGION_NAME)\n",
    "bedrock_client = my_session.client('bedrock', region_name=REGION_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Guardrail\n",
    "In this section we will create a Bedrock Guardrail with automated reasoning\n",
    "This allows us to validate LLM responses against predefined rules and constraints\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Policy arn for which will be attached to the guardrail\n",
    "AR_POLICY_ARN=\"<AR_POLICY_ARN>\"\n",
    "\n",
    "# Unique identifier for the automated reasoning policy\n",
    "AR_POLICY_ID=\"<AR_POLICY_ID>\"\n",
    "\n",
    "# Version of the automated reasoning policy to use\n",
    "AR_POLICY_VERSION = \"DRAFT\"\n",
    "\n",
    "# Id of the model used by bedrock when generating LLM responses\n",
    "MODEL_ID=\"<MODEL_ID>\"\n",
    "\n",
    "# Guardrail profile ID used when creating guardrail.\n",
    "# Guardrails with automated reasoning must have cross region guardrail profile.\n",
    "GUARDRAIL_PROFILE_ID = 'us.guardrail.v1:0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_guardrail(name, automated_reasoning_policy_config, cross_region_config, blocked_input_messaging, blocked_output_messaging):\n",
    "    \"\"\"\n",
    "    Creates a new guardrail configuration in Amazon Bedrock.\n",
    "    \n",
    "    Args:\n",
    "        name (str): The name of the guardrail\n",
    "        automated_reasoning_policy_config (dict): Configuration for automated reasoning policies\n",
    "        blocked_input_messaging (dict): Configuration for blocked input message patterns\n",
    "        blocked_output_messaging (dict): Configuration for blocked output message patterns\n",
    "        \n",
    "    Returns:\n",
    "        dict: Response from the create_guardrail API call\n",
    "        \n",
    "    Raises:\n",
    "        Exception: If there is an error creating the guardrail\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return bedrock_client.create_guardrail(\n",
    "            name=name,\n",
    "            automatedReasoningPolicyConfig=automated_reasoning_policy_config,\n",
    "            crossRegionConfig=cross_region_config,\n",
    "            blockedInputMessaging=blocked_input_messaging,\n",
    "            blockedOutputsMessaging=blocked_output_messaging,\n",
    "            clientRequestToken=str(uuid.uuid4())\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"Error creating guardrail: {str(e)}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new guardrail with specified configuration\n",
    "# - Sets the name, policy details and blocked message text\n",
    "# - Uses automated reasoning policy with confidence threshold of 1.0\n",
    "create_guardrail_response = create_guardrail(\n",
    "    name=\"test_guardrail\",\n",
    "    automated_reasoning_policy_config={\n",
    "        \"policies\": [f\"{AR_POLICY_ARN}\"],\n",
    "        \"confidenceThreshold\": 1.0\n",
    "    },\n",
    "    cross_region_config={ 'guardrailProfileIdentifier': GUARDRAIL_PROFILE_ID },\n",
    "    blocked_input_messaging=\"Input is blocked\", \n",
    "    blocked_output_messaging=\"Output is blocked\")\n",
    "\n",
    "# Extract the guardrail ID and version from the response\n",
    "guardrail_id = create_guardrail_response[\"guardrailId\"]\n",
    "guardrail_version = create_guardrail_response[\"version\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Call ApplyGuardrail API\n",
    "\n",
    "Now, we call the guardrail that we created above to validate the LLM response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_guardrail(guardrail_id, guardrail_version, content, source):\n",
    "    \"\"\"\n",
    "    Calls ApplyGuardrail API to perform content validation.\n",
    "    \n",
    "    Args:\n",
    "        guardrail_id (str): The ID of the guardrail\n",
    "        guardrail_version (str): The version of the guardrail to use for validation\n",
    "        content (str): The content to apply the guardrail to\n",
    "        source (str): The source of the content, must be either 'INPUT' or 'OUTPUT'\n",
    "\n",
    "    Returns:\n",
    "        dict: Response from the apply_guardrail API call\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return runtime_client.apply_guardrail(\n",
    "            guardrailIdentifier=guardrail_id,\n",
    "            guardrailVersion=guardrail_version,\n",
    "            source=source,\n",
    "            content=content\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"Error applying guardrail: {str(e)}\")\n",
    "        raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The user's original query/prompt that was sent to the LLM\n",
    "user_query = \"<USER QUERY>\"\n",
    "\n",
    "# The response generated by the LLM that needs to be validated\n",
    "llm_response = \"<LLM RESPONSE>\"\n",
    "\n",
    "# Create a list of dictionaries containing the text content to validate\n",
    "# Each dictionary has a nested text object with the actual text and qualifiers\n",
    "content_to_validate = [\n",
    "    {\"text\": {\"text\": user_query, \"qualifiers\": [\"query\"]}},\n",
    "    {\"text\": {\"text\": llm_response, \"qualifiers\": [\"guard_content\"]}}\n",
    "]\n",
    "\n",
    "# Call ApplyGuardrail API to perform the content validation\n",
    "apply_guardrail_response = apply_guardrail(\n",
    "    guardrail_id=guardrail_id,\n",
    "    guardrail_version=guardrail_version, \n",
    "    source=\"OUTPUT\",\n",
    "    content=content_to_validate)\n",
    "\n",
    "# Convert the guardrail response to JSON format\n",
    "print(json.dumps(apply_guardrail_response, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the policy definition\n",
    "policy_definition = get_policy_definition(bedrock_policy_client, AR_POLICY_ARN)\n",
    "\n",
    "# Generate a user readable output from the automated reasoning findings\n",
    "formatted_findings = extract_reasoning_findings(\n",
    "    apply_guardrail_response, \n",
    "    policy_definition\n",
    ")\n",
    "print(formatted_findings)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
