{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bfb6374e",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Batch Inference to write email for product recomendation\n",
    "\n",
    "> *This notebook should work well with the **`Data Science 3.0`** kernel in SageMaker Studio*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e85a8d0-06dc-4109-9898-05f288ef239a",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "This Jupyter notebook demonstrates how to use Amazon Bedrock for batch inference to generate personalized product recommendation emails at scale. It showcases a multi-threaded invocation job pattern, allowing for efficient processing of large datasets.\n",
    "\n",
    "\n",
    "\n",
    "#### Context\n",
    "\n",
    "In the world of e-commerce and digital marketing, personalized product recommendations are crucial for engaging customers and driving sales. However, creating individualized marketing emails for thousands of customers can be time-consuming and resource-intensive. This notebook presents a solution using Amazon Bedrock's batch inference capabilities to automate and scale this process.\n",
    "\n",
    "\n",
    "#### Use Case\n",
    "\n",
    "An e-commerce company wants to send personalized product recommendation emails to its large customer base. The marketing team needs to:\n",
    "- Generate customized email content for each customer based on their name and a recommended product.\n",
    "- Process thousands of customer records efficiently.\n",
    "- Create engaging, human-like email copy that feels personalized to each recipient.\n",
    "- Scale the email generation process to handle growing customer lists without increasing manual effort.\n",
    "\n",
    "This solution addresses these needs by leveraging Amazon Bedrock's language models to generate personalized email content in a batch process, allowing the marketing team to create thousands of customized emails quickly and efficiently.\n",
    "\n",
    "\n",
    "#### Pattern\n",
    "\n",
    "The pattern used in this notebook is a Batch Inference with Multi-threaded Invocation Job. This approach allows for:\n",
    "- Generation of synthetic customer and product data\n",
    "- Preparation of input data for the language model\n",
    "- Batch processing of multiple inputs in parallel\n",
    "- Efficient use of compute resources\n",
    "- Scalable generation of personalized marketing emails\n",
    "\n",
    "\n",
    "\n",
    "#### Persona\n",
    "\n",
    "This solution is designed for:\n",
    "- Marketing teams in e-commerce companies\n",
    "- Data scientists and ML engineers working on customer personalization\n",
    "- Product managers looking to implement scalable recommendation systems\n",
    "\n",
    "\n",
    "#### Implementation\n",
    "The implementation consists of the following key components:\n",
    "- Data Generation: Creation of synthetic customer names and product recommendations\n",
    "- Input Preparation: Formatting the data for the language model\n",
    "- S3 Integration: Uploading input data to Amazon S3\n",
    "- Batch Job Configuration: Setting up the Amazon Bedrock batch inference job\n",
    "- Job Execution and Monitoring: Running the batch job and checking its status"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a60fa0a5-4971-48d8-a30f-adeb8266f885",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e12f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import string\n",
    "import json\n",
    "import boto3\n",
    "import sagemaker\n",
    "import os\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "bucket = sess.default_bucket()\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "bedrock = boto3.client(service_name=\"bedrock\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1482fb5c-3dd4-489a-809f-f70ecc317247",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Prepare synthetic dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d323253",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define lists for generating synthetic product data\n",
    "\n",
    "adjectives = [\"Cutting-edge\", \"Innovative\", \"Premium\", \"Advanced\", \"Powerful\", \"Sleek\", \"Stylish\"]\n",
    "nouns = [\"Smartwatch\", \"Headphones\", \"Laptop\", \"Tablet\", \"Smartphone\", \"Speaker\", \"Camera\"]\n",
    "descriptions = [\n",
    "    \"Designed to help you stay motivated and achieve your fitness goals.\",\n",
    "    \"Featuring advanced noise-canceling technology and long-lasting battery life.\",\n",
    "    \"With its lightweight and portable design, perfect for on-the-go productivity.\",\n",
    "    \"Offering an immersive entertainment experience with stunning visuals and powerful sound.\",\n",
    "    \"Capture every moment with stunning clarity and detail.\",\n",
    "    \"Seamlessly blending fashion and functionality.\",\n",
    "    \"Unleash your creativity with powerful performance and cutting-edge features.\"\n",
    "]\n",
    "\n",
    "# Function to generate synthetic customer names and product recommendations\n",
    "def generate_data(num_names):\n",
    "    names = []\n",
    "    product_recs = []\n",
    "\n",
    "    for _ in range(num_names):\n",
    "        first_name = ''.join(random.choices(string.ascii_uppercase, k=1)) + ''.join(random.choices(string.ascii_lowercase, k=random.randint(5, 10)))\n",
    "        last_name = ''.join(random.choices(string.ascii_uppercase, k=1)) + ''.join(random.choices(string.ascii_lowercase, k=random.randint(5, 10)))\n",
    "        name = f\"{first_name} {last_name}\"\n",
    "        names.append(name)\n",
    "\n",
    "        adj = random.choice(adjectives)\n",
    "        noun = random.choice(nouns)\n",
    "        desc = random.choice(descriptions)\n",
    "        product_name = f\"{adj} {noun}\"\n",
    "        product_description = f\"{product_name} {desc}\"\n",
    "\n",
    "        product_rec = {\n",
    "            \"product_name\": product_name,\n",
    "            \"product_description\": product_description\n",
    "        }\n",
    "        product_recs.append(product_rec)\n",
    "\n",
    "    return names, product_recs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c01493bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate data\n",
    "num_names = 12000\n",
    "names, product_recs = generate_data(num_names)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d553041d-93a4-4ad6-a538-73bc48079dd2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to generate model input data for batch inference\n",
    "def generate_model_input(names, product_recs):\n",
    "    model_inputs = []\n",
    "\n",
    "    for i, name in enumerate(names):\n",
    "        record_id = ''.join(random.choices(string.ascii_letters + string.digits, k=12))\n",
    "        product_rec = product_recs[i % len(product_recs)]\n",
    "\n",
    "        input_text = f\"Write a marketing email for the customer based on the provided product and description: Customer Name: {name} | Recommended Product(s): {product_rec['product_name']} | Product Description: {product_rec['product_description']}\"        \n",
    "\n",
    "        body = {\n",
    "            \"anthropic_version\": \"bedrock-2023-05-31\",\n",
    "            \"messages\": [{\"role\": 'user',\n",
    "                     \"content\": [\n",
    "                         {'type': 'text',\n",
    "                          'text': input_text}]\n",
    "                     }],\n",
    "            \"max_tokens\": 300,\n",
    "            \"temperature\": 0.9,\n",
    "            \"top_p\": 0.9,\n",
    "            \"top_k\": 100,\n",
    "        } \n",
    "\n",
    "        model_input = {\n",
    "            \"recordId\": record_id,\n",
    "            \"modelInput\": body\n",
    "        }\n",
    "        \n",
    "        model_inputs.append(model_input)\n",
    "\n",
    "    return model_inputs\n",
    "\n",
    "# Function to write data to a JSONL file\n",
    "def write_jsonl(data, file_path):\n",
    "    with open(file_path, 'w') as file:\n",
    "        for item in data:\n",
    "            json_str = json.dumps(item)\n",
    "            file.write(json_str + '\\n')\n",
    "\n",
    "# Function to upload files or directories to an S3 bucket\n",
    "def upload_to_s3(path, bucket_name, bucket_subfolder=None):\n",
    "    \"\"\"\n",
    "    Upload a file or directory to an AWS S3 bucket.\n",
    "\n",
    "    :param path: Path to the file or directory to be uploaded\n",
    "    :param bucket_name: Name of the S3 bucket\n",
    "    :param bucket_subfolder: Name of the subfolder within the S3 bucket (optional)\n",
    "    :return: True if the file(s) were uploaded successfully, False otherwise\n",
    "    \"\"\"\n",
    "    s3 = boto3.client('s3')\n",
    "\n",
    "    if os.path.isfile(path):\n",
    "        # If the path is a file, upload it directly\n",
    "        object_name = os.path.basename(path) if bucket_subfolder is None else f\"{bucket_subfolder}/{os.path.basename(path)}\"\n",
    "        try:\n",
    "            s3.upload_file(path, bucket_name, object_name)\n",
    "            print(f\"Successfully uploaded {path} to {bucket_name}/{object_name}\")\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"Error uploading {path} to S3: {e}\")\n",
    "            return False\n",
    "    elif os.path.isdir(path):\n",
    "        # If the path is a directory, recursively upload all files within it\n",
    "        for root, dirs, files in os.walk(path):\n",
    "            for file in files:\n",
    "                file_path = os.path.join(root, file)\n",
    "                relative_path = os.path.relpath(file_path, path)\n",
    "                object_name = relative_path if bucket_subfolder is None else f\"{bucket_subfolder}/{relative_path}\"\n",
    "                try:\n",
    "                    s3.upload_file(file_path, bucket_name, object_name)\n",
    "                    print(f\"Successfully uploaded {file_path} to {bucket_name}/{object_name}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Error uploading {file_path} to S3: {e}\")\n",
    "        return True\n",
    "    else:\n",
    "        print(f\"{path} is not a file or directory.\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab8082af-db37-4531-a193-19f106bd29bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Generate model inputs\n",
    "model_inputs = generate_model_input(names, product_recs)\n",
    "\n",
    "# Write model inputs to a jsonl file\n",
    "write_jsonl(model_inputs, 'model_inputs.jsonl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611e9897",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload the generated JSONL file to an S3 bucket\n",
    "upload_to_s3(\"model_inputs.jsonl\", \n",
    "             bucket, \n",
    "             bucket_subfolder='batch-inf-test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd10452b",
   "metadata": {},
   "source": [
    "# Setup Batch Inference Job:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a50314",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure input and output data configurations for the batch job\n",
    "inputDataConfig=({\n",
    "    \"s3InputDataConfig\": {\n",
    "        \"s3Uri\": f\"s3://{bucket}/batch-inf-test/model_inputs.jsonl\"\n",
    "    }\n",
    "})\n",
    "\n",
    "outputDataConfig=({\n",
    "    \"s3OutputDataConfig\": {\n",
    "        \"s3Uri\": f\"s3://{bucket}/batch-inf-test/out/\"\n",
    "    }\n",
    "})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab33e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a model invocation job for batch inference\n",
    "response=bedrock.create_model_invocation_job(\n",
    "    roleArn=role,\n",
    "    modelId=\"anthropic.claude-3-haiku-20240307-v1:0\",\n",
    "    jobName=\"batch-job-v11\",\n",
    "    inputDataConfig=inputDataConfig,\n",
    "    outputDataConfig=outputDataConfig\n",
    ")\n",
    "\n",
    "jobArn = response.get('jobArn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f859e046",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the status of the batch inference job\n",
    "bedrock.get_model_invocation_job(jobIdentifier=jobArn)['status']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "337f8650",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "The multi-threaded invocation job pattern demonstrated in this example allows for efficient processing of large datasets, making it an excellent solution for generating personalized marketing content at scale. By leveraging Amazon Bedrock's batch inference capabilities, marketing teams can automate the creation of customized product recommendation emails, saving time and resources while potentially improving customer engagement and sales.\n",
    "\n",
    "\n",
    "### Take aways\n",
    "- Adapt this notebook to experiment with different models available through Amazon Bedrock \n",
    "- Apply different prompt engineering principles to get better outputs. Refer to the prompt guide for your chosen model for recommendations, e.g. [here is the prompt guide for Claude](https://docs.anthropic.com/claude/docs/introduction-to-prompt-design)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c5231c6-fe1e-4d38-9289-ee85ce80d20a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
