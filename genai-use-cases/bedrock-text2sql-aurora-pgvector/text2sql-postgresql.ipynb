{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Text-to-SQL with PostgreSQL Vector Search\n",
    "\n",
    "This notebook demonstrates the integration of **traditional relational database operations** with **vector search capabilities** in PostgreSQL, featuring automated query strategy selection based on user intent analysis.\n",
    "\n",
    "### ðŸŽ¯ **Core Technical Demonstrations:**\n",
    "\n",
    "#### 1. **Complex Schema Text-to-SQL Generation**\n",
    "- LLM-powered natural language to SQL conversion across multi-table schemas\n",
    "- Handling hierarchical data structures, complex joins, and nested aggregations\n",
    "- **Demonstrating schema comprehension for enterprise-scale database architectures**\n",
    "\n",
    "#### 2. **PostgreSQL pgvector Integration** \n",
    "- Native vector storage and similarity search within PostgreSQL\n",
    "- Embedding-based semantic search on unstructured text data\n",
    "- Demonstrating RDBMS + vector database convergence\n",
    "\n",
    "#### 3. **Automated Query Strategy Selection**\n",
    "- Foundation model analysis of query intent and optimal execution path determination\n",
    "- Context-aware routing between structured SQL and semantic vector operations\n",
    "- Unified interface abstracting query complexity from end users\n",
    "\n",
    "### ðŸ—ï¸ **Database Schema Architecture**\n",
    "\n",
    "ecommerce schema demonstrating complex relationships:\n",
    "\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚     users       â”‚    â”‚    categories    â”‚    â”‚    products     â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚ user_id (PK)    â”‚    â”‚ category_id (PK) â”‚    â”‚ product_id (PK) â”‚\n",
    "â”‚ email           â”‚    â”‚ name             â”‚    â”‚ sku             â”‚\n",
    "â”‚ username        â”‚    â”‚ slug             â”‚    â”‚ name            â”‚\n",
    "â”‚ first_name      â”‚    â”‚ description      â”‚    â”‚ description     â”‚\n",
    "â”‚ last_name       â”‚    â”‚ parent_category_idâ”‚   â”‚ category_id (FK)â”‚\n",
    "â”‚ city            â”‚    â”‚   (FK to self)   â”‚    â”‚ brand           â”‚\n",
    "â”‚ state_province  â”‚    â”‚ product_count    â”‚    â”‚ price           â”‚\n",
    "â”‚ total_orders    â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚ stock_quantity  â”‚\n",
    "â”‚ total_spent     â”‚           â”‚                â”‚ rating_average  â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚                â”‚ total_sales     â”‚\n",
    "         â”‚                    â”‚                â”‚ revenue_generatedâ”‚\n",
    "         â”‚                    â”‚                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "         â”‚                    â”‚                         â”‚\n",
    "         â”‚                    â”‚                         â”‚\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚     orders      â”‚    â”‚   order_items    â”‚    â”‚    reviews      â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚ order_id (PK)   â”‚â”€â”€â”€â”€â”‚ order_id (FK)    â”‚    â”‚ review_id (PK)  â”‚\n",
    "â”‚ order_number    â”‚    â”‚ product_id (FK)  â”‚â”€â”€â”€â”€â”‚ product_id (FK) â”‚\n",
    "â”‚ user_id (FK)    â”‚    â”‚ quantity         â”‚    â”‚ user_id (FK)    â”‚\n",
    "â”‚ order_status    â”‚    â”‚ unit_price       â”‚    â”‚ order_id (FK)   â”‚\n",
    "â”‚ payment_status  â”‚    â”‚ total_price      â”‚    â”‚ rating          â”‚\n",
    "â”‚ total_amount    â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚ title           â”‚\n",
    "â”‚ shipping_method â”‚                            â”‚ comment         â”‚\n",
    "â”‚ created_at      â”‚                            â”‚ comment_embeddingâ”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                            â”‚   (VECTOR)      â”‚\n",
    "                                               â”‚ pros            â”‚\n",
    "                                               â”‚ cons            â”‚\n",
    "                                               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```\n",
    "\n",
    "**Schema Complexity Features:**\n",
    "- **Self-referencing hierarchies**: Categories with parent/child relationships\n",
    "- **Junction table patterns**: Many-to-many order-product relationships via order_items\n",
    "- **Vector integration**: Native pgvector storage in reviews.comment_embedding\n",
    "- **Multi-level foreign keys**: Reviews referencing users, products, and orders\n",
    "\n",
    "### ðŸ’¡ **Technical Implementation:**\n",
    "\n",
    "1. **Hybrid Database Architecture**: PostgreSQL with pgvector extension for unified structured + vector operations\n",
    "2. **LLM Schema Comprehension**: Foundation model understanding of complex table relationships and optimal query generation\n",
    "3. **Embedding-based Similarity**: Amazon Titan text embeddings for semantic content matching\n",
    "4. **Automated Tool Selection**: Context analysis determining SQL vs vector search execution paths\n",
    "\n",
    "## Technical Prerequisites\n",
    "- AWS account with Bedrock and RDS permissions\n",
    "- Understanding of vector embeddings and similarity search concepts\n",
    "- Familiarity with PostgreSQL and complex SQL operations\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“¦ STEP 1: Install Required Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0afb548c-60e7-4929-9ae2-26113df7e5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required Python packages for AWS and SQL parsing\n",
    "!pip install --upgrade pip\n",
    "!pip install boto3 sqlparse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ—ï¸ STEP 2: Deploy AWS Infrastructure\n",
    "\n",
    "This step creates:\n",
    "- **VPC with 3 subnets** across availability zones\n",
    "- **Aurora PostgreSQL Serverless v2 cluster** with HTTP endpoint enabled\n",
    "- **Security groups** and networking configuration\n",
    "- **Secrets Manager** for database credentials\n",
    "\n",
    "**Note**: This takes ~5-10 minutes to complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4efd1122-9bee-4cde-a536-0d149b796f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deploy AWS infrastructure (VPC, Aurora PostgreSQL, Security Groups)\n",
    "# This script creates all necessary AWS resources for our demo\n",
    "\n",
    "!python infra.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ”§ STEP 3: Setup Database Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a29e0a2-12ff-42f7-b1aa-8ffecf097633",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries for AWS services and database operations\n",
    "import json\n",
    "import boto3\n",
    "import logging\n",
    "import sqlparse\n",
    "from typing import Dict, Any, List, Union\n",
    "from botocore.exceptions import ClientError\n",
    "from botocore.config import Config\n",
    "\n",
    "# Get current AWS region dynamically\n",
    "session = boto3.Session()\n",
    "AWS_REGION = session.region_name or 'us-west-2'  # fallback to us-west-2 if not set\n",
    "print(f\"Using AWS region: {AWS_REGION}\")\n",
    "\n",
    "# Setup logging to track our progress\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb84fc4-0b36-493d-a269-60959ece77a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Database connection configuration\n",
    "# **Update these values after running infra.py with the output provided**\n",
    "CLUSTER_ARN = ''\n",
    "SECRET_ARN = ''\n",
    "DATABASE_NAME = ''\n",
    "AWS_REGION = ''\n",
    "\n",
    "# Initialize RDS Data API client (allows SQL execution without direct connections, to learn more visit https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/data-api.html)\n",
    "rds_client = boto3.client('rds-data', region_name=AWS_REGION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ› ï¸ STEP 4: Create Database Schema & Load Data\n",
    "\n",
    "We'll create a streamlined but complex ecommerce schema with 6 core tables that demonstrate:\n",
    "- **Hierarchical relationships** (categories with parent/child structure)\n",
    "- **Many-to-many relationships** (orders â†” products via junction table) \n",
    "- **Vector integration** (reviews with embedding column for semantic search)\n",
    "- **Analytics capabilities** (aggregated sales metrics and customer data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd1d2ddd-b839-4fe0-9fb9-edf566807245",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_sql(query: str, database: str = None) -> dict:\n",
    "    \"\"\"\n",
    "    Execute SQL query using RDS Data API\n",
    "    This is our main function for running any SQL command\n",
    "    \"\"\"\n",
    "    try:\n",
    "        params = {\n",
    "            'resourceArn': CLUSTER_ARN,\n",
    "            'secretArn': SECRET_ARN,\n",
    "            'sql': query\n",
    "        }\n",
    "        if database:\n",
    "            params['database'] = database\n",
    "            \n",
    "        response = rds_client.execute_statement(**params)\n",
    "        return response\n",
    "    except Exception as e:\n",
    "        print(f\"SQL execution error: {e}\")\n",
    "        return {\"error\": str(e)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "440ad441-0550-49c5-af88-15efec549268",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable pgvector extension for semantic search capabilities\n",
    "# pgvector allows PostgreSQL to store and search vector embeddings\n",
    "try:\n",
    "    result = run_sql('CREATE EXTENSION IF NOT EXISTS vector;', DATABASE_NAME)\n",
    "    print(\"âœ… pgvector extension enabled successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"Extension setup error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d52f3db-5f84-44d1-9292-470afdc863a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create tables by reading our schema file\n",
    "# Parse SQL file into individual statements (RDS Data API requirement)\n",
    "with open('ecommerce_schema.sql', 'r') as f:\n",
    "    schema_sql = f.read()\n",
    "\n",
    "statements = sqlparse.split(schema_sql)\n",
    "statements = [stmt.strip() for stmt in statements if stmt.strip()]\n",
    "\n",
    "print(f\"Creating {len(statements)} database tables...\")\n",
    "print(\"ðŸ“Š Schema includes: users, categories, products, orders, order_items, reviews\")\n",
    "print(\"ðŸ§  Vector integration: reviews.comment_embedding for semantic search\")\n",
    "\n",
    "# Execute each CREATE TABLE statement\n",
    "for i, statement in enumerate(statements, 1):\n",
    "    try:\n",
    "        run_sql(statement, DATABASE_NAME)\n",
    "        print(f\"  âœ… Table {i} created successfully\")\n",
    "    except Exception as e:\n",
    "        print(f\"  âŒ Table {i} failed: {e}\")\n",
    "\n",
    "print(\"âœ… Database schema creation completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19105a1b-ae33-4619-9860-88d2c9a93be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert sample data into our tables\n",
    "with open('ecommerce_data.sql', 'r') as f:\n",
    "    data_sql = f.read()\n",
    "\n",
    "data_statements = sqlparse.split(data_sql)\n",
    "data_statements = [stmt.strip() for stmt in data_statements if stmt.strip()]\n",
    "\n",
    "print(f\"Inserting sample data with {len(data_statements)} statements...\")\n",
    "print(\"ðŸ‘¥ 15 users across different US cities with spending history\")\n",
    "print(\"ðŸ“¦ 16 products across 8 categories (Electronics â†’ Audio/Video, Smart Devices, etc.)\")\n",
    "print(\"ðŸ›’ 10 orders with various statuses (delivered, shipped, processing, cancelled)\")\n",
    "print(\"â­ 13 detailed product reviews perfect for semantic search\")\n",
    "\n",
    "for i, statement in enumerate(data_statements, 1):\n",
    "    try:\n",
    "        result = run_sql(statement, DATABASE_NAME)\n",
    "        records_affected = result.get('numberOfRecordsUpdated', 0)\n",
    "        print(f\"  âœ… Dataset {i}: {records_affected} records inserted\")\n",
    "    except Exception as e:\n",
    "        print(f\"  âŒ Dataset {i} failed: {e}\")\n",
    "\n",
    "print(\"âœ… Sample data insertion completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ§  STEP 5: Bedrock Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfcd2744-65c2-4bf4-87e5-ef21e781bdc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure Bedrock client with extended timeouts for large requests\n",
    "bedrock_config = Config(\n",
    "    connect_timeout=60*5,  # 5 minutes\n",
    "    read_timeout=60*5,     # 5 minutes\n",
    ")\n",
    "\n",
    "bedrock = boto3.client(\n",
    "    service_name='bedrock-runtime', \n",
    "    region_name=AWS_REGION,\n",
    "    config=bedrock_config\n",
    ")\n",
    "\n",
    "# Model IDs for our use\n",
    "CLAUDE_MODEL = \"us.anthropic.claude-3-7-sonnet-20250219-v1:0\"  # For text-to-SQL\n",
    "EMBEDDING_MODEL = \"amazon.titan-embed-text-v2:0\"                # For vector search\n",
    "\n",
    "print(\"âœ… Bedrock configured successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5352dc09-f513-4c27-b619-376dfcf49d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatabaseTools:\n",
    "    \"\"\"Simple database helper for executing SQL queries\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.rds_client = boto3.client(\"rds-data\", region_name=AWS_REGION)\n",
    "    \n",
    "    def execute_sql(self, query: str) -> str:\n",
    "        \"\"\"Execute SQL query and return results as JSON string\"\"\"\n",
    "        try:\n",
    "            response = self.rds_client.execute_statement(\n",
    "                resourceArn=CLUSTER_ARN,\n",
    "                secretArn=SECRET_ARN,\n",
    "                database=DATABASE_NAME,\n",
    "                sql=query,\n",
    "                includeResultMetadata=True,\n",
    "            )\n",
    "            \n",
    "            # Handle empty results\n",
    "            if \"records\" not in response or not response[\"records\"]:\n",
    "                return json.dumps([])\n",
    "            \n",
    "            # Get column names and format results\n",
    "            columns = [field[\"name\"] for field in response.get(\"columnMetadata\", [])]\n",
    "            results = []\n",
    "            \n",
    "            for record in response[\"records\"]:\n",
    "                row_values = []\n",
    "                for field in record:\n",
    "                    # Extract value from different field types\n",
    "                    if \"stringValue\" in field:\n",
    "                        row_values.append(field[\"stringValue\"])\n",
    "                    elif \"longValue\" in field:\n",
    "                        row_values.append(field[\"longValue\"])\n",
    "                    elif \"doubleValue\" in field:\n",
    "                        row_values.append(field[\"doubleValue\"])\n",
    "                    elif \"booleanValue\" in field:\n",
    "                        row_values.append(field[\"booleanValue\"])\n",
    "                    else:\n",
    "                        row_values.append(None)\n",
    "                \n",
    "                results.append(dict(zip(columns, row_values)))\n",
    "            \n",
    "            return json.dumps(results, indent=2)\n",
    "            \n",
    "        except Exception as e:\n",
    "            return json.dumps({\"error\": f\"Database error: {str(e)}\"})\n",
    "\n",
    "# Test database connection\n",
    "db_tools = DatabaseTools()\n",
    "result = db_tools.execute_sql(\"SELECT current_timestamp;\")\n",
    "print(\"âœ… Database connection test successful\")\n",
    "print(\"Current time:\", json.loads(result)[0][\"current_timestamp\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ”¢ STEP 6: Generate Vector Embeddings for Semantic Search\n",
    "\n",
    "**Hybrid RDBMS + Vector Database Implementation:**\n",
    "\n",
    "Vector embeddings convert textual content into high-dimensional numerical representations that capture semantic relationships. PostgreSQL's pgvector extension enables native vector operations within the relational database, eliminating the need for separate vector database infrastructure.\n",
    "\n",
    "**Technical Implementation:**\n",
    "- Amazon Titan Text Embeddings v2 (1024-dimensional vectors)\n",
    "- PostgreSQL VECTOR data type with cosine similarity operations\n",
    "- Semantic search on review content independent of exact keyword matching\n",
    "\n",
    "This approach demonstrates the convergence of traditional RDBMS and vector database capabilities in production systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a417e1-8051-40b0-84c0-464f9f7923ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_embedding(text: str) -> List[float]:\n",
    "    \"\"\"\n",
    "    Convert text into a vector embedding using Amazon Titan\n",
    "    Returns a list of 1024 numbers that represent the text's meaning\n",
    "    \"\"\"\n",
    "    payload = {\n",
    "        \"inputText\": text,\n",
    "        \"embeddingTypes\": [\"float\"]\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        response = bedrock.invoke_model(\n",
    "            modelId=EMBEDDING_MODEL,\n",
    "            body=json.dumps(payload),\n",
    "            accept=\"application/json\",\n",
    "            contentType=\"application/json\"\n",
    "        )\n",
    "        \n",
    "        body = json.loads(response[\"body\"].read())\n",
    "        embeddings = body.get(\"embeddingsByType\", {}).get(\"float\", [])\n",
    "        return embeddings\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Embedding generation error: {e}\")\n",
    "        return []\n",
    "\n",
    "# Test embedding generation\n",
    "test_text = \"This battery lasts a long time\"\n",
    "test_embedding = create_embedding(test_text)\n",
    "print(f\"âœ… Generated embedding with {len(test_embedding)} dimensions\")\n",
    "print(f\"Sample values: {test_embedding[:5]}...\")  # Show first 5 numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a95f6d-6ea7-418d-9930-c50b854ca0c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_embeddings_to_reviews():\n",
    "    \"\"\"\n",
    "    Generate embeddings for all review comments and store them in the database\n",
    "    This enables semantic search on review content\n",
    "    \"\"\"\n",
    "    \n",
    "    # Step 1: Find reviews that need embeddings\n",
    "    count_query = \"SELECT COUNT(*) FROM reviews WHERE comment_embedding IS NULL\"\n",
    "    count_result = db_tools.execute_sql(count_query)\n",
    "    total_missing = json.loads(count_result)[0][\"count\"]\n",
    "    \n",
    "    print(f\"Found {total_missing} reviews needing embeddings\")\n",
    "    \n",
    "    if total_missing == 0:\n",
    "        print(\"âœ… All reviews already have embeddings!\")\n",
    "        return\n",
    "    \n",
    "    # Step 2: Get reviews without embeddings\n",
    "    select_query = \"\"\"\n",
    "        SELECT review_id, comment \n",
    "        FROM reviews \n",
    "        WHERE comment_embedding IS NULL \n",
    "        AND comment IS NOT NULL\n",
    "        ORDER BY review_id\n",
    "    \"\"\"\n",
    "    \n",
    "    result = db_tools.execute_sql(select_query)\n",
    "    reviews = json.loads(result)\n",
    "    \n",
    "    # Step 3: Generate embeddings for each review\n",
    "    for review in reviews:\n",
    "        review_id = review[\"review_id\"]\n",
    "        comment = review[\"comment\"]\n",
    "        \n",
    "        if not comment:\n",
    "            continue\n",
    "            \n",
    "        print(f\"  Processing review {review_id}...\")\n",
    "        \n",
    "        # Generate embedding\n",
    "        embedding = create_embedding(comment)\n",
    "        if not embedding:\n",
    "            continue\n",
    "            \n",
    "        # Convert to PostgreSQL vector format\n",
    "        vector_str = \"[\" + \",\".join(str(x) for x in embedding) + \"]\"\n",
    "        \n",
    "        # Update database with embedding\n",
    "        update_query = f\"\"\"\n",
    "            UPDATE reviews \n",
    "            SET comment_embedding = '{vector_str}'::vector \n",
    "            WHERE review_id = {review_id}\n",
    "        \"\"\"\n",
    "        \n",
    "        run_sql(update_query, DATABASE_NAME)\n",
    "        print(f\"    âœ… Added embedding for review {review_id}\")\n",
    "    \n",
    "    print(\"âœ… All review embeddings generated successfully!\")\n",
    "\n",
    "# Generate embeddings for all reviews\n",
    "add_embeddings_to_reviews()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ¤– STEP 7: Foundation Model Tool Selection System\n",
    "\n",
    "**Query Strategy Determination:**\n",
    "\n",
    "Claude Sonnet analyzes natural language queries and automatically determines the optimal execution strategy through tool selection logic:\n",
    "\n",
    "**ðŸ“Š Structured Query Scenarios (SQL Tool Selection):**\n",
    "- Aggregation operations: \"What's the average order value by state?\"\n",
    "- Complex joins: \"Show customers with repeat purchases in Electronics\"\n",
    "- Mathematical calculations: \"Calculate profit margins by product category\"\n",
    "- Temporal analysis: \"Find order trends over the last quarter\"\n",
    "\n",
    "**ðŸ” Semantic Search Scenarios (Vector Tool Selection):**\n",
    "- Content similarity: \"Find reviews about build quality issues\"\n",
    "- Sentiment analysis: \"Show complaints about customer service\"\n",
    "- Topic clustering: \"What do users say about product durability?\"\n",
    "- Conceptual matching: Independent of exact keyword presence\n",
    "\n",
    "**ðŸŽ¯ Hybrid Query Execution:**\n",
    "- Complex scenarios may trigger multiple tool usage\n",
    "- Foundation model orchestrates sequential or parallel execution\n",
    "- Results synthesis from both structured and semantic operations\n",
    "\n",
    "**Technical Architecture:**\n",
    "- Tool specification via JSON schema definitions\n",
    "- Automated function calling based on intent classification\n",
    "- Context-aware execution path optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf4ee1a5-c963-48d3-bbb7-efbde659aac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def semantic_search(search_text: str, limit: int = 5) -> str:\n",
    "    \"\"\"\n",
    "    Find reviews similar to the search text using vector similarity\n",
    "    Returns the most semantically similar reviews\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Generate embedding for search text\n",
    "        search_embedding = create_embedding(search_text)\n",
    "        if not search_embedding:\n",
    "            return json.dumps({\"error\": \"Could not generate embedding\"})\n",
    "        \n",
    "        # Convert to PostgreSQL vector format\n",
    "        vector_str = \"[\" + \",\".join(str(x) for x in search_embedding) + \"]\"\n",
    "        \n",
    "        # Find similar reviews using cosine distance (<-> operator)\n",
    "        query = f\"\"\"\n",
    "        SELECT \n",
    "            rating,\n",
    "            title,\n",
    "            comment,\n",
    "            pros,\n",
    "            cons,\n",
    "            helpful_count,\n",
    "            (1 - (comment_embedding <-> '{vector_str}'::vector)) as similarity_score\n",
    "        FROM reviews\n",
    "        WHERE comment IS NOT NULL \n",
    "        AND comment_embedding IS NOT NULL\n",
    "        ORDER BY comment_embedding <-> '{vector_str}'::vector\n",
    "        LIMIT {limit}\n",
    "        \"\"\"\n",
    "        \n",
    "        result = db_tools.execute_sql(query)\n",
    "        return result\n",
    "        \n",
    "    except Exception as e:\n",
    "        return json.dumps({\"error\": f\"Vector search error: {str(e)}\"})\n",
    "\n",
    "# Test vector search\n",
    "test_search = semantic_search(\"battery problems\", limit=3)\n",
    "print(\"âœ… Vector search test successful\")\n",
    "print(\"Sample results:\", json.loads(test_search)[0][\"title\"] if json.loads(test_search) else \"No results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5c586e-b60f-4283-a0be-8a4876e22de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the tools available to Claude\n",
    "TOOLS = {\n",
    "    \"tools\": [\n",
    "        {\n",
    "            \"toolSpec\": {\n",
    "                \"name\": \"execute_sql\",\n",
    "                \"description\": \"Execute SQL queries for structured data analysis (counts, filters, joins, aggregations)\",\n",
    "                \"inputSchema\": {\n",
    "                    \"json\": {\n",
    "                        \"type\": \"object\",\n",
    "                        \"properties\": {\n",
    "                            \"query\": {\n",
    "                                \"type\": \"string\",\n",
    "                                \"description\": \"SQL query to execute against the ecommerce database\"\n",
    "                            }\n",
    "                        },\n",
    "                        \"required\": [\"query\"]\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"toolSpec\": {\n",
    "                \"name\": \"vector_search\",\n",
    "                \"description\": \"Perform semantic similarity search on review content to find similar topics/themes\",\n",
    "                \"inputSchema\": {\n",
    "                    \"json\": {\n",
    "                        \"type\": \"object\",\n",
    "                        \"properties\": {\n",
    "                            \"text\": {\n",
    "                                \"type\": \"string\",\n",
    "                                \"description\": \"Text to search for semantically similar content in reviews\"\n",
    "                            }\n",
    "                        },\n",
    "                        \"required\": [\"text\"]\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    ],\n",
    "    \"toolChoice\": {\"auto\": {}}\n",
    "}\n",
    "\n",
    "print(\"âœ… AI tools configured - Claude can now choose between SQL and vector search!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68119147",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = \"\"\"\n",
    "# Advanced Text-to-SQL System Prompt with PostgreSQL Vector Search\n",
    "\n",
    "<role>\n",
    "You are an advanced database query optimization system specializing in hybrid SQL and vector search operations. \n",
    "Your primary function is to analyze natural language queries, determine optimal execution strategies, and generate PostgreSQL queries that leverage both relational and vector capabilities.\n",
    "</role>\n",
    "\n",
    "<schema>\n",
    "\n",
    "<table name=\"users\">\n",
    "<purpose>\n",
    "Customer profiles with pre-computed analytics for performance optimization\n",
    "</purpose>\n",
    "<key_columns>\n",
    "- user_id (SERIAL PRIMARY KEY)\n",
    "- email, username (UNIQUE constraints for data integrity)\n",
    "- first_name, last_name, phone_number, date_of_birth, gender\n",
    "- city, state_province, country_code (geographic segmentation)\n",
    "- account_status (operational flag)\n",
    "- total_orders, total_spent (denormalized aggregates for fast analytics)\n",
    "- created_at (temporal tracking)\n",
    "</key_columns>\n",
    "</table>\n",
    "\n",
    "<table name=\"categories\">\n",
    "<purpose>\n",
    "Hierarchical product taxonomy with recursive relationship support\n",
    "</purpose>\n",
    "<key_columns>\n",
    "- category_id (SERIAL PRIMARY KEY)\n",
    "- name, slug (unique URL-safe identifier), description\n",
    "- parent_category_id (SELF-REFERENTIAL FK enabling tree structures)\n",
    "- is_active (soft delete support)\n",
    "- product_count (denormalized for performance)\n",
    "- created_at\n",
    "</key_columns>\n",
    "</table>\n",
    "\n",
    "<table name=\"products\">\n",
    "<purpose>\n",
    "Product catalog with inventory tracking and performance metrics\n",
    "</purpose>\n",
    "<key_columns>\n",
    "- product_id (SERIAL PRIMARY KEY)\n",
    "- sku (UNIQUE business identifier)\n",
    "- name, slug, description, short_description\n",
    "- category_id (FK to categories)\n",
    "- brand, price, cost (profit margin calculation)\n",
    "- weight_kg, stock_quantity (logistics data)\n",
    "- is_active, is_featured (display control)\n",
    "- warranty_months\n",
    "- rating_average, rating_count (computed from reviews)\n",
    "- total_sales, revenue_generated (business metrics)\n",
    "- created_at, updated_at (audit trail)\n",
    "</key_columns>\n",
    "</table>\n",
    "\n",
    "<table name=\"orders\">\n",
    "<purpose>\n",
    "Transaction lifecycle management with comprehensive status tracking\n",
    "</purpose>\n",
    "<key_columns>\n",
    "- order_id (SERIAL PRIMARY KEY)\n",
    "- order_number (UNIQUE human-readable identifier)\n",
    "- user_id (FK to users)\n",
    "- order_status: pending|processing|shipped|delivered|cancelled|refunded\n",
    "- payment_status: pending|paid|failed|refunded\n",
    "- shipping_address (full text for flexibility)\n",
    "- financial_breakdown:\n",
    "  * subtotal (items before adjustments)\n",
    "  * tax_amount, shipping_cost, discount_amount\n",
    "  * total_amount (final charge)\n",
    "- payment_method: credit_card|paypal|bank_transfer\n",
    "- shipping_method: standard|express|overnight\n",
    "- customer_notes, tracking_number\n",
    "- shipped_at, delivered_at (fulfillment tracking)\n",
    "- created_at, updated_at\n",
    "</key_columns>\n",
    "</table>\n",
    "\n",
    "<table name=\"order_items\">\n",
    "<purpose>\n",
    "Junction table capturing point-in-time pricing and item-level details\n",
    "</purpose>\n",
    "<key_columns>\n",
    "- order_item_id (SERIAL PRIMARY KEY)\n",
    "- order_id (FK CASCADE DELETE)\n",
    "- product_id (FK)\n",
    "- quantity, unit_price (historical pricing preservation)\n",
    "- discount_amount, tax_amount (item-level adjustments)\n",
    "- total_price (computed line total)\n",
    "- created_at\n",
    "</key_columns>\n",
    "</table>\n",
    "\n",
    "<table name=\"reviews\">\n",
    "<purpose>\n",
    "Customer feedback with vector embeddings for semantic analysis\n",
    "</purpose>\n",
    "<key_columns>\n",
    "- review_id (SERIAL PRIMARY KEY)\n",
    "- product_id (FK CASCADE DELETE)\n",
    "- user_id (FK)\n",
    "- order_id (FK optional - links to purchase)\n",
    "- rating (INTEGER CHECK 1-5)\n",
    "- title (VARCHAR(200))\n",
    "- comment (TEXT - source for embeddings)\n",
    "- comment_embedding (VECTOR(1024) - semantic representation)\n",
    "- pros, cons (structured sentiment extraction)\n",
    "- is_verified_purchase (trust signal)\n",
    "- helpful_count (community validation)\n",
    "- status: pending|approved|rejected\n",
    "- created_at, updated_at\n",
    "</key_columns>\n",
    "<vector_capabilities>\n",
    "- comment_embedding enables semantic similarity search\n",
    "- Cosine distance for finding related reviews\n",
    "- Supports sentiment clustering and topic modeling\n",
    "</vector_capabilities>\n",
    "</table>\n",
    "</schema>\n",
    "\n",
    "<tool_selection>\n",
    "**execute_sql**: Use for structured queries, aggregations, joins, filtering by exact values\n",
    "\n",
    "**vector_search**: Use for semantic similarity on review comments, finding related content\n",
    "\n",
    "Examples:\n",
    "- \"total revenue by category\" â†’ execute_sql\n",
    "- \"reviews similar to 'great battery life'\" â†’ vector_search\n",
    "- \"average rating of products with positive reviews\" â†’ both tools\n",
    "</tool_selection>\n",
    "\n",
    "<query_patterns>\n",
    "SQL Example:\n",
    "```sql\n",
    "SELECT c.name, SUM(p.revenue_generated) as revenue\n",
    "FROM categories c\n",
    "JOIN products p ON c.category_id = p.category_id\n",
    "GROUP BY c.name\n",
    "ORDER BY revenue DESC;\n",
    "```\n",
    "\n",
    "Vector Example:\n",
    "```sql\n",
    "-- Note: query_embedding would be provided by the system as a VECTOR(1024)\n",
    "SELECT r.comment, p.name, \n",
    "       r.comment_embedding <=> query_embedding as similarity\n",
    "FROM reviews r\n",
    "JOIN products p ON r.product_id = p.product_id\n",
    "ORDER BY similarity\n",
    "LIMIT 5;\n",
    "```\n",
    "</query_patterns>\n",
    "\n",
    "### SQL Query Best Practices\n",
    "<sql_requirements>\n",
    "1. **Explicit JOINs**: Always use explicit JOIN syntax with ON conditions\n",
    "2. **Table Aliases**: Use meaningful aliases (u for users, p for products)\n",
    "3. **NULL Handling**: Account for optional fields with COALESCE or IS NULL\n",
    "4. **Data Types**: Cast when necessary, especially for date operations\n",
    "5. **Aggregation Rules**: Include all non-aggregate columns in GROUP BY\n",
    "6. **Order Stability**: Add secondary ORDER BY for deterministic results\n",
    "7. **Limit Appropriately**: Include LIMIT for top-N queries\n",
    "8. **Comment Complex Logic**: Add -- comments for CTEs or complex conditions\n",
    "</sql_requirements>\n",
    "\n",
    "### Vector Search Best Practices\n",
    "<vector_requirements>\n",
    "1. **Distance Metrics**: Use cosine distance (<=>) for normalized embeddings\n",
    "2. **Result Limits**: Always limit results (default 10-20 for readability)\n",
    "3. **Threshold Filtering**: Consider similarity threshold for quality control\n",
    "4. **Metadata Inclusion**: Join with products/users for context\n",
    "5. **Explain Similarity**: Include distance scores in results\n",
    "</vector_requirements>\n",
    "\n",
    "<output_format>\n",
    "### Response Structure\n",
    "```\n",
    "QUERY ANALYSIS:\n",
    "- Intent: [Extracted user intent]\n",
    "- Strategy: [Selected tool(s) and rationale]\n",
    "- Key Operations: [Main database operations required]\n",
    "\n",
    "GENERATED QUERY:\n",
    "[Actual SQL or vector search syntax]\n",
    "\n",
    "EXPECTED INSIGHTS:\n",
    "- [Key patterns or metrics the query will reveal]\n",
    "- [Business value of the results]\n",
    "```\n",
    "</output_format>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "542b7cc1-da90-4d63-912b-2ba8b5f97488",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_ai(question: str) -> str:\n",
    "    \"\"\"\n",
    "    Send a question to Claude and handle tool execution\n",
    "    Claude will automatically choose between SQL and vector search\n",
    "    Handles multiple rounds of tool calls until completion\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create the conversation\n",
    "    messages = [{\"role\": \"user\", \"content\": [{\"text\": question}]}]\n",
    "    \n",
    "    try:\n",
    "        # Continue conversation until Claude stops requesting tools\n",
    "        max_turns = 10  # Prevent infinite loops\n",
    "        turn_count = 0\n",
    "        \n",
    "        while turn_count < max_turns:\n",
    "            turn_count += 1\n",
    "            \n",
    "            # Send to Claude with tools\n",
    "            response = bedrock.converse(\n",
    "                modelId=CLAUDE_MODEL,\n",
    "                system=[{\"text\": SYSTEM_PROMPT}],\n",
    "                messages=messages,\n",
    "                toolConfig=TOOLS\n",
    "            )\n",
    "            \n",
    "            assistant_message = response[\"output\"][\"message\"]\n",
    "            messages.append(assistant_message)\n",
    "            \n",
    "            # Check if Claude wants to use tools\n",
    "            tool_uses = [content for content in assistant_message[\"content\"] if \"toolUse\" in content]\n",
    "            \n",
    "            if tool_uses:\n",
    "                # Execute each tool Claude requested\n",
    "                for tool_use in tool_uses:\n",
    "                    tool_name = tool_use[\"toolUse\"][\"name\"]\n",
    "                    tool_input = tool_use[\"toolUse\"][\"input\"]\n",
    "                    tool_id = tool_use[\"toolUse\"][\"toolUseId\"]\n",
    "                    \n",
    "                    print(f\"ðŸ”§ Claude is using: {tool_name}\")\n",
    "                    \n",
    "                    # Execute the appropriate tool\n",
    "                    if tool_name == \"execute_sql\":\n",
    "                        tool_result = db_tools.execute_sql(tool_input[\"query\"])\n",
    "                        print(f\"ðŸ“Š SQL Query: {tool_input['query']}\")\n",
    "                        \n",
    "                    elif tool_name == \"vector_search\":\n",
    "                        tool_result = semantic_search(tool_input[\"text\"])\n",
    "                        print(f\"ðŸ” Searching for: {tool_input['text']}\")\n",
    "                    \n",
    "                    # Send tool result back to Claude\n",
    "                    tool_message = {\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": [{\n",
    "                            \"toolResult\": {\n",
    "                                \"toolUseId\": tool_id,\n",
    "                                \"content\": [{\"text\": tool_result}]\n",
    "                            }\n",
    "                        }]\n",
    "                    }\n",
    "                    messages.append(tool_message)\n",
    "                \n",
    "                # Continue the loop to let Claude process results and potentially make more tool calls\n",
    "                continue\n",
    "            \n",
    "            else:\n",
    "                # No tools needed, extract and return the final response\n",
    "                final_content = assistant_message[\"content\"]\n",
    "                text_response = next((c[\"text\"] for c in final_content if \"text\" in c), \"\")\n",
    "                return text_response\n",
    "        \n",
    "        # If we hit max turns, return what we have\n",
    "        return \"Response completed after maximum tool execution rounds.\"\n",
    "            \n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\"\n",
    "\n",
    "print(\"âœ… Enhanced LLM assistant ready with multi-round tool execution support!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸš€ STEP 8: Technical Demonstrations\n",
    "\n",
    "### Demo 1: Complex Schema Text-to-SQL Generation\n",
    "**Objective:** Validate LLM comprehension of multi-table relationships and automated SQL generation for complex analytical queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca62e41-6c03-49c8-a280-426d9de633c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEMO 1: Complex Schema Text-to-SQL Generation\n",
    "print(\"=\" * 70)\n",
    "print(\"DEMO 1: Complex Schema Text-to-SQL Generation\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Test multi-table join with hierarchical traversal and aggregation\n",
    "question1 = \"Show me the top 3 customers by total spending, including their order count and favorite product category\"\n",
    "print(f\"Query: {question1}\")\n",
    "print(\"\\nðŸ”§ Expected: Multi-table JOIN across users, orders, order_items, products, categories\")\n",
    "print(\"\\nExecution:\")\n",
    "answer1 = ask_ai(question1)\n",
    "print(answer1)\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demo 2: PostgreSQL Vector Search Implementation\n",
    "**Objective:** Demonstrate native vector operations within PostgreSQL using pgvector for semantic similarity search on unstructured content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47633120-d09e-47c6-a0ca-c8973eb70463",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEMO 2: PostgreSQL Vector Search Implementation\n",
    "print(\"DEMO 2: PostgreSQL Vector Search Implementation\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "question2 = \"Find reviews about battery life issues and charging problems\"\n",
    "print(f\"Query: {question2}\")\n",
    "print(\"\\nðŸ”§ Expected: Vector similarity search using pgvector cosine distance\")\n",
    "print(\"ðŸ“Š Operation: Embedding generation + semantic matching on reviews.comment_embedding\")\n",
    "print(\"ðŸŽ¯ Capability: Content similarity independent of exact keyword presence\")\n",
    "print(\"\\nExecution:\")\n",
    "answer2 = ask_ai(question2)\n",
    "print(answer2)\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demo 3: Automated Query Strategy Selection\n",
    "**Objective:** Capability to analyze query intent and select optimal execution strategy between SQL and vector operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c86224-f7ff-40e6-92f7-9da4d520c895",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEMO 3: Automated Query Strategy Selection\n",
    "print(\"DEMO 3: Automated Query Strategy Selection\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Ambiguous query that could use either approach\n",
    "question3 = \"What are the main product quality issues customers mention in their reviews?\"\n",
    "print(f\"Query: {question3}\")\n",
    "print(\"\\nðŸ¤” Strategy Options:\")\n",
    "print(\"   ðŸ“Š SQL Approach: Aggregate review ratings and identify low-rated products\")\n",
    "print(\"   ðŸ” Vector Approach: Semantic search for quality-related content themes\") \n",
    "print(\"   ðŸŽ¯ Hybrid Approach: Combine structured filtering with content analysis\")\n",
    "print(\"\\nðŸ”§ Foundation Model Decision Process:\")\n",
    "print(\"\\nExecution:\")\n",
    "answer3 = ask_ai(question3)\n",
    "print(answer3)\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ’¬ Interactive Query Testing\n",
    "\n",
    "**Technical Validation Environment**\n",
    "\n",
    "Test the foundation model's query strategy selection across different analytical scenarios. The system will demonstrate automated tool selection based on query characteristics and optimal execution path determination.\n",
    "\n",
    "**Structured Query Test Cases:**\n",
    "\n",
    "**ðŸ“Š Complex SQL Operations:**\n",
    "- \"Calculate profit margins by hierarchical product category\"\n",
    "- \"Identify customers with highest purchase frequency in Texas\"\n",
    "- \"Analyze order value distribution across payment methods\"\n",
    "\n",
    "**ðŸ” Vector Similarity Operations:**\n",
    "- \"Find reviews discussing build quality and manufacturing defects\"\n",
    "- \"Locate customer feedback about shipping and logistics issues\"\n",
    "- \"Identify content related to product longevity and durability concerns\"\n",
    "- \"Search for mentions of value proposition and pricing feedback\"\n",
    "\n",
    "**ðŸŽ¯ Complex Analytical Scenarios:**\n",
    "- \"Which products receive the most quality-related complaints?\"\n",
    "- \"Analyze sentiment patterns across different customer segments\"\n",
    "- \"Find correlation between product price points and satisfaction themes\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92781fad-9afc-469d-aec7-c693da3b2fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive Query Testing Environment\n",
    "print(\"ðŸ”§ Foundation Model Query Strategy Testing\")\n",
    "print(\"Enter queries to validate automated tool selection logic. Type 'quit' to exit.\")\n",
    "print(\"\\nðŸ“‹ Test Categories:\")\n",
    "\n",
    "print(\"\\nðŸ“Š Structured Data Operations:\")\n",
    "print(\"â€¢ 'Which product categories have the highest profit margins?'\")\n",
    "print(\"â€¢ 'Show customer geographic distribution by total spending'\")\n",
    "print(\"â€¢ 'Analyze order completion rates by shipping method'\")\n",
    "\n",
    "print(\"\\nðŸ” Semantic Content Analysis:\")\n",
    "print(\"â€¢ 'Find reviews about products being difficult to use or setup'\")\n",
    "print(\"â€¢ 'Locate feedback about customer support experiences'\")\n",
    "print(\"â€¢ 'Search for mentions of product packaging and presentation'\")\n",
    "\n",
    "print(\"\\nðŸŽ¯ Hybrid Analysis Scenarios:\")\n",
    "print(\"â€¢ 'Identify top-selling products with usability complaints'\")\n",
    "print(\"â€¢ 'Find high-value customers who mention quality concerns'\")\n",
    "\n",
    "print(\"-\" * 70)\n",
    "\n",
    "while True:\n",
    "    question = input(\"\\nðŸ” Query: \").strip()\n",
    "    \n",
    "    if question.lower() == 'quit':\n",
    "        print(\"âœ… Query testing session completed\")\n",
    "        break\n",
    "    \n",
    "    if question:\n",
    "        print(f\"\\nðŸ“ Processing: {question}\")\n",
    "        print(\"âš™ï¸  Analyzing query intent and determining execution strategy...\")\n",
    "        answer = ask_ai(question)\n",
    "        print(f\"\\nðŸ“Š Result: {answer}\")\n",
    "        print(\"-\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ§¹ STEP 9: Cleanup (Optional)\n",
    "Run this to delete all AWS resources and avoid charges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e71657-53ff-403b-a3ee-dc28bdcf1188",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup AWS resources to avoid ongoing charges\n",
    "# This will delete the Aurora cluster, VPC, and all related resources\n",
    "\n",
    "# Primary method:\n",
    "!python clean.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
