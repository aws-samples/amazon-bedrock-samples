{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Dynamic AI Assistants with Amazon Bedrock Inline Agents\n",
    "\n",
    "In this notebook, we'll walk through the process of setting up and invoking an inline agent, showcasing its flexibility and power in creating dynamic AI assistants. By following our progressive approach, you will gain a comprehensive understanding of how to use inline agents for various use cases and complexity levels. Throughout a single interactive conversation, we will demonstrate how the agent can be enhanced `on the fly` with new tools and instructions while maintaining context of our ongoing discussion.\n",
    "\n",
    "We'll follow a progressive approach to building our assistant:\n",
    "\n",
    "1. Simple Inline Agent: We'll start with a basic inline agent with a code interpreter.\n",
    "2. Adding Knowledge Bases: We'll enhance our agent by incorporating a knowledge base with role-based access.\n",
    "3. Integrating Action Groups: Finally, we'll add custom tools to extend the agent's functionality.\n",
    "\n",
    "## What are Inline Agents?\n",
    "\n",
    "[Inline agents](https://docs.aws.amazon.com/bedrock/latest/userguide/agents-create-inline.html) are a powerful feature of Amazon Bedrock that allow developers to create flexible and adaptable AI assistants. \n",
    "\n",
    "Unlike traditional static agents, inline agents can be dynamically configured at runtime, enabling real time adjustments to their behavior, capabilities, and knowledge base.\n",
    "\n",
    "Key features of inline agents include:\n",
    "\n",
    "1. **Dynamic configuration**: Modify the agent's instructions, action groups, and other parameters on the fly.\n",
    "2. **Flexible integration**: Easily incorporate external APIs and services as needed for each interaction.\n",
    "3. **Contextual adaptation**: Adjust the agent's responses based on user roles, preferences, or specific scenarios.\n",
    "\n",
    "## Why Use Inline Agents?\n",
    "\n",
    "Inline agents offer several advantages for building AI applications:\n",
    "\n",
    "1. **Rapid prototyping**: Quickly experiment with different configurations without redeploying your application.\n",
    "2. **Personalization**: Tailor the agent's capabilities to individual users or use cases in real time.\n",
    "3. **Scalability**: Efficiently manage a single agent that can adapt to multiple roles or functions.\n",
    "4. **Cost effectiveness**: Optimize resource usage by dynamically selecting only the necessary tools and knowledge for each interaction.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "Before you begin, make sure that you have:\n",
    "\n",
    "1. An active AWS account with access to Amazon Bedrock.\n",
    "2. Necessary permissions to create and invoke inline agents.\n",
    "3. Be sure to complete additonal prerequisites, visit [Amazon Bedrock Inline Agent prerequisites documentation](https://docs.aws.amazon.com/bedrock/latest/userguide/inline-agent-prereq.html) to learn more.\n",
    "\n",
    "### Installing prerequisites\n",
    "Let's begin with installing the required packages. This step is important as you need `boto3` version `1.35.68` or later to use inline agents."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-02-27T00:54:53.567467Z",
     "start_time": "2025-02-27T00:54:51.626329Z"
    }
   },
   "source": [
    "# uncomment to install the required python packages\n",
    "!pip install --upgrade -r requirements.txt"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: boto3 in /Users/kabouk/Code/github/aws-samples/amazon-bedrock-samples/.venv/lib/python3.13/site-packages (from -r requirements.txt (line 1)) (1.37.2)\r\n",
      "Requirement already satisfied: opensearch-py in /Users/kabouk/Code/github/aws-samples/amazon-bedrock-samples/.venv/lib/python3.13/site-packages (from -r requirements.txt (line 2)) (2.8.0)\r\n",
      "Requirement already satisfied: botocore in /Users/kabouk/Code/github/aws-samples/amazon-bedrock-samples/.venv/lib/python3.13/site-packages (from -r requirements.txt (line 3)) (1.37.2)\r\n",
      "Requirement already satisfied: awscli in /Users/kabouk/Code/github/aws-samples/amazon-bedrock-samples/.venv/lib/python3.13/site-packages (from -r requirements.txt (line 4)) (1.38.2)\r\n",
      "Requirement already satisfied: retrying in /Users/kabouk/Code/github/aws-samples/amazon-bedrock-samples/.venv/lib/python3.13/site-packages (from -r requirements.txt (line 5)) (1.3.4)\r\n",
      "Requirement already satisfied: termcolor in /Users/kabouk/Code/github/aws-samples/amazon-bedrock-samples/.venv/lib/python3.13/site-packages (from -r requirements.txt (line 6)) (2.5.0)\r\n",
      "Requirement already satisfied: rich in /Users/kabouk/Code/github/aws-samples/amazon-bedrock-samples/.venv/lib/python3.13/site-packages (from -r requirements.txt (line 7)) (13.9.4)\r\n",
      "Requirement already satisfied: ipywidgets in /Users/kabouk/Code/github/aws-samples/amazon-bedrock-samples/.venv/lib/python3.13/site-packages (from -r requirements.txt (line 8)) (8.1.5)\r\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /Users/kabouk/Code/github/aws-samples/amazon-bedrock-samples/.venv/lib/python3.13/site-packages (from boto3->-r requirements.txt (line 1)) (1.0.1)\r\n",
      "Requirement already satisfied: s3transfer<0.12.0,>=0.11.0 in /Users/kabouk/Code/github/aws-samples/amazon-bedrock-samples/.venv/lib/python3.13/site-packages (from boto3->-r requirements.txt (line 1)) (0.11.3)\r\n",
      "Requirement already satisfied: urllib3!=2.2.0,!=2.2.1,<3,>=1.26.19 in /Users/kabouk/Code/github/aws-samples/amazon-bedrock-samples/.venv/lib/python3.13/site-packages (from opensearch-py->-r requirements.txt (line 2)) (2.3.0)\r\n",
      "Requirement already satisfied: requests<3.0.0,>=2.32.0 in /Users/kabouk/Code/github/aws-samples/amazon-bedrock-samples/.venv/lib/python3.13/site-packages (from opensearch-py->-r requirements.txt (line 2)) (2.32.3)\r\n",
      "Requirement already satisfied: python-dateutil in /Users/kabouk/Code/github/aws-samples/amazon-bedrock-samples/.venv/lib/python3.13/site-packages (from opensearch-py->-r requirements.txt (line 2)) (2.9.0.post0)\r\n",
      "Requirement already satisfied: certifi>=2024.07.04 in /Users/kabouk/Code/github/aws-samples/amazon-bedrock-samples/.venv/lib/python3.13/site-packages (from opensearch-py->-r requirements.txt (line 2)) (2025.1.31)\r\n",
      "Requirement already satisfied: Events in /Users/kabouk/Code/github/aws-samples/amazon-bedrock-samples/.venv/lib/python3.13/site-packages (from opensearch-py->-r requirements.txt (line 2)) (0.5)\r\n",
      "Requirement already satisfied: docutils<0.17,>=0.10 in /Users/kabouk/Code/github/aws-samples/amazon-bedrock-samples/.venv/lib/python3.13/site-packages (from awscli->-r requirements.txt (line 4)) (0.16)\r\n",
      "Requirement already satisfied: PyYAML<6.1,>=3.10 in /Users/kabouk/Code/github/aws-samples/amazon-bedrock-samples/.venv/lib/python3.13/site-packages (from awscli->-r requirements.txt (line 4)) (6.0.2)\r\n",
      "Requirement already satisfied: colorama<0.4.7,>=0.2.5 in /Users/kabouk/Code/github/aws-samples/amazon-bedrock-samples/.venv/lib/python3.13/site-packages (from awscli->-r requirements.txt (line 4)) (0.4.6)\r\n",
      "Requirement already satisfied: rsa<4.8,>=3.1.2 in /Users/kabouk/Code/github/aws-samples/amazon-bedrock-samples/.venv/lib/python3.13/site-packages (from awscli->-r requirements.txt (line 4)) (4.7.2)\r\n",
      "Requirement already satisfied: six>=1.7.0 in /Users/kabouk/Code/github/aws-samples/amazon-bedrock-samples/.venv/lib/python3.13/site-packages (from retrying->-r requirements.txt (line 5)) (1.17.0)\r\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/kabouk/Code/github/aws-samples/amazon-bedrock-samples/.venv/lib/python3.13/site-packages (from rich->-r requirements.txt (line 7)) (3.0.0)\r\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/kabouk/Code/github/aws-samples/amazon-bedrock-samples/.venv/lib/python3.13/site-packages (from rich->-r requirements.txt (line 7)) (2.19.1)\r\n",
      "Requirement already satisfied: comm>=0.1.3 in /Users/kabouk/Code/github/aws-samples/amazon-bedrock-samples/.venv/lib/python3.13/site-packages (from ipywidgets->-r requirements.txt (line 8)) (0.2.2)\r\n",
      "Requirement already satisfied: ipython>=6.1.0 in /Users/kabouk/Code/github/aws-samples/amazon-bedrock-samples/.venv/lib/python3.13/site-packages (from ipywidgets->-r requirements.txt (line 8)) (8.32.0)\r\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /Users/kabouk/Code/github/aws-samples/amazon-bedrock-samples/.venv/lib/python3.13/site-packages (from ipywidgets->-r requirements.txt (line 8)) (5.14.3)\r\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.12 in /Users/kabouk/Code/github/aws-samples/amazon-bedrock-samples/.venv/lib/python3.13/site-packages (from ipywidgets->-r requirements.txt (line 8)) (4.0.13)\r\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.12 in /Users/kabouk/Code/github/aws-samples/amazon-bedrock-samples/.venv/lib/python3.13/site-packages (from ipywidgets->-r requirements.txt (line 8)) (3.0.13)\r\n",
      "Requirement already satisfied: decorator in /Users/kabouk/Code/github/aws-samples/amazon-bedrock-samples/.venv/lib/python3.13/site-packages (from ipython>=6.1.0->ipywidgets->-r requirements.txt (line 8)) (5.2.1)\r\n",
      "Requirement already satisfied: jedi>=0.16 in /Users/kabouk/Code/github/aws-samples/amazon-bedrock-samples/.venv/lib/python3.13/site-packages (from ipython>=6.1.0->ipywidgets->-r requirements.txt (line 8)) (0.19.2)\r\n",
      "Requirement already satisfied: matplotlib-inline in /Users/kabouk/Code/github/aws-samples/amazon-bedrock-samples/.venv/lib/python3.13/site-packages (from ipython>=6.1.0->ipywidgets->-r requirements.txt (line 8)) (0.1.7)\r\n",
      "Requirement already satisfied: pexpect>4.3 in /Users/kabouk/Code/github/aws-samples/amazon-bedrock-samples/.venv/lib/python3.13/site-packages (from ipython>=6.1.0->ipywidgets->-r requirements.txt (line 8)) (4.9.0)\r\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in /Users/kabouk/Code/github/aws-samples/amazon-bedrock-samples/.venv/lib/python3.13/site-packages (from ipython>=6.1.0->ipywidgets->-r requirements.txt (line 8)) (3.0.50)\r\n",
      "Requirement already satisfied: stack_data in /Users/kabouk/Code/github/aws-samples/amazon-bedrock-samples/.venv/lib/python3.13/site-packages (from ipython>=6.1.0->ipywidgets->-r requirements.txt (line 8)) (0.6.3)\r\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/kabouk/Code/github/aws-samples/amazon-bedrock-samples/.venv/lib/python3.13/site-packages (from markdown-it-py>=2.2.0->rich->-r requirements.txt (line 7)) (0.1.2)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/kabouk/Code/github/aws-samples/amazon-bedrock-samples/.venv/lib/python3.13/site-packages (from requests<3.0.0,>=2.32.0->opensearch-py->-r requirements.txt (line 2)) (3.4.1)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/kabouk/Code/github/aws-samples/amazon-bedrock-samples/.venv/lib/python3.13/site-packages (from requests<3.0.0,>=2.32.0->opensearch-py->-r requirements.txt (line 2)) (3.10)\r\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /Users/kabouk/Code/github/aws-samples/amazon-bedrock-samples/.venv/lib/python3.13/site-packages (from rsa<4.8,>=3.1.2->awscli->-r requirements.txt (line 4)) (0.6.1)\r\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /Users/kabouk/Code/github/aws-samples/amazon-bedrock-samples/.venv/lib/python3.13/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets->-r requirements.txt (line 8)) (0.8.4)\r\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /Users/kabouk/Code/github/aws-samples/amazon-bedrock-samples/.venv/lib/python3.13/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets->-r requirements.txt (line 8)) (0.7.0)\r\n",
      "Requirement already satisfied: wcwidth in /Users/kabouk/Code/github/aws-samples/amazon-bedrock-samples/.venv/lib/python3.13/site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets->-r requirements.txt (line 8)) (0.2.13)\r\n",
      "Requirement already satisfied: executing>=1.2.0 in /Users/kabouk/Code/github/aws-samples/amazon-bedrock-samples/.venv/lib/python3.13/site-packages (from stack_data->ipython>=6.1.0->ipywidgets->-r requirements.txt (line 8)) (2.2.0)\r\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /Users/kabouk/Code/github/aws-samples/amazon-bedrock-samples/.venv/lib/python3.13/site-packages (from stack_data->ipython>=6.1.0->ipywidgets->-r requirements.txt (line 8)) (3.0.0)\r\n",
      "Requirement already satisfied: pure-eval in /Users/kabouk/Code/github/aws-samples/amazon-bedrock-samples/.venv/lib/python3.13/site-packages (from stack_data->ipython>=6.1.0->ipywidgets->-r requirements.txt (line 8)) (0.2.3)\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m24.3.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m25.0.1\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-02-27T00:55:33.195240Z",
     "start_time": "2025-02-27T00:55:33.124798Z"
    }
   },
   "source": [
    "# # restart kernel\n",
    "from IPython.core.display import HTML\n",
    "HTML(\"<script>Jupyter.notebook.kernel.restart()</script>\")"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "<script>Jupyter.notebook.kernel.restart()</script>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports\n",
    "\n",
    "First, let's import the necessary libraries and set up our Bedrock client."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-02-27T00:55:37.727623Z",
     "start_time": "2025-02-27T00:55:37.337744Z"
    }
   },
   "source": [
    "import os\n",
    "import json\n",
    "from pprint import pprint\n",
    "import boto3\n",
    "from datetime import datetime\n",
    "import random\n",
    "import pprint\n",
    "from termcolor import colored\n",
    "from rich.console import Console\n",
    "from rich.markdown import Markdown\n",
    "import ipywidgets as widgets\n",
    "\n",
    "session = boto3.session.Session()\n",
    "region = session.region_name\n",
    "\n",
    "# Runtime Endpoints\n",
    "bedrock_rt_client = boto3.client(\n",
    "    \"bedrock-agent-runtime\",\n",
    "    region_name=region\n",
    ")\n",
    "\n",
    "sts_client = boto3.client(\"sts\")\n",
    "account_id = sts_client.get_caller_identity()[\"Account\"]\n",
    "\n",
    "# To manage session id:\n",
    "random_int = random.randint(1,100000)"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Model Selection\n",
    "Select the Foundation model to use."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-27T01:05:14.530590Z",
     "start_time": "2025-02-27T01:05:14.524887Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Create a dropdown for model selection\n",
    "model_dropdown = widgets.Dropdown(\n",
    "    options=[\n",
    "        ('Claude 3.0 Sonnet', 'anthropic.claude-3-sonnet-20240229-v1:0'),\n",
    "        ('Claude 3.5 Sonnet', 'anthropic.claude-3-5-sonnet-20240620-v1:0'),\n",
    "        # ('Claude 3.7 Sonnet', 'anthropic.claude-3-7-sonnet-20250219-v1:0')\n",
    "    ],\n",
    "    description='Model:',\n",
    "    disabled=False,\n",
    ")\n",
    "\n",
    "display(model_dropdown)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dropdown(description='Model:', options=(('Claude 3.0 Sonnet', 'anthropic.claude-3-sonnet-20240229-v1:0'), ('Clâ€¦"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "afa0511bfe144f9698bf78f658cdcce5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": ""
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuring the Inline Agent\n",
    "\n",
    "Next, we'll set up the basic configuration for our Amazon Bedrock Inline Agent. This includes specifying the foundation model, session management, and basic instructions."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-02-27T00:55:51.533823Z",
     "start_time": "2025-02-27T00:55:51.530507Z"
    }
   },
   "source": [
    "# change model id as needed:\n",
    "model_id = model_dropdown.value\n",
    "\n",
    "sessionId = f'custom-session-id-{random_int}'\n",
    "endSession = False\n",
    "enableTrace = True\n",
    "\n",
    "# customize instructions of inline agent:\n",
    "agent_instruction = \"\"\"You are a helpful AI assistant helping Octank Inc employees with their questions and processes. \n",
    "You write short and direct responses while being cheerful. You have access to python coding environment that helps you extend your capabilities.\"\"\""
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Inline Agent Invocation\n",
    "\n",
    "Let's start by invoking a simple inline agent with just the foundation model and basic instructions."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-02-27T00:55:53.709293Z",
     "start_time": "2025-02-27T00:55:53.706476Z"
    }
   },
   "source": [
    "# prepare request parameters before invoking inline agent\n",
    "request_params = {\n",
    "    \"instruction\": agent_instruction,\n",
    "    \"foundationModel\": model_id,\n",
    "    \"sessionId\": sessionId,\n",
    "    \"endSession\": endSession,\n",
    "    \"enableTrace\": enableTrace,\n",
    "}\n",
    "\n",
    "# define code interpreter tool\n",
    "code_interpreter_tool = {\n",
    "    \"actionGroupName\": \"UserInputAction\",\n",
    "    \"parentActionGroupSignature\": \"AMAZON.CodeInterpreter\",\n",
    "    \"toolChoice\": \"auto\"\n",
    "}\n",
    "\n",
    "# add the tool to request parameter of inline agent\n",
    "request_params[\"actionGroups\"] = [code_interpreter_tool]\n",
    "\n",
    "# enable traces\n",
    "request_params[\"enableTrace\"] = True"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-02-27T00:55:54.757279Z",
     "start_time": "2025-02-27T00:55:54.755369Z"
    }
   },
   "source": [
    "# enter the question you want the inline agent to answer\n",
    "request_params['inputText'] = 'what is the time right now in pacific timezone?'"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Compatibility"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-27T00:55:57.755263Z",
     "start_time": "2025-02-27T00:55:57.750216Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def process_tool_response(response_event):\n",
    "    \"\"\"\n",
    "    Process tool response events to ensure tool_use_id is properly included\n",
    "    for Claude 3.5 Sonnet compatibility\n",
    "    \"\"\"\n",
    "    if \"trace\" in response_event and \"trace\" in response_event[\"trace\"]:\n",
    "        trace_data = response_event[\"trace\"][\"trace\"]\n",
    "\n",
    "        # Check for orchestration trace with tool interactions\n",
    "        if \"orchestrationTrace\" in trace_data:\n",
    "            orch_trace = trace_data[\"orchestrationTrace\"]\n",
    "\n",
    "            # If we have tool invocation and observation pairs, ensure IDs are linked\n",
    "            if \"invocationInput\" in orch_trace and \"observation\" in orch_trace:\n",
    "                tool_input = orch_trace.get(\"invocationInput\", {})\n",
    "                observation = orch_trace.get(\"observation\", {})\n",
    "\n",
    "                # Extract tool_use_id from input if present\n",
    "                tool_use_id = None\n",
    "                if \"actionGroupInvocationInput\" in tool_input:\n",
    "                    tool_use_id = tool_input[\"actionGroupInvocationInput\"].get(\"id\")\n",
    "                elif \"codeInterpreterInvocationInput\" in tool_input:\n",
    "                    tool_use_id = tool_input[\"codeInterpreterInvocationInput\"].get(\"id\")\n",
    "\n",
    "                # If we have a tool_use_id and an observation without one, add it\n",
    "                if tool_use_id:\n",
    "                    if \"actionGroupInvocationOutput\" in observation:\n",
    "                        if \"id\" not in observation[\"actionGroupInvocationOutput\"]:\n",
    "                            observation[\"actionGroupInvocationOutput\"][\"id\"] = tool_use_id\n",
    "                    elif \"codeInterpreterInvocationOutput\" in observation:\n",
    "                        if \"id\" not in observation[\"codeInterpreterInvocationOutput\"]:\n",
    "                            observation[\"codeInterpreterInvocationOutput\"][\"id\"] = tool_use_id\n",
    "\n",
    "    return response_event"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Invoking a simple Inline Agent\n",
    "\n",
    "We'll send a request to the agent asking it to perform a simple calculation or code execution task. This will showcase how the agent can interpret and run code on the fly.\n",
    "\n",
    "To do so, we will use the [InvokeInlineAgent](https://docs.aws.amazon.com/bedrock/latest/APIReference/API_agent-runtime_InvokeInlineAgent.html) API via boto3 `bedrock-agent-runtime` client.\n",
    "\n",
    "Our function `invoke_inline_agent_helper` also helps us processing the agent trace request and format it for easier readibility. You do not have to use this function in your system, but it will make it easier to observe the code used by code interpreter, the function invocations and the knowledge base content.\n",
    "\n",
    "We also provide the metrics for the agent invocation time and the input and output tokens"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-02-27T00:59:41.526807Z",
     "start_time": "2025-02-27T00:59:41.502049Z"
    }
   },
   "source": [
    "def invoke_inline_agent_helper(client, request_params, trace_level=\"core\"):\n",
    "    # Check if using Claude 3.5\n",
    "    is_claude_3 = \"claude-3-sonnet\" in model_id\n",
    "\n",
    "    if is_claude_3:\n",
    "        for i in request_params[\"actionGroups\"]:\n",
    "            i.pop('toolChoice',None)\n",
    "    else:\n",
    "        # Ensure we include sessionState to maintain context for tools\n",
    "        if \"sessionState\" not in request_params:\n",
    "            request_params[\"sessionState\"] = \"{}\"\n",
    "\n",
    "    _time_before_call = datetime.now()\n",
    "\n",
    "    _agent_resp = client.invoke_inline_agent(\n",
    "        **request_params\n",
    "    )\n",
    "\n",
    "    if request_params[\"enableTrace\"]:\n",
    "        if trace_level == \"all\":\n",
    "            print(f\"invokeAgent API response object: {_agent_resp}\")\n",
    "        else:\n",
    "            print(\n",
    "                f\"invokeAgent API request ID: {_agent_resp['ResponseMetadata']['RequestId']}\"\n",
    "            )\n",
    "            session_id = request_params[\"sessionId\"]\n",
    "            print(f\"invokeAgent API session ID: {session_id}\")\n",
    "\n",
    "    # Return error message if invoke was unsuccessful\n",
    "    if _agent_resp[\"ResponseMetadata\"][\"HTTPStatusCode\"] != 200:\n",
    "        _error_message = f\"API Response was not 200: {_agent_resp}\"\n",
    "        if request_params[\"enableTrace\"] and trace_level == \"all\":\n",
    "            print(_error_message)\n",
    "        return _error_message\n",
    "\n",
    "    _total_in_tokens = 0\n",
    "    _total_out_tokens = 0\n",
    "    _total_llm_calls = 0\n",
    "    _orch_step = 0\n",
    "    _sub_step = 0\n",
    "    _trace_truncation_lenght = 300\n",
    "    _time_before_orchestration = datetime.now()\n",
    "\n",
    "    _agent_answer = \"\"\n",
    "    _event_stream = _agent_resp[\"completion\"]\n",
    "\n",
    "    try:\n",
    "        for _event in _event_stream:\n",
    "            # Process the event to ensure tool_use_id compatibility\n",
    "            _event = process_tool_response(_event)\n",
    "            _sub_agent_alias_id = None\n",
    "\n",
    "            if \"chunk\" in _event:\n",
    "                _data = _event[\"chunk\"][\"bytes\"]\n",
    "                _agent_answer = _data.decode(\"utf8\")\n",
    "\n",
    "            if \"trace\" in _event and request_params[\"enableTrace\"]:\n",
    "                if \"failureTrace\" in _event[\"trace\"][\"trace\"]:\n",
    "                    print(\n",
    "                        colored(\n",
    "                            f\"Agent error: {_event['trace']['trace']['failureTrace']['failureReason']}\",\n",
    "                            \"red\",\n",
    "                        )\n",
    "                    )\n",
    "\n",
    "                if \"orchestrationTrace\" in _event[\"trace\"][\"trace\"]:\n",
    "                    _orch = _event[\"trace\"][\"trace\"][\"orchestrationTrace\"]\n",
    "\n",
    "                    if trace_level in [\"core\", \"outline\"]:\n",
    "                        if \"rationale\" in _orch:\n",
    "                            _rationale = _orch[\"rationale\"]\n",
    "                            print(colored(f\"{_rationale['text']}\", \"blue\"))\n",
    "\n",
    "                        if \"invocationInput\" in _orch:\n",
    "                            # NOTE: when agent determines invocations should happen in parallel\n",
    "                            # the trace objects for invocation input still come back one at a time.\n",
    "                            _input = _orch[\"invocationInput\"]\n",
    "                            print(_input)\n",
    "\n",
    "                            if \"actionGroupInvocationInput\" in _input:\n",
    "                                if 'function' in _input['actionGroupInvocationInput']:\n",
    "                                    tool = _input['actionGroupInvocationInput']['function']\n",
    "                                elif 'apiPath' in _input['actionGroupInvocationInput']:\n",
    "                                    tool = _input['actionGroupInvocationInput']['apiPath']\n",
    "                                else:\n",
    "                                    tool = 'undefined'\n",
    "                                if trace_level == \"outline\":\n",
    "                                    print(\n",
    "                                        colored(\n",
    "                                            f\"Using tool: {tool}\",\n",
    "                                            \"magenta\",\n",
    "                                        )\n",
    "                                    )\n",
    "                                else:\n",
    "                                    print(\n",
    "                                        colored(\n",
    "                                            f\"Using tool: {tool} with these inputs:\",\n",
    "                                            \"magenta\",\n",
    "                                        )\n",
    "                                    )\n",
    "                                    if (\n",
    "                                        len(\n",
    "                                            _input[\"actionGroupInvocationInput\"][\n",
    "                                                \"parameters\"\n",
    "                                            ]\n",
    "                                        )\n",
    "                                        == 1\n",
    "                                    ) and (\n",
    "                                        _input[\"actionGroupInvocationInput\"][\n",
    "                                            \"parameters\"\n",
    "                                        ][0][\"name\"]\n",
    "                                        == \"input_text\"\n",
    "                                    ):\n",
    "                                        print(\n",
    "                                            colored(\n",
    "                                                f\"{_input['actionGroupInvocationInput']['parameters'][0]['value']}\",\n",
    "                                                \"magenta\",\n",
    "                                            )\n",
    "                                        )\n",
    "                                    else:\n",
    "                                        print(\n",
    "                                            colored(\n",
    "                                                f\"{_input['actionGroupInvocationInput']['parameters']}\\n\",\n",
    "                                                \"magenta\",\n",
    "                                            )\n",
    "                                        )\n",
    "\n",
    "                            elif \"codeInterpreterInvocationInput\" in _input:\n",
    "                                if trace_level == \"outline\":\n",
    "                                    print(\n",
    "                                        colored(\n",
    "                                            f\"Using code interpreter\", \"magenta\"\n",
    "                                        )\n",
    "                                    )\n",
    "                                else:\n",
    "                                    console = Console()\n",
    "                                    _gen_code = _input[\n",
    "                                        \"codeInterpreterInvocationInput\"\n",
    "                                    ][\"code\"]\n",
    "                                    _code = f\"```python\\n{_gen_code}\\n```\"\n",
    "\n",
    "                                    console.print(\n",
    "                                        Markdown(f\"**Generated code**\\n{_code}\")\n",
    "                                    )\n",
    "\n",
    "                        if \"observation\" in _orch:\n",
    "                            if trace_level == \"core\":\n",
    "                                _output = _orch[\"observation\"]\n",
    "                                if \"actionGroupInvocationOutput\" in _output:\n",
    "                                    print(\n",
    "                                        colored(\n",
    "                                            f\"--tool outputs:\\n{_output['actionGroupInvocationOutput']['text'][0:_trace_truncation_lenght]}...\\n\",\n",
    "                                            \"magenta\",\n",
    "                                        )\n",
    "                                    )\n",
    "\n",
    "                                if \"agentCollaboratorInvocationOutput\" in _output:\n",
    "                                    _collab_name = _output[\n",
    "                                        \"agentCollaboratorInvocationOutput\"\n",
    "                                    ][\"agentCollaboratorName\"]\n",
    "                                    _collab_output_text = _output[\n",
    "                                        \"agentCollaboratorInvocationOutput\"\n",
    "                                    ][\"output\"][\"text\"][0:_trace_truncation_lenght]\n",
    "                                    print(\n",
    "                                        colored(\n",
    "                                            f\"\\n----sub-agent {_collab_name} output text:\\n{_collab_output_text}...\\n\",\n",
    "                                            \"magenta\",\n",
    "                                        )\n",
    "                                    )\n",
    "\n",
    "                                if \"finalResponse\" in _output:\n",
    "                                    print(\n",
    "                                        colored(\n",
    "                                            f\"Final response:\\n{_output['finalResponse']['text'][0:_trace_truncation_lenght]}...\",\n",
    "                                            \"cyan\",\n",
    "                                        )\n",
    "                                    )\n",
    "\n",
    "\n",
    "                    if \"modelInvocationOutput\" in _orch:\n",
    "                        _orch_step += 1\n",
    "                        _sub_step = 0\n",
    "                        print(colored(f\"---- Step {_orch_step} ----\", \"green\"))\n",
    "\n",
    "                        _llm_usage = _orch[\"modelInvocationOutput\"][\"metadata\"][\n",
    "                            \"usage\"\n",
    "                        ]\n",
    "                        _in_tokens = _llm_usage.get(\"inputTokens\",None)\n",
    "                        _total_in_tokens += _in_tokens\n",
    "\n",
    "                        _out_tokens = _llm_usage[\"outputTokens\"]\n",
    "                        _total_out_tokens += _out_tokens\n",
    "\n",
    "                        _total_llm_calls += 1\n",
    "                        _orch_duration = (\n",
    "                            datetime.now() - _time_before_orchestration\n",
    "                        )\n",
    "\n",
    "                        print(\n",
    "                            colored(\n",
    "                                f\"Took {_orch_duration.total_seconds():,.1f}s, using {_in_tokens+_out_tokens} tokens (in: {_in_tokens}, out: {_out_tokens}) to complete prior action, observe, orchestrate.\",\n",
    "                                \"yellow\",\n",
    "                            )\n",
    "                        )\n",
    "\n",
    "                        # restart the clock for next step/sub-step\n",
    "                        _time_before_orchestration = datetime.now()\n",
    "\n",
    "                elif \"preProcessingTrace\" in _event[\"trace\"][\"trace\"]:\n",
    "                    _pre = _event[\"trace\"][\"trace\"][\"preProcessingTrace\"]\n",
    "                    if \"modelInvocationOutput\" in _pre:\n",
    "                        _llm_usage = _pre[\"modelInvocationOutput\"][\"metadata\"][\n",
    "                            \"usage\"\n",
    "                        ]\n",
    "                        _in_tokens = _llm_usage[\"inputTokens\"]\n",
    "                        _total_in_tokens += _in_tokens\n",
    "\n",
    "                        _out_tokens = _llm_usage[\"outputTokens\"]\n",
    "                        _total_out_tokens += _out_tokens\n",
    "\n",
    "                        _total_llm_calls += 1\n",
    "\n",
    "                        print(\n",
    "                            colored(\n",
    "                                \"Pre-processing trace, agent came up with an initial plan.\",\n",
    "                                \"yellow\",\n",
    "                            )\n",
    "                        )\n",
    "                        print(\n",
    "                            colored(\n",
    "                                f\"Used LLM tokens, in: {_in_tokens}, out: {_out_tokens}\",\n",
    "                                \"yellow\",\n",
    "                            )\n",
    "                        )\n",
    "\n",
    "                elif \"postProcessingTrace\" in _event[\"trace\"][\"trace\"]:\n",
    "                    _post = _event[\"trace\"][\"trace\"][\"postProcessingTrace\"]\n",
    "                    if \"modelInvocationOutput\" in _post:\n",
    "                        _llm_usage = _post[\"modelInvocationOutput\"][\"metadata\"][\n",
    "                            \"usage\"\n",
    "                        ]\n",
    "                        _in_tokens = _llm_usage[\"inputTokens\"]\n",
    "                        _total_in_tokens += _in_tokens\n",
    "\n",
    "                        _out_tokens = _llm_usage[\"outputTokens\"]\n",
    "                        _total_out_tokens += _out_tokens\n",
    "\n",
    "                        _total_llm_calls += 1\n",
    "                        print(colored(\"Agent post-processing complete.\", \"yellow\"))\n",
    "                        print(\n",
    "                            colored(\n",
    "                                f\"Used LLM tokens, in: {_in_tokens}, out: {_out_tokens}\",\n",
    "                                \"yellow\",\n",
    "                            )\n",
    "                        )\n",
    "\n",
    "                if trace_level == \"all\":\n",
    "                    print(json.dumps(_event[\"trace\"], indent=2))\n",
    "\n",
    "            if \"files\" in _event.keys() and request_params[\"enableTrace\"]:\n",
    "                console = Console()\n",
    "                files_event = _event[\"files\"]\n",
    "                console.print(Markdown(\"**Files**\"))\n",
    "\n",
    "                files_list = files_event[\"files\"]\n",
    "                for this_file in files_list:\n",
    "                    print(f\"{this_file['name']} ({this_file['type']})\")\n",
    "                    file_bytes = this_file[\"bytes\"]\n",
    "\n",
    "                    # save bytes to file, given the name of file and the bytes\n",
    "                    file_name = os.path.join(\"output\", this_file[\"name\"])\n",
    "                    with open(file_name, \"wb\") as f:\n",
    "                        f.write(file_bytes)\n",
    "\n",
    "        if request_params[\"enableTrace\"]:\n",
    "            duration = datetime.now() - _time_before_call\n",
    "\n",
    "            if trace_level in [\"core\", \"outline\"]:\n",
    "                print(\n",
    "                    colored(\n",
    "                        f\"Agent made a total of {_total_llm_calls} LLM calls, \"\n",
    "                        + f\"using {_total_in_tokens+_total_out_tokens} tokens \"\n",
    "                        + f\"(in: {_total_in_tokens}, out: {_total_out_tokens})\"\n",
    "                        + f\", and took {duration.total_seconds():,.1f} total seconds\",\n",
    "                        \"yellow\",\n",
    "                    )\n",
    "                )\n",
    "\n",
    "            if trace_level == \"all\":\n",
    "                print(f\"Returning agent answer as: {_agent_answer}\")\n",
    "\n",
    "        return _agent_answer\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Caught exception while processing input to invokeAgent:\\n\")\n",
    "        input_text = request_params[\"inputText\"]\n",
    "        print(f\"  for input text:\\n{input_text}\\n\")\n",
    "        print(\n",
    "            f\"  request ID: {_agent_resp['ResponseMetadata']['RequestId']}, retries: {_agent_resp['ResponseMetadata']['RetryAttempts']}\\n\"\n",
    "        )\n",
    "        print(f\"Error: {e}\")\n",
    "        raise Exception(\"Unexpected exception: \", e)"
   ],
   "outputs": [],
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-02-27T00:59:45.809353Z",
     "start_time": "2025-02-27T00:59:42.450731Z"
    }
   },
   "source": "invoke_inline_agent_helper(bedrock_rt_client, request_params, trace_level=\"core\")",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "invokeAgent API request ID: c51ab19c-a590-424c-b937-d973045afdf8\n",
      "invokeAgent API session ID: custom-session-id-14904\n",
      "\u001B[32m---- Step 1 ----\u001B[0m\n",
      "\u001B[33mTook 3.1s, using 2337 tokens (in: 2231, out: 106) to complete prior action, observe, orchestrate.\u001B[0m\n",
      "\u001B[34mSince the knowledge base did not contain information about employee compensation bonuses, I will need to apologize that I could not find a specific answer to this question.\u001B[0m\n",
      "\u001B[36mFinal response:\n",
      "I'm sorry, I could not find any details about the employee compensation bonus amounts or policies in the company knowledge base that was provided to me. The knowledge base seems to be missing information specifically related to bonus compensation. I do not have enough information to accurately answe...\u001B[0m\n",
      "\u001B[33mAgent made a total of 1 LLM calls, using 2337 tokens (in: 2231, out: 106), and took 3.4 total seconds\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"I'm sorry, I could not find any details about the employee compensation bonus amounts or policies in the company knowledge base that was provided to me. The knowledge base seems to be missing information specifically related to bonus compensation. I do not have enough information to accurately answer how much the employee compensation bonus is.\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 18
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding a Knowledge Base\n",
    "\n",
    "Now, we'll demonstrate how to incorporate a knowledge base into our inline agent invocation. Let's first create a knowledge base using fictional HR policy documents that we will later use in with inline agent.\n",
    "\n",
    "We will use [Amazon Bedrock Knowledge Base](https://aws.amazon.com/bedrock/knowledge-bases/) to create our knowledge base. To do so, we use the support function `create_knowledge_base` available in the `create_knowledge_base.py` file. It will abstract away the work to create the underline vector database, the vector indexes with the appropriated chunking strategy as well as the indexation of the documents to the knowledge base. Take a look at the `create_knowledge_base.py` file for more details."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-02-27T01:00:09.287970Z",
     "start_time": "2025-02-27T01:00:09.285524Z"
    }
   },
   "source": [
    "import os\n",
    "from create_knowledge_base import create_knowledge_base\n",
    "\n",
    "# Configuration\n",
    "bucket_name = f\"inline-agent-bucket-{random_int}\"\n",
    "kb_name = f\"policy-kb-{random_int}\"\n",
    "data_path = \"policy_documents\"\n",
    "\n",
    "# Create knowledge base and upload documents\n",
    "kb_id, bucket_name, kb_metadata = create_knowledge_base(region, bucket_name, kb_name, data_path)"
   ],
   "outputs": [],
   "execution_count": 19
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up Knowledge Base configuration to invoke inline agent\n",
    "\n",
    "Let's now set up the knowledge base configuration to invoke our inline agent"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-02-27T01:00:12.809387Z",
     "start_time": "2025-02-27T01:00:12.804546Z"
    }
   },
   "source": [
    "# define number of chunks to retrieve\n",
    "num_results = 3\n",
    "search_strategy = \"HYBRID\"\n",
    "\n",
    "# provide instructions about knowledge base that inline agent can use\n",
    "kb_description = 'This knowledge base contains information about company HR policies, code or conduct, performance reviews and much more'\n",
    "\n",
    "# lets define access level for metadata filtering\n",
    "user_profile = 'basic'\n",
    "access_filter = {\n",
    "    \"equals\": {\n",
    "        \"key\": \"access_level\",\n",
    "        \"value\": user_profile\n",
    "    }\n",
    "}\n",
    "\n",
    "# lets revise our Knowledge bases configuration\n",
    "kb_config = {\n",
    "    \"knowledgeBaseId\": kb_id,\n",
    "    \"description\": kb_description,\n",
    "    \"retrievalConfiguration\": {\n",
    "        \"vectorSearchConfiguration\": {\n",
    "            \"filter\": access_filter,\n",
    "            \"numberOfResults\": num_results,\n",
    "            \"overrideSearchType\": \"HYBRID\"\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# lets add knowledge bases to our request parameters\n",
    "request_params[\"knowledgeBases\"] = [kb_config]\n",
    "    \n",
    "# update the agent instructions to inform inline agent that it has access to a knowlegde base\n",
    "new_capabilities = \"\"\"You have access to Octank Inc company policies knowledge base. \n",
    "Use this database to search for information about company policies, company HR policies, code or conduct, performance reviews and much more. And use them to briefly answer the use question.\"\"\"\n",
    "request_params[\"instruction\"] += f\"\\n\\n{new_capabilities}\"\n",
    "\n",
    "# check updated request parameters including instructions for the inline agent\n",
    "print(request_params)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'instruction': 'You are a helpful AI assistant helping Octank Inc employees with their questions and processes. \\nYou write short and direct responses while being cheerful. You have access to python coding environment that helps you extend your capabilities.\\n\\nYou have access to Octank Inc company policies knowledge base. \\nUse this database to search for information about company policies, company HR policies, code or conduct, performance reviews and much more. And use them to briefly answer the use question.\\n\\nYou have access to Octank Inc company policies knowledge base. \\nUse this database to search for information about company policies, company HR policies, code or conduct, performance reviews and much more. And use them to briefly answer the use question.', 'foundationModel': 'anthropic.claude-3-sonnet-20240229-v1:0', 'sessionId': 'custom-session-id-14904', 'endSession': False, 'enableTrace': True, 'actionGroups': [{'actionGroupName': 'UserInputAction', 'parentActionGroupSignature': 'AMAZON.CodeInterpreter'}], 'inputText': 'How much is the employee compensation bonus?', 'knowledgeBases': [{'knowledgeBaseId': 'QPTMUET0TV', 'description': 'This knowledge base contains information about company HR policies, code or conduct, performance reviews and much more', 'retrievalConfiguration': {'vectorSearchConfiguration': {'filter': {'equals': {'key': 'access_level', 'value': 'basic'}}, 'numberOfResults': 3, 'overrideSearchType': 'HYBRID'}}}]}\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Querying the Enhanced Agent\n",
    "\n",
    "We'll send a query that requires the agent to retrieve information from the knowledge base and provide an informed response."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-02-27T01:00:16.625773Z",
     "start_time": "2025-02-27T01:00:16.622245Z"
    }
   },
   "source": [
    "# enter the question that will use knowledge bases\n",
    "request_params['inputText'] = 'How much is the employee compensation bonus?'"
   ],
   "outputs": [],
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-02-27T01:01:33.743578Z",
     "start_time": "2025-02-27T01:01:29.478388Z"
    }
   },
   "source": [
    "# invoke the inline agent\n",
    "invoke_inline_agent_helper(bedrock_rt_client, request_params)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "invokeAgent API request ID: e9ad2098-c9e9-47ec-931f-c67fd01a558c\n",
      "invokeAgent API session ID: custom-session-id-14904\n",
      "\u001B[32m---- Step 1 ----\u001B[0m\n",
      "\u001B[33mTook 4.2s, using 2706 tokens (in: 2549, out: 157) to complete prior action, observe, orchestrate.\u001B[0m\n",
      "\u001B[34mI have already searched the provided knowledge base and stated multiple times that I could not find information to answer this specific question about employee compensation bonus amounts. Repeating the same response will not provide any new information, so I should acknowledge that I cannot provide a satisfactory answer.\u001B[0m\n",
      "\u001B[36mFinal response:\n",
      "I'm afraid I do not have enough information in the company knowledge base provided to me to specify the amount of employee compensation bonuses at Octank Inc. I have searched thoroughly but could not find any details related to bonus compensation policies or amounts. Without access to that data, I c...\u001B[0m\n",
      "\u001B[33mAgent made a total of 1 LLM calls, using 2706 tokens (in: 2549, out: 157), and took 4.3 total seconds\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"I'm afraid I do not have enough information in the company knowledge base provided to me to specify the amount of employee compensation bonuses at Octank Inc. I have searched thoroughly but could not find any details related to bonus compensation policies or amounts. Without access to that data, I cannot give you a definitive answer to your question about how much the employee compensation bonus is. I apologize that I do not have a more complete response to provide.\""
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 24
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyzing the Knowledge Base Integration\n",
    "\n",
    "We see that there are two types of access levels defined in the knowledge base, basic and manager. Compensation related access is `Manager` only. Let's try the same query with proper filter."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-02-27T01:01:53.077157Z",
     "start_time": "2025-02-27T01:01:43.342984Z"
    }
   },
   "source": [
    "# lets define access level for metadata filtering\n",
    "user_profile = 'Manager'\n",
    "# user_profile = 'basic'\n",
    "access_filter = {\n",
    "    \"equals\": {\n",
    "        \"key\": \"access_level\",\n",
    "        \"value\": user_profile\n",
    "    }\n",
    "}\n",
    "\n",
    "# lets revise our Knowledge bases configuration\n",
    "kb_config = {\n",
    "    \"knowledgeBaseId\": kb_id,\n",
    "    \"description\": kb_description,\n",
    "    \"retrievalConfiguration\": {\n",
    "        \"vectorSearchConfiguration\": {\n",
    "            \"filter\": access_filter,\n",
    "            \"numberOfResults\": num_results,\n",
    "            \"overrideSearchType\": \"HYBRID\"\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# lets add knowledge bases to our request parameters\n",
    "request_params[\"knowledgeBases\"] = [kb_config]\n",
    "\n",
    "# invoke the inline agent\n",
    "invoke_inline_agent_helper(bedrock_rt_client, request_params)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "invokeAgent API request ID: fd7f3a85-70cd-4380-a493-d63da5c7f615\n",
      "invokeAgent API session ID: custom-session-id-14904\n",
      "\u001B[32m---- Step 1 ----\u001B[0m\n",
      "\u001B[33mTook 9.6s, using 2929 tokens (in: 2722, out: 207) to complete prior action, observe, orchestrate.\u001B[0m\n",
      "\u001B[34mI have clearly stated multiple times now that I do not have access to information about employee compensation bonus amounts in the provided company knowledge base. Repeating myself further will not provide any new or useful information to the user. I should acknowledge the limitation of my knowledge and suggest the user consult official company policies or human resources if they need a definitive answer.\u001B[0m\n",
      "\u001B[36mFinal response:\n",
      "I'm sorry, but as I've mentioned, I do not have any information about the specific amounts for employee compensation bonuses at Octank Inc. in the knowledge base I can access. I've searched thoroughly but could not find details on bonus compensation policies or amounts. Without being able to referen...\u001B[0m\n",
      "\u001B[33mAgent made a total of 1 LLM calls, using 2929 tokens (in: 2722, out: 207), and took 9.7 total seconds\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"I'm sorry, but as I've mentioned, I do not have any information about the specific amounts for employee compensation bonuses at Octank Inc. in the knowledge base I can access. I've searched thoroughly but could not find details on bonus compensation policies or amounts. Without being able to reference an official company policy on this topic, I cannot provide a definitive answer to your question. If you need to know the exact bonus compensation details, I would suggest consulting Octank's official policies or human resources department directly. I apologize that I do not have more complete information to share regarding this particular query.\""
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 25
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integrating Action Groups\n",
    "\n",
    "In this section, we'll show how to add a custom tool (action group) to our agent invocation. This illustrates how to extend the agent's functionality with external services via the API.\n",
    "\n",
    "Let's first create a lambda function that we will later use in with inline agent."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-02-27T01:02:04.016169Z",
     "start_time": "2025-02-27T01:01:53.082848Z"
    }
   },
   "source": [
    "# run lambda function creation\n",
    "from lambda_creator import create_lambda_function_and_its_resources\n",
    "import os\n",
    "\n",
    "present_directory = os.getcwd()\n",
    "lambda_function_code_path = str(present_directory) + \"/pto_lambda/lambda_function.py\"\n",
    "\n",
    "# Create all resources\n",
    "resources = create_lambda_function_and_its_resources(\n",
    "    region=region,\n",
    "    account_id=account_id,\n",
    "    custom_name=f\"hr-inlineagent-lambda-{random_int}\",\n",
    "    lambda_code_path=lambda_function_code_path\n",
    ")\n",
    "\n",
    "# Access the created resources\n",
    "lambda_function = resources['lambda_function']\n",
    "lambda_function_arn = lambda_function['FunctionArn']\n",
    "print(lambda_function_arn)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arn:aws:lambda:us-east-1:537124940578:function:hr-inlineagent-lambda-14904-us-east-1-537124940578\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuring the Agent with the Action Group\n",
    "\n",
    "We'll update our agent configuration to include the new action group, allowing it to interact with the external service.\n",
    "For this example we are providing an OpenAPI Schema to define our action group tools. You can also use function definition to do the same, but your lambda function even will change a bit. For more information see the documentation [here](https://docs.aws.amazon.com/bedrock/latest/userguide/action-define.html)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-02-27T01:02:04.040157Z",
     "start_time": "2025-02-27T01:02:04.033908Z"
    }
   },
   "source": [
    "apply_vacation_tool = {\n",
    "            'actionGroupName': 'FetchDetails',\n",
    "            \"actionGroupExecutor\": {\n",
    "                \"lambda\": lambda_function_arn\n",
    "            }, \"apiSchema\": {\n",
    "                \"payload\": \"\"\"\n",
    "    {\n",
    "    \"openapi\": \"3.0.0\",\n",
    "    \"info\": {\n",
    "        \"title\": \"Vacation Management API\",\n",
    "        \"version\": \"1.0.0\",\n",
    "        \"description\": \"API for managing vacation requests\"\n",
    "    },\n",
    "    \"paths\": {\n",
    "        \"/vacation\": {\n",
    "            \"post\": {\n",
    "                \"summary\": \"Process vacation request\",\n",
    "                \"description\": \"Process a vacation request or check balance\",\n",
    "                \"operationId\": \"processVacation\",\n",
    "                \"parameters\": [\n",
    "                    {\n",
    "                        \"name\": \"action\",\n",
    "                        \"in\": \"query\",\n",
    "                        \"description\": \"The type of vacation action to perform\",\n",
    "                        \"required\": true,\n",
    "                        \"schema\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"enum\": [\"check_balance\", \"check balance\", \"apply\", \"request\"],\n",
    "                            \"description\": \"Action type for vacation management\"\n",
    "                        }\n",
    "                    },\n",
    "                    {\n",
    "                        \"name\": \"days\",\n",
    "                        \"in\": \"query\",\n",
    "                        \"description\": \"Number of vacation days requested\",\n",
    "                        \"required\": false,\n",
    "                        \"schema\": {\n",
    "                            \"type\": \"integer\",\n",
    "                            \"minimum\": 1\n",
    "                        }\n",
    "                    }\n",
    "                ],\n",
    "                \"responses\": {\n",
    "                    \"200\": {\n",
    "                        \"description\": \"Request processed successfully\",\n",
    "                        \"content\": {\n",
    "                            \"application/json\": {\n",
    "                                \"schema\": {\n",
    "                                    \"type\": \"object\",\n",
    "                                    \"properties\": {\n",
    "                                        \"status\": {\n",
    "                                            \"type\": \"string\",\n",
    "                                            \"enum\": [\"approved\", \"pending\", \"rejected\", \"info\"],\n",
    "                                            \"description\": \"Status of the vacation request\"\n",
    "                                        },\n",
    "                                        \"message\": {\n",
    "                                            \"type\": \"string\",\n",
    "                                            \"description\": \"Detailed response message\"\n",
    "                                        },\n",
    "                                        \"ticket_url\": {\n",
    "                                            \"type\": \"string\",\n",
    "                                            \"description\": \"Ticket URL for long vacation requests\"\n",
    "                                        }\n",
    "                                    },\n",
    "                                    \"required\": [\"status\", \"message\"]\n",
    "                                }\n",
    "                            }\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "    \"\"\"\n",
    "            },\n",
    "            \"description\": \"Process vacation and check leave balance\",\n",
    "            \"toolChoice\": \"auto\"\n",
    "}\n",
    "            \n",
    "# update the tools that inline agent has access to\n",
    "request_params[\"actionGroups\"] = [code_interpreter_tool, apply_vacation_tool]"
   ],
   "outputs": [],
   "execution_count": 27
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the Full Featured Agent\n",
    "\n",
    "We'll send a complex query that requires the agent to use its language understanding, access the knowledge base, and interact with the external service via the action group.\n",
    "\n",
    "### Analyzing the Complete Agent Behavior\n",
    "\n",
    "We'll examine the agent's response, focusing on how it orchestrates different capabilities (language model, knowledge base, and external actions) to handle complex queries."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-02-27T01:02:21.589889Z",
     "start_time": "2025-02-27T01:02:10.672664Z"
    }
   },
   "source": [
    "# ask question:\n",
    "request_params['inputText'] = 'I will be out of office from 2024/11/28 for the next 3 days'\n",
    "\n",
    "# invoke the inline agent\n",
    "invoke_inline_agent_helper(bedrock_rt_client, request_params)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "invokeAgent API request ID: ef41b71f-6801-4b10-bda8-293ecc119ede\n",
      "invokeAgent API session ID: custom-session-id-14904\n",
      "\u001B[32m---- Step 1 ----\u001B[0m\n",
      "\u001B[33mTook 8.8s, using 3238 tokens (in: 3146, out: 92) to complete prior action, observe, orchestrate.\u001B[0m\n",
      "\u001B[34mTo process this vacation request, I will need to invoke the processVacation tool with the appropriate parameters.\u001B[0m\n",
      "{'actionGroupInvocationInput': {'actionGroupName': 'FetchDetails', 'apiPath': '/vacation', 'executionType': 'LAMBDA', 'parameters': [{'name': 'action', 'type': 'string', 'value': 'request'}, {'name': 'days', 'type': 'integer', 'value': '3'}], 'verb': 'post'}, 'invocationType': 'ACTION_GROUP', 'traceId': 'ef41b71f-6801-4b10-bda8-293ecc119ede-0'}\n",
      "\u001B[35mUsing tool: /vacation with these inputs:\u001B[0m\n",
      "\u001B[35m[{'name': 'action', 'type': 'string', 'value': 'request'}, {'name': 'days', 'type': 'integer', 'value': '3'}]\n",
      "\u001B[0m\n",
      "\u001B[35m--tool outputs:\n",
      "{\"status\": \"approved\", \"message\": \"Your 3-day leave request is approved. New balance: 22 days.\"}...\n",
      "\u001B[0m\n",
      "\u001B[32m---- Step 2 ----\u001B[0m\n",
      "\u001B[33mTook 2.1s, using 3367 tokens (in: 3327, out: 40) to complete prior action, observe, orchestrate.\u001B[0m\n",
      "\u001B[36mFinal response:\n",
      "Your 3-day vacation request from 2024/11/28 has been approved. You now have 22 days remaining in your vacation balance....\u001B[0m\n",
      "\u001B[33mAgent made a total of 2 LLM calls, using 6605 tokens (in: 6473, out: 132), and took 10.9 total seconds\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Your 3-day vacation request from 2024/11/28 has been approved. You now have 22 days remaining in your vacation balance.'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 28
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean up\n",
    "\n",
    "Let's delete the resources that were created in this notebook"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "lambda_client = boto3.client('lambda')\n",
    "iam_client = boto3.client('iam')\n",
    "\n",
    "def delete_iam_roles_and_policies(role_name, iam_client):\n",
    "    try:\n",
    "        iam_client.get_role(RoleName=role_name)\n",
    "    except iam_client.exceptions.NoSuchEntityException:\n",
    "        print(f\"Role {role_name} does not exist\") \n",
    "    attached_policies = iam_client.list_attached_role_policies(RoleName=role_name)[\"AttachedPolicies\"]\n",
    "    print(f\"======Attached policies with role {role_name}========\\n\", attached_policies)\n",
    "    for attached_policy in attached_policies:\n",
    "        policy_arn = attached_policy[\"PolicyArn\"]\n",
    "        policy_name = attached_policy[\"PolicyName\"]\n",
    "        iam_client.detach_role_policy(RoleName=role_name, PolicyArn=policy_arn)\n",
    "        print(f\"Detached policy {policy_name} from role {role_name}\")\n",
    "        if str(policy_arn.split(\"/\")[1]) == \"service-role\":\n",
    "            print(f\"Skipping deletion of service-linked role policy {policy_name}\")\n",
    "        else: \n",
    "            iam_client.delete_policy(PolicyArn=policy_arn)\n",
    "            print(f\"Deleted policy {policy_name} from role {role_name}\")\n",
    "\n",
    "    iam_client.delete_role(RoleName=role_name)\n",
    "    print(f\"Deleted role {role_name}\")\n",
    "    print(\"======== All IAM roles and policies deleted =========\")\n",
    "    \n",
    "# delete lambda function\n",
    "response = lambda_client.delete_function(\n",
    "    FunctionName=resources['lambda_function']['FunctionName']\n",
    ")\n",
    "# delete lamnda role and policy\n",
    "delete_iam_roles_and_policies(resources['lambda_role']['Role']['RoleName'], iam_client)\n",
    "# delete knowledge base\n",
    "kb_metadata.delete_kb(delete_s3_bucket=True, delete_iam_roles_and_policies=True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook has demonstrated the key aspects of using the Amazon Bedrock Inline Agents API:\n",
    "\n",
    "1. Basic agent invocation\n",
    "2. Incorporating knowledge bases\n",
    "3. Adding custom action groups\n",
    "4. Implementing guardrails\n",
    "\n",
    "By leveraging these API capabilities, developers can create dynamic, adaptable AI assistants that can be easily customized for various use cases without redeploying applications.\n",
    "\n",
    "Key takeaways:\n",
    "1. Inline agents offer great flexibility through their API\n",
    "2. Knowledge bases and action groups can be easily integrated\n",
    "3. Guardrails help maintain responsible AI practices"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
