{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f3de924-5afd-4df3-b81b-1d2950390a29",
   "metadata": {},
   "source": [
    "# Multi-Agents Real-Time Weather Example by Using SuperAgentX with AWS Bedrock LLM function Calling Feature.\n",
    "\n",
    "### Open Source Github Repository URL: https://github.com/superagentxai/superagentx\n",
    "\n",
    "## What is SuperAgentX?\n",
    "\n",
    "SuperAgentX is an advanced agentic AI framework designed to accelerate the development of Artificial General Intelligence (AGI). It provides a powerful, modular, and flexible platform for building autonomous AI agents capable of executing complex tasks with minimal human intervention.\n",
    "\n",
    "Using the SuperAgentX agentic AI framework, function calling with AWS Bedrock LLMs is simplified.\n",
    "\n",
    "The below example creates weather as a handler (Tool) and invokes using SuperAgentX's agent.\n",
    "\n",
    "#### The Below example explains how to invoke Bedrock Converse API using the SuperAgentX framework.\n",
    "\n",
    "In this example, the SuperAgentX Agent module can automatically invoke a mock weather handler (Tool). This function can be fully operational by integrating any weather service API. Later in the example, we connect to the Open-Meteo API.\n",
    "\n",
    "![SuperAgentX Multi Agent](assets/superagentX-Example-Weather.svg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e84a3e-07c5-4bfe-a00c-1e95ac06be23",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install superagentx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "49046b9a-5b97-4820-854c-2fd47da4c5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from superagentx.agent import Agent\n",
    "from superagentx.agent import Engine\n",
    "from superagentx.agentxpipe import AgentXPipe\n",
    "from superagentx.llm import LLMClient\n",
    "from superagentx.prompt import PromptTemplate\n",
    "from superagentx.memory import Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "5a01aec8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "table {float:left}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<style>\n",
    "table {float:left}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3973645-f92f-44b6-82be-e76e994a5386",
   "metadata": {},
   "source": [
    "<style>\n",
    "  table {margin-left: 0 !important;}\n",
    "</style>\n",
    "\n",
    "Although this example leverages Claude 3 Sonnet, Bedrock supports many other models. The full list of models and supported features can be found [here](https://docs.aws.amazon.com/bedrock/latest/userguide/conversation-inference.html). The models are invoked via `bedrock-runtime`.\n",
    "\n",
    "\n",
    "**Best Practice**: Always set your AWS credentials as environment variables.\n",
    "\n",
    "```\n",
    "export AWS_ACCESS_KEY=<<`YOUR_ACCESS_KEY`>>\n",
    "export AWS_SECRET_KEY=<<`YOUR_ACCESS_SECRET_KEY`>>\n",
    "export AWS_REGION=<<`AWS_REGION`>>\n",
    "```\n",
    "\n",
    "#### LLM Config in SuperAgentX\n",
    "\n",
    "LLM Configuration Specify ==> llm_config\n",
    "\n",
    "| Name | Description | Data Type | Required | Example |\n",
    "|:-----|:------------|:----------|:---------|:--------|\n",
    "|`model`| AWS Bedrock supported [models](https://docs.aws.amazon.com/bedrock/latest/userguide/conversation-inference.html)|str| Yes| 'model': 'anthropic.claude-3-5-sonnet-20240620-v1:0' |\n",
    "|`llm_type`| LLM type - `bedrock`|str| Yes| 'llm_type':'bedrock'\n",
    "\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "64768dc6-5f0f-4d26-b0ca-f40f63834fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_config = {'model': 'anthropic.claude-3-5-sonnet-20241022-v2:0', 'llm_type':'bedrock'}\n",
    "\n",
    "llm_client: LLMClient = LLMClient(llm_config=llm_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d3ed52-5ff9-4c2c-ad7a-42fd8f453fa3",
   "metadata": {},
   "source": [
    "### Handler (Tool) definition \n",
    "\n",
    "We define `WeatherHandler` as a class where individual handlers (tools) are defined as functions. Note that there is nothing specific to the model used or Bedrock in this definition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "26ebfd29-1069-48a5-854a-9f6af856f9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "from superagentx.handler.base import BaseHandler\n",
    "from superagentx.handler.decorators import tool\n",
    "\n",
    "class WeatherHandler(BaseHandler):\n",
    "\n",
    "    @tool\n",
    "    async def get_weather(self, latitude: str, longitude: str) -> dict:\n",
    "        \"\"\"\n",
    "        Get the weather data based on given latitude & longitude.\n",
    "\n",
    "        Args:\n",
    "            @param latitude: latitude of the location\n",
    "            @param longitude: longitude of the location\n",
    "\n",
    "            @return result (Str): Return Fake Weather for the given city & name in Fahrenheit\n",
    "        \"\"\"\n",
    "\n",
    "        url = f\"https://api.open-meteo.com/v1/forecast?latitude={latitude}&longitude={longitude}&current_weather=true\"\n",
    "        response = requests.get(url)\n",
    "        return response.json()\n",
    "\n",
    "    @tool\n",
    "    async def get_lat_long(self, place: str) -> dict:\n",
    "\n",
    "        \"\"\"\n",
    "        Get the coordinates of a city based on a location.\n",
    "\n",
    "        Args:\n",
    "            @param city (str): The place name\n",
    "\n",
    "            @return result (Str): Return the real latitude & longitude for the given place.\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        header_dict = {\n",
    "            \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/90.0.4430.212 Safari/537.36\",\n",
    "            \"referer\": 'https://www.guichevirtual.com.br'\n",
    "        }\n",
    "        url = \"http://nominatim.openstreetmap.org/search\"\n",
    "\n",
    "        params = {'q': place, 'format': 'json', 'limit': 1}\n",
    "        response = requests.get(url, params=params, headers=header_dict).json()\n",
    "        if response:\n",
    "            lat = response[0][\"lat\"]\n",
    "            lon = response[0][\"lon\"]\n",
    "            return {\"latitude\": lat, \"longitude\": lon}\n",
    "        else:\n",
    "            return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a5dd9f-d43e-4f8d-a144-a186f1af30d3",
   "metadata": {},
   "source": [
    "### Create Prompt Template Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "3a732b3a-e562-4703-854e-f1ab3a0595a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"You're provided with a tool that can get the coordinates for a specific city \n",
    "        'get_lat_long' and a tool that can get the weather for that city, but requires the coordinates 'get_weather'; \n",
    "        only use the tool if required. You can call the tool multiple times in the same response if required. Don't \n",
    "        make reference to the tools in your final answer.\"\"\"\n",
    "\n",
    "weather_prompt = PromptTemplate(system_message=system_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0833bcb1",
   "metadata": {},
   "source": [
    "### Handler Engine\n",
    "\n",
    "Create `Engine` object to invoke `WeatherHandler` along with prompt template and LLM client of `Bedrock` converse API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "adf0cc3f-50c2-4ddf-b97d-967ba5222731",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_forecast_engine = Engine(\n",
    "            handler=WeatherHandler(),\n",
    "            llm=llm_client,\n",
    "            prompt_template=weather_prompt\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1be4eb0f",
   "metadata": {},
   "source": [
    "\n",
    "## Agent attributes\n",
    "\n",
    "| Attribute                  | Parameter  | Description                                                                                                                                                                                                                                    |\n",
    "| :------------------------- | :--------- | :--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n",
    "| **Role**                   | `role`     | Defines the agent's function within the SuperAgentX. It determines the kind of activcity the agent is best suited for.                                                                                                                                    |\n",
    "| **Goal**                   | `goal`     | The individual objective that the agent aims to achieve. It guides the agent's decision-making process.                                                                                                                                        |\n",
    "| **LLM**              | `llm`| Represents the language model that will run the agent.|\n",
    "| **Retry Max** *(optional)*       | `max_retry`      | sets the maximum number of iterations an agent can complete before it must provide its best possible answer. Default `5`                                                       |\n",
    "| **Prompt Template**       | `prompt_template`      | Specifies the prompt format for the agent. |                                                       |\n",
    "| **Engine**    | `engines`      | A list of engines (or lists of engines) that the engine can utilize in `parallel` or `sequnetial`. This allows for flexibility in processing and task execution based on different capabilities or configurations or or configurations.|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b0b70d3",
   "metadata": {},
   "source": [
    "#### Agent - Get latitude & longitude from Weather Handler using `engine`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "31b003a7-b8de-44c7-bd73-5900a4f84a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "lat_and_long_agent = Agent(\n",
    "            role=\"Weather Man\",\n",
    "            goal=\"Get the latitude and longitude for the given place\",\n",
    "            llm=llm_client,\n",
    "            max_retry=2,  # Default Max Retry is 5\n",
    "            prompt_template=weather_prompt,\n",
    "            engines=[weather_forecast_engine],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe1de7a1",
   "metadata": {},
   "source": [
    "#### Agent - Get real-time weather for the given latitude & longitude from Weather Handler using `engine`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "961a636e-c8ef-4142-bc83-5a8ea086374e",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_agent_agent = Agent(\n",
    "            role=\"Weather Man\",\n",
    "            goal=\"Get the real-time weather based on the given latitude and longitude.\",\n",
    "            llm=llm_client,\n",
    "            max_retry=2,  # Default Max Retry is 5\n",
    "            prompt_template=weather_prompt,\n",
    "            engines=[weather_forecast_engine],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79371999",
   "metadata": {},
   "source": [
    "### Pipe Attributes\n",
    "\n",
    "| Attribute                  | Parameter  | Description                                                                                                                                                                                                                                    |\n",
    "| :------------------------- | :--------- | :--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n",
    "| **Name**                   | `name`     | An optional name for the agentxpipe, providing a more friendly reference for display or logging purposes.                                                                                                                                    |\n",
    "| **Agents**                   | `agents`     | A list of Agent instances (or lists of Agent instances) that are part of this structure. These agents can perform tasks and contribute to achieving the defined goal.         |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53bc96dc",
   "metadata": {},
   "source": [
    "#### Pipe - Executes agents `sequential` and provide results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "82b00c28-ea7c-4817-a1b9-0babf15c2fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = AgentXPipe(\n",
    "            name='Weather Man',\n",
    "            agents=[lat_and_long_agent, weather_agent_agent]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc69127",
   "metadata": {},
   "source": [
    "#### Pipe Flow - Triggers the pipe flow based on the user input `query_instruction`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "fd2dec9d-0037-4298-abcb-58b5a309eade",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = await pipe.flow(query_instruction=\"What is the weather in Las Vegas?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6de7b05",
   "metadata": {},
   "source": [
    "#### Print Results. The result object contains array of `GoalResult`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "801753ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weather result => \n",
      "[GoalResult(name='Agent-4996bc6bbb6749e1a70b165e32e017f9', agent_id='4996bc6bbb6749e1a70b165e32e017f9', reason='The output context contains the correct latitude and longitude coordinates for Las Vegas: latitude of 36.1672559 and longitude of -115.148516. This directly fulfills the goal of getting coordinates for the given place.', result={'latitude': '36.1672559', 'longitude': '-115.148516'}, content=None, error=None, is_goal_satisfied=True), GoalResult(name='Agent-4996bc6bbb6749e1a70b165e32e017f9', agent_id='4996bc6bbb6749e1a70b165e32e017f9', reason='The output context contains the required weather information for Las Vegas with specific coordinates (36.1672559, -115.148516). The data shows current temperature, wind speed, wind direction, and weather conditions.', result='Currently in Las Vegas, the temperature is 13.9°C with a wind speed of 10.7 km/h from the northwest (310°). The sky is clear (weathercode: 0).', content=None, error=None, is_goal_satisfied=True)]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Weather result => \\n{result}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
